{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "# import ipdb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('residual_net_n', 7, '')\n",
    "tf.app.flags.DEFINE_string('train_tf_path', './data/train.tf', '')\n",
    "tf.app.flags.DEFINE_string('val_tf_path', './data/test.tf', '')\n",
    "tf.app.flags.DEFINE_integer('train_batch_size', 128, '')\n",
    "tf.app.flags.DEFINE_integer('val_batch_size', 100, '')\n",
    "tf.app.flags.DEFINE_float('weight_decay', 0.0005, 'Weight decay')\n",
    "tf.app.flags.DEFINE_integer('summary_interval', 100, 'Interval for summary.')\n",
    "tf.app.flags.DEFINE_integer('val_interval', 1000, 'Interval for evaluation.')\n",
    "tf.app.flags.DEFINE_integer('max_steps', 80000, 'Maximum number of iterations.')\n",
    "tf.app.flags.DEFINE_integer('save_interval', 5000, '')\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_embedding(label, n_classes):\n",
    "  \"\"\"\n",
    "  One-hot embedding\n",
    "  Args:\n",
    "    label: int32 tensor [B]\n",
    "    n_classes: int32, number of classes\n",
    "  Return:\n",
    "    embedding: tensor [B x n_classes]\n",
    "  \"\"\"\n",
    "  embedding_params = np.eye(n_classes, dtype=np.float32)\n",
    "  with tf.device('/cpu:0'):\n",
    "    params = tf.constant(embedding_params)\n",
    "    embedding = tf.gather(params, label)\n",
    "  return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, n_in, n_out, k, s, p='SAME', bias=False, scope='conv'):\n",
    "  with tf.variable_scope(scope):\n",
    "    kernel = tf.Variable(\n",
    "      tf.truncated_normal([k, k, n_in, n_out],\n",
    "        stddev=math.sqrt(2/(k*k*n_in))),\n",
    "      name='weight')\n",
    "    tf.add_to_collection('weights', kernel)\n",
    "    conv = tf.nn.conv2d(x, kernel, [1,s,s,1], padding=p)\n",
    "    if bias:\n",
    "      bias = tf.get_variable('bias', [n_out], initializer=tf.constant_initializer(0.0))\n",
    "      tf.add_to_collection('biases', bias)\n",
    "      conv = tf.nn.bias_add(conv, bias)\n",
    "  return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, scope='bn', affine=True):\n",
    "  \"\"\"\n",
    "  Batch normalization on convolutional maps.\n",
    "  Args:\n",
    "    x: Tensor, 4D BHWD input maps\n",
    "    n_out: integer, depth of input maps\n",
    "    phase_train: boolean tf.Variable, true indicates training phase\n",
    "    scope: string, variable scope\n",
    "    affine: whether to affine-transform outputs\n",
    "  Return:\n",
    "    normed: batch-normalized maps\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope):\n",
    "    beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "      name='beta', trainable=True)\n",
    "    gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "      name='gamma', trainable=affine)\n",
    "    tf.add_to_collection('biases', beta)\n",
    "    tf.add_to_collection('weights', gamma)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "\n",
    "    def mean_var_with_update():\n",
    "      ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "      with tf.control_dependencies([ema_apply_op]):\n",
    "        return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "      mean_var_with_update,\n",
    "      lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var, \n",
    "      beta, gamma, 1e-3, affine)\n",
    "  return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, n_in, n_out, subsample, phase_train, scope='res_block'):\n",
    "  with tf.variable_scope(scope):\n",
    "    if subsample:\n",
    "      y = conv2d(x, n_in, n_out, 3, 2, 'SAME', False, scope='conv_1')\n",
    "      shortcut = conv2d(x, n_in, n_out, 3, 2, 'SAME',\n",
    "                False, scope='shortcut')\n",
    "    else:\n",
    "      y = conv2d(x, n_in, n_out, 3, 1, 'SAME', False, scope='conv_1')\n",
    "      shortcut = tf.identity(x, name='shortcut')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_1')\n",
    "    y = tf.nn.relu(y, name='relu_1')\n",
    "    y = conv2d(y, n_out, n_out, 3, 1, 'SAME', True, scope='conv_2')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_2')\n",
    "    y = y + shortcut\n",
    "    y = tf.nn.relu(y, name='relu_2')\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_group(x, n_in, n_out, n, first_subsample, phase_train, scope='res_group'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = residual_block(x, n_in, n_out, first_subsample, phase_train, scope='block_1')\n",
    "    for i in range(n - 1):\n",
    "      y = residual_block(y, n_out, n_out, False, phase_train, scope='block_%d' % (i + 2))\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_net(x, n, n_classes, phase_train, scope='res_net'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = conv2d(x, 3, 16, 3, 1, 'SAME', False, scope='conv_init')\n",
    "    y = batch_norm(y, 16, phase_train, scope='bn_init')\n",
    "    y = tf.nn.relu(y, name='relu_init')\n",
    "    y = residual_group(y, 16, 16, n, False, phase_train, scope='group_1')\n",
    "    y = residual_group(y, 16, 32, n, True, phase_train, scope='group_2')\n",
    "    y = residual_group(y, 32, 64, n, True, phase_train, scope='group_3')\n",
    "#     y = conv2d(y, 64, n_classes, 1, 1, 'SAME', True, scope='conv_last')\n",
    "    y = tf.nn.avg_pool(y, [1, 8, 8, 1], [1, 1, 1, 1], 'VALID', name='avg_pool')\n",
    "    y = tf.reshape(y, [-1, 64])\n",
    "    w = tf.get_variable(name='weight_fc', shape=[64, n_classes], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    tf.add_to_collection('weights', w)\n",
    "    b = tf.get_variable(name='weight_biase', shape=[n_classes], initializer=tf.constant_initializer(0))\n",
    "    tf.add_to_collection('last_biases', b)\n",
    "    y = tf.matmul(y, w) + b\n",
    "#     y = tf.squeeze(y, squeeze_dims=[1, 2])\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _loss(logits, labels, scope='loss'):\n",
    "  with tf.variable_scope(scope):\n",
    "    # entropy loss\n",
    "    targets = one_hot_embedding(labels, 10)\n",
    "    entropy_loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),\n",
    "      name='entropy_loss')\n",
    "    tf.add_to_collection('losses', entropy_loss)\n",
    "    # weight l2 decay loss\n",
    "    weight_l2_losses = [tf.nn.l2_loss(o) for o in tf.get_collection('weights')]\n",
    "    weight_decay_loss = FLAGS.weight_decay*tf.add_n(weight_l2_losses)\n",
    "    tf.add_to_collection('losses', weight_decay_loss)\n",
    "  # for var in tf.get_collection('losses'):\n",
    "    # tf.scalar_summary('losses/' + var.op.name, var)\n",
    "  # total loss\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _accuracy(logits, gt_label, scope='accuracy'):\n",
    "  with tf.variable_scope(scope):\n",
    "    pred_label = tf.argmax(logits, 1)\n",
    "    acc = 1.0 - tf.nn.zero_fraction(\n",
    "      tf.cast(tf.equal(pred_label, gt_label), tf.int32))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_op(loss, global_step, learning_rate):\n",
    "  params = tf.trainable_variables()\n",
    "  gradients = tf.gradients(loss, params, name='gradients')\n",
    "  optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "  update = optim.apply_gradients(zip(gradients, params))\n",
    "  with tf.control_dependencies([update]):\n",
    "    train_op = tf.no_op(name='train_op')\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar10_input_stream(records_path):\n",
    "  reader = tf.TFRecordReader()\n",
    "  filename_queue = tf.train.string_input_producer([records_path], None)\n",
    "  _, record_value = reader.read(filename_queue)\n",
    "  features = tf.parse_single_example(record_value,\n",
    "    {\n",
    "      'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "  image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "  image = tf.reshape(image, [32,32,3])\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  label = tf.cast(features['label'], tf.int64)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "  # meanstd = joblib.load(FLAGS.mean_std_path)\n",
    "  # mean, std = meanstd['mean'], meanstd['std']\n",
    "  mean = [ 125.30690002,122.95014954,113.86599731]\n",
    "  std = [ 62.9932518,62.08860397,66.70500946]\n",
    "  normed_image = (image - mean) / std\n",
    "  return normed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_distort_image(image):\n",
    "  distorted_image = image\n",
    "  distorted_image = tf.image.pad_to_bounding_box(\n",
    "    image, 4, 4, 40, 40)  # pad 4 pixels to each side\n",
    "  distorted_image = tf.random_crop(distorted_image, [32, 32, 3])\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "  return distorted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_batch(train_records_path, batch_size):\n",
    "  with tf.variable_scope('train_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      train_image, train_label = cifar10_input_stream(train_records_path)\n",
    "      train_image = normalize_image(train_image)\n",
    "      train_image = random_distort_image(train_image)\n",
    "      train_image_batch, train_label_batch = tf.train.shuffle_batch(\n",
    "        [train_image, train_label], batch_size=batch_size, num_threads=4,\n",
    "        capacity=50000,\n",
    "        min_after_dequeue=1000)\n",
    "  return train_image_batch, train_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_validation_batch(test_records_path, batch_size):\n",
    "  with tf.variable_scope('evaluate_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      test_image, test_label = cifar10_input_stream(test_records_path)\n",
    "      test_image = normalize_image(test_image)\n",
    "      test_image_batch, test_label_batch = tf.train.batch(\n",
    "        [test_image, test_label], batch_size=batch_size, num_threads=1,\n",
    "        capacity=10000)\n",
    "  return test_image_batch, test_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5533cdbb8cb6>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "train_image_batch, train_label_batch = make_train_batch(FLAGS.train_tf_path, FLAGS.train_batch_size)\n",
    "val_image_batch, val_label_batch = make_validation_batch(FLAGS.val_tf_path, FLAGS.val_batch_size)\n",
    "\n",
    "image_batch, label_batch = control_flow_ops.cond(phase_train,lambda: (train_image_batch, train_label_batch),lambda: (val_image_batch, val_label_batch))\n",
    "\n",
    "\n",
    "logits = residual_net(image_batch, FLAGS.residual_net_n, 10, phase_train)\n",
    "\n",
    "\n",
    "loss = _loss(logits, label_batch)\n",
    "accuracy = _accuracy(logits, label_batch)\n",
    "\n",
    "# train one step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "INFO:tensorflow:Restoring parameters from ./full_precision/res44/model/res.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-train_batch/input_producer-train_batch/input_producer/input_producer_EnqueueMany, started daemon 140086708520704)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140086716913408)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140086725306112)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140086733698816)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140086700128000)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/input_producer-evaluate_batch/input_producer/input_producer_EnqueueMany, started daemon 140086691735296)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/batch/fifo_queue-evaluate_batch/batch/fifo_queue_enqueue, started daemon 140086683342592)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "print('Initializing...')\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'./full_precision/res44/model/res.ckpt')\n",
    "\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Test accuracy = 0.933200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# validation\n",
    "\n",
    "print('Evaluating...')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "  fetches = [logits, label_batch, loss]\n",
    "  session_outputs = sess.run(\n",
    "    fetches, {phase_train.name: False})\n",
    "  val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "  val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "  val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(\n",
    "  pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_prune_on_grads(grads_and_vars, dict_nzidx):\n",
    "    for key, nzidx in dict_nzidx.items():\n",
    "        count = 0\n",
    "        for grad, var in grads_and_vars:\n",
    "            if var.name == key:\n",
    "                nzidx_obj = tf.cast(tf.constant(sess.run(dict_nzidx[key])), tf.float32)\n",
    "                grads_and_vars[count] = (tf.multiply(nzidx_obj, grad), var)\n",
    "            count += 1\n",
    "    return grads_and_vars\n",
    "\n",
    "def apply_inq(weights, inq_dict, var_name, prune_rate):  \n",
    "    for target in var_name:\n",
    "        wl = target\n",
    "        bit = 8\n",
    "\n",
    "        weight_obj = weights[wl]\n",
    "        weight_arr = sess.run(weight_obj)\n",
    "\n",
    "        weight_rest = np.reshape(weight_arr, [-1])\n",
    "        dic_tem = np.reshape(sess.run(inq_dict[wl]), [-1])\n",
    "        idx_rest = np.flip(np.argsort(abs(np.reshape(weight_rest, [-1]))), 0)\n",
    "        num_prune = int(len(weight_rest) * prune_rate)\n",
    "        weight_toINQ = weight_rest[idx_rest[:num_prune]]\n",
    "\n",
    "        n1 = (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        n2 = n1 + 1 - bit / 4\n",
    "        upper_bound = 2 ** (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        lower_bound = 2 ** (n1 + 1 - bit / 4)\n",
    "\n",
    "        weight_toINQ[abs(weight_toINQ) < lower_bound] = 0\n",
    "        weight_toINQ[weight_toINQ != 0] = 2 ** (np.floor(np.log2(abs(weight_toINQ[weight_toINQ != 0] * 4 / 3)))) * np.sign(weight_toINQ[weight_toINQ != 0])\n",
    "\n",
    "        weight_rest[idx_rest[:num_prune]] = weight_toINQ\n",
    "        weight_arr = np.reshape(weight_rest, np.shape(weight_arr))\n",
    "        dic_tem[idx_rest[:num_prune]] = np.zeros_like(dic_tem[idx_rest[:num_prune]])\n",
    "        inq_dict[wl] = tf.cast(np.reshape(dic_tem, np.shape(sess.run(inq_dict[wl]))), tf.float32)\n",
    "        sess.run(weights[wl].assign(weight_arr))\n",
    "    return inq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一轮  量化\n",
    "prune_rate =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.933200\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.08215426 -0.05700303  0.04312498  0.1090302  -0.0417071  -0.07600322\n",
      "  0.00174217 -0.00667335  0.03555666 -0.09022148]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.5)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-17 16:56:12.172671] Iteration 100, train loss = 1.903270, train accuracy = 0.343750\n",
      "[2018-07-17 16:56:20.445568] Iteration 200, train loss = 2.097512, train accuracy = 0.218750\n",
      "[2018-07-17 16:56:28.396475] Iteration 300, train loss = 1.765162, train accuracy = 0.312500\n",
      "[2018-07-17 16:56:36.242398] Iteration 400, train loss = 1.566771, train accuracy = 0.382812\n",
      "[2018-07-17 16:56:44.054265] Iteration 500, train loss = 1.650104, train accuracy = 0.343750\n",
      "[2018-07-17 16:56:51.855389] Iteration 600, train loss = 1.318387, train accuracy = 0.476562\n",
      "[2018-07-17 16:56:59.693854] Iteration 700, train loss = 1.478517, train accuracy = 0.453125\n",
      "[2018-07-17 16:57:07.573966] Iteration 800, train loss = 1.137687, train accuracy = 0.625000\n",
      "[2018-07-17 16:57:15.469568] Iteration 900, train loss = 1.280052, train accuracy = 0.531250\n",
      "[2018-07-17 16:57:23.313343] Iteration 1000, train loss = 1.194305, train accuracy = 0.609375\n",
      "Evaluating...\n",
      "Test accuracy = 0.505000\n",
      "[2018-07-17 16:57:33.493955] Iteration 1100, train loss = 1.139900, train accuracy = 0.632812\n",
      "[2018-07-17 16:57:41.399304] Iteration 1200, train loss = 1.002450, train accuracy = 0.664062\n",
      "[2018-07-17 16:57:49.287334] Iteration 1300, train loss = 1.306045, train accuracy = 0.578125\n",
      "[2018-07-17 16:57:57.169460] Iteration 1400, train loss = 0.966001, train accuracy = 0.671875\n",
      "[2018-07-17 16:58:05.084528] Iteration 1500, train loss = 1.011706, train accuracy = 0.656250\n",
      "[2018-07-17 16:58:13.013541] Iteration 1600, train loss = 0.985467, train accuracy = 0.656250\n",
      "[2018-07-17 16:58:20.925060] Iteration 1700, train loss = 0.799291, train accuracy = 0.718750\n",
      "[2018-07-17 16:58:28.879193] Iteration 1800, train loss = 0.982065, train accuracy = 0.625000\n",
      "[2018-07-17 16:58:36.915707] Iteration 1900, train loss = 0.954336, train accuracy = 0.656250\n",
      "[2018-07-17 16:58:45.012067] Iteration 2000, train loss = 0.808410, train accuracy = 0.757812\n",
      "Evaluating...\n",
      "Test accuracy = 0.508300\n",
      "[2018-07-17 16:58:55.557076] Iteration 2100, train loss = 0.729247, train accuracy = 0.773438\n",
      "[2018-07-17 16:59:03.852908] Iteration 2200, train loss = 0.671728, train accuracy = 0.820312\n",
      "[2018-07-17 16:59:12.036208] Iteration 2300, train loss = 0.939784, train accuracy = 0.710938\n",
      "[2018-07-17 16:59:20.314243] Iteration 2400, train loss = 0.820577, train accuracy = 0.726562\n",
      "[2018-07-17 16:59:28.904553] Iteration 2500, train loss = 0.767967, train accuracy = 0.789062\n",
      "[2018-07-17 16:59:37.471333] Iteration 2600, train loss = 0.758369, train accuracy = 0.742188\n",
      "[2018-07-17 16:59:46.123030] Iteration 2700, train loss = 0.750967, train accuracy = 0.757812\n",
      "[2018-07-17 16:59:54.705290] Iteration 2800, train loss = 0.803871, train accuracy = 0.734375\n",
      "[2018-07-17 17:00:03.314699] Iteration 2900, train loss = 0.639873, train accuracy = 0.820312\n",
      "[2018-07-17 17:00:11.992894] Iteration 3000, train loss = 0.746322, train accuracy = 0.750000\n",
      "Evaluating...\n",
      "Test accuracy = 0.697100\n",
      "[2018-07-17 17:00:23.264193] Iteration 3100, train loss = 0.569197, train accuracy = 0.812500\n",
      "[2018-07-17 17:00:31.822464] Iteration 3200, train loss = 0.641157, train accuracy = 0.789062\n",
      "[2018-07-17 17:00:40.645037] Iteration 3300, train loss = 0.818684, train accuracy = 0.757812\n",
      "[2018-07-17 17:00:49.386977] Iteration 3400, train loss = 0.736178, train accuracy = 0.742188\n",
      "[2018-07-17 17:00:58.185640] Iteration 3500, train loss = 0.582897, train accuracy = 0.828125\n",
      "[2018-07-17 17:01:06.957872] Iteration 3600, train loss = 0.746289, train accuracy = 0.765625\n",
      "[2018-07-17 17:01:15.569562] Iteration 3700, train loss = 0.846372, train accuracy = 0.710938\n",
      "[2018-07-17 17:01:24.186147] Iteration 3800, train loss = 0.693048, train accuracy = 0.820312\n",
      "[2018-07-17 17:01:33.043044] Iteration 3900, train loss = 0.656843, train accuracy = 0.789062\n",
      "[2018-07-17 17:01:41.887985] Iteration 4000, train loss = 0.616088, train accuracy = 0.820312\n",
      "Evaluating...\n",
      "Test accuracy = 0.671400\n",
      "[2018-07-17 17:01:53.183714] Iteration 4100, train loss = 0.570294, train accuracy = 0.796875\n",
      "[2018-07-17 17:02:01.947548] Iteration 4200, train loss = 0.582884, train accuracy = 0.843750\n",
      "[2018-07-17 17:02:10.414555] Iteration 4300, train loss = 0.561413, train accuracy = 0.843750\n",
      "[2018-07-17 17:02:19.227892] Iteration 4400, train loss = 0.559742, train accuracy = 0.804688\n",
      "[2018-07-17 17:02:28.072457] Iteration 4500, train loss = 0.588573, train accuracy = 0.804688\n",
      "[2018-07-17 17:02:36.905167] Iteration 4600, train loss = 0.556274, train accuracy = 0.835938\n",
      "[2018-07-17 17:02:45.756641] Iteration 4700, train loss = 0.569719, train accuracy = 0.820312\n",
      "[2018-07-17 17:02:54.596184] Iteration 4800, train loss = 0.598909, train accuracy = 0.851562\n",
      "[2018-07-17 17:03:03.418950] Iteration 4900, train loss = 0.677570, train accuracy = 0.796875\n",
      "[2018-07-17 17:03:12.199497] Iteration 5000, train loss = 0.632307, train accuracy = 0.789062\n",
      "Evaluating...\n",
      "Test accuracy = 0.689800\n",
      "[2018-07-17 17:03:23.496879] Iteration 5100, train loss = 0.660341, train accuracy = 0.796875\n",
      "[2018-07-17 17:03:31.991460] Iteration 5200, train loss = 0.549519, train accuracy = 0.828125\n",
      "[2018-07-17 17:03:40.484957] Iteration 5300, train loss = 0.538731, train accuracy = 0.828125\n",
      "[2018-07-17 17:03:49.245182] Iteration 5400, train loss = 0.583250, train accuracy = 0.835938\n",
      "[2018-07-17 17:03:58.062177] Iteration 5500, train loss = 0.653113, train accuracy = 0.804688\n",
      "[2018-07-17 17:04:06.823462] Iteration 5600, train loss = 0.518619, train accuracy = 0.843750\n",
      "[2018-07-17 17:04:15.543499] Iteration 5700, train loss = 0.452301, train accuracy = 0.859375\n",
      "[2018-07-17 17:04:24.187147] Iteration 5800, train loss = 0.478575, train accuracy = 0.812500\n",
      "[2018-07-17 17:04:32.785136] Iteration 5900, train loss = 0.515728, train accuracy = 0.835938\n",
      "[2018-07-17 17:04:41.393016] Iteration 6000, train loss = 0.499645, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.749200\n",
      "[2018-07-17 17:04:52.658193] Iteration 6100, train loss = 0.485460, train accuracy = 0.859375\n",
      "[2018-07-17 17:05:01.486151] Iteration 6200, train loss = 0.421265, train accuracy = 0.875000\n",
      "[2018-07-17 17:05:10.226880] Iteration 6300, train loss = 0.496514, train accuracy = 0.835938\n",
      "[2018-07-17 17:05:18.788574] Iteration 6400, train loss = 0.494950, train accuracy = 0.828125\n",
      "[2018-07-17 17:05:27.381803] Iteration 6500, train loss = 0.448287, train accuracy = 0.867188\n",
      "[2018-07-17 17:05:36.130823] Iteration 6600, train loss = 0.409314, train accuracy = 0.898438\n",
      "[2018-07-17 17:05:44.913366] Iteration 6700, train loss = 0.580199, train accuracy = 0.828125\n",
      "[2018-07-17 17:05:53.642595] Iteration 6800, train loss = 0.518948, train accuracy = 0.828125\n",
      "[2018-07-17 17:06:02.412636] Iteration 6900, train loss = 0.493987, train accuracy = 0.828125\n",
      "[2018-07-17 17:06:11.201175] Iteration 7000, train loss = 0.485903, train accuracy = 0.882812\n",
      "Evaluating...\n",
      "Test accuracy = 0.762700\n",
      "[2018-07-17 17:06:22.573562] Iteration 7100, train loss = 0.343843, train accuracy = 0.898438\n",
      "[2018-07-17 17:06:31.366456] Iteration 7200, train loss = 0.415498, train accuracy = 0.875000\n",
      "[2018-07-17 17:06:40.221457] Iteration 7300, train loss = 0.286733, train accuracy = 0.945312\n",
      "[2018-07-17 17:06:49.023450] Iteration 7400, train loss = 0.371814, train accuracy = 0.906250\n",
      "[2018-07-17 17:06:57.792792] Iteration 7500, train loss = 0.432929, train accuracy = 0.898438\n",
      "[2018-07-17 17:07:06.442818] Iteration 7600, train loss = 0.574795, train accuracy = 0.820312\n",
      "[2018-07-17 17:07:15.229906] Iteration 7700, train loss = 0.489116, train accuracy = 0.828125\n",
      "[2018-07-17 17:07:24.058817] Iteration 7800, train loss = 0.529575, train accuracy = 0.828125\n",
      "[2018-07-17 17:07:32.897690] Iteration 7900, train loss = 0.396936, train accuracy = 0.890625\n",
      "[2018-07-17 17:07:41.655820] Iteration 8000, train loss = 0.611845, train accuracy = 0.812500\n",
      "Evaluating...\n",
      "Test accuracy = 0.678000\n",
      "[2018-07-17 17:07:52.951564] Iteration 8100, train loss = 0.400977, train accuracy = 0.890625\n",
      "[2018-07-17 17:08:01.755975] Iteration 8200, train loss = 0.531752, train accuracy = 0.820312\n",
      "[2018-07-17 17:08:10.530535] Iteration 8300, train loss = 0.374861, train accuracy = 0.906250\n",
      "[2018-07-17 17:08:19.382409] Iteration 8400, train loss = 0.516478, train accuracy = 0.851562\n",
      "[2018-07-17 17:08:28.192096] Iteration 8500, train loss = 0.330460, train accuracy = 0.890625\n",
      "[2018-07-17 17:08:36.925663] Iteration 8600, train loss = 0.334769, train accuracy = 0.914062\n",
      "[2018-07-17 17:08:45.770833] Iteration 8700, train loss = 0.471710, train accuracy = 0.867188\n",
      "[2018-07-17 17:08:54.544310] Iteration 8800, train loss = 0.475860, train accuracy = 0.859375\n",
      "[2018-07-17 17:09:03.249427] Iteration 8900, train loss = 0.326216, train accuracy = 0.906250\n",
      "[2018-07-17 17:09:12.083901] Iteration 9000, train loss = 0.397340, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.752900\n",
      "[2018-07-17 17:09:23.496760] Iteration 9100, train loss = 0.552665, train accuracy = 0.843750\n",
      "[2018-07-17 17:09:32.332925] Iteration 9200, train loss = 0.318169, train accuracy = 0.921875\n",
      "[2018-07-17 17:09:40.952456] Iteration 9300, train loss = 0.474906, train accuracy = 0.859375\n",
      "[2018-07-17 17:09:49.791697] Iteration 9400, train loss = 0.441763, train accuracy = 0.851562\n",
      "[2018-07-17 17:09:58.634641] Iteration 9500, train loss = 0.417445, train accuracy = 0.906250\n",
      "[2018-07-17 17:10:07.453325] Iteration 9600, train loss = 0.321999, train accuracy = 0.898438\n",
      "[2018-07-17 17:10:16.303979] Iteration 9700, train loss = 0.412948, train accuracy = 0.882812\n",
      "[2018-07-17 17:10:24.993938] Iteration 9800, train loss = 0.411528, train accuracy = 0.890625\n",
      "[2018-07-17 17:10:33.772525] Iteration 9900, train loss = 0.440631, train accuracy = 0.875000\n",
      "[2018-07-17 17:10:42.631978] Iteration 10000, train loss = 0.302891, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.804600\n",
      "[2018-07-17 17:10:54.004442] Iteration 10100, train loss = 0.367716, train accuracy = 0.906250\n",
      "[2018-07-17 17:11:02.869592] Iteration 10200, train loss = 0.536899, train accuracy = 0.851562\n",
      "[2018-07-17 17:11:11.650832] Iteration 10300, train loss = 0.394538, train accuracy = 0.890625\n",
      "[2018-07-17 17:11:20.515952] Iteration 10400, train loss = 0.448745, train accuracy = 0.851562\n",
      "[2018-07-17 17:11:29.386009] Iteration 10500, train loss = 0.303079, train accuracy = 0.937500\n",
      "[2018-07-17 17:11:38.180973] Iteration 10600, train loss = 0.321022, train accuracy = 0.906250\n",
      "[2018-07-17 17:11:46.845747] Iteration 10700, train loss = 0.613280, train accuracy = 0.828125\n",
      "[2018-07-17 17:11:55.547313] Iteration 10800, train loss = 0.432924, train accuracy = 0.875000\n",
      "[2018-07-17 17:12:04.325570] Iteration 10900, train loss = 0.472989, train accuracy = 0.890625\n",
      "[2018-07-17 17:12:13.171438] Iteration 11000, train loss = 0.382807, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.766600\n",
      "[2018-07-17 17:12:24.427713] Iteration 11100, train loss = 0.315660, train accuracy = 0.945312\n",
      "[2018-07-17 17:12:33.283476] Iteration 11200, train loss = 0.294883, train accuracy = 0.937500\n",
      "[2018-07-17 17:12:41.985221] Iteration 11300, train loss = 0.375814, train accuracy = 0.906250\n",
      "[2018-07-17 17:12:50.726226] Iteration 11400, train loss = 0.416478, train accuracy = 0.875000\n",
      "[2018-07-17 17:12:59.265123] Iteration 11500, train loss = 0.394442, train accuracy = 0.875000\n",
      "[2018-07-17 17:13:07.864009] Iteration 11600, train loss = 0.331750, train accuracy = 0.914062\n",
      "[2018-07-17 17:13:16.665275] Iteration 11700, train loss = 0.497281, train accuracy = 0.843750\n",
      "[2018-07-17 17:13:25.450480] Iteration 11800, train loss = 0.282361, train accuracy = 0.937500\n",
      "[2018-07-17 17:13:34.263271] Iteration 11900, train loss = 0.364600, train accuracy = 0.914062\n",
      "[2018-07-17 17:13:42.998956] Iteration 12000, train loss = 0.385171, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.773100\n",
      "[2018-07-17 17:13:54.343907] Iteration 12100, train loss = 0.378260, train accuracy = 0.875000\n",
      "[2018-07-17 17:14:03.175102] Iteration 12200, train loss = 0.251688, train accuracy = 0.953125\n",
      "[2018-07-17 17:14:12.045060] Iteration 12300, train loss = 0.299160, train accuracy = 0.929688\n",
      "[2018-07-17 17:14:20.839399] Iteration 12400, train loss = 0.411008, train accuracy = 0.882812\n",
      "[2018-07-17 17:14:29.543304] Iteration 12500, train loss = 0.274837, train accuracy = 0.914062\n",
      "[2018-07-17 17:14:38.283751] Iteration 12600, train loss = 0.287611, train accuracy = 0.937500\n",
      "[2018-07-17 17:14:47.111087] Iteration 12700, train loss = 0.411554, train accuracy = 0.906250\n",
      "[2018-07-17 17:14:55.912411] Iteration 12800, train loss = 0.272268, train accuracy = 0.921875\n",
      "[2018-07-17 17:15:04.678597] Iteration 12900, train loss = 0.336604, train accuracy = 0.921875\n",
      "[2018-07-17 17:15:13.505714] Iteration 13000, train loss = 0.311286, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.821600\n",
      "[2018-07-17 17:15:24.880229] Iteration 13100, train loss = 0.289143, train accuracy = 0.914062\n",
      "[2018-07-17 17:15:33.739645] Iteration 13200, train loss = 0.388032, train accuracy = 0.882812\n",
      "[2018-07-17 17:15:42.573837] Iteration 13300, train loss = 0.340583, train accuracy = 0.890625\n",
      "[2018-07-17 17:15:51.100258] Iteration 13400, train loss = 0.343405, train accuracy = 0.906250\n",
      "[2018-07-17 17:15:59.737484] Iteration 13500, train loss = 0.397324, train accuracy = 0.906250\n",
      "[2018-07-17 17:16:08.244907] Iteration 13600, train loss = 0.366588, train accuracy = 0.929688\n",
      "[2018-07-17 17:16:16.826743] Iteration 13700, train loss = 0.317745, train accuracy = 0.898438\n",
      "[2018-07-17 17:16:25.592272] Iteration 13800, train loss = 0.404067, train accuracy = 0.882812\n",
      "[2018-07-17 17:16:34.412271] Iteration 13900, train loss = 0.382942, train accuracy = 0.882812\n",
      "[2018-07-17 17:16:43.267934] Iteration 14000, train loss = 0.237140, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.848200\n",
      "[2018-07-17 17:16:54.637909] Iteration 14100, train loss = 0.247861, train accuracy = 0.953125\n",
      "[2018-07-17 17:17:03.498639] Iteration 14200, train loss = 0.256015, train accuracy = 0.929688\n",
      "[2018-07-17 17:17:12.316619] Iteration 14300, train loss = 0.243945, train accuracy = 0.914062\n",
      "[2018-07-17 17:17:21.166832] Iteration 14400, train loss = 0.259751, train accuracy = 0.929688\n",
      "[2018-07-17 17:17:29.946915] Iteration 14500, train loss = 0.313292, train accuracy = 0.914062\n",
      "[2018-07-17 17:17:38.681775] Iteration 14600, train loss = 0.372020, train accuracy = 0.875000\n",
      "[2018-07-17 17:17:47.214880] Iteration 14700, train loss = 0.299625, train accuracy = 0.914062\n",
      "[2018-07-17 17:17:55.762224] Iteration 14800, train loss = 0.338138, train accuracy = 0.882812\n",
      "[2018-07-17 17:18:04.590751] Iteration 14900, train loss = 0.440117, train accuracy = 0.875000\n",
      "[2018-07-17 17:18:13.369998] Iteration 15000, train loss = 0.312092, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.788700\n",
      "[2018-07-17 17:18:24.757499] Iteration 15100, train loss = 0.347542, train accuracy = 0.867188\n",
      "[2018-07-17 17:18:33.502889] Iteration 15200, train loss = 0.331482, train accuracy = 0.921875\n",
      "[2018-07-17 17:18:42.319476] Iteration 15300, train loss = 0.413880, train accuracy = 0.898438\n",
      "[2018-07-17 17:18:51.099930] Iteration 15400, train loss = 0.251250, train accuracy = 0.945312\n",
      "[2018-07-17 17:18:59.943204] Iteration 15500, train loss = 0.270957, train accuracy = 0.953125\n",
      "[2018-07-17 17:19:08.555721] Iteration 15600, train loss = 0.467781, train accuracy = 0.867188\n",
      "[2018-07-17 17:19:17.115555] Iteration 15700, train loss = 0.478080, train accuracy = 0.882812\n",
      "[2018-07-17 17:19:25.816452] Iteration 15800, train loss = 0.234318, train accuracy = 0.953125\n",
      "[2018-07-17 17:19:34.639920] Iteration 15900, train loss = 0.311846, train accuracy = 0.906250\n",
      "[2018-07-17 17:19:43.490948] Iteration 16000, train loss = 0.324373, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.807000\n",
      "[2018-07-17 17:19:54.704619] Iteration 16100, train loss = 0.282496, train accuracy = 0.921875\n",
      "[2018-07-17 17:20:03.580082] Iteration 16200, train loss = 0.333621, train accuracy = 0.929688\n",
      "[2018-07-17 17:20:12.346391] Iteration 16300, train loss = 0.336855, train accuracy = 0.898438\n",
      "[2018-07-17 17:20:21.127942] Iteration 16400, train loss = 0.329573, train accuracy = 0.898438\n",
      "[2018-07-17 17:20:29.909133] Iteration 16500, train loss = 0.338926, train accuracy = 0.898438\n",
      "[2018-07-17 17:20:38.698949] Iteration 16600, train loss = 0.324964, train accuracy = 0.937500\n",
      "[2018-07-17 17:20:47.557981] Iteration 16700, train loss = 0.355770, train accuracy = 0.898438\n",
      "[2018-07-17 17:20:56.349293] Iteration 16800, train loss = 0.237614, train accuracy = 0.945312\n",
      "[2018-07-17 17:21:05.191852] Iteration 16900, train loss = 0.401286, train accuracy = 0.898438\n",
      "[2018-07-17 17:21:14.047425] Iteration 17000, train loss = 0.370790, train accuracy = 0.890625\n",
      "Evaluating...\n",
      "Test accuracy = 0.810200\n",
      "[2018-07-17 17:21:25.455045] Iteration 17100, train loss = 0.243935, train accuracy = 0.953125\n",
      "[2018-07-17 17:21:34.284888] Iteration 17200, train loss = 0.269541, train accuracy = 0.921875\n",
      "[2018-07-17 17:21:43.082566] Iteration 17300, train loss = 0.221160, train accuracy = 0.953125\n",
      "[2018-07-17 17:21:51.941108] Iteration 17400, train loss = 0.255990, train accuracy = 0.929688\n",
      "[2018-07-17 17:22:00.716907] Iteration 17500, train loss = 0.338866, train accuracy = 0.914062\n",
      "[2018-07-17 17:22:09.403453] Iteration 17600, train loss = 0.347198, train accuracy = 0.890625\n",
      "[2018-07-17 17:22:18.218249] Iteration 17700, train loss = 0.257278, train accuracy = 0.937500\n",
      "[2018-07-17 17:22:26.984950] Iteration 17800, train loss = 0.257416, train accuracy = 0.914062\n",
      "[2018-07-17 17:22:35.651489] Iteration 17900, train loss = 0.243209, train accuracy = 0.921875\n",
      "[2018-07-17 17:22:44.408586] Iteration 18000, train loss = 0.212554, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.808800\n",
      "[2018-07-17 17:22:55.733210] Iteration 18100, train loss = 0.290136, train accuracy = 0.953125\n",
      "[2018-07-17 17:23:04.505388] Iteration 18200, train loss = 0.338815, train accuracy = 0.898438\n",
      "[2018-07-17 17:23:13.320816] Iteration 18300, train loss = 0.294999, train accuracy = 0.914062\n",
      "[2018-07-17 17:23:22.043171] Iteration 18400, train loss = 0.341228, train accuracy = 0.906250\n",
      "[2018-07-17 17:23:30.712794] Iteration 18500, train loss = 0.278992, train accuracy = 0.937500\n",
      "[2018-07-17 17:23:39.374172] Iteration 18600, train loss = 0.395222, train accuracy = 0.875000\n",
      "[2018-07-17 17:23:48.105983] Iteration 18700, train loss = 0.266983, train accuracy = 0.937500\n",
      "[2018-07-17 17:23:56.742740] Iteration 18800, train loss = 0.304558, train accuracy = 0.906250\n",
      "[2018-07-17 17:24:05.590939] Iteration 18900, train loss = 0.234522, train accuracy = 0.953125\n",
      "[2018-07-17 17:24:14.177689] Iteration 19000, train loss = 0.307135, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.790400\n",
      "[2018-07-17 17:24:25.511274] Iteration 19100, train loss = 0.232834, train accuracy = 0.960938\n",
      "[2018-07-17 17:24:34.271961] Iteration 19200, train loss = 0.309608, train accuracy = 0.929688\n",
      "[2018-07-17 17:24:43.094217] Iteration 19300, train loss = 0.282320, train accuracy = 0.929688\n",
      "[2018-07-17 17:24:51.766696] Iteration 19400, train loss = 0.222880, train accuracy = 0.914062\n",
      "[2018-07-17 17:25:00.538239] Iteration 19500, train loss = 0.184761, train accuracy = 0.945312\n",
      "[2018-07-17 17:25:09.401851] Iteration 19600, train loss = 0.280734, train accuracy = 0.921875\n",
      "[2018-07-17 17:25:18.061019] Iteration 19700, train loss = 0.197657, train accuracy = 0.960938\n",
      "[2018-07-17 17:25:26.841758] Iteration 19800, train loss = 0.325166, train accuracy = 0.921875\n",
      "[2018-07-17 17:25:35.599405] Iteration 19900, train loss = 0.223463, train accuracy = 0.945312\n",
      "[2018-07-17 17:25:44.087865] Iteration 20000, train loss = 0.322640, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.858100\n",
      "[2018-07-17 17:25:55.457592] Iteration 20100, train loss = 0.433178, train accuracy = 0.867188\n",
      "[2018-07-17 17:26:04.238932] Iteration 20200, train loss = 0.237271, train accuracy = 0.921875\n",
      "[2018-07-17 17:26:12.986631] Iteration 20300, train loss = 0.190713, train accuracy = 0.976562\n",
      "[2018-07-17 17:26:21.799556] Iteration 20400, train loss = 0.302170, train accuracy = 0.937500\n",
      "[2018-07-17 17:26:30.657402] Iteration 20500, train loss = 0.234013, train accuracy = 0.945312\n",
      "[2018-07-17 17:26:39.521835] Iteration 20600, train loss = 0.276825, train accuracy = 0.921875\n",
      "[2018-07-17 17:26:48.336415] Iteration 20700, train loss = 0.232147, train accuracy = 0.937500\n",
      "[2018-07-17 17:26:57.046824] Iteration 20800, train loss = 0.311037, train accuracy = 0.898438\n",
      "[2018-07-17 17:27:05.800406] Iteration 20900, train loss = 0.245428, train accuracy = 0.945312\n",
      "[2018-07-17 17:27:14.484702] Iteration 21000, train loss = 0.254607, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.815000\n",
      "[2018-07-17 17:27:25.865612] Iteration 21100, train loss = 0.246129, train accuracy = 0.960938\n",
      "[2018-07-17 17:27:34.676537] Iteration 21200, train loss = 0.266617, train accuracy = 0.945312\n",
      "[2018-07-17 17:27:43.506019] Iteration 21300, train loss = 0.377508, train accuracy = 0.898438\n",
      "[2018-07-17 17:27:52.361473] Iteration 21400, train loss = 0.239065, train accuracy = 0.929688\n",
      "[2018-07-17 17:28:01.017968] Iteration 21500, train loss = 0.261762, train accuracy = 0.953125\n",
      "[2018-07-17 17:28:09.809881] Iteration 21600, train loss = 0.326439, train accuracy = 0.906250\n",
      "[2018-07-17 17:28:18.454935] Iteration 21700, train loss = 0.372906, train accuracy = 0.890625\n",
      "[2018-07-17 17:28:26.940388] Iteration 21800, train loss = 0.257987, train accuracy = 0.929688\n",
      "[2018-07-17 17:28:35.669940] Iteration 21900, train loss = 0.223630, train accuracy = 0.945312\n",
      "[2018-07-17 17:28:44.208993] Iteration 22000, train loss = 0.211008, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.816800\n",
      "[2018-07-17 17:28:55.507962] Iteration 22100, train loss = 0.178972, train accuracy = 0.953125\n",
      "[2018-07-17 17:29:04.276369] Iteration 22200, train loss = 0.329994, train accuracy = 0.914062\n",
      "[2018-07-17 17:29:13.133903] Iteration 22300, train loss = 0.308167, train accuracy = 0.921875\n",
      "[2018-07-17 17:29:22.001281] Iteration 22400, train loss = 0.218534, train accuracy = 0.937500\n",
      "[2018-07-17 17:29:30.853402] Iteration 22500, train loss = 0.281865, train accuracy = 0.945312\n",
      "[2018-07-17 17:29:39.662330] Iteration 22600, train loss = 0.180787, train accuracy = 0.976562\n",
      "[2018-07-17 17:29:48.312265] Iteration 22700, train loss = 0.271008, train accuracy = 0.945312\n",
      "[2018-07-17 17:29:57.058234] Iteration 22800, train loss = 0.227623, train accuracy = 0.953125\n",
      "[2018-07-17 17:30:05.830030] Iteration 22900, train loss = 0.218572, train accuracy = 0.953125\n",
      "[2018-07-17 17:30:14.683881] Iteration 23000, train loss = 0.294471, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.835200\n",
      "[2018-07-17 17:30:26.045124] Iteration 23100, train loss = 0.212671, train accuracy = 0.953125\n",
      "[2018-07-17 17:30:34.888189] Iteration 23200, train loss = 0.359749, train accuracy = 0.898438\n",
      "[2018-07-17 17:30:43.703417] Iteration 23300, train loss = 0.211464, train accuracy = 0.945312\n",
      "[2018-07-17 17:30:52.552448] Iteration 23400, train loss = 0.287357, train accuracy = 0.921875\n",
      "[2018-07-17 17:31:01.415894] Iteration 23500, train loss = 0.259741, train accuracy = 0.937500\n",
      "[2018-07-17 17:31:10.140719] Iteration 23600, train loss = 0.288709, train accuracy = 0.898438\n",
      "[2018-07-17 17:31:18.772781] Iteration 23700, train loss = 0.218783, train accuracy = 0.953125\n",
      "[2018-07-17 17:31:27.340698] Iteration 23800, train loss = 0.375449, train accuracy = 0.906250\n",
      "[2018-07-17 17:31:35.999163] Iteration 23900, train loss = 0.221029, train accuracy = 0.953125\n",
      "[2018-07-17 17:31:44.777789] Iteration 24000, train loss = 0.200289, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.845800\n",
      "[2018-07-17 17:31:55.966630] Iteration 24100, train loss = 0.217950, train accuracy = 0.953125\n",
      "[2018-07-17 17:32:04.515917] Iteration 24200, train loss = 0.291512, train accuracy = 0.945312\n",
      "[2018-07-17 17:32:13.175581] Iteration 24300, train loss = 0.235454, train accuracy = 0.937500\n",
      "[2018-07-17 17:32:21.962580] Iteration 24400, train loss = 0.306436, train accuracy = 0.921875\n",
      "[2018-07-17 17:32:30.832716] Iteration 24500, train loss = 0.227490, train accuracy = 0.953125\n",
      "[2018-07-17 17:32:39.564713] Iteration 24600, train loss = 0.208001, train accuracy = 0.960938\n",
      "[2018-07-17 17:32:48.413066] Iteration 24700, train loss = 0.268552, train accuracy = 0.921875\n",
      "[2018-07-17 17:32:57.136666] Iteration 24800, train loss = 0.281145, train accuracy = 0.937500\n",
      "[2018-07-17 17:33:05.999330] Iteration 24900, train loss = 0.145797, train accuracy = 0.976562\n",
      "[2018-07-17 17:33:14.828974] Iteration 25000, train loss = 0.204067, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.831200\n",
      "[2018-07-17 17:33:26.008741] Iteration 25100, train loss = 0.274973, train accuracy = 0.937500\n",
      "[2018-07-17 17:33:34.600673] Iteration 25200, train loss = 0.307599, train accuracy = 0.914062\n",
      "[2018-07-17 17:33:43.414670] Iteration 25300, train loss = 0.160480, train accuracy = 0.976562\n",
      "[2018-07-17 17:33:52.147421] Iteration 25400, train loss = 0.294560, train accuracy = 0.921875\n",
      "[2018-07-17 17:34:00.986118] Iteration 25500, train loss = 0.223900, train accuracy = 0.945312\n",
      "[2018-07-17 17:34:09.798080] Iteration 25600, train loss = 0.245883, train accuracy = 0.921875\n",
      "[2018-07-17 17:34:18.544078] Iteration 25700, train loss = 0.212489, train accuracy = 0.945312\n",
      "[2018-07-17 17:34:27.398357] Iteration 25800, train loss = 0.191784, train accuracy = 0.976562\n",
      "[2018-07-17 17:34:36.226778] Iteration 25900, train loss = 0.263905, train accuracy = 0.937500\n",
      "[2018-07-17 17:34:44.940206] Iteration 26000, train loss = 0.234322, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.846800\n",
      "[2018-07-17 17:34:56.340747] Iteration 26100, train loss = 0.217427, train accuracy = 0.945312\n",
      "[2018-07-17 17:35:05.164757] Iteration 26200, train loss = 0.256334, train accuracy = 0.921875\n",
      "[2018-07-17 17:35:14.001580] Iteration 26300, train loss = 0.178215, train accuracy = 0.960938\n",
      "[2018-07-17 17:35:22.862679] Iteration 26400, train loss = 0.243619, train accuracy = 0.945312\n",
      "[2018-07-17 17:35:31.692507] Iteration 26500, train loss = 0.182332, train accuracy = 0.945312\n",
      "[2018-07-17 17:35:40.481065] Iteration 26600, train loss = 0.260197, train accuracy = 0.921875\n",
      "[2018-07-17 17:35:49.313738] Iteration 26700, train loss = 0.313774, train accuracy = 0.921875\n",
      "[2018-07-17 17:35:58.004523] Iteration 26800, train loss = 0.237622, train accuracy = 0.929688\n",
      "[2018-07-17 17:36:06.729400] Iteration 26900, train loss = 0.238734, train accuracy = 0.937500\n",
      "[2018-07-17 17:36:15.468572] Iteration 27000, train loss = 0.248321, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.861800\n",
      "[2018-07-17 17:36:26.712210] Iteration 27100, train loss = 0.270306, train accuracy = 0.937500\n",
      "[2018-07-17 17:36:35.547259] Iteration 27200, train loss = 0.243789, train accuracy = 0.937500\n",
      "[2018-07-17 17:36:44.414929] Iteration 27300, train loss = 0.211631, train accuracy = 0.953125\n",
      "[2018-07-17 17:36:53.255775] Iteration 27400, train loss = 0.267640, train accuracy = 0.937500\n",
      "[2018-07-17 17:37:02.006844] Iteration 27500, train loss = 0.325996, train accuracy = 0.890625\n",
      "[2018-07-17 17:37:10.799892] Iteration 27600, train loss = 0.301645, train accuracy = 0.937500\n",
      "[2018-07-17 17:37:19.520948] Iteration 27700, train loss = 0.247635, train accuracy = 0.937500\n",
      "[2018-07-17 17:37:28.307833] Iteration 27800, train loss = 0.198317, train accuracy = 0.937500\n",
      "[2018-07-17 17:37:37.068089] Iteration 27900, train loss = 0.183085, train accuracy = 0.976562\n",
      "[2018-07-17 17:37:45.810027] Iteration 28000, train loss = 0.233062, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.867100\n",
      "[2018-07-17 17:37:57.192099] Iteration 28100, train loss = 0.264140, train accuracy = 0.929688\n",
      "[2018-07-17 17:38:05.982537] Iteration 28200, train loss = 0.238853, train accuracy = 0.945312\n",
      "[2018-07-17 17:38:14.798703] Iteration 28300, train loss = 0.207615, train accuracy = 0.953125\n",
      "[2018-07-17 17:38:23.537824] Iteration 28400, train loss = 0.234015, train accuracy = 0.968750\n",
      "[2018-07-17 17:38:31.996575] Iteration 28500, train loss = 0.234670, train accuracy = 0.953125\n",
      "[2018-07-17 17:38:40.761377] Iteration 28600, train loss = 0.323435, train accuracy = 0.914062\n",
      "[2018-07-17 17:38:49.644112] Iteration 28700, train loss = 0.156621, train accuracy = 0.968750\n",
      "[2018-07-17 17:38:58.462461] Iteration 28800, train loss = 0.227324, train accuracy = 0.953125\n",
      "[2018-07-17 17:39:07.266302] Iteration 28900, train loss = 0.215072, train accuracy = 0.960938\n",
      "[2018-07-17 17:39:16.112856] Iteration 29000, train loss = 0.161855, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.838700\n",
      "[2018-07-17 17:39:27.473615] Iteration 29100, train loss = 0.196853, train accuracy = 0.968750\n",
      "[2018-07-17 17:39:36.300346] Iteration 29200, train loss = 0.295344, train accuracy = 0.921875\n",
      "[2018-07-17 17:39:44.700779] Iteration 29300, train loss = 0.312438, train accuracy = 0.898438\n",
      "[2018-07-17 17:39:53.380915] Iteration 29400, train loss = 0.164132, train accuracy = 0.968750\n",
      "[2018-07-17 17:40:02.096127] Iteration 29500, train loss = 0.243245, train accuracy = 0.953125\n",
      "[2018-07-17 17:40:10.824945] Iteration 29600, train loss = 0.197649, train accuracy = 0.945312\n",
      "[2018-07-17 17:40:19.686592] Iteration 29700, train loss = 0.256786, train accuracy = 0.953125\n",
      "[2018-07-17 17:40:28.507932] Iteration 29800, train loss = 0.192175, train accuracy = 0.960938\n",
      "[2018-07-17 17:40:37.321780] Iteration 29900, train loss = 0.213481, train accuracy = 0.960938\n",
      "[2018-07-17 17:40:46.115365] Iteration 30000, train loss = 0.241753, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.871800\n",
      "[2018-07-17 17:40:57.442432] Iteration 30100, train loss = 0.153597, train accuracy = 0.984375\n",
      "[2018-07-17 17:41:06.196957] Iteration 30200, train loss = 0.135511, train accuracy = 0.976562\n",
      "[2018-07-17 17:41:15.056564] Iteration 30300, train loss = 0.294895, train accuracy = 0.898438\n",
      "[2018-07-17 17:41:23.885613] Iteration 30400, train loss = 0.142958, train accuracy = 0.984375\n",
      "[2018-07-17 17:41:32.647393] Iteration 30500, train loss = 0.185773, train accuracy = 0.968750\n",
      "[2018-07-17 17:41:41.312982] Iteration 30600, train loss = 0.198302, train accuracy = 0.953125\n",
      "[2018-07-17 17:41:49.923831] Iteration 30700, train loss = 0.194450, train accuracy = 0.968750\n",
      "[2018-07-17 17:41:58.707863] Iteration 30800, train loss = 0.203563, train accuracy = 0.953125\n",
      "[2018-07-17 17:42:07.446163] Iteration 30900, train loss = 0.253145, train accuracy = 0.906250\n",
      "[2018-07-17 17:42:16.190551] Iteration 31000, train loss = 0.188616, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.866700\n",
      "[2018-07-17 17:42:27.573985] Iteration 31100, train loss = 0.200657, train accuracy = 0.968750\n",
      "[2018-07-17 17:42:36.418018] Iteration 31200, train loss = 0.173972, train accuracy = 0.976562\n",
      "[2018-07-17 17:42:45.171254] Iteration 31300, train loss = 0.195432, train accuracy = 0.968750\n",
      "[2018-07-17 17:42:54.025239] Iteration 31400, train loss = 0.247131, train accuracy = 0.960938\n",
      "[2018-07-17 17:43:02.644032] Iteration 31500, train loss = 0.252894, train accuracy = 0.906250\n",
      "[2018-07-17 17:43:11.489578] Iteration 31600, train loss = 0.227250, train accuracy = 0.953125\n",
      "[2018-07-17 17:43:20.342092] Iteration 31700, train loss = 0.250259, train accuracy = 0.945312\n",
      "[2018-07-17 17:43:29.205143] Iteration 31800, train loss = 0.144961, train accuracy = 0.984375\n",
      "[2018-07-17 17:43:37.973926] Iteration 31900, train loss = 0.225871, train accuracy = 0.953125\n",
      "[2018-07-17 17:43:46.602396] Iteration 32000, train loss = 0.271418, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.862300\n",
      "[2018-07-17 17:43:57.893677] Iteration 32100, train loss = 0.202787, train accuracy = 0.953125\n",
      "[2018-07-17 17:44:06.739455] Iteration 32200, train loss = 0.157876, train accuracy = 0.976562\n",
      "[2018-07-17 17:44:15.606856] Iteration 32300, train loss = 0.204101, train accuracy = 0.968750\n",
      "[2018-07-17 17:44:24.358774] Iteration 32400, train loss = 0.230035, train accuracy = 0.929688\n",
      "[2018-07-17 17:44:32.976481] Iteration 32500, train loss = 0.186284, train accuracy = 0.953125\n",
      "[2018-07-17 17:44:41.651259] Iteration 32600, train loss = 0.247065, train accuracy = 0.937500\n",
      "[2018-07-17 17:44:50.389247] Iteration 32700, train loss = 0.197599, train accuracy = 0.945312\n",
      "[2018-07-17 17:44:59.092219] Iteration 32800, train loss = 0.215996, train accuracy = 0.953125\n",
      "[2018-07-17 17:45:07.951147] Iteration 32900, train loss = 0.169941, train accuracy = 0.976562\n",
      "[2018-07-17 17:45:16.811233] Iteration 33000, train loss = 0.164806, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.865000\n",
      "[2018-07-17 17:45:28.077628] Iteration 33100, train loss = 0.180913, train accuracy = 0.945312\n",
      "[2018-07-17 17:45:36.663942] Iteration 33200, train loss = 0.214983, train accuracy = 0.960938\n",
      "[2018-07-17 17:45:45.403840] Iteration 33300, train loss = 0.237017, train accuracy = 0.929688\n",
      "[2018-07-17 17:45:54.047448] Iteration 33400, train loss = 0.160912, train accuracy = 0.968750\n",
      "[2018-07-17 17:46:02.865073] Iteration 33500, train loss = 0.199783, train accuracy = 0.953125\n",
      "[2018-07-17 17:46:11.714960] Iteration 33600, train loss = 0.155147, train accuracy = 0.960938\n",
      "[2018-07-17 17:46:20.502785] Iteration 33700, train loss = 0.287527, train accuracy = 0.929688\n",
      "[2018-07-17 17:46:29.326199] Iteration 33800, train loss = 0.234491, train accuracy = 0.921875\n",
      "[2018-07-17 17:46:37.995240] Iteration 33900, train loss = 0.224514, train accuracy = 0.937500\n",
      "[2018-07-17 17:46:46.785042] Iteration 34000, train loss = 0.191864, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.859900\n",
      "[2018-07-17 17:46:58.102750] Iteration 34100, train loss = 0.122178, train accuracy = 1.000000\n",
      "[2018-07-17 17:47:06.901120] Iteration 34200, train loss = 0.192765, train accuracy = 0.945312\n",
      "[2018-07-17 17:47:15.699609] Iteration 34300, train loss = 0.153427, train accuracy = 0.976562\n",
      "[2018-07-17 17:47:24.407864] Iteration 34400, train loss = 0.199389, train accuracy = 0.968750\n",
      "[2018-07-17 17:47:33.269531] Iteration 34500, train loss = 0.232105, train accuracy = 0.945312\n",
      "[2018-07-17 17:47:42.120230] Iteration 34600, train loss = 0.164032, train accuracy = 0.976562\n",
      "[2018-07-17 17:47:50.780704] Iteration 34700, train loss = 0.178180, train accuracy = 0.968750\n",
      "[2018-07-17 17:47:59.565791] Iteration 34800, train loss = 0.146720, train accuracy = 0.984375\n",
      "[2018-07-17 17:48:08.415589] Iteration 34900, train loss = 0.229278, train accuracy = 0.921875\n",
      "[2018-07-17 17:48:17.081450] Iteration 35000, train loss = 0.229289, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.868500\n",
      "[2018-07-17 17:48:28.428499] Iteration 35100, train loss = 0.212461, train accuracy = 0.945312\n",
      "[2018-07-17 17:48:37.231064] Iteration 35200, train loss = 0.178011, train accuracy = 0.953125\n",
      "[2018-07-17 17:48:45.911966] Iteration 35300, train loss = 0.167810, train accuracy = 0.960938\n",
      "[2018-07-17 17:48:54.640445] Iteration 35400, train loss = 0.265221, train accuracy = 0.906250\n",
      "[2018-07-17 17:49:03.206673] Iteration 35500, train loss = 0.137947, train accuracy = 0.992188\n",
      "[2018-07-17 17:49:11.945641] Iteration 35600, train loss = 0.249775, train accuracy = 0.929688\n",
      "[2018-07-17 17:49:20.811022] Iteration 35700, train loss = 0.195762, train accuracy = 0.960938\n",
      "[2018-07-17 17:49:29.625965] Iteration 35800, train loss = 0.209655, train accuracy = 0.937500\n",
      "[2018-07-17 17:49:38.493842] Iteration 35900, train loss = 0.215306, train accuracy = 0.953125\n",
      "[2018-07-17 17:49:47.352914] Iteration 36000, train loss = 0.186165, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.852400\n",
      "[2018-07-17 17:49:58.755728] Iteration 36100, train loss = 0.311159, train accuracy = 0.914062\n",
      "[2018-07-17 17:50:07.618483] Iteration 36200, train loss = 0.216565, train accuracy = 0.960938\n",
      "[2018-07-17 17:50:16.493053] Iteration 36300, train loss = 0.214495, train accuracy = 0.945312\n",
      "[2018-07-17 17:50:25.229712] Iteration 36400, train loss = 0.163036, train accuracy = 0.976562\n",
      "[2018-07-17 17:50:34.076740] Iteration 36500, train loss = 0.117964, train accuracy = 1.000000\n",
      "[2018-07-17 17:50:42.834472] Iteration 36600, train loss = 0.221363, train accuracy = 0.929688\n",
      "[2018-07-17 17:50:51.515087] Iteration 36700, train loss = 0.179326, train accuracy = 0.976562\n",
      "[2018-07-17 17:51:00.191233] Iteration 36800, train loss = 0.249184, train accuracy = 0.937500\n",
      "[2018-07-17 17:51:08.773995] Iteration 36900, train loss = 0.171719, train accuracy = 0.976562\n",
      "[2018-07-17 17:51:17.412271] Iteration 37000, train loss = 0.161358, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.866600\n",
      "[2018-07-17 17:51:28.345054] Iteration 37100, train loss = 0.233328, train accuracy = 0.945312\n",
      "[2018-07-17 17:51:36.734961] Iteration 37200, train loss = 0.169670, train accuracy = 0.968750\n",
      "[2018-07-17 17:51:45.357479] Iteration 37300, train loss = 0.185384, train accuracy = 0.968750\n",
      "[2018-07-17 17:51:53.849902] Iteration 37400, train loss = 0.173868, train accuracy = 0.968750\n",
      "[2018-07-17 17:52:02.416871] Iteration 37500, train loss = 0.241144, train accuracy = 0.929688\n",
      "[2018-07-17 17:52:11.103895] Iteration 37600, train loss = 0.198220, train accuracy = 0.953125\n",
      "[2018-07-17 17:52:19.831119] Iteration 37700, train loss = 0.172862, train accuracy = 0.968750\n",
      "[2018-07-17 17:52:28.510045] Iteration 37800, train loss = 0.190538, train accuracy = 0.953125\n",
      "[2018-07-17 17:52:37.251297] Iteration 37900, train loss = 0.235496, train accuracy = 0.953125\n",
      "[2018-07-17 17:52:45.822688] Iteration 38000, train loss = 0.163778, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.857100\n",
      "[2018-07-17 17:52:57.002834] Iteration 38100, train loss = 0.192885, train accuracy = 0.960938\n",
      "[2018-07-17 17:53:05.742694] Iteration 38200, train loss = 0.231890, train accuracy = 0.953125\n",
      "[2018-07-17 17:53:14.605736] Iteration 38300, train loss = 0.228607, train accuracy = 0.953125\n",
      "[2018-07-17 17:53:23.469920] Iteration 38400, train loss = 0.216576, train accuracy = 0.953125\n",
      "[2018-07-17 17:53:32.323784] Iteration 38500, train loss = 0.154809, train accuracy = 0.984375\n",
      "[2018-07-17 17:53:41.151675] Iteration 38600, train loss = 0.180965, train accuracy = 0.953125\n",
      "[2018-07-17 17:53:49.930819] Iteration 38700, train loss = 0.226722, train accuracy = 0.945312\n",
      "[2018-07-17 17:53:58.768486] Iteration 38800, train loss = 0.217412, train accuracy = 0.929688\n",
      "[2018-07-17 17:54:07.541768] Iteration 38900, train loss = 0.200711, train accuracy = 0.960938\n",
      "[2018-07-17 17:54:16.356966] Iteration 39000, train loss = 0.186009, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.868700\n",
      "[2018-07-17 17:54:27.729040] Iteration 39100, train loss = 0.136338, train accuracy = 0.984375\n",
      "[2018-07-17 17:54:36.562823] Iteration 39200, train loss = 0.227131, train accuracy = 0.929688\n",
      "[2018-07-17 17:54:45.238949] Iteration 39300, train loss = 0.204415, train accuracy = 0.953125\n",
      "[2018-07-17 17:54:54.101687] Iteration 39400, train loss = 0.288200, train accuracy = 0.960938\n",
      "[2018-07-17 17:55:02.966257] Iteration 39500, train loss = 0.151778, train accuracy = 0.976562\n",
      "[2018-07-17 17:55:11.614166] Iteration 39600, train loss = 0.276061, train accuracy = 0.937500\n",
      "[2018-07-17 17:55:20.159421] Iteration 39700, train loss = 0.220801, train accuracy = 0.945312\n",
      "[2018-07-17 17:55:28.830015] Iteration 39800, train loss = 0.139967, train accuracy = 0.984375\n",
      "[2018-07-17 17:55:37.598418] Iteration 39900, train loss = 0.231897, train accuracy = 0.953125\n"
     ]
    }
   ],
   "source": [
    "curr_lr = 0\n",
    "for step in range(40000):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二轮 量化\n",
    "prune_rate = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.864800\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625      0.          0.03413247  0.125       0.00889578 -0.0625\n",
      " -0.00152558 -0.09894396 -0.19610858 -0.0625    ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.75)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-17 17:57:30.721648] Iteration 100, train loss = 1.534838, train accuracy = 0.515625\n",
      "[2018-07-17 17:57:38.697495] Iteration 200, train loss = 1.539278, train accuracy = 0.468750\n",
      "[2018-07-17 17:57:46.731930] Iteration 300, train loss = 1.265530, train accuracy = 0.570312\n",
      "[2018-07-17 17:57:54.865035] Iteration 400, train loss = 1.305935, train accuracy = 0.578125\n",
      "[2018-07-17 17:58:03.123215] Iteration 500, train loss = 1.102514, train accuracy = 0.617188\n",
      "[2018-07-17 17:58:11.333917] Iteration 600, train loss = 1.098331, train accuracy = 0.625000\n",
      "[2018-07-17 17:58:19.557904] Iteration 700, train loss = 0.996875, train accuracy = 0.656250\n",
      "[2018-07-17 17:58:28.149973] Iteration 800, train loss = 0.958525, train accuracy = 0.695312\n",
      "[2018-07-17 17:58:36.782508] Iteration 900, train loss = 0.966294, train accuracy = 0.664062\n",
      "[2018-07-17 17:58:45.381854] Iteration 1000, train loss = 0.776158, train accuracy = 0.765625\n",
      "Evaluating...\n",
      "Test accuracy = 0.660400\n",
      "[2018-07-17 17:58:56.679543] Iteration 1100, train loss = 0.868888, train accuracy = 0.710938\n",
      "[2018-07-17 17:59:05.489296] Iteration 1200, train loss = 0.852328, train accuracy = 0.710938\n",
      "[2018-07-17 17:59:14.379084] Iteration 1300, train loss = 0.803740, train accuracy = 0.726562\n",
      "[2018-07-17 17:59:23.215557] Iteration 1400, train loss = 0.766476, train accuracy = 0.726562\n",
      "[2018-07-17 17:59:32.085817] Iteration 1500, train loss = 0.753307, train accuracy = 0.742188\n",
      "[2018-07-17 17:59:40.599594] Iteration 1600, train loss = 0.793665, train accuracy = 0.742188\n",
      "[2018-07-17 17:59:49.176300] Iteration 1700, train loss = 0.800176, train accuracy = 0.734375\n",
      "[2018-07-17 17:59:57.621047] Iteration 1800, train loss = 0.657173, train accuracy = 0.765625\n",
      "[2018-07-17 18:00:06.076972] Iteration 1900, train loss = 0.665374, train accuracy = 0.750000\n",
      "[2018-07-17 18:00:14.607903] Iteration 2000, train loss = 0.720028, train accuracy = 0.765625\n",
      "Evaluating...\n",
      "Test accuracy = 0.684800\n",
      "[2018-07-17 18:00:25.907365] Iteration 2100, train loss = 0.732603, train accuracy = 0.742188\n",
      "[2018-07-17 18:00:34.521365] Iteration 2200, train loss = 0.655025, train accuracy = 0.765625\n",
      "[2018-07-17 18:00:43.390644] Iteration 2300, train loss = 0.733810, train accuracy = 0.765625\n",
      "[2018-07-17 18:00:52.075912] Iteration 2400, train loss = 0.636097, train accuracy = 0.773438\n",
      "[2018-07-17 18:01:00.904084] Iteration 2500, train loss = 0.704611, train accuracy = 0.781250\n",
      "[2018-07-17 18:01:09.679684] Iteration 2600, train loss = 0.543966, train accuracy = 0.804688\n",
      "[2018-07-17 18:01:18.565726] Iteration 2700, train loss = 0.567192, train accuracy = 0.851562\n",
      "[2018-07-17 18:01:27.446140] Iteration 2800, train loss = 0.520257, train accuracy = 0.820312\n",
      "[2018-07-17 18:01:36.319888] Iteration 2900, train loss = 0.494988, train accuracy = 0.835938\n",
      "[2018-07-17 18:01:45.174608] Iteration 3000, train loss = 0.669788, train accuracy = 0.812500\n",
      "Evaluating...\n",
      "Test accuracy = 0.670800\n",
      "[2018-07-17 18:01:56.309625] Iteration 3100, train loss = 0.676067, train accuracy = 0.789062\n",
      "[2018-07-17 18:02:04.731657] Iteration 3200, train loss = 0.683036, train accuracy = 0.757812\n",
      "[2018-07-17 18:02:13.374338] Iteration 3300, train loss = 0.443035, train accuracy = 0.875000\n",
      "[2018-07-17 18:02:22.262234] Iteration 3400, train loss = 0.571537, train accuracy = 0.796875\n",
      "[2018-07-17 18:02:30.897857] Iteration 3500, train loss = 0.480824, train accuracy = 0.882812\n",
      "[2018-07-17 18:02:39.617134] Iteration 3600, train loss = 0.705057, train accuracy = 0.750000\n",
      "[2018-07-17 18:02:48.468320] Iteration 3700, train loss = 0.512481, train accuracy = 0.843750\n",
      "[2018-07-17 18:02:57.324985] Iteration 3800, train loss = 0.560822, train accuracy = 0.859375\n",
      "[2018-07-17 18:03:06.055301] Iteration 3900, train loss = 0.660695, train accuracy = 0.796875\n",
      "[2018-07-17 18:03:14.871426] Iteration 4000, train loss = 0.597237, train accuracy = 0.812500\n",
      "Evaluating...\n",
      "Test accuracy = 0.690000\n",
      "[2018-07-17 18:03:26.213959] Iteration 4100, train loss = 0.543848, train accuracy = 0.812500\n",
      "[2018-07-17 18:03:35.055389] Iteration 4200, train loss = 0.427627, train accuracy = 0.859375\n",
      "[2018-07-17 18:03:43.554080] Iteration 4300, train loss = 0.458318, train accuracy = 0.859375\n",
      "[2018-07-17 18:03:52.223587] Iteration 4400, train loss = 0.631401, train accuracy = 0.804688\n",
      "[2018-07-17 18:04:01.052737] Iteration 4500, train loss = 0.574268, train accuracy = 0.820312\n",
      "[2018-07-17 18:04:09.790408] Iteration 4600, train loss = 0.475303, train accuracy = 0.867188\n",
      "[2018-07-17 18:04:18.619736] Iteration 4700, train loss = 0.478280, train accuracy = 0.859375\n",
      "[2018-07-17 18:04:27.464856] Iteration 4800, train loss = 0.569712, train accuracy = 0.828125\n",
      "[2018-07-17 18:04:36.066782] Iteration 4900, train loss = 0.585233, train accuracy = 0.851562\n",
      "[2018-07-17 18:04:44.763105] Iteration 5000, train loss = 0.618366, train accuracy = 0.820312\n",
      "Evaluating...\n",
      "Test accuracy = 0.776200\n",
      "[2018-07-17 18:04:56.181320] Iteration 5100, train loss = 0.437623, train accuracy = 0.875000\n",
      "[2018-07-17 18:05:05.022714] Iteration 5200, train loss = 0.614878, train accuracy = 0.781250\n",
      "[2018-07-17 18:05:13.842634] Iteration 5300, train loss = 0.498252, train accuracy = 0.851562\n",
      "[2018-07-17 18:05:22.668780] Iteration 5400, train loss = 0.601030, train accuracy = 0.812500\n",
      "[2018-07-17 18:05:31.590616] Iteration 5500, train loss = 0.405146, train accuracy = 0.890625\n",
      "[2018-07-17 18:05:40.450120] Iteration 5600, train loss = 0.347266, train accuracy = 0.914062\n",
      "[2018-07-17 18:05:49.321640] Iteration 5700, train loss = 0.618073, train accuracy = 0.804688\n",
      "[2018-07-17 18:05:58.079670] Iteration 5800, train loss = 0.508430, train accuracy = 0.851562\n",
      "[2018-07-17 18:06:06.903116] Iteration 5900, train loss = 0.440777, train accuracy = 0.906250\n",
      "[2018-07-17 18:06:15.543480] Iteration 6000, train loss = 0.564956, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.766900\n",
      "[2018-07-17 18:06:26.878442] Iteration 6100, train loss = 0.401726, train accuracy = 0.914062\n",
      "[2018-07-17 18:06:35.750706] Iteration 6200, train loss = 0.461032, train accuracy = 0.859375\n",
      "[2018-07-17 18:06:44.600659] Iteration 6300, train loss = 0.388089, train accuracy = 0.890625\n",
      "[2018-07-17 18:06:53.274170] Iteration 6400, train loss = 0.447467, train accuracy = 0.875000\n",
      "[2018-07-17 18:07:01.942973] Iteration 6500, train loss = 0.349815, train accuracy = 0.882812\n",
      "[2018-07-17 18:07:10.725573] Iteration 6600, train loss = 0.502087, train accuracy = 0.851562\n",
      "[2018-07-17 18:07:19.503072] Iteration 6700, train loss = 0.492998, train accuracy = 0.835938\n",
      "[2018-07-17 18:07:28.345063] Iteration 6800, train loss = 0.510166, train accuracy = 0.859375\n",
      "[2018-07-17 18:07:37.160280] Iteration 6900, train loss = 0.385087, train accuracy = 0.890625\n",
      "[2018-07-17 18:07:45.998373] Iteration 7000, train loss = 0.581552, train accuracy = 0.796875\n",
      "Evaluating...\n",
      "Test accuracy = 0.754200\n",
      "[2018-07-17 18:07:57.414862] Iteration 7100, train loss = 0.537880, train accuracy = 0.882812\n",
      "[2018-07-17 18:08:06.275107] Iteration 7200, train loss = 0.394883, train accuracy = 0.906250\n",
      "[2018-07-17 18:08:15.081869] Iteration 7300, train loss = 0.405739, train accuracy = 0.859375\n",
      "[2018-07-17 18:08:23.875191] Iteration 7400, train loss = 0.362666, train accuracy = 0.921875\n",
      "[2018-07-17 18:08:32.705835] Iteration 7500, train loss = 0.305380, train accuracy = 0.906250\n",
      "[2018-07-17 18:08:41.565465] Iteration 7600, train loss = 0.518328, train accuracy = 0.835938\n",
      "[2018-07-17 18:08:50.190755] Iteration 7700, train loss = 0.395779, train accuracy = 0.890625\n",
      "[2018-07-17 18:08:59.059447] Iteration 7800, train loss = 0.305809, train accuracy = 0.921875\n",
      "[2018-07-17 18:09:07.617044] Iteration 7900, train loss = 0.353323, train accuracy = 0.882812\n",
      "[2018-07-17 18:09:16.096062] Iteration 8000, train loss = 0.459314, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.752200\n",
      "[2018-07-17 18:09:27.380308] Iteration 8100, train loss = 0.371205, train accuracy = 0.882812\n",
      "[2018-07-17 18:09:36.053322] Iteration 8200, train loss = 0.451979, train accuracy = 0.851562\n",
      "[2018-07-17 18:09:44.656380] Iteration 8300, train loss = 0.562349, train accuracy = 0.828125\n",
      "[2018-07-17 18:09:53.205050] Iteration 8400, train loss = 0.352773, train accuracy = 0.882812\n",
      "[2018-07-17 18:10:01.850965] Iteration 8500, train loss = 0.469775, train accuracy = 0.851562\n",
      "[2018-07-17 18:10:10.506710] Iteration 8600, train loss = 0.350495, train accuracy = 0.914062\n",
      "[2018-07-17 18:10:19.241747] Iteration 8700, train loss = 0.540318, train accuracy = 0.867188\n",
      "[2018-07-17 18:10:28.030930] Iteration 8800, train loss = 0.511396, train accuracy = 0.828125\n",
      "[2018-07-17 18:10:36.846600] Iteration 8900, train loss = 0.384462, train accuracy = 0.882812\n",
      "[2018-07-17 18:10:45.432463] Iteration 9000, train loss = 0.543045, train accuracy = 0.851562\n",
      "Evaluating...\n",
      "Test accuracy = 0.806000\n",
      "[2018-07-17 18:10:56.821315] Iteration 9100, train loss = 0.481384, train accuracy = 0.851562\n",
      "[2018-07-17 18:11:05.439566] Iteration 9200, train loss = 0.242115, train accuracy = 0.945312\n",
      "[2018-07-17 18:11:14.258297] Iteration 9300, train loss = 0.400078, train accuracy = 0.882812\n",
      "[2018-07-17 18:11:23.077322] Iteration 9400, train loss = 0.503787, train accuracy = 0.859375\n",
      "[2018-07-17 18:11:31.886489] Iteration 9500, train loss = 0.368692, train accuracy = 0.867188\n",
      "[2018-07-17 18:11:40.489810] Iteration 9600, train loss = 0.375156, train accuracy = 0.898438\n",
      "[2018-07-17 18:11:49.195440] Iteration 9700, train loss = 0.446302, train accuracy = 0.867188\n",
      "[2018-07-17 18:11:58.008827] Iteration 9800, train loss = 0.402875, train accuracy = 0.843750\n",
      "[2018-07-17 18:12:06.776547] Iteration 9900, train loss = 0.399918, train accuracy = 0.882812\n",
      "[2018-07-17 18:12:15.345027] Iteration 10000, train loss = 0.443460, train accuracy = 0.890625\n",
      "Evaluating...\n",
      "Test accuracy = 0.816600\n",
      "[2018-07-17 18:12:26.600036] Iteration 10100, train loss = 0.401366, train accuracy = 0.851562\n",
      "[2018-07-17 18:12:35.382133] Iteration 10200, train loss = 0.520002, train accuracy = 0.843750\n",
      "[2018-07-17 18:12:44.185106] Iteration 10300, train loss = 0.381017, train accuracy = 0.890625\n",
      "[2018-07-17 18:12:53.051611] Iteration 10400, train loss = 0.361792, train accuracy = 0.921875\n",
      "[2018-07-17 18:13:01.615824] Iteration 10500, train loss = 0.445458, train accuracy = 0.851562\n",
      "[2018-07-17 18:13:10.237410] Iteration 10600, train loss = 0.476761, train accuracy = 0.835938\n",
      "[2018-07-17 18:13:18.939244] Iteration 10700, train loss = 0.586306, train accuracy = 0.835938\n",
      "[2018-07-17 18:13:27.808047] Iteration 10800, train loss = 0.305401, train accuracy = 0.937500\n",
      "[2018-07-17 18:13:36.669036] Iteration 10900, train loss = 0.389970, train accuracy = 0.882812\n",
      "[2018-07-17 18:13:45.532859] Iteration 11000, train loss = 0.399498, train accuracy = 0.867188\n",
      "Evaluating...\n",
      "Test accuracy = 0.791700\n",
      "[2018-07-17 18:13:56.924517] Iteration 11100, train loss = 0.410596, train accuracy = 0.867188\n",
      "[2018-07-17 18:14:05.753082] Iteration 11200, train loss = 0.297888, train accuracy = 0.914062\n",
      "[2018-07-17 18:14:14.592236] Iteration 11300, train loss = 0.453110, train accuracy = 0.867188\n",
      "[2018-07-17 18:14:23.435324] Iteration 11400, train loss = 0.454487, train accuracy = 0.859375\n",
      "[2018-07-17 18:14:32.275802] Iteration 11500, train loss = 0.350938, train accuracy = 0.914062\n",
      "[2018-07-17 18:14:41.066161] Iteration 11600, train loss = 0.351520, train accuracy = 0.890625\n",
      "[2018-07-17 18:14:49.931257] Iteration 11700, train loss = 0.436915, train accuracy = 0.867188\n",
      "[2018-07-17 18:14:58.610156] Iteration 11800, train loss = 0.315521, train accuracy = 0.914062\n",
      "[2018-07-17 18:15:07.325240] Iteration 11900, train loss = 0.331670, train accuracy = 0.921875\n",
      "[2018-07-17 18:15:15.806358] Iteration 12000, train loss = 0.320957, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.754700\n",
      "[2018-07-17 18:15:27.141155] Iteration 12100, train loss = 0.365179, train accuracy = 0.875000\n",
      "[2018-07-17 18:15:36.028955] Iteration 12200, train loss = 0.365529, train accuracy = 0.898438\n",
      "[2018-07-17 18:15:44.811695] Iteration 12300, train loss = 0.251587, train accuracy = 0.937500\n",
      "[2018-07-17 18:15:53.563018] Iteration 12400, train loss = 0.308451, train accuracy = 0.914062\n",
      "[2018-07-17 18:16:02.379611] Iteration 12500, train loss = 0.375889, train accuracy = 0.914062\n",
      "[2018-07-17 18:16:11.220971] Iteration 12600, train loss = 0.316386, train accuracy = 0.937500\n",
      "[2018-07-17 18:16:20.059239] Iteration 12700, train loss = 0.448804, train accuracy = 0.859375\n",
      "[2018-07-17 18:16:28.921133] Iteration 12800, train loss = 0.324132, train accuracy = 0.937500\n",
      "[2018-07-17 18:16:37.781705] Iteration 12900, train loss = 0.480853, train accuracy = 0.851562\n",
      "[2018-07-17 18:16:46.550454] Iteration 13000, train loss = 0.438950, train accuracy = 0.851562\n",
      "Evaluating...\n",
      "Test accuracy = 0.802000\n",
      "[2018-07-17 18:16:57.943493] Iteration 13100, train loss = 0.292417, train accuracy = 0.929688\n",
      "[2018-07-17 18:17:06.733835] Iteration 13200, train loss = 0.301152, train accuracy = 0.937500\n",
      "[2018-07-17 18:17:15.557845] Iteration 13300, train loss = 0.421636, train accuracy = 0.906250\n",
      "[2018-07-17 18:17:24.415442] Iteration 13400, train loss = 0.435597, train accuracy = 0.867188\n",
      "[2018-07-17 18:17:33.243682] Iteration 13500, train loss = 0.364093, train accuracy = 0.882812\n",
      "[2018-07-17 18:17:42.101388] Iteration 13600, train loss = 0.253186, train accuracy = 0.937500\n",
      "[2018-07-17 18:17:50.901307] Iteration 13700, train loss = 0.351121, train accuracy = 0.914062\n",
      "[2018-07-17 18:17:59.771817] Iteration 13800, train loss = 0.385428, train accuracy = 0.898438\n",
      "[2018-07-17 18:18:08.615894] Iteration 13900, train loss = 0.438448, train accuracy = 0.875000\n",
      "[2018-07-17 18:18:17.434613] Iteration 14000, train loss = 0.364948, train accuracy = 0.890625\n",
      "Evaluating...\n",
      "Test accuracy = 0.770400\n",
      "[2018-07-17 18:18:28.712008] Iteration 14100, train loss = 0.242085, train accuracy = 0.953125\n",
      "[2018-07-17 18:18:37.585393] Iteration 14200, train loss = 0.317082, train accuracy = 0.882812\n",
      "[2018-07-17 18:18:46.424494] Iteration 14300, train loss = 0.312044, train accuracy = 0.921875\n",
      "[2018-07-17 18:18:55.273123] Iteration 14400, train loss = 0.341603, train accuracy = 0.898438\n",
      "[2018-07-17 18:19:03.963244] Iteration 14500, train loss = 0.253804, train accuracy = 0.937500\n",
      "[2018-07-17 18:19:12.521319] Iteration 14600, train loss = 0.432775, train accuracy = 0.843750\n",
      "[2018-07-17 18:19:21.347747] Iteration 14700, train loss = 0.418386, train accuracy = 0.859375\n",
      "[2018-07-17 18:19:30.194026] Iteration 14800, train loss = 0.399542, train accuracy = 0.867188\n",
      "[2018-07-17 18:19:38.636385] Iteration 14900, train loss = 0.327675, train accuracy = 0.921875\n",
      "[2018-07-17 18:19:47.149777] Iteration 15000, train loss = 0.290750, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.748400\n",
      "[2018-07-17 18:19:58.506040] Iteration 15100, train loss = 0.393961, train accuracy = 0.882812\n",
      "[2018-07-17 18:20:07.345367] Iteration 15200, train loss = 0.208544, train accuracy = 0.960938\n",
      "[2018-07-17 18:20:16.203838] Iteration 15300, train loss = 0.297364, train accuracy = 0.929688\n",
      "[2018-07-17 18:20:25.082607] Iteration 15400, train loss = 0.398173, train accuracy = 0.867188\n",
      "[2018-07-17 18:20:33.953507] Iteration 15500, train loss = 0.285216, train accuracy = 0.929688\n",
      "[2018-07-17 18:20:42.817606] Iteration 15600, train loss = 0.422556, train accuracy = 0.882812\n",
      "[2018-07-17 18:20:51.701673] Iteration 15700, train loss = 0.283339, train accuracy = 0.929688\n",
      "[2018-07-17 18:21:00.513106] Iteration 15800, train loss = 0.343705, train accuracy = 0.898438\n",
      "[2018-07-17 18:21:09.365684] Iteration 15900, train loss = 0.319956, train accuracy = 0.929688\n",
      "[2018-07-17 18:21:18.155146] Iteration 16000, train loss = 0.364215, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.849800\n",
      "[2018-07-17 18:21:29.551881] Iteration 16100, train loss = 0.321624, train accuracy = 0.914062\n",
      "[2018-07-17 18:21:38.367462] Iteration 16200, train loss = 0.344896, train accuracy = 0.906250\n",
      "[2018-07-17 18:21:47.056327] Iteration 16300, train loss = 0.361226, train accuracy = 0.898438\n",
      "[2018-07-17 18:21:55.873904] Iteration 16400, train loss = 0.288146, train accuracy = 0.937500\n",
      "[2018-07-17 18:22:04.728829] Iteration 16500, train loss = 0.261252, train accuracy = 0.937500\n",
      "[2018-07-17 18:22:13.586543] Iteration 16600, train loss = 0.460267, train accuracy = 0.875000\n",
      "[2018-07-17 18:22:22.426570] Iteration 16700, train loss = 0.358819, train accuracy = 0.898438\n",
      "[2018-07-17 18:22:31.307466] Iteration 16800, train loss = 0.324550, train accuracy = 0.906250\n",
      "[2018-07-17 18:22:40.119915] Iteration 16900, train loss = 0.396946, train accuracy = 0.882812\n",
      "[2018-07-17 18:22:48.878797] Iteration 17000, train loss = 0.390236, train accuracy = 0.882812\n",
      "Evaluating...\n",
      "Test accuracy = 0.803800\n",
      "[2018-07-17 18:23:00.130008] Iteration 17100, train loss = 0.392070, train accuracy = 0.882812\n",
      "[2018-07-17 18:23:08.970538] Iteration 17200, train loss = 0.372979, train accuracy = 0.882812\n",
      "[2018-07-17 18:23:17.689872] Iteration 17300, train loss = 0.352504, train accuracy = 0.890625\n",
      "[2018-07-17 18:23:26.463962] Iteration 17400, train loss = 0.262979, train accuracy = 0.945312\n",
      "[2018-07-17 18:23:35.334959] Iteration 17500, train loss = 0.322078, train accuracy = 0.945312\n",
      "[2018-07-17 18:23:44.184601] Iteration 17600, train loss = 0.357384, train accuracy = 0.890625\n",
      "[2018-07-17 18:23:53.035815] Iteration 17700, train loss = 0.267483, train accuracy = 0.929688\n",
      "[2018-07-17 18:24:01.922434] Iteration 17800, train loss = 0.273106, train accuracy = 0.921875\n",
      "[2018-07-17 18:24:10.798325] Iteration 17900, train loss = 0.309713, train accuracy = 0.906250\n",
      "[2018-07-17 18:24:19.643588] Iteration 18000, train loss = 0.293783, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.826800\n",
      "[2018-07-17 18:24:31.002319] Iteration 18100, train loss = 0.421433, train accuracy = 0.859375\n",
      "[2018-07-17 18:24:39.835320] Iteration 18200, train loss = 0.248977, train accuracy = 0.945312\n",
      "[2018-07-17 18:24:48.695813] Iteration 18300, train loss = 0.250487, train accuracy = 0.937500\n",
      "[2018-07-17 18:24:57.411333] Iteration 18400, train loss = 0.246734, train accuracy = 0.953125\n",
      "[2018-07-17 18:25:06.120987] Iteration 18500, train loss = 0.422977, train accuracy = 0.906250\n",
      "[2018-07-17 18:25:14.880471] Iteration 18600, train loss = 0.241853, train accuracy = 0.945312\n",
      "[2018-07-17 18:25:23.489487] Iteration 18700, train loss = 0.328760, train accuracy = 0.937500\n",
      "[2018-07-17 18:25:32.237209] Iteration 18800, train loss = 0.158169, train accuracy = 0.976562\n",
      "[2018-07-17 18:25:40.959039] Iteration 18900, train loss = 0.343045, train accuracy = 0.906250\n",
      "[2018-07-17 18:25:49.772223] Iteration 19000, train loss = 0.265714, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.852200\n",
      "[2018-07-17 18:26:01.145365] Iteration 19100, train loss = 0.333173, train accuracy = 0.906250\n",
      "[2018-07-17 18:26:09.909004] Iteration 19200, train loss = 0.301908, train accuracy = 0.890625\n",
      "[2018-07-17 18:26:18.558045] Iteration 19300, train loss = 0.243831, train accuracy = 0.929688\n",
      "[2018-07-17 18:26:27.276590] Iteration 19400, train loss = 0.288600, train accuracy = 0.906250\n",
      "[2018-07-17 18:26:35.779004] Iteration 19500, train loss = 0.245513, train accuracy = 0.960938\n",
      "[2018-07-17 18:26:44.589017] Iteration 19600, train loss = 0.258805, train accuracy = 0.937500\n",
      "[2018-07-17 18:26:53.355526] Iteration 19700, train loss = 0.415440, train accuracy = 0.859375\n",
      "[2018-07-17 18:27:02.067126] Iteration 19800, train loss = 0.327410, train accuracy = 0.906250\n",
      "[2018-07-17 18:27:10.856495] Iteration 19900, train loss = 0.327277, train accuracy = 0.929688\n",
      "[2018-07-17 18:27:19.719135] Iteration 20000, train loss = 0.400802, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.811900\n",
      "[2018-07-17 18:27:31.129471] Iteration 20100, train loss = 0.322026, train accuracy = 0.929688\n",
      "[2018-07-17 18:27:39.968318] Iteration 20200, train loss = 0.274898, train accuracy = 0.937500\n",
      "[2018-07-17 18:27:48.716705] Iteration 20300, train loss = 0.344439, train accuracy = 0.898438\n",
      "[2018-07-17 18:27:57.596642] Iteration 20400, train loss = 0.257614, train accuracy = 0.914062\n",
      "[2018-07-17 18:28:06.246275] Iteration 20500, train loss = 0.271165, train accuracy = 0.929688\n",
      "[2018-07-17 18:28:15.064478] Iteration 20600, train loss = 0.345281, train accuracy = 0.890625\n",
      "[2018-07-17 18:28:23.928553] Iteration 20700, train loss = 0.286023, train accuracy = 0.921875\n",
      "[2018-07-17 18:28:32.713956] Iteration 20800, train loss = 0.370332, train accuracy = 0.898438\n",
      "[2018-07-17 18:28:41.558980] Iteration 20900, train loss = 0.242115, train accuracy = 0.921875\n",
      "[2018-07-17 18:28:50.345446] Iteration 21000, train loss = 0.315903, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.817300\n",
      "[2018-07-17 18:29:01.560196] Iteration 21100, train loss = 0.206045, train accuracy = 0.976562\n",
      "[2018-07-17 18:29:10.285892] Iteration 21200, train loss = 0.281593, train accuracy = 0.945312\n",
      "[2018-07-17 18:29:18.893530] Iteration 21300, train loss = 0.295312, train accuracy = 0.921875\n",
      "[2018-07-17 18:29:27.528690] Iteration 21400, train loss = 0.276816, train accuracy = 0.898438\n",
      "[2018-07-17 18:29:36.301058] Iteration 21500, train loss = 0.292488, train accuracy = 0.914062\n",
      "[2018-07-17 18:29:45.156153] Iteration 21600, train loss = 0.320811, train accuracy = 0.890625\n",
      "[2018-07-17 18:29:54.010309] Iteration 21700, train loss = 0.285969, train accuracy = 0.929688\n",
      "[2018-07-17 18:30:02.833535] Iteration 21800, train loss = 0.332527, train accuracy = 0.898438\n",
      "[2018-07-17 18:30:11.570585] Iteration 21900, train loss = 0.254710, train accuracy = 0.945312\n",
      "[2018-07-17 18:30:20.259870] Iteration 22000, train loss = 0.326238, train accuracy = 0.882812\n",
      "Evaluating...\n",
      "Test accuracy = 0.809600\n",
      "[2018-07-17 18:30:31.668652] Iteration 22100, train loss = 0.300074, train accuracy = 0.937500\n",
      "[2018-07-17 18:30:40.351260] Iteration 22200, train loss = 0.312405, train accuracy = 0.937500\n",
      "[2018-07-17 18:30:49.113645] Iteration 22300, train loss = 0.353245, train accuracy = 0.898438\n",
      "[2018-07-17 18:30:57.702403] Iteration 22400, train loss = 0.380848, train accuracy = 0.898438\n",
      "[2018-07-17 18:31:06.404891] Iteration 22500, train loss = 0.275243, train accuracy = 0.937500\n",
      "[2018-07-17 18:31:15.189721] Iteration 22600, train loss = 0.287552, train accuracy = 0.945312\n",
      "[2018-07-17 18:31:24.011153] Iteration 22700, train loss = 0.199088, train accuracy = 0.960938\n",
      "[2018-07-17 18:31:32.880906] Iteration 22800, train loss = 0.254844, train accuracy = 0.929688\n",
      "[2018-07-17 18:31:41.664834] Iteration 22900, train loss = 0.307472, train accuracy = 0.937500\n",
      "[2018-07-17 18:31:50.444194] Iteration 23000, train loss = 0.336019, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.843000\n",
      "[2018-07-17 18:32:01.767130] Iteration 23100, train loss = 0.387751, train accuracy = 0.882812\n",
      "[2018-07-17 18:32:10.667116] Iteration 23200, train loss = 0.264954, train accuracy = 0.914062\n",
      "[2018-07-17 18:32:19.457251] Iteration 23300, train loss = 0.195767, train accuracy = 0.953125\n",
      "[2018-07-17 18:32:28.123757] Iteration 23400, train loss = 0.290702, train accuracy = 0.921875\n",
      "[2018-07-17 18:32:36.862866] Iteration 23500, train loss = 0.301494, train accuracy = 0.921875\n",
      "[2018-07-17 18:32:45.559511] Iteration 23600, train loss = 0.281211, train accuracy = 0.937500\n",
      "[2018-07-17 18:32:54.429918] Iteration 23700, train loss = 0.343554, train accuracy = 0.929688\n",
      "[2018-07-17 18:33:03.333933] Iteration 23800, train loss = 0.296558, train accuracy = 0.921875\n",
      "[2018-07-17 18:33:12.158047] Iteration 23900, train loss = 0.325069, train accuracy = 0.890625\n",
      "[2018-07-17 18:33:20.993484] Iteration 24000, train loss = 0.379900, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.814000\n",
      "[2018-07-17 18:33:32.247557] Iteration 24100, train loss = 0.236602, train accuracy = 0.929688\n",
      "[2018-07-17 18:33:41.004765] Iteration 24200, train loss = 0.310881, train accuracy = 0.921875\n",
      "[2018-07-17 18:33:49.884782] Iteration 24300, train loss = 0.282871, train accuracy = 0.929688\n",
      "[2018-07-17 18:33:58.746952] Iteration 24400, train loss = 0.311661, train accuracy = 0.914062\n",
      "[2018-07-17 18:34:07.609566] Iteration 24500, train loss = 0.257861, train accuracy = 0.945312\n",
      "[2018-07-17 18:34:16.317886] Iteration 24600, train loss = 0.323391, train accuracy = 0.921875\n",
      "[2018-07-17 18:34:25.013683] Iteration 24700, train loss = 0.321192, train accuracy = 0.890625\n",
      "[2018-07-17 18:34:33.817970] Iteration 24800, train loss = 0.195519, train accuracy = 0.968750\n",
      "[2018-07-17 18:34:42.615150] Iteration 24900, train loss = 0.318060, train accuracy = 0.906250\n",
      "[2018-07-17 18:34:51.431045] Iteration 25000, train loss = 0.316657, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.847800\n",
      "[2018-07-17 18:35:02.748516] Iteration 25100, train loss = 0.260783, train accuracy = 0.929688\n",
      "[2018-07-17 18:35:11.616448] Iteration 25200, train loss = 0.240488, train accuracy = 0.953125\n",
      "[2018-07-17 18:35:20.485676] Iteration 25300, train loss = 0.275836, train accuracy = 0.921875\n",
      "[2018-07-17 18:35:29.355357] Iteration 25400, train loss = 0.291541, train accuracy = 0.929688\n",
      "[2018-07-17 18:35:38.051921] Iteration 25500, train loss = 0.210794, train accuracy = 0.953125\n",
      "[2018-07-17 18:35:46.711765] Iteration 25600, train loss = 0.323639, train accuracy = 0.914062\n",
      "[2018-07-17 18:35:55.458236] Iteration 25700, train loss = 0.236287, train accuracy = 0.937500\n",
      "[2018-07-17 18:36:04.335080] Iteration 25800, train loss = 0.352143, train accuracy = 0.914062\n",
      "[2018-07-17 18:36:13.175374] Iteration 25900, train loss = 0.318618, train accuracy = 0.890625\n",
      "[2018-07-17 18:36:22.035170] Iteration 26000, train loss = 0.318493, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.800000\n",
      "[2018-07-17 18:36:33.453260] Iteration 26100, train loss = 0.395817, train accuracy = 0.898438\n",
      "[2018-07-17 18:36:42.326317] Iteration 26200, train loss = 0.237333, train accuracy = 0.945312\n",
      "[2018-07-17 18:36:51.191855] Iteration 26300, train loss = 0.244701, train accuracy = 0.914062\n",
      "[2018-07-17 18:37:00.098050] Iteration 26400, train loss = 0.210609, train accuracy = 0.960938\n",
      "[2018-07-17 18:37:08.930560] Iteration 26500, train loss = 0.223800, train accuracy = 0.921875\n",
      "[2018-07-17 18:37:17.804498] Iteration 26600, train loss = 0.273069, train accuracy = 0.929688\n",
      "[2018-07-17 18:37:26.673126] Iteration 26700, train loss = 0.193697, train accuracy = 0.953125\n",
      "[2018-07-17 18:37:35.539449] Iteration 26800, train loss = 0.283685, train accuracy = 0.945312\n",
      "[2018-07-17 18:37:44.418482] Iteration 26900, train loss = 0.280621, train accuracy = 0.921875\n",
      "[2018-07-17 18:37:53.206142] Iteration 27000, train loss = 0.290456, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.820300\n",
      "[2018-07-17 18:38:04.499697] Iteration 27100, train loss = 0.211988, train accuracy = 0.960938\n",
      "[2018-07-17 18:38:13.247041] Iteration 27200, train loss = 0.335545, train accuracy = 0.914062\n",
      "[2018-07-17 18:38:22.093002] Iteration 27300, train loss = 0.308990, train accuracy = 0.953125\n",
      "[2018-07-17 18:38:30.833461] Iteration 27400, train loss = 0.269468, train accuracy = 0.921875\n",
      "[2018-07-17 18:38:39.686514] Iteration 27500, train loss = 0.279698, train accuracy = 0.914062\n",
      "[2018-07-17 18:38:48.430598] Iteration 27600, train loss = 0.230913, train accuracy = 0.953125\n",
      "[2018-07-17 18:38:56.958816] Iteration 27700, train loss = 0.190770, train accuracy = 0.953125\n",
      "[2018-07-17 18:39:05.523807] Iteration 27800, train loss = 0.198416, train accuracy = 0.960938\n",
      "[2018-07-17 18:39:14.300241] Iteration 27900, train loss = 0.331954, train accuracy = 0.898438\n",
      "[2018-07-17 18:39:23.095713] Iteration 28000, train loss = 0.328160, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.857400\n",
      "[2018-07-17 18:39:34.493370] Iteration 28100, train loss = 0.288155, train accuracy = 0.921875\n",
      "[2018-07-17 18:39:43.139497] Iteration 28200, train loss = 0.218955, train accuracy = 0.953125\n",
      "[2018-07-17 18:39:51.651555] Iteration 28300, train loss = 0.224630, train accuracy = 0.945312\n",
      "[2018-07-17 18:40:00.469491] Iteration 28400, train loss = 0.281391, train accuracy = 0.906250\n",
      "[2018-07-17 18:40:09.156102] Iteration 28500, train loss = 0.352701, train accuracy = 0.898438\n",
      "[2018-07-17 18:40:17.688309] Iteration 28600, train loss = 0.255191, train accuracy = 0.937500\n",
      "[2018-07-17 18:40:26.415759] Iteration 28700, train loss = 0.218982, train accuracy = 0.960938\n",
      "[2018-07-17 18:40:35.067334] Iteration 28800, train loss = 0.217962, train accuracy = 0.945312\n",
      "[2018-07-17 18:40:43.612422] Iteration 28900, train loss = 0.342366, train accuracy = 0.906250\n",
      "[2018-07-17 18:40:52.448117] Iteration 29000, train loss = 0.342874, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.836600\n",
      "[2018-07-17 18:41:03.795319] Iteration 29100, train loss = 0.274055, train accuracy = 0.937500\n",
      "[2018-07-17 18:41:12.630949] Iteration 29200, train loss = 0.337621, train accuracy = 0.914062\n",
      "[2018-07-17 18:41:21.364280] Iteration 29300, train loss = 0.267575, train accuracy = 0.914062\n",
      "[2018-07-17 18:41:30.093560] Iteration 29400, train loss = 0.313737, train accuracy = 0.898438\n",
      "[2018-07-17 18:41:38.934282] Iteration 29500, train loss = 0.235878, train accuracy = 0.945312\n",
      "[2018-07-17 18:41:47.658290] Iteration 29600, train loss = 0.220115, train accuracy = 0.945312\n",
      "[2018-07-17 18:41:56.377364] Iteration 29700, train loss = 0.224322, train accuracy = 0.945312\n",
      "[2018-07-17 18:42:05.051651] Iteration 29800, train loss = 0.242000, train accuracy = 0.937500\n",
      "[2018-07-17 18:42:13.887634] Iteration 29900, train loss = 0.274208, train accuracy = 0.914062\n",
      "[2018-07-17 18:42:22.713497] Iteration 30000, train loss = 0.365447, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.851400\n",
      "[2018-07-17 18:42:34.099474] Iteration 30100, train loss = 0.275687, train accuracy = 0.921875\n",
      "[2018-07-17 18:42:42.971367] Iteration 30200, train loss = 0.298449, train accuracy = 0.914062\n",
      "[2018-07-17 18:42:51.821110] Iteration 30300, train loss = 0.269999, train accuracy = 0.898438\n",
      "[2018-07-17 18:43:00.652655] Iteration 30400, train loss = 0.246493, train accuracy = 0.937500\n",
      "[2018-07-17 18:43:09.519864] Iteration 30500, train loss = 0.266693, train accuracy = 0.929688\n",
      "[2018-07-17 18:43:18.393688] Iteration 30600, train loss = 0.429193, train accuracy = 0.867188\n",
      "[2018-07-17 18:43:27.273648] Iteration 30700, train loss = 0.279804, train accuracy = 0.937500\n",
      "[2018-07-17 18:43:36.154694] Iteration 30800, train loss = 0.258926, train accuracy = 0.937500\n",
      "[2018-07-17 18:43:44.848610] Iteration 30900, train loss = 0.262546, train accuracy = 0.929688\n",
      "[2018-07-17 18:43:53.727313] Iteration 31000, train loss = 0.384614, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.826800\n",
      "[2018-07-17 18:44:05.128514] Iteration 31100, train loss = 0.254866, train accuracy = 0.929688\n",
      "[2018-07-17 18:44:13.770729] Iteration 31200, train loss = 0.251081, train accuracy = 0.929688\n",
      "[2018-07-17 18:44:22.410666] Iteration 31300, train loss = 0.342088, train accuracy = 0.914062\n",
      "[2018-07-17 18:44:31.276136] Iteration 31400, train loss = 0.207677, train accuracy = 0.960938\n",
      "[2018-07-17 18:44:40.157020] Iteration 31500, train loss = 0.268397, train accuracy = 0.914062\n",
      "[2018-07-17 18:44:48.939561] Iteration 31600, train loss = 0.265351, train accuracy = 0.929688\n",
      "[2018-07-17 18:44:57.673940] Iteration 31700, train loss = 0.372190, train accuracy = 0.882812\n",
      "[2018-07-17 18:45:06.242507] Iteration 31800, train loss = 0.170672, train accuracy = 0.968750\n",
      "[2018-07-17 18:45:15.034943] Iteration 31900, train loss = 0.432424, train accuracy = 0.851562\n",
      "[2018-07-17 18:45:23.811596] Iteration 32000, train loss = 0.258341, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.839900\n",
      "[2018-07-17 18:45:34.979220] Iteration 32100, train loss = 0.249697, train accuracy = 0.945312\n",
      "[2018-07-17 18:45:43.754144] Iteration 32200, train loss = 0.179400, train accuracy = 0.968750\n",
      "[2018-07-17 18:45:52.622393] Iteration 32300, train loss = 0.225191, train accuracy = 0.953125\n",
      "[2018-07-17 18:46:01.402481] Iteration 32400, train loss = 0.309140, train accuracy = 0.882812\n",
      "[2018-07-17 18:46:10.065071] Iteration 32500, train loss = 0.242425, train accuracy = 0.929688\n",
      "[2018-07-17 18:46:18.566035] Iteration 32600, train loss = 0.253770, train accuracy = 0.929688\n",
      "[2018-07-17 18:46:27.209527] Iteration 32700, train loss = 0.231105, train accuracy = 0.968750\n",
      "[2018-07-17 18:46:35.946658] Iteration 32800, train loss = 0.271438, train accuracy = 0.937500\n",
      "[2018-07-17 18:46:44.813215] Iteration 32900, train loss = 0.393088, train accuracy = 0.882812\n",
      "[2018-07-17 18:46:53.671954] Iteration 33000, train loss = 0.310541, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.855200\n",
      "[2018-07-17 18:47:04.976073] Iteration 33100, train loss = 0.250960, train accuracy = 0.937500\n",
      "[2018-07-17 18:47:13.549878] Iteration 33200, train loss = 0.180583, train accuracy = 0.953125\n",
      "[2018-07-17 18:47:22.216156] Iteration 33300, train loss = 0.260665, train accuracy = 0.929688\n",
      "[2018-07-17 18:47:30.960585] Iteration 33400, train loss = 0.244396, train accuracy = 0.945312\n",
      "[2018-07-17 18:47:39.809911] Iteration 33500, train loss = 0.268038, train accuracy = 0.945312\n",
      "[2018-07-17 18:47:48.540114] Iteration 33600, train loss = 0.422991, train accuracy = 0.882812\n",
      "[2018-07-17 18:47:57.180865] Iteration 33700, train loss = 0.176614, train accuracy = 0.976562\n",
      "[2018-07-17 18:48:05.707874] Iteration 33800, train loss = 0.156123, train accuracy = 0.976562\n",
      "[2018-07-17 18:48:14.471937] Iteration 33900, train loss = 0.281957, train accuracy = 0.914062\n",
      "[2018-07-17 18:48:23.203286] Iteration 34000, train loss = 0.172469, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.825900\n",
      "[2018-07-17 18:48:34.543058] Iteration 34100, train loss = 0.200764, train accuracy = 0.960938\n",
      "[2018-07-17 18:48:43.314822] Iteration 34200, train loss = 0.306726, train accuracy = 0.921875\n",
      "[2018-07-17 18:48:52.172909] Iteration 34300, train loss = 0.213116, train accuracy = 0.953125\n",
      "[2018-07-17 18:49:00.949113] Iteration 34400, train loss = 0.467553, train accuracy = 0.835938\n",
      "[2018-07-17 18:49:09.777510] Iteration 34500, train loss = 0.258511, train accuracy = 0.937500\n",
      "[2018-07-17 18:49:18.342039] Iteration 34600, train loss = 0.263814, train accuracy = 0.929688\n",
      "[2018-07-17 18:49:27.134941] Iteration 34700, train loss = 0.204094, train accuracy = 0.945312\n",
      "[2018-07-17 18:49:36.013202] Iteration 34800, train loss = 0.184600, train accuracy = 0.968750\n",
      "[2018-07-17 18:49:44.882140] Iteration 34900, train loss = 0.313836, train accuracy = 0.921875\n",
      "[2018-07-17 18:49:53.750978] Iteration 35000, train loss = 0.290200, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.809100\n",
      "[2018-07-17 18:50:05.117118] Iteration 35100, train loss = 0.198927, train accuracy = 0.968750\n",
      "[2018-07-17 18:50:13.736555] Iteration 35200, train loss = 0.255813, train accuracy = 0.945312\n",
      "[2018-07-17 18:50:22.603367] Iteration 35300, train loss = 0.279986, train accuracy = 0.937500\n",
      "[2018-07-17 18:50:31.470216] Iteration 35400, train loss = 0.320235, train accuracy = 0.890625\n",
      "[2018-07-17 18:50:40.216127] Iteration 35500, train loss = 0.215542, train accuracy = 0.968750\n",
      "[2018-07-17 18:50:49.054736] Iteration 35600, train loss = 0.205669, train accuracy = 0.953125\n",
      "[2018-07-17 18:50:57.857326] Iteration 35700, train loss = 0.300730, train accuracy = 0.937500\n",
      "[2018-07-17 18:51:06.670209] Iteration 35800, train loss = 0.163812, train accuracy = 0.976562\n",
      "[2018-07-17 18:51:15.377277] Iteration 35900, train loss = 0.213111, train accuracy = 0.953125\n",
      "[2018-07-17 18:51:24.210085] Iteration 36000, train loss = 0.247537, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.835900\n",
      "[2018-07-17 18:51:35.586671] Iteration 36100, train loss = 0.255894, train accuracy = 0.937500\n",
      "[2018-07-17 18:51:44.401909] Iteration 36200, train loss = 0.320433, train accuracy = 0.914062\n",
      "[2018-07-17 18:51:53.274165] Iteration 36300, train loss = 0.270445, train accuracy = 0.945312\n",
      "[2018-07-17 18:52:02.137048] Iteration 36400, train loss = 0.237390, train accuracy = 0.953125\n",
      "[2018-07-17 18:52:10.907220] Iteration 36500, train loss = 0.315837, train accuracy = 0.914062\n",
      "[2018-07-17 18:52:19.632456] Iteration 36600, train loss = 0.335570, train accuracy = 0.921875\n",
      "[2018-07-17 18:52:28.458556] Iteration 36700, train loss = 0.188090, train accuracy = 0.960938\n",
      "[2018-07-17 18:52:37.282345] Iteration 36800, train loss = 0.230515, train accuracy = 0.937500\n",
      "[2018-07-17 18:52:46.077162] Iteration 36900, train loss = 0.350966, train accuracy = 0.914062\n",
      "[2018-07-17 18:52:54.884477] Iteration 37000, train loss = 0.215555, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.827200\n",
      "[2018-07-17 18:53:06.249864] Iteration 37100, train loss = 0.194562, train accuracy = 0.960938\n",
      "[2018-07-17 18:53:14.947979] Iteration 37200, train loss = 0.272595, train accuracy = 0.914062\n",
      "[2018-07-17 18:53:23.445161] Iteration 37300, train loss = 0.211071, train accuracy = 0.953125\n",
      "[2018-07-17 18:53:31.991224] Iteration 37400, train loss = 0.237154, train accuracy = 0.929688\n",
      "[2018-07-17 18:53:40.836667] Iteration 37500, train loss = 0.222151, train accuracy = 0.953125\n",
      "[2018-07-17 18:53:49.499984] Iteration 37600, train loss = 0.273198, train accuracy = 0.929688\n",
      "[2018-07-17 18:53:58.181613] Iteration 37700, train loss = 0.277612, train accuracy = 0.921875\n",
      "[2018-07-17 18:54:07.040769] Iteration 37800, train loss = 0.204256, train accuracy = 0.968750\n",
      "[2018-07-17 18:54:15.866703] Iteration 37900, train loss = 0.276493, train accuracy = 0.921875\n",
      "[2018-07-17 18:54:24.685828] Iteration 38000, train loss = 0.232379, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.817000\n",
      "[2018-07-17 18:54:35.914699] Iteration 38100, train loss = 0.196505, train accuracy = 0.968750\n",
      "[2018-07-17 18:54:44.592941] Iteration 38200, train loss = 0.246441, train accuracy = 0.945312\n",
      "[2018-07-17 18:54:53.423605] Iteration 38300, train loss = 0.230490, train accuracy = 0.929688\n",
      "[2018-07-17 18:55:02.297347] Iteration 38400, train loss = 0.276626, train accuracy = 0.937500\n",
      "[2018-07-17 18:55:11.076422] Iteration 38500, train loss = 0.239933, train accuracy = 0.929688\n",
      "[2018-07-17 18:55:19.856323] Iteration 38600, train loss = 0.214709, train accuracy = 0.945312\n",
      "[2018-07-17 18:55:28.581551] Iteration 38700, train loss = 0.281327, train accuracy = 0.945312\n",
      "[2018-07-17 18:55:37.377185] Iteration 38800, train loss = 0.221404, train accuracy = 0.937500\n",
      "[2018-07-17 18:55:46.096304] Iteration 38900, train loss = 0.267446, train accuracy = 0.921875\n",
      "[2018-07-17 18:55:54.935892] Iteration 39000, train loss = 0.188042, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.853500\n",
      "[2018-07-17 18:56:06.171399] Iteration 39100, train loss = 0.241857, train accuracy = 0.953125\n",
      "[2018-07-17 18:56:14.930003] Iteration 39200, train loss = 0.246061, train accuracy = 0.960938\n",
      "[2018-07-17 18:56:23.607236] Iteration 39300, train loss = 0.230470, train accuracy = 0.953125\n",
      "[2018-07-17 18:56:32.487891] Iteration 39400, train loss = 0.292920, train accuracy = 0.937500\n",
      "[2018-07-17 18:56:41.334996] Iteration 39500, train loss = 0.262746, train accuracy = 0.929688\n",
      "[2018-07-17 18:56:50.125995] Iteration 39600, train loss = 0.158149, train accuracy = 0.976562\n",
      "[2018-07-17 18:56:58.783530] Iteration 39700, train loss = 0.220456, train accuracy = 0.968750\n",
      "[2018-07-17 18:57:07.640572] Iteration 39800, train loss = 0.275251, train accuracy = 0.914062\n",
      "[2018-07-17 18:57:16.397528] Iteration 39900, train loss = 0.278661, train accuracy = 0.937500\n",
      "[2018-07-17 18:57:25.183524] Iteration 40000, train loss = 0.187652, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.847000\n",
      "[2018-07-17 18:57:36.562567] Iteration 40100, train loss = 0.238540, train accuracy = 0.937500\n",
      "[2018-07-17 18:57:45.408098] Iteration 40200, train loss = 0.313047, train accuracy = 0.906250\n",
      "[2018-07-17 18:57:54.251951] Iteration 40300, train loss = 0.180972, train accuracy = 0.953125\n",
      "[2018-07-17 18:58:03.010643] Iteration 40400, train loss = 0.243852, train accuracy = 0.921875\n",
      "[2018-07-17 18:58:11.667108] Iteration 40500, train loss = 0.195060, train accuracy = 0.953125\n",
      "[2018-07-17 18:58:20.495226] Iteration 40600, train loss = 0.313654, train accuracy = 0.914062\n",
      "[2018-07-17 18:58:29.155537] Iteration 40700, train loss = 0.272754, train accuracy = 0.921875\n",
      "[2018-07-17 18:58:37.678380] Iteration 40800, train loss = 0.223932, train accuracy = 0.960938\n",
      "[2018-07-17 18:58:46.157158] Iteration 40900, train loss = 0.233079, train accuracy = 0.945312\n",
      "[2018-07-17 18:58:54.775910] Iteration 41000, train loss = 0.282580, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.824600\n",
      "[2018-07-17 18:59:06.106770] Iteration 41100, train loss = 0.225544, train accuracy = 0.953125\n",
      "[2018-07-17 18:59:14.955164] Iteration 41200, train loss = 0.213014, train accuracy = 0.953125\n",
      "[2018-07-17 18:59:23.677291] Iteration 41300, train loss = 0.352785, train accuracy = 0.898438\n",
      "[2018-07-17 18:59:32.549514] Iteration 41400, train loss = 0.213007, train accuracy = 0.929688\n",
      "[2018-07-17 18:59:41.204645] Iteration 41500, train loss = 0.171609, train accuracy = 0.976562\n",
      "[2018-07-17 18:59:49.760921] Iteration 41600, train loss = 0.303641, train accuracy = 0.890625\n",
      "[2018-07-17 18:59:58.399401] Iteration 41700, train loss = 0.210531, train accuracy = 0.945312\n",
      "[2018-07-17 19:00:07.184873] Iteration 41800, train loss = 0.248667, train accuracy = 0.960938\n",
      "[2018-07-17 19:00:16.052531] Iteration 41900, train loss = 0.294376, train accuracy = 0.914062\n",
      "[2018-07-17 19:00:24.929620] Iteration 42000, train loss = 0.198666, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.860100\n",
      "[2018-07-17 19:00:36.327776] Iteration 42100, train loss = 0.301156, train accuracy = 0.937500\n",
      "[2018-07-17 19:00:45.195650] Iteration 42200, train loss = 0.286858, train accuracy = 0.929688\n",
      "[2018-07-17 19:00:54.077090] Iteration 42300, train loss = 0.322245, train accuracy = 0.921875\n",
      "[2018-07-17 19:01:02.941670] Iteration 42400, train loss = 0.227442, train accuracy = 0.937500\n",
      "[2018-07-17 19:01:11.422186] Iteration 42500, train loss = 0.397337, train accuracy = 0.898438\n",
      "[2018-07-17 19:01:20.254184] Iteration 42600, train loss = 0.285268, train accuracy = 0.921875\n",
      "[2018-07-17 19:01:29.106807] Iteration 42700, train loss = 0.251319, train accuracy = 0.953125\n",
      "[2018-07-17 19:01:37.985801] Iteration 42800, train loss = 0.214845, train accuracy = 0.945312\n",
      "[2018-07-17 19:01:46.751987] Iteration 42900, train loss = 0.164532, train accuracy = 0.976562\n",
      "[2018-07-17 19:01:55.398961] Iteration 43000, train loss = 0.295181, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.855600\n",
      "[2018-07-17 19:02:06.582351] Iteration 43100, train loss = 0.348931, train accuracy = 0.906250\n",
      "[2018-07-17 19:02:15.285013] Iteration 43200, train loss = 0.233218, train accuracy = 0.945312\n",
      "[2018-07-17 19:02:24.104069] Iteration 43300, train loss = 0.184312, train accuracy = 0.953125\n",
      "[2018-07-17 19:02:32.940144] Iteration 43400, train loss = 0.212215, train accuracy = 0.937500\n",
      "[2018-07-17 19:02:41.660431] Iteration 43500, train loss = 0.158947, train accuracy = 0.968750\n",
      "[2018-07-17 19:02:50.405863] Iteration 43600, train loss = 0.255628, train accuracy = 0.937500\n",
      "[2018-07-17 19:02:59.084220] Iteration 43700, train loss = 0.289797, train accuracy = 0.921875\n",
      "[2018-07-17 19:03:07.704588] Iteration 43800, train loss = 0.276936, train accuracy = 0.937500\n",
      "[2018-07-17 19:03:16.561337] Iteration 43900, train loss = 0.248208, train accuracy = 0.945312\n",
      "[2018-07-17 19:03:25.413586] Iteration 44000, train loss = 0.241650, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.865800\n",
      "[2018-07-17 19:03:36.835709] Iteration 44100, train loss = 0.225490, train accuracy = 0.945312\n",
      "[2018-07-17 19:03:45.701413] Iteration 44200, train loss = 0.214831, train accuracy = 0.945312\n",
      "[2018-07-17 19:03:54.523983] Iteration 44300, train loss = 0.167349, train accuracy = 0.976562\n",
      "[2018-07-17 19:04:03.257286] Iteration 44400, train loss = 0.227247, train accuracy = 0.945312\n",
      "[2018-07-17 19:04:12.073863] Iteration 44500, train loss = 0.268728, train accuracy = 0.914062\n",
      "[2018-07-17 19:04:20.898911] Iteration 44600, train loss = 0.256922, train accuracy = 0.960938\n",
      "[2018-07-17 19:04:29.680899] Iteration 44700, train loss = 0.171119, train accuracy = 0.984375\n",
      "[2018-07-17 19:04:38.455161] Iteration 44800, train loss = 0.247183, train accuracy = 0.929688\n",
      "[2018-07-17 19:04:47.188128] Iteration 44900, train loss = 0.205108, train accuracy = 0.953125\n",
      "[2018-07-17 19:04:56.015123] Iteration 45000, train loss = 0.185251, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.839100\n",
      "[2018-07-17 19:05:07.390031] Iteration 45100, train loss = 0.331943, train accuracy = 0.898438\n",
      "[2018-07-17 19:05:16.202473] Iteration 45200, train loss = 0.225072, train accuracy = 0.953125\n",
      "[2018-07-17 19:05:24.702128] Iteration 45300, train loss = 0.254902, train accuracy = 0.929688\n",
      "[2018-07-17 19:05:33.379499] Iteration 45400, train loss = 0.237247, train accuracy = 0.953125\n",
      "[2018-07-17 19:05:42.139455] Iteration 45500, train loss = 0.144891, train accuracy = 0.976562\n",
      "[2018-07-17 19:05:50.855233] Iteration 45600, train loss = 0.254975, train accuracy = 0.953125\n",
      "[2018-07-17 19:05:59.346229] Iteration 45700, train loss = 0.255386, train accuracy = 0.929688\n",
      "[2018-07-17 19:06:08.032125] Iteration 45800, train loss = 0.204462, train accuracy = 0.953125\n",
      "[2018-07-17 19:06:16.755925] Iteration 45900, train loss = 0.162093, train accuracy = 0.976562\n",
      "[2018-07-17 19:06:25.577059] Iteration 46000, train loss = 0.248299, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.849600\n",
      "[2018-07-17 19:06:36.823843] Iteration 46100, train loss = 0.248951, train accuracy = 0.937500\n",
      "[2018-07-17 19:06:45.639223] Iteration 46200, train loss = 0.234331, train accuracy = 0.945312\n",
      "[2018-07-17 19:06:54.511414] Iteration 46300, train loss = 0.242718, train accuracy = 0.945312\n",
      "[2018-07-17 19:07:03.361515] Iteration 46400, train loss = 0.235736, train accuracy = 0.953125\n",
      "[2018-07-17 19:07:12.030103] Iteration 46500, train loss = 0.318583, train accuracy = 0.898438\n",
      "[2018-07-17 19:07:20.707310] Iteration 46600, train loss = 0.151413, train accuracy = 0.976562\n",
      "[2018-07-17 19:07:29.279265] Iteration 46700, train loss = 0.195587, train accuracy = 0.937500\n",
      "[2018-07-17 19:07:37.888176] Iteration 46800, train loss = 0.268858, train accuracy = 0.929688\n",
      "[2018-07-17 19:07:46.623162] Iteration 46900, train loss = 0.152655, train accuracy = 0.992188\n",
      "[2018-07-17 19:07:55.364341] Iteration 47000, train loss = 0.213416, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.856000\n",
      "[2018-07-17 19:08:06.755737] Iteration 47100, train loss = 0.213108, train accuracy = 0.937500\n",
      "[2018-07-17 19:08:15.581246] Iteration 47200, train loss = 0.220846, train accuracy = 0.929688\n",
      "[2018-07-17 19:08:24.361976] Iteration 47300, train loss = 0.241632, train accuracy = 0.937500\n",
      "[2018-07-17 19:08:33.225206] Iteration 47400, train loss = 0.215543, train accuracy = 0.960938\n",
      "[2018-07-17 19:08:42.097110] Iteration 47500, train loss = 0.145419, train accuracy = 0.992188\n",
      "[2018-07-17 19:08:50.860874] Iteration 47600, train loss = 0.213074, train accuracy = 0.945312\n",
      "[2018-07-17 19:08:59.595092] Iteration 47700, train loss = 0.172753, train accuracy = 0.960938\n",
      "[2018-07-17 19:09:08.166422] Iteration 47800, train loss = 0.224322, train accuracy = 0.968750\n",
      "[2018-07-17 19:09:17.015751] Iteration 47900, train loss = 0.258172, train accuracy = 0.921875\n",
      "[2018-07-17 19:09:25.737343] Iteration 48000, train loss = 0.220075, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.832300\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-17 19:09:37.115395] Iteration 48100, train loss = 0.166262, train accuracy = 0.984375\n",
      "[2018-07-17 19:09:45.993934] Iteration 48200, train loss = 0.148293, train accuracy = 0.984375\n",
      "[2018-07-17 19:09:54.852964] Iteration 48300, train loss = 0.142383, train accuracy = 0.976562\n",
      "[2018-07-17 19:10:03.562949] Iteration 48400, train loss = 0.178063, train accuracy = 0.953125\n",
      "[2018-07-17 19:10:12.319192] Iteration 48500, train loss = 0.191728, train accuracy = 0.953125\n",
      "[2018-07-17 19:10:21.104335] Iteration 48600, train loss = 0.175062, train accuracy = 0.953125\n",
      "[2018-07-17 19:10:29.928976] Iteration 48700, train loss = 0.185992, train accuracy = 0.960938\n",
      "[2018-07-17 19:10:38.785154] Iteration 48800, train loss = 0.128402, train accuracy = 0.984375\n",
      "[2018-07-17 19:10:47.655090] Iteration 48900, train loss = 0.167426, train accuracy = 0.968750\n",
      "[2018-07-17 19:10:56.483867] Iteration 49000, train loss = 0.160270, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.890900\n",
      "[2018-07-17 19:11:07.873476] Iteration 49100, train loss = 0.154504, train accuracy = 0.968750\n",
      "[2018-07-17 19:11:16.654349] Iteration 49200, train loss = 0.181238, train accuracy = 0.960938\n",
      "[2018-07-17 19:11:25.549593] Iteration 49300, train loss = 0.162058, train accuracy = 0.968750\n",
      "[2018-07-17 19:11:34.421646] Iteration 49400, train loss = 0.240624, train accuracy = 0.937500\n",
      "[2018-07-17 19:11:43.282789] Iteration 49500, train loss = 0.170378, train accuracy = 0.960938\n",
      "[2018-07-17 19:11:52.003114] Iteration 49600, train loss = 0.107836, train accuracy = 1.000000\n",
      "[2018-07-17 19:12:00.683301] Iteration 49700, train loss = 0.211417, train accuracy = 0.968750\n",
      "[2018-07-17 19:12:09.512361] Iteration 49800, train loss = 0.245044, train accuracy = 0.937500\n",
      "[2018-07-17 19:12:18.369916] Iteration 49900, train loss = 0.202290, train accuracy = 0.960938\n",
      "[2018-07-17 19:12:27.244694] Iteration 50000, train loss = 0.158558, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.890200\n",
      "[2018-07-17 19:12:38.559164] Iteration 50100, train loss = 0.174217, train accuracy = 0.960938\n",
      "[2018-07-17 19:12:47.434096] Iteration 50200, train loss = 0.125294, train accuracy = 0.992188\n",
      "[2018-07-17 19:12:56.122730] Iteration 50300, train loss = 0.121645, train accuracy = 0.976562\n",
      "[2018-07-17 19:13:04.674700] Iteration 50400, train loss = 0.195936, train accuracy = 0.968750\n",
      "[2018-07-17 19:13:13.212164] Iteration 50500, train loss = 0.161849, train accuracy = 0.968750\n",
      "[2018-07-17 19:13:21.840525] Iteration 50600, train loss = 0.203980, train accuracy = 0.937500\n",
      "[2018-07-17 19:13:30.400885] Iteration 50700, train loss = 0.126525, train accuracy = 0.992188\n",
      "[2018-07-17 19:13:39.219246] Iteration 50800, train loss = 0.148973, train accuracy = 0.968750\n",
      "[2018-07-17 19:13:47.896260] Iteration 50900, train loss = 0.158170, train accuracy = 0.984375\n",
      "[2018-07-17 19:13:56.634789] Iteration 51000, train loss = 0.150014, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.891600\n",
      "[2018-07-17 19:14:07.964991] Iteration 51100, train loss = 0.249523, train accuracy = 0.914062\n",
      "[2018-07-17 19:14:16.837127] Iteration 51200, train loss = 0.158852, train accuracy = 0.976562\n",
      "[2018-07-17 19:14:25.626427] Iteration 51300, train loss = 0.143617, train accuracy = 0.984375\n",
      "[2018-07-17 19:14:34.441882] Iteration 51400, train loss = 0.143179, train accuracy = 0.976562\n",
      "[2018-07-17 19:14:43.062217] Iteration 51500, train loss = 0.179239, train accuracy = 0.968750\n",
      "[2018-07-17 19:14:51.880425] Iteration 51600, train loss = 0.177234, train accuracy = 0.968750\n",
      "[2018-07-17 19:15:00.600713] Iteration 51700, train loss = 0.170815, train accuracy = 0.984375\n",
      "[2018-07-17 19:15:09.416816] Iteration 51800, train loss = 0.169879, train accuracy = 0.968750\n",
      "[2018-07-17 19:15:18.213286] Iteration 51900, train loss = 0.154638, train accuracy = 0.968750\n",
      "[2018-07-17 19:15:27.068424] Iteration 52000, train loss = 0.141956, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.892100\n",
      "[2018-07-17 19:15:38.308222] Iteration 52100, train loss = 0.170084, train accuracy = 0.953125\n",
      "[2018-07-17 19:15:46.949635] Iteration 52200, train loss = 0.190714, train accuracy = 0.960938\n",
      "[2018-07-17 19:15:55.595596] Iteration 52300, train loss = 0.149548, train accuracy = 0.976562\n",
      "[2018-07-17 19:16:04.306417] Iteration 52400, train loss = 0.171233, train accuracy = 0.976562\n",
      "[2018-07-17 19:16:13.026789] Iteration 52500, train loss = 0.193015, train accuracy = 0.960938\n",
      "[2018-07-17 19:16:21.744352] Iteration 52600, train loss = 0.183424, train accuracy = 0.953125\n",
      "[2018-07-17 19:16:30.450137] Iteration 52700, train loss = 0.120427, train accuracy = 1.000000\n",
      "[2018-07-17 19:16:39.153772] Iteration 52800, train loss = 0.131828, train accuracy = 0.984375\n",
      "[2018-07-17 19:16:47.888222] Iteration 52900, train loss = 0.198085, train accuracy = 0.953125\n",
      "[2018-07-17 19:16:56.664762] Iteration 53000, train loss = 0.241841, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.891900\n",
      "[2018-07-17 19:17:08.066977] Iteration 53100, train loss = 0.225791, train accuracy = 0.929688\n",
      "[2018-07-17 19:17:16.764748] Iteration 53200, train loss = 0.162130, train accuracy = 0.953125\n",
      "[2018-07-17 19:17:25.589364] Iteration 53300, train loss = 0.155914, train accuracy = 0.976562\n",
      "[2018-07-17 19:17:34.459514] Iteration 53400, train loss = 0.190007, train accuracy = 0.945312\n",
      "[2018-07-17 19:17:43.258824] Iteration 53500, train loss = 0.122981, train accuracy = 0.992188\n",
      "[2018-07-17 19:17:51.776441] Iteration 53600, train loss = 0.128530, train accuracy = 0.992188\n",
      "[2018-07-17 19:18:00.509597] Iteration 53700, train loss = 0.132210, train accuracy = 0.984375\n",
      "[2018-07-17 19:18:09.347584] Iteration 53800, train loss = 0.174279, train accuracy = 0.984375\n",
      "[2018-07-17 19:18:18.221688] Iteration 53900, train loss = 0.138386, train accuracy = 0.984375\n",
      "[2018-07-17 19:18:27.076339] Iteration 54000, train loss = 0.129606, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.891400\n",
      "[2018-07-17 19:18:38.414769] Iteration 54100, train loss = 0.127255, train accuracy = 0.992188\n",
      "[2018-07-17 19:18:47.182138] Iteration 54200, train loss = 0.229828, train accuracy = 0.968750\n",
      "[2018-07-17 19:18:55.956476] Iteration 54300, train loss = 0.122092, train accuracy = 0.984375\n",
      "[2018-07-17 19:19:04.807523] Iteration 54400, train loss = 0.183144, train accuracy = 0.968750\n",
      "[2018-07-17 19:19:13.544021] Iteration 54500, train loss = 0.168641, train accuracy = 0.976562\n",
      "[2018-07-17 19:19:22.263151] Iteration 54600, train loss = 0.187557, train accuracy = 0.968750\n",
      "[2018-07-17 19:19:31.032300] Iteration 54700, train loss = 0.194677, train accuracy = 0.937500\n",
      "[2018-07-17 19:19:39.796477] Iteration 54800, train loss = 0.181264, train accuracy = 0.968750\n",
      "[2018-07-17 19:19:48.310727] Iteration 54900, train loss = 0.241057, train accuracy = 0.937500\n",
      "[2018-07-17 19:19:56.953555] Iteration 55000, train loss = 0.212873, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.890900\n",
      "[2018-07-17 19:20:08.336084] Iteration 55100, train loss = 0.140261, train accuracy = 0.984375\n",
      "[2018-07-17 19:20:17.187651] Iteration 55200, train loss = 0.141723, train accuracy = 0.976562\n",
      "[2018-07-17 19:20:25.959571] Iteration 55300, train loss = 0.139603, train accuracy = 0.984375\n",
      "[2018-07-17 19:20:34.834760] Iteration 55400, train loss = 0.179230, train accuracy = 0.953125\n",
      "[2018-07-17 19:20:43.593295] Iteration 55500, train loss = 0.157982, train accuracy = 0.968750\n",
      "[2018-07-17 19:20:52.428457] Iteration 55600, train loss = 0.143651, train accuracy = 0.984375\n",
      "[2018-07-17 19:21:01.306580] Iteration 55700, train loss = 0.189233, train accuracy = 0.968750\n",
      "[2018-07-17 19:21:10.057239] Iteration 55800, train loss = 0.201473, train accuracy = 0.968750\n",
      "[2018-07-17 19:21:18.824282] Iteration 55900, train loss = 0.156912, train accuracy = 0.976562\n",
      "[2018-07-17 19:21:27.476811] Iteration 56000, train loss = 0.185606, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.891500\n",
      "[2018-07-17 19:21:38.822472] Iteration 56100, train loss = 0.162083, train accuracy = 0.968750\n",
      "[2018-07-17 19:21:47.515345] Iteration 56200, train loss = 0.143340, train accuracy = 0.984375\n",
      "[2018-07-17 19:21:56.309954] Iteration 56300, train loss = 0.134072, train accuracy = 0.984375\n",
      "[2018-07-17 19:22:05.081912] Iteration 56400, train loss = 0.123960, train accuracy = 0.992188\n",
      "[2018-07-17 19:22:13.760667] Iteration 56500, train loss = 0.149322, train accuracy = 0.968750\n",
      "[2018-07-17 19:22:22.618794] Iteration 56600, train loss = 0.216520, train accuracy = 0.968750\n",
      "[2018-07-17 19:22:31.464693] Iteration 56700, train loss = 0.127114, train accuracy = 0.992188\n",
      "[2018-07-17 19:22:40.299024] Iteration 56800, train loss = 0.141318, train accuracy = 0.976562\n",
      "[2018-07-17 19:22:49.187560] Iteration 56900, train loss = 0.169660, train accuracy = 0.976562\n",
      "[2018-07-17 19:22:58.011355] Iteration 57000, train loss = 0.204498, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.892100\n",
      "[2018-07-17 19:23:09.366503] Iteration 57100, train loss = 0.152258, train accuracy = 0.984375\n",
      "[2018-07-17 19:23:18.116483] Iteration 57200, train loss = 0.150702, train accuracy = 0.960938\n",
      "[2018-07-17 19:23:26.920452] Iteration 57300, train loss = 0.174263, train accuracy = 0.968750\n",
      "[2018-07-17 19:23:35.641313] Iteration 57400, train loss = 0.137149, train accuracy = 0.984375\n",
      "[2018-07-17 19:23:44.256129] Iteration 57500, train loss = 0.142270, train accuracy = 0.984375\n",
      "[2018-07-17 19:23:53.078476] Iteration 57600, train loss = 0.108414, train accuracy = 1.000000\n",
      "[2018-07-17 19:24:01.877927] Iteration 57700, train loss = 0.127044, train accuracy = 0.992188\n",
      "[2018-07-17 19:24:10.684556] Iteration 57800, train loss = 0.155001, train accuracy = 0.992188\n",
      "[2018-07-17 19:24:19.255845] Iteration 57900, train loss = 0.159394, train accuracy = 0.976562\n",
      "[2018-07-17 19:24:28.074984] Iteration 58000, train loss = 0.180728, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.891700\n",
      "[2018-07-17 19:24:39.508072] Iteration 58100, train loss = 0.171942, train accuracy = 0.984375\n",
      "[2018-07-17 19:24:48.383099] Iteration 58200, train loss = 0.127563, train accuracy = 0.984375\n",
      "[2018-07-17 19:24:57.249214] Iteration 58300, train loss = 0.145566, train accuracy = 0.976562\n",
      "[2018-07-17 19:25:06.118028] Iteration 58400, train loss = 0.145023, train accuracy = 0.968750\n",
      "[2018-07-17 19:25:14.941843] Iteration 58500, train loss = 0.129885, train accuracy = 0.992188\n",
      "[2018-07-17 19:25:23.748763] Iteration 58600, train loss = 0.097247, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:32.629790] Iteration 58700, train loss = 0.180206, train accuracy = 0.953125\n",
      "[2018-07-17 19:25:41.498625] Iteration 58800, train loss = 0.213931, train accuracy = 0.953125\n",
      "[2018-07-17 19:25:50.358897] Iteration 58900, train loss = 0.168386, train accuracy = 0.968750\n",
      "[2018-07-17 19:25:59.099436] Iteration 59000, train loss = 0.172285, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.891600\n",
      "[2018-07-17 19:26:10.465410] Iteration 59100, train loss = 0.148107, train accuracy = 0.992188\n",
      "[2018-07-17 19:26:19.230160] Iteration 59200, train loss = 0.169601, train accuracy = 0.976562\n",
      "[2018-07-17 19:26:27.855138] Iteration 59300, train loss = 0.141181, train accuracy = 0.976562\n",
      "[2018-07-17 19:26:36.583716] Iteration 59400, train loss = 0.149217, train accuracy = 0.992188\n",
      "[2018-07-17 19:26:45.379424] Iteration 59500, train loss = 0.147470, train accuracy = 0.984375\n",
      "[2018-07-17 19:26:54.258120] Iteration 59600, train loss = 0.211329, train accuracy = 0.953125\n",
      "[2018-07-17 19:27:03.101542] Iteration 59700, train loss = 0.155526, train accuracy = 0.968750\n",
      "[2018-07-17 19:27:11.963097] Iteration 59800, train loss = 0.153181, train accuracy = 0.984375\n",
      "[2018-07-17 19:27:20.833177] Iteration 59900, train loss = 0.161555, train accuracy = 0.968750\n",
      "[2018-07-17 19:27:29.707635] Iteration 60000, train loss = 0.204678, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.892500\n",
      "[2018-07-17 19:27:40.850417] Iteration 60100, train loss = 0.237049, train accuracy = 0.921875\n",
      "[2018-07-17 19:27:49.300257] Iteration 60200, train loss = 0.137489, train accuracy = 0.984375\n",
      "[2018-07-17 19:27:58.114470] Iteration 60300, train loss = 0.115986, train accuracy = 0.992188\n",
      "[2018-07-17 19:28:06.978737] Iteration 60400, train loss = 0.158510, train accuracy = 0.984375\n",
      "[2018-07-17 19:28:15.777728] Iteration 60500, train loss = 0.201691, train accuracy = 0.960938\n",
      "[2018-07-17 19:28:24.440635] Iteration 60600, train loss = 0.108964, train accuracy = 0.992188\n",
      "[2018-07-17 19:28:33.291320] Iteration 60700, train loss = 0.194473, train accuracy = 0.953125\n",
      "[2018-07-17 19:28:42.148451] Iteration 60800, train loss = 0.134632, train accuracy = 0.992188\n",
      "[2018-07-17 19:28:50.835975] Iteration 60900, train loss = 0.181575, train accuracy = 0.968750\n",
      "[2018-07-17 19:28:59.332760] Iteration 61000, train loss = 0.133722, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.892700\n",
      "[2018-07-17 19:29:10.594714] Iteration 61100, train loss = 0.217501, train accuracy = 0.945312\n",
      "[2018-07-17 19:29:19.381489] Iteration 61200, train loss = 0.196292, train accuracy = 0.960938\n",
      "[2018-07-17 19:29:27.974024] Iteration 61300, train loss = 0.206146, train accuracy = 0.953125\n",
      "[2018-07-17 19:29:36.797469] Iteration 61400, train loss = 0.143070, train accuracy = 0.984375\n",
      "[2018-07-17 19:29:45.635586] Iteration 61500, train loss = 0.136407, train accuracy = 0.984375\n",
      "[2018-07-17 19:29:54.427378] Iteration 61600, train loss = 0.165003, train accuracy = 0.968750\n",
      "[2018-07-17 19:30:03.332136] Iteration 61700, train loss = 0.125034, train accuracy = 0.992188\n",
      "[2018-07-17 19:30:12.171780] Iteration 61800, train loss = 0.150766, train accuracy = 0.968750\n",
      "[2018-07-17 19:30:20.897409] Iteration 61900, train loss = 0.180143, train accuracy = 0.953125\n",
      "[2018-07-17 19:30:29.730322] Iteration 62000, train loss = 0.139557, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.892400\n",
      "[2018-07-17 19:30:41.125997] Iteration 62100, train loss = 0.188281, train accuracy = 0.960938\n",
      "[2018-07-17 19:30:49.916338] Iteration 62200, train loss = 0.128302, train accuracy = 0.976562\n",
      "[2018-07-17 19:30:58.627012] Iteration 62300, train loss = 0.183263, train accuracy = 0.968750\n",
      "[2018-07-17 19:31:07.364805] Iteration 62400, train loss = 0.164726, train accuracy = 0.968750\n",
      "[2018-07-17 19:31:16.145577] Iteration 62500, train loss = 0.184948, train accuracy = 0.968750\n",
      "[2018-07-17 19:31:24.777675] Iteration 62600, train loss = 0.181670, train accuracy = 0.960938\n",
      "[2018-07-17 19:31:33.421516] Iteration 62700, train loss = 0.107603, train accuracy = 1.000000\n",
      "[2018-07-17 19:31:42.228618] Iteration 62800, train loss = 0.179344, train accuracy = 0.960938\n",
      "[2018-07-17 19:31:50.967535] Iteration 62900, train loss = 0.125156, train accuracy = 0.984375\n",
      "[2018-07-17 19:31:59.672272] Iteration 63000, train loss = 0.136923, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.892300\n",
      "[2018-07-17 19:32:11.063493] Iteration 63100, train loss = 0.164187, train accuracy = 0.984375\n",
      "[2018-07-17 19:32:19.872555] Iteration 63200, train loss = 0.159082, train accuracy = 0.976562\n",
      "[2018-07-17 19:32:28.717853] Iteration 63300, train loss = 0.180345, train accuracy = 0.960938\n",
      "[2018-07-17 19:32:37.259105] Iteration 63400, train loss = 0.158438, train accuracy = 0.984375\n",
      "[2018-07-17 19:32:45.979300] Iteration 63500, train loss = 0.124810, train accuracy = 0.976562\n",
      "[2018-07-17 19:32:54.745599] Iteration 63600, train loss = 0.164712, train accuracy = 0.945312\n",
      "[2018-07-17 19:33:03.580951] Iteration 63700, train loss = 0.155186, train accuracy = 0.984375\n",
      "[2018-07-17 19:33:12.460548] Iteration 63800, train loss = 0.182235, train accuracy = 0.960938\n",
      "[2018-07-17 19:33:21.248079] Iteration 63900, train loss = 0.130819, train accuracy = 0.984375\n",
      "[2018-07-17 19:33:30.097347] Iteration 64000, train loss = 0.100759, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.892300\n",
      "[2018-07-17 19:33:41.439322] Iteration 64100, train loss = 0.209113, train accuracy = 0.945312\n",
      "[2018-07-17 19:33:50.278341] Iteration 64200, train loss = 0.142311, train accuracy = 0.968750\n",
      "[2018-07-17 19:33:59.032201] Iteration 64300, train loss = 0.167896, train accuracy = 0.968750\n",
      "[2018-07-17 19:34:07.786654] Iteration 64400, train loss = 0.120832, train accuracy = 0.992188\n",
      "[2018-07-17 19:34:16.533358] Iteration 64500, train loss = 0.183531, train accuracy = 0.953125\n",
      "[2018-07-17 19:34:25.380483] Iteration 64600, train loss = 0.179264, train accuracy = 0.976562\n",
      "[2018-07-17 19:34:34.196900] Iteration 64700, train loss = 0.152605, train accuracy = 0.976562\n",
      "[2018-07-17 19:34:42.914355] Iteration 64800, train loss = 0.123969, train accuracy = 0.984375\n",
      "[2018-07-17 19:34:51.624327] Iteration 64900, train loss = 0.131465, train accuracy = 0.992188\n",
      "[2018-07-17 19:35:00.324971] Iteration 65000, train loss = 0.172416, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.892400\n",
      "[2018-07-17 19:35:11.437038] Iteration 65100, train loss = 0.143075, train accuracy = 0.984375\n",
      "[2018-07-17 19:35:20.322031] Iteration 65200, train loss = 0.159507, train accuracy = 0.968750\n",
      "[2018-07-17 19:35:29.183487] Iteration 65300, train loss = 0.148516, train accuracy = 0.984375\n",
      "[2018-07-17 19:35:38.046657] Iteration 65400, train loss = 0.153680, train accuracy = 0.992188\n",
      "[2018-07-17 19:35:46.825007] Iteration 65500, train loss = 0.187681, train accuracy = 0.953125\n",
      "[2018-07-17 19:35:55.580459] Iteration 65600, train loss = 0.152423, train accuracy = 0.968750\n",
      "[2018-07-17 19:36:04.339918] Iteration 65700, train loss = 0.153316, train accuracy = 0.960938\n",
      "[2018-07-17 19:36:13.167032] Iteration 65800, train loss = 0.139211, train accuracy = 0.976562\n",
      "[2018-07-17 19:36:21.853562] Iteration 65900, train loss = 0.142566, train accuracy = 0.976562\n",
      "[2018-07-17 19:36:30.698625] Iteration 66000, train loss = 0.129971, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.890600\n",
      "[2018-07-17 19:36:41.860580] Iteration 66100, train loss = 0.159618, train accuracy = 0.960938\n",
      "[2018-07-17 19:36:50.347597] Iteration 66200, train loss = 0.115451, train accuracy = 1.000000\n",
      "[2018-07-17 19:36:58.935239] Iteration 66300, train loss = 0.178876, train accuracy = 0.960938\n",
      "[2018-07-17 19:37:07.459189] Iteration 66400, train loss = 0.110690, train accuracy = 1.000000\n",
      "[2018-07-17 19:37:16.217576] Iteration 66500, train loss = 0.126413, train accuracy = 0.984375\n",
      "[2018-07-17 19:37:25.103539] Iteration 66600, train loss = 0.190965, train accuracy = 0.945312\n",
      "[2018-07-17 19:37:33.933681] Iteration 66700, train loss = 0.147437, train accuracy = 0.968750\n",
      "[2018-07-17 19:37:42.759945] Iteration 66800, train loss = 0.155979, train accuracy = 0.976562\n",
      "[2018-07-17 19:37:51.571481] Iteration 66900, train loss = 0.183566, train accuracy = 0.968750\n",
      "[2018-07-17 19:38:00.311879] Iteration 67000, train loss = 0.145962, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.892900\n",
      "[2018-07-17 19:38:11.331849] Iteration 67100, train loss = 0.113820, train accuracy = 1.000000\n",
      "[2018-07-17 19:38:19.888979] Iteration 67200, train loss = 0.145521, train accuracy = 0.968750\n",
      "[2018-07-17 19:38:28.370443] Iteration 67300, train loss = 0.129367, train accuracy = 0.992188\n",
      "[2018-07-17 19:38:36.911973] Iteration 67400, train loss = 0.158428, train accuracy = 0.968750\n",
      "[2018-07-17 19:38:45.353669] Iteration 67500, train loss = 0.115732, train accuracy = 1.000000\n",
      "[2018-07-17 19:38:53.794945] Iteration 67600, train loss = 0.143346, train accuracy = 0.992188\n",
      "[2018-07-17 19:39:02.158913] Iteration 67700, train loss = 0.152701, train accuracy = 0.976562\n",
      "[2018-07-17 19:39:10.508547] Iteration 67800, train loss = 0.124525, train accuracy = 0.992188\n",
      "[2018-07-17 19:39:18.870750] Iteration 67900, train loss = 0.153183, train accuracy = 0.976562\n",
      "[2018-07-17 19:39:27.289603] Iteration 68000, train loss = 0.241445, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.889700\n",
      "[2018-07-17 19:39:38.052618] Iteration 68100, train loss = 0.137712, train accuracy = 0.984375\n",
      "[2018-07-17 19:39:46.495891] Iteration 68200, train loss = 0.154233, train accuracy = 0.976562\n",
      "[2018-07-17 19:39:54.927126] Iteration 68300, train loss = 0.125167, train accuracy = 0.992188\n",
      "[2018-07-17 19:40:03.200533] Iteration 68400, train loss = 0.141055, train accuracy = 0.976562\n",
      "[2018-07-17 19:40:11.680613] Iteration 68500, train loss = 0.135208, train accuracy = 0.984375\n",
      "[2018-07-17 19:40:20.157971] Iteration 68600, train loss = 0.192598, train accuracy = 0.953125\n",
      "[2018-07-17 19:40:28.636830] Iteration 68700, train loss = 0.160453, train accuracy = 0.984375\n",
      "[2018-07-17 19:40:37.265779] Iteration 68800, train loss = 0.145546, train accuracy = 0.992188\n",
      "[2018-07-17 19:40:45.882426] Iteration 68900, train loss = 0.137476, train accuracy = 0.992188\n",
      "[2018-07-17 19:40:54.417003] Iteration 69000, train loss = 0.163834, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.891700\n",
      "[2018-07-17 19:41:05.399905] Iteration 69100, train loss = 0.186615, train accuracy = 0.976562\n",
      "[2018-07-17 19:41:14.114674] Iteration 69200, train loss = 0.178565, train accuracy = 0.953125\n",
      "[2018-07-17 19:41:22.806906] Iteration 69300, train loss = 0.145741, train accuracy = 0.984375\n",
      "[2018-07-17 19:41:31.516926] Iteration 69400, train loss = 0.118271, train accuracy = 1.000000\n",
      "[2018-07-17 19:41:40.121951] Iteration 69500, train loss = 0.127466, train accuracy = 0.992188\n",
      "[2018-07-17 19:41:48.879498] Iteration 69600, train loss = 0.188174, train accuracy = 0.968750\n",
      "[2018-07-17 19:41:57.737724] Iteration 69700, train loss = 0.135289, train accuracy = 0.976562\n",
      "[2018-07-17 19:42:06.492477] Iteration 69800, train loss = 0.148118, train accuracy = 0.984375\n",
      "[2018-07-17 19:42:15.196001] Iteration 69900, train loss = 0.187611, train accuracy = 0.945312\n",
      "[2018-07-17 19:42:23.907418] Iteration 70000, train loss = 0.152267, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.889900\n",
      "[2018-07-17 19:42:35.255011] Iteration 70100, train loss = 0.133561, train accuracy = 0.976562\n",
      "[2018-07-17 19:42:43.992199] Iteration 70200, train loss = 0.104153, train accuracy = 0.992188\n",
      "[2018-07-17 19:42:52.836644] Iteration 70300, train loss = 0.241216, train accuracy = 0.937500\n",
      "[2018-07-17 19:43:01.491140] Iteration 70400, train loss = 0.183178, train accuracy = 0.968750\n",
      "[2018-07-17 19:43:10.171479] Iteration 70500, train loss = 0.177567, train accuracy = 0.968750\n",
      "[2018-07-17 19:43:18.918959] Iteration 70600, train loss = 0.122655, train accuracy = 0.992188\n",
      "[2018-07-17 19:43:27.585184] Iteration 70700, train loss = 0.160878, train accuracy = 0.976562\n",
      "[2018-07-17 19:43:36.258419] Iteration 70800, train loss = 0.126247, train accuracy = 0.992188\n",
      "[2018-07-17 19:43:44.910757] Iteration 70900, train loss = 0.179453, train accuracy = 0.960938\n",
      "[2018-07-17 19:43:53.535231] Iteration 71000, train loss = 0.148318, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.889600\n",
      "[2018-07-17 19:44:04.927959] Iteration 71100, train loss = 0.169497, train accuracy = 0.968750\n",
      "[2018-07-17 19:44:13.707510] Iteration 71200, train loss = 0.181797, train accuracy = 0.968750\n",
      "[2018-07-17 19:44:22.487276] Iteration 71300, train loss = 0.149217, train accuracy = 0.992188\n",
      "[2018-07-17 19:44:31.116630] Iteration 71400, train loss = 0.154238, train accuracy = 0.968750\n",
      "[2018-07-17 19:44:39.684189] Iteration 71500, train loss = 0.121078, train accuracy = 0.992188\n",
      "[2018-07-17 19:44:48.200858] Iteration 71600, train loss = 0.121534, train accuracy = 0.992188\n",
      "[2018-07-17 19:44:56.852666] Iteration 71700, train loss = 0.213109, train accuracy = 0.960938\n",
      "[2018-07-17 19:45:05.572874] Iteration 71800, train loss = 0.139246, train accuracy = 0.984375\n",
      "[2018-07-17 19:45:14.407135] Iteration 71900, train loss = 0.135173, train accuracy = 0.984375\n",
      "[2018-07-17 19:45:23.224582] Iteration 72000, train loss = 0.215326, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.892200\n",
      "[2018-07-17 19:45:34.634773] Iteration 72100, train loss = 0.175425, train accuracy = 0.953125\n",
      "[2018-07-17 19:45:43.506082] Iteration 72200, train loss = 0.178928, train accuracy = 0.960938\n",
      "[2018-07-17 19:45:52.021489] Iteration 72300, train loss = 0.196049, train accuracy = 0.976562\n",
      "[2018-07-17 19:46:00.593814] Iteration 72400, train loss = 0.148509, train accuracy = 0.960938\n",
      "[2018-07-17 19:46:09.439250] Iteration 72500, train loss = 0.198590, train accuracy = 0.953125\n",
      "[2018-07-17 19:46:18.088335] Iteration 72600, train loss = 0.134181, train accuracy = 0.984375\n",
      "[2018-07-17 19:46:26.813084] Iteration 72700, train loss = 0.145652, train accuracy = 0.984375\n",
      "[2018-07-17 19:46:35.622101] Iteration 72800, train loss = 0.165657, train accuracy = 0.976562\n",
      "[2018-07-17 19:46:44.225146] Iteration 72900, train loss = 0.117319, train accuracy = 0.992188\n",
      "[2018-07-17 19:46:53.115991] Iteration 73000, train loss = 0.138886, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.892300\n",
      "[2018-07-17 19:47:04.467807] Iteration 73100, train loss = 0.155963, train accuracy = 0.984375\n",
      "[2018-07-17 19:47:13.102815] Iteration 73200, train loss = 0.129492, train accuracy = 0.976562\n",
      "[2018-07-17 19:47:21.842567] Iteration 73300, train loss = 0.161618, train accuracy = 0.968750\n",
      "[2018-07-17 19:47:30.693245] Iteration 73400, train loss = 0.146670, train accuracy = 0.976562\n",
      "[2018-07-17 19:47:39.485552] Iteration 73500, train loss = 0.153780, train accuracy = 0.976562\n",
      "[2018-07-17 19:47:48.258022] Iteration 73600, train loss = 0.148882, train accuracy = 0.984375\n",
      "[2018-07-17 19:47:57.129384] Iteration 73700, train loss = 0.141518, train accuracy = 0.992188\n",
      "[2018-07-17 19:48:05.979928] Iteration 73800, train loss = 0.168150, train accuracy = 0.984375\n",
      "[2018-07-17 19:48:14.886496] Iteration 73900, train loss = 0.174916, train accuracy = 0.960938\n",
      "[2018-07-17 19:48:23.624068] Iteration 74000, train loss = 0.145864, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.889400\n",
      "[2018-07-17 19:48:35.025800] Iteration 74100, train loss = 0.118246, train accuracy = 0.992188\n",
      "[2018-07-17 19:48:43.702018] Iteration 74200, train loss = 0.137461, train accuracy = 0.976562\n",
      "[2018-07-17 19:48:52.556337] Iteration 74300, train loss = 0.235355, train accuracy = 0.953125\n",
      "[2018-07-17 19:49:01.395638] Iteration 74400, train loss = 0.150375, train accuracy = 0.976562\n",
      "[2018-07-17 19:49:10.100888] Iteration 74500, train loss = 0.161399, train accuracy = 0.976562\n",
      "[2018-07-17 19:49:18.879792] Iteration 74600, train loss = 0.147609, train accuracy = 0.984375\n",
      "[2018-07-17 19:49:27.699875] Iteration 74700, train loss = 0.164300, train accuracy = 0.968750\n",
      "[2018-07-17 19:49:36.551961] Iteration 74800, train loss = 0.128603, train accuracy = 0.984375\n",
      "[2018-07-17 19:49:45.393195] Iteration 74900, train loss = 0.166391, train accuracy = 0.960938\n",
      "[2018-07-17 19:49:54.268819] Iteration 75000, train loss = 0.177732, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.892300\n",
      "[2018-07-17 19:50:05.590975] Iteration 75100, train loss = 0.152353, train accuracy = 0.984375\n",
      "[2018-07-17 19:50:14.408811] Iteration 75200, train loss = 0.146872, train accuracy = 0.992188\n",
      "[2018-07-17 19:50:23.128471] Iteration 75300, train loss = 0.122736, train accuracy = 0.992188\n",
      "[2018-07-17 19:50:32.008633] Iteration 75400, train loss = 0.138164, train accuracy = 0.992188\n",
      "[2018-07-17 19:50:40.800087] Iteration 75500, train loss = 0.134565, train accuracy = 0.976562\n",
      "[2018-07-17 19:50:49.656590] Iteration 75600, train loss = 0.133701, train accuracy = 0.976562\n",
      "[2018-07-17 19:50:58.504968] Iteration 75700, train loss = 0.117379, train accuracy = 0.992188\n",
      "[2018-07-17 19:51:07.422727] Iteration 75800, train loss = 0.161330, train accuracy = 0.976562\n",
      "[2018-07-17 19:51:16.382313] Iteration 75900, train loss = 0.109253, train accuracy = 0.992188\n",
      "[2018-07-17 19:51:25.555335] Iteration 76000, train loss = 0.155741, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.892700\n",
      "[2018-07-17 19:51:37.055833] Iteration 76100, train loss = 0.144152, train accuracy = 0.984375\n",
      "[2018-07-17 19:51:45.843172] Iteration 76200, train loss = 0.168342, train accuracy = 0.976562\n",
      "[2018-07-17 19:51:54.610679] Iteration 76300, train loss = 0.170461, train accuracy = 0.968750\n",
      "[2018-07-17 19:52:03.199059] Iteration 76400, train loss = 0.102163, train accuracy = 0.992188\n",
      "[2018-07-17 19:52:11.614027] Iteration 76500, train loss = 0.169784, train accuracy = 0.976562\n",
      "[2018-07-17 19:52:20.081856] Iteration 76600, train loss = 0.150011, train accuracy = 0.984375\n",
      "[2018-07-17 19:52:28.630819] Iteration 76700, train loss = 0.148587, train accuracy = 0.976562\n",
      "[2018-07-17 19:52:37.394728] Iteration 76800, train loss = 0.124911, train accuracy = 1.000000\n",
      "[2018-07-17 19:52:46.217559] Iteration 76900, train loss = 0.139310, train accuracy = 0.960938\n",
      "[2018-07-17 19:52:55.032350] Iteration 77000, train loss = 0.117704, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.892500\n",
      "[2018-07-17 19:53:06.480415] Iteration 77100, train loss = 0.168178, train accuracy = 0.953125\n",
      "[2018-07-17 19:53:15.343418] Iteration 77200, train loss = 0.121110, train accuracy = 0.992188\n",
      "[2018-07-17 19:53:24.199082] Iteration 77300, train loss = 0.141408, train accuracy = 0.984375\n",
      "[2018-07-17 19:53:32.803864] Iteration 77400, train loss = 0.110657, train accuracy = 1.000000\n",
      "[2018-07-17 19:53:41.242371] Iteration 77500, train loss = 0.150942, train accuracy = 0.976562\n",
      "[2018-07-17 19:53:49.770861] Iteration 77600, train loss = 0.151129, train accuracy = 0.968750\n",
      "[2018-07-17 19:53:58.634133] Iteration 77700, train loss = 0.145494, train accuracy = 0.976562\n",
      "[2018-07-17 19:54:07.467431] Iteration 77800, train loss = 0.194145, train accuracy = 0.968750\n",
      "[2018-07-17 19:54:16.253775] Iteration 77900, train loss = 0.111479, train accuracy = 0.992188\n",
      "[2018-07-17 19:54:25.127539] Iteration 78000, train loss = 0.168944, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.891800\n",
      "[2018-07-17 19:54:36.521034] Iteration 78100, train loss = 0.148429, train accuracy = 0.976562\n",
      "[2018-07-17 19:54:45.246559] Iteration 78200, train loss = 0.124731, train accuracy = 0.984375\n",
      "[2018-07-17 19:54:54.011303] Iteration 78300, train loss = 0.166164, train accuracy = 0.984375\n",
      "[2018-07-17 19:55:02.648370] Iteration 78400, train loss = 0.156662, train accuracy = 0.984375\n",
      "[2018-07-17 19:55:11.101704] Iteration 78500, train loss = 0.204792, train accuracy = 0.960938\n",
      "[2018-07-17 19:55:19.932271] Iteration 78600, train loss = 0.140134, train accuracy = 0.968750\n",
      "[2018-07-17 19:55:28.748058] Iteration 78700, train loss = 0.131654, train accuracy = 0.984375\n",
      "[2018-07-17 19:55:37.598872] Iteration 78800, train loss = 0.115069, train accuracy = 0.992188\n",
      "[2018-07-17 19:55:46.438297] Iteration 78900, train loss = 0.098976, train accuracy = 0.992188\n",
      "[2018-07-17 19:55:55.296222] Iteration 79000, train loss = 0.178374, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.888900\n",
      "[2018-07-17 19:56:06.519460] Iteration 79100, train loss = 0.131833, train accuracy = 0.992188\n",
      "[2018-07-17 19:56:14.818975] Iteration 79200, train loss = 0.130964, train accuracy = 0.984375\n",
      "[2018-07-17 19:56:23.529171] Iteration 79300, train loss = 0.140296, train accuracy = 0.976562\n",
      "[2018-07-17 19:56:32.232024] Iteration 79400, train loss = 0.120897, train accuracy = 0.984375\n",
      "[2018-07-17 19:56:41.029151] Iteration 79500, train loss = 0.228285, train accuracy = 0.921875\n",
      "[2018-07-17 19:56:49.840608] Iteration 79600, train loss = 0.174809, train accuracy = 0.984375\n",
      "[2018-07-17 19:56:58.467836] Iteration 79700, train loss = 0.151630, train accuracy = 0.976562\n",
      "[2018-07-17 19:57:07.028322] Iteration 79800, train loss = 0.112095, train accuracy = 1.000000\n",
      "[2018-07-17 19:57:15.898646] Iteration 79900, train loss = 0.115671, train accuracy = 0.992188\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三轮  量化\n",
    "prune_rate = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.889400\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.         -0.08464392  0.          0.125       0.06231114  0.\n",
      "  0.11832674  0.         -0.25        0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.85)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-17 19:59:55.582136] Iteration 100, train loss = 1.320621, train accuracy = 0.546875\n",
      "[2018-07-17 20:00:03.454748] Iteration 200, train loss = 1.184263, train accuracy = 0.617188\n",
      "[2018-07-17 20:00:11.339847] Iteration 300, train loss = 1.021544, train accuracy = 0.703125\n",
      "[2018-07-17 20:00:19.245027] Iteration 400, train loss = 0.926669, train accuracy = 0.718750\n",
      "[2018-07-17 20:00:27.251195] Iteration 500, train loss = 0.854170, train accuracy = 0.703125\n",
      "[2018-07-17 20:00:35.437961] Iteration 600, train loss = 0.814507, train accuracy = 0.734375\n",
      "[2018-07-17 20:00:43.708402] Iteration 700, train loss = 0.918158, train accuracy = 0.687500\n",
      "[2018-07-17 20:00:51.881003] Iteration 800, train loss = 0.748516, train accuracy = 0.742188\n",
      "[2018-07-17 20:01:00.333449] Iteration 900, train loss = 0.722276, train accuracy = 0.781250\n",
      "[2018-07-17 20:01:08.951004] Iteration 1000, train loss = 0.777127, train accuracy = 0.757812\n",
      "Evaluating...\n",
      "Test accuracy = 0.706600\n",
      "[2018-07-17 20:01:19.980476] Iteration 1100, train loss = 0.813447, train accuracy = 0.726562\n",
      "[2018-07-17 20:01:28.541677] Iteration 1200, train loss = 0.648508, train accuracy = 0.812500\n",
      "[2018-07-17 20:01:37.247492] Iteration 1300, train loss = 0.818875, train accuracy = 0.765625\n",
      "[2018-07-17 20:01:46.048427] Iteration 1400, train loss = 0.709630, train accuracy = 0.789062\n",
      "[2018-07-17 20:01:54.835990] Iteration 1500, train loss = 0.642958, train accuracy = 0.781250\n",
      "[2018-07-17 20:02:03.569242] Iteration 1600, train loss = 0.678917, train accuracy = 0.789062\n",
      "[2018-07-17 20:02:12.091686] Iteration 1700, train loss = 0.725123, train accuracy = 0.789062\n",
      "[2018-07-17 20:02:20.921147] Iteration 1800, train loss = 0.551401, train accuracy = 0.835938\n",
      "[2018-07-17 20:02:29.707631] Iteration 1900, train loss = 0.564805, train accuracy = 0.828125\n",
      "[2018-07-17 20:02:38.529394] Iteration 2000, train loss = 0.575156, train accuracy = 0.835938\n",
      "Evaluating...\n",
      "Test accuracy = 0.747400\n",
      "[2018-07-17 20:02:49.881956] Iteration 2100, train loss = 0.608355, train accuracy = 0.812500\n",
      "[2018-07-17 20:02:58.706002] Iteration 2200, train loss = 0.662001, train accuracy = 0.789062\n",
      "[2018-07-17 20:03:07.510093] Iteration 2300, train loss = 0.669388, train accuracy = 0.828125\n",
      "[2018-07-17 20:03:16.079159] Iteration 2400, train loss = 0.510550, train accuracy = 0.851562\n",
      "[2018-07-17 20:03:24.712587] Iteration 2500, train loss = 0.573020, train accuracy = 0.804688\n",
      "[2018-07-17 20:03:33.199759] Iteration 2600, train loss = 0.606845, train accuracy = 0.820312\n",
      "[2018-07-17 20:03:41.971054] Iteration 2700, train loss = 0.520408, train accuracy = 0.835938\n",
      "[2018-07-17 20:03:50.773012] Iteration 2800, train loss = 0.505656, train accuracy = 0.867188\n",
      "[2018-07-17 20:03:59.321507] Iteration 2900, train loss = 0.524109, train accuracy = 0.835938\n",
      "[2018-07-17 20:04:07.940466] Iteration 3000, train loss = 0.640950, train accuracy = 0.828125\n",
      "Evaluating...\n",
      "Test accuracy = 0.795800\n",
      "[2018-07-17 20:04:19.256242] Iteration 3100, train loss = 0.584663, train accuracy = 0.843750\n",
      "[2018-07-17 20:04:28.028909] Iteration 3200, train loss = 0.410120, train accuracy = 0.867188\n",
      "[2018-07-17 20:04:36.595338] Iteration 3300, train loss = 0.550658, train accuracy = 0.796875\n",
      "[2018-07-17 20:04:45.071045] Iteration 3400, train loss = 0.559835, train accuracy = 0.851562\n",
      "[2018-07-17 20:04:53.590960] Iteration 3500, train loss = 0.506030, train accuracy = 0.882812\n",
      "[2018-07-17 20:05:02.358304] Iteration 3600, train loss = 0.597503, train accuracy = 0.773438\n",
      "[2018-07-17 20:05:11.129154] Iteration 3700, train loss = 0.386667, train accuracy = 0.906250\n",
      "[2018-07-17 20:05:19.923948] Iteration 3800, train loss = 0.454928, train accuracy = 0.867188\n",
      "[2018-07-17 20:05:28.706365] Iteration 3900, train loss = 0.542298, train accuracy = 0.843750\n",
      "[2018-07-17 20:05:37.527958] Iteration 4000, train loss = 0.528864, train accuracy = 0.859375\n",
      "Evaluating...\n",
      "Test accuracy = 0.801700\n",
      "[2018-07-17 20:05:48.726202] Iteration 4100, train loss = 0.457997, train accuracy = 0.875000\n",
      "[2018-07-17 20:05:57.499177] Iteration 4200, train loss = 0.544389, train accuracy = 0.859375\n",
      "[2018-07-17 20:06:06.135780] Iteration 4300, train loss = 0.465166, train accuracy = 0.867188\n",
      "[2018-07-17 20:06:14.945242] Iteration 4400, train loss = 0.526618, train accuracy = 0.843750\n",
      "[2018-07-17 20:06:23.773286] Iteration 4500, train loss = 0.410462, train accuracy = 0.859375\n",
      "[2018-07-17 20:06:32.596789] Iteration 4600, train loss = 0.479736, train accuracy = 0.843750\n",
      "[2018-07-17 20:06:41.297969] Iteration 4700, train loss = 0.640251, train accuracy = 0.820312\n",
      "[2018-07-17 20:06:49.860232] Iteration 4800, train loss = 0.469497, train accuracy = 0.835938\n",
      "[2018-07-17 20:06:58.452066] Iteration 4900, train loss = 0.514211, train accuracy = 0.859375\n",
      "[2018-07-17 20:07:06.913334] Iteration 5000, train loss = 0.557761, train accuracy = 0.804688\n",
      "Evaluating...\n",
      "Test accuracy = 0.786200\n",
      "[2018-07-17 20:07:18.270600] Iteration 5100, train loss = 0.401238, train accuracy = 0.882812\n",
      "[2018-07-17 20:07:27.027994] Iteration 5200, train loss = 0.511168, train accuracy = 0.851562\n",
      "[2018-07-17 20:07:35.765072] Iteration 5300, train loss = 0.353194, train accuracy = 0.929688\n",
      "[2018-07-17 20:07:44.477954] Iteration 5400, train loss = 0.464724, train accuracy = 0.820312\n",
      "[2018-07-17 20:07:53.146239] Iteration 5500, train loss = 0.404595, train accuracy = 0.875000\n",
      "[2018-07-17 20:08:01.975260] Iteration 5600, train loss = 0.463605, train accuracy = 0.859375\n",
      "[2018-07-17 20:08:10.696222] Iteration 5700, train loss = 0.382034, train accuracy = 0.921875\n",
      "[2018-07-17 20:08:19.509293] Iteration 5800, train loss = 0.437515, train accuracy = 0.882812\n",
      "[2018-07-17 20:08:28.342569] Iteration 5900, train loss = 0.454331, train accuracy = 0.875000\n",
      "[2018-07-17 20:08:37.035397] Iteration 6000, train loss = 0.429258, train accuracy = 0.867188\n",
      "Evaluating...\n",
      "Test accuracy = 0.756100\n",
      "[2018-07-17 20:08:48.351722] Iteration 6100, train loss = 0.491894, train accuracy = 0.843750\n",
      "[2018-07-17 20:08:57.113403] Iteration 6200, train loss = 0.471228, train accuracy = 0.859375\n",
      "[2018-07-17 20:09:05.722074] Iteration 6300, train loss = 0.467015, train accuracy = 0.859375\n",
      "[2018-07-17 20:09:14.302017] Iteration 6400, train loss = 0.389033, train accuracy = 0.867188\n",
      "[2018-07-17 20:09:23.151474] Iteration 6500, train loss = 0.473413, train accuracy = 0.867188\n",
      "[2018-07-17 20:09:31.977869] Iteration 6600, train loss = 0.474905, train accuracy = 0.882812\n",
      "[2018-07-17 20:09:40.676258] Iteration 6700, train loss = 0.480131, train accuracy = 0.828125\n",
      "[2018-07-17 20:09:49.311255] Iteration 6800, train loss = 0.365385, train accuracy = 0.906250\n",
      "[2018-07-17 20:09:58.158407] Iteration 6900, train loss = 0.435284, train accuracy = 0.906250\n",
      "[2018-07-17 20:10:06.991577] Iteration 7000, train loss = 0.392669, train accuracy = 0.867188\n",
      "Evaluating...\n",
      "Test accuracy = 0.814900\n",
      "[2018-07-17 20:10:18.381580] Iteration 7100, train loss = 0.443314, train accuracy = 0.875000\n",
      "[2018-07-17 20:10:27.134818] Iteration 7200, train loss = 0.328638, train accuracy = 0.945312\n",
      "[2018-07-17 20:10:35.966664] Iteration 7300, train loss = 0.321797, train accuracy = 0.914062\n",
      "[2018-07-17 20:10:44.829443] Iteration 7400, train loss = 0.352828, train accuracy = 0.929688\n",
      "[2018-07-17 20:10:53.337557] Iteration 7500, train loss = 0.455656, train accuracy = 0.890625\n",
      "[2018-07-17 20:11:02.090170] Iteration 7600, train loss = 0.479210, train accuracy = 0.867188\n",
      "[2018-07-17 20:11:10.907246] Iteration 7700, train loss = 0.447797, train accuracy = 0.851562\n",
      "[2018-07-17 20:11:19.667581] Iteration 7800, train loss = 0.371869, train accuracy = 0.890625\n",
      "[2018-07-17 20:11:28.496871] Iteration 7900, train loss = 0.397717, train accuracy = 0.898438\n",
      "[2018-07-17 20:11:37.212138] Iteration 8000, train loss = 0.324485, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.801200\n",
      "[2018-07-17 20:11:48.435328] Iteration 8100, train loss = 0.365188, train accuracy = 0.898438\n",
      "[2018-07-17 20:11:57.177745] Iteration 8200, train loss = 0.353255, train accuracy = 0.906250\n",
      "[2018-07-17 20:12:06.017328] Iteration 8300, train loss = 0.531119, train accuracy = 0.828125\n",
      "[2018-07-17 20:12:14.835204] Iteration 8400, train loss = 0.437719, train accuracy = 0.890625\n",
      "[2018-07-17 20:12:23.460051] Iteration 8500, train loss = 0.606807, train accuracy = 0.781250\n",
      "[2018-07-17 20:12:32.296078] Iteration 8600, train loss = 0.388301, train accuracy = 0.867188\n",
      "[2018-07-17 20:12:41.003895] Iteration 8700, train loss = 0.552575, train accuracy = 0.828125\n",
      "[2018-07-17 20:12:49.814064] Iteration 8800, train loss = 0.423413, train accuracy = 0.859375\n",
      "[2018-07-17 20:12:58.643304] Iteration 8900, train loss = 0.359230, train accuracy = 0.898438\n",
      "[2018-07-17 20:13:07.450869] Iteration 9000, train loss = 0.433429, train accuracy = 0.867188\n",
      "Evaluating...\n",
      "Test accuracy = 0.804400\n",
      "[2018-07-17 20:13:18.817672] Iteration 9100, train loss = 0.539648, train accuracy = 0.804688\n",
      "[2018-07-17 20:13:27.675803] Iteration 9200, train loss = 0.481450, train accuracy = 0.851562\n",
      "[2018-07-17 20:13:36.471695] Iteration 9300, train loss = 0.375964, train accuracy = 0.898438\n",
      "[2018-07-17 20:13:45.214535] Iteration 9400, train loss = 0.369492, train accuracy = 0.898438\n",
      "[2018-07-17 20:13:53.894341] Iteration 9500, train loss = 0.440000, train accuracy = 0.875000\n",
      "[2018-07-17 20:14:02.715117] Iteration 9600, train loss = 0.432328, train accuracy = 0.890625\n",
      "[2018-07-17 20:14:11.462146] Iteration 9700, train loss = 0.460914, train accuracy = 0.828125\n",
      "[2018-07-17 20:14:20.302316] Iteration 9800, train loss = 0.381837, train accuracy = 0.867188\n",
      "[2018-07-17 20:14:29.088809] Iteration 9900, train loss = 0.310236, train accuracy = 0.906250\n",
      "[2018-07-17 20:14:37.639249] Iteration 10000, train loss = 0.518800, train accuracy = 0.851562\n",
      "Evaluating...\n",
      "Test accuracy = 0.802400\n",
      "[2018-07-17 20:14:49.010228] Iteration 10100, train loss = 0.340729, train accuracy = 0.906250\n",
      "[2018-07-17 20:14:57.828176] Iteration 10200, train loss = 0.370322, train accuracy = 0.882812\n",
      "[2018-07-17 20:15:06.630660] Iteration 10300, train loss = 0.455451, train accuracy = 0.875000\n",
      "[2018-07-17 20:15:15.343509] Iteration 10400, train loss = 0.310122, train accuracy = 0.921875\n",
      "[2018-07-17 20:15:23.951690] Iteration 10500, train loss = 0.340346, train accuracy = 0.929688\n",
      "[2018-07-17 20:15:32.591001] Iteration 10600, train loss = 0.392016, train accuracy = 0.851562\n",
      "[2018-07-17 20:15:41.403897] Iteration 10700, train loss = 0.410515, train accuracy = 0.890625\n",
      "[2018-07-17 20:15:50.172051] Iteration 10800, train loss = 0.386257, train accuracy = 0.906250\n",
      "[2018-07-17 20:15:58.911689] Iteration 10900, train loss = 0.377187, train accuracy = 0.882812\n",
      "[2018-07-17 20:16:07.723596] Iteration 11000, train loss = 0.472353, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.822200\n",
      "[2018-07-17 20:16:18.989680] Iteration 11100, train loss = 0.313961, train accuracy = 0.929688\n",
      "[2018-07-17 20:16:27.821090] Iteration 11200, train loss = 0.439181, train accuracy = 0.929688\n",
      "[2018-07-17 20:16:36.520736] Iteration 11300, train loss = 0.418165, train accuracy = 0.875000\n",
      "[2018-07-17 20:16:45.064518] Iteration 11400, train loss = 0.443376, train accuracy = 0.875000\n",
      "[2018-07-17 20:16:53.622155] Iteration 11500, train loss = 0.579096, train accuracy = 0.828125\n",
      "[2018-07-17 20:17:02.126350] Iteration 11600, train loss = 0.366498, train accuracy = 0.906250\n",
      "[2018-07-17 20:17:10.630464] Iteration 11700, train loss = 0.375879, train accuracy = 0.898438\n",
      "[2018-07-17 20:17:19.161401] Iteration 11800, train loss = 0.491183, train accuracy = 0.867188\n",
      "[2018-07-17 20:17:27.788617] Iteration 11900, train loss = 0.409463, train accuracy = 0.890625\n",
      "[2018-07-17 20:17:36.629388] Iteration 12000, train loss = 0.346148, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.824200\n",
      "[2018-07-17 20:17:47.848487] Iteration 12100, train loss = 0.344106, train accuracy = 0.898438\n",
      "[2018-07-17 20:17:56.681711] Iteration 12200, train loss = 0.336799, train accuracy = 0.898438\n",
      "[2018-07-17 20:18:05.449088] Iteration 12300, train loss = 0.379088, train accuracy = 0.906250\n",
      "[2018-07-17 20:18:14.271928] Iteration 12400, train loss = 0.545022, train accuracy = 0.820312\n",
      "[2018-07-17 20:18:23.102333] Iteration 12500, train loss = 0.460843, train accuracy = 0.867188\n",
      "[2018-07-17 20:18:31.864662] Iteration 12600, train loss = 0.383380, train accuracy = 0.875000\n",
      "[2018-07-17 20:18:40.542662] Iteration 12700, train loss = 0.579935, train accuracy = 0.835938\n",
      "[2018-07-17 20:18:49.049792] Iteration 12800, train loss = 0.392228, train accuracy = 0.890625\n",
      "[2018-07-17 20:18:57.659176] Iteration 12900, train loss = 0.381641, train accuracy = 0.906250\n",
      "[2018-07-17 20:19:06.479556] Iteration 13000, train loss = 0.526106, train accuracy = 0.843750\n",
      "Evaluating...\n",
      "Test accuracy = 0.804400\n",
      "[2018-07-17 20:19:17.820536] Iteration 13100, train loss = 0.476743, train accuracy = 0.875000\n",
      "[2018-07-17 20:19:26.436220] Iteration 13200, train loss = 0.292474, train accuracy = 0.921875\n",
      "[2018-07-17 20:19:35.045961] Iteration 13300, train loss = 0.404225, train accuracy = 0.859375\n",
      "[2018-07-17 20:19:43.815474] Iteration 13400, train loss = 0.352672, train accuracy = 0.906250\n",
      "[2018-07-17 20:19:52.546399] Iteration 13500, train loss = 0.289287, train accuracy = 0.914062\n",
      "[2018-07-17 20:20:01.151007] Iteration 13600, train loss = 0.446941, train accuracy = 0.882812\n",
      "[2018-07-17 20:20:09.977411] Iteration 13700, train loss = 0.482268, train accuracy = 0.890625\n",
      "[2018-07-17 20:20:18.780977] Iteration 13800, train loss = 0.366266, train accuracy = 0.921875\n",
      "[2018-07-17 20:20:27.424356] Iteration 13900, train loss = 0.461637, train accuracy = 0.890625\n",
      "[2018-07-17 20:20:36.243323] Iteration 14000, train loss = 0.337831, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.786200\n",
      "[2018-07-17 20:20:47.533381] Iteration 14100, train loss = 0.288549, train accuracy = 0.921875\n",
      "[2018-07-17 20:20:56.267076] Iteration 14200, train loss = 0.393058, train accuracy = 0.882812\n",
      "[2018-07-17 20:21:04.904746] Iteration 14300, train loss = 0.402809, train accuracy = 0.875000\n",
      "[2018-07-17 20:21:13.687735] Iteration 14400, train loss = 0.454695, train accuracy = 0.851562\n",
      "[2018-07-17 20:21:22.428632] Iteration 14500, train loss = 0.464941, train accuracy = 0.859375\n",
      "[2018-07-17 20:21:31.253772] Iteration 14600, train loss = 0.414433, train accuracy = 0.914062\n",
      "[2018-07-17 20:21:39.986392] Iteration 14700, train loss = 0.417983, train accuracy = 0.875000\n",
      "[2018-07-17 20:21:48.706626] Iteration 14800, train loss = 0.363864, train accuracy = 0.890625\n",
      "[2018-07-17 20:21:57.315904] Iteration 14900, train loss = 0.426600, train accuracy = 0.875000\n",
      "[2018-07-17 20:22:05.863344] Iteration 15000, train loss = 0.352533, train accuracy = 0.882812\n",
      "Evaluating...\n",
      "Test accuracy = 0.815200\n",
      "[2018-07-17 20:22:17.165191] Iteration 15100, train loss = 0.313331, train accuracy = 0.890625\n",
      "[2018-07-17 20:22:25.992860] Iteration 15200, train loss = 0.373805, train accuracy = 0.890625\n",
      "[2018-07-17 20:22:34.598989] Iteration 15300, train loss = 0.328450, train accuracy = 0.921875\n",
      "[2018-07-17 20:22:43.240798] Iteration 15400, train loss = 0.366056, train accuracy = 0.882812\n",
      "[2018-07-17 20:22:51.916442] Iteration 15500, train loss = 0.391670, train accuracy = 0.859375\n",
      "[2018-07-17 20:23:00.735119] Iteration 15600, train loss = 0.417017, train accuracy = 0.906250\n",
      "[2018-07-17 20:23:09.534843] Iteration 15700, train loss = 0.341751, train accuracy = 0.898438\n",
      "[2018-07-17 20:23:18.190994] Iteration 15800, train loss = 0.345880, train accuracy = 0.898438\n",
      "[2018-07-17 20:23:26.956586] Iteration 15900, train loss = 0.327538, train accuracy = 0.929688\n",
      "[2018-07-17 20:23:35.619046] Iteration 16000, train loss = 0.426153, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.832000\n",
      "[2018-07-17 20:23:46.960333] Iteration 16100, train loss = 0.414486, train accuracy = 0.851562\n",
      "[2018-07-17 20:23:55.741524] Iteration 16200, train loss = 0.350816, train accuracy = 0.921875\n",
      "[2018-07-17 20:24:04.611131] Iteration 16300, train loss = 0.440942, train accuracy = 0.875000\n",
      "[2018-07-17 20:24:13.448399] Iteration 16400, train loss = 0.441086, train accuracy = 0.906250\n",
      "[2018-07-17 20:24:22.303805] Iteration 16500, train loss = 0.213455, train accuracy = 0.968750\n",
      "[2018-07-17 20:24:31.124497] Iteration 16600, train loss = 0.288453, train accuracy = 0.914062\n",
      "[2018-07-17 20:24:39.945812] Iteration 16700, train loss = 0.400207, train accuracy = 0.859375\n",
      "[2018-07-17 20:24:48.568480] Iteration 16800, train loss = 0.390518, train accuracy = 0.875000\n",
      "[2018-07-17 20:24:57.303929] Iteration 16900, train loss = 0.316714, train accuracy = 0.898438\n",
      "[2018-07-17 20:25:05.937884] Iteration 17000, train loss = 0.292959, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.811500\n",
      "[2018-07-17 20:25:17.111893] Iteration 17100, train loss = 0.459128, train accuracy = 0.867188\n",
      "[2018-07-17 20:25:25.746585] Iteration 17200, train loss = 0.285440, train accuracy = 0.929688\n",
      "[2018-07-17 20:25:34.585597] Iteration 17300, train loss = 0.358817, train accuracy = 0.882812\n",
      "[2018-07-17 20:25:43.422237] Iteration 17400, train loss = 0.385473, train accuracy = 0.867188\n",
      "[2018-07-17 20:25:52.198495] Iteration 17500, train loss = 0.336917, train accuracy = 0.898438\n",
      "[2018-07-17 20:26:00.863701] Iteration 17600, train loss = 0.308685, train accuracy = 0.898438\n",
      "[2018-07-17 20:26:09.668996] Iteration 17700, train loss = 0.337368, train accuracy = 0.898438\n",
      "[2018-07-17 20:26:18.364299] Iteration 17800, train loss = 0.331756, train accuracy = 0.906250\n",
      "[2018-07-17 20:26:27.171602] Iteration 17900, train loss = 0.267914, train accuracy = 0.937500\n",
      "[2018-07-17 20:26:35.990713] Iteration 18000, train loss = 0.400701, train accuracy = 0.875000\n",
      "Evaluating...\n",
      "Test accuracy = 0.814900\n",
      "[2018-07-17 20:26:47.387980] Iteration 18100, train loss = 0.377973, train accuracy = 0.890625\n",
      "[2018-07-17 20:26:56.212189] Iteration 18200, train loss = 0.508013, train accuracy = 0.867188\n",
      "[2018-07-17 20:27:04.864613] Iteration 18300, train loss = 0.382273, train accuracy = 0.914062\n",
      "[2018-07-17 20:27:13.443936] Iteration 18400, train loss = 0.373847, train accuracy = 0.906250\n",
      "[2018-07-17 20:27:22.110952] Iteration 18500, train loss = 0.257260, train accuracy = 0.953125\n",
      "[2018-07-17 20:27:30.669882] Iteration 18600, train loss = 0.443110, train accuracy = 0.890625\n",
      "[2018-07-17 20:27:39.345544] Iteration 18700, train loss = 0.430777, train accuracy = 0.890625\n",
      "[2018-07-17 20:27:48.175711] Iteration 18800, train loss = 0.419753, train accuracy = 0.851562\n",
      "[2018-07-17 20:27:56.963778] Iteration 18900, train loss = 0.304293, train accuracy = 0.945312\n",
      "[2018-07-17 20:28:05.665869] Iteration 19000, train loss = 0.407286, train accuracy = 0.890625\n",
      "Evaluating...\n",
      "Test accuracy = 0.834500\n",
      "[2018-07-17 20:28:16.940900] Iteration 19100, train loss = 0.316639, train accuracy = 0.906250\n",
      "[2018-07-17 20:28:25.590953] Iteration 19200, train loss = 0.396318, train accuracy = 0.890625\n",
      "[2018-07-17 20:28:34.330974] Iteration 19300, train loss = 0.415689, train accuracy = 0.867188\n",
      "[2018-07-17 20:28:43.119288] Iteration 19400, train loss = 0.350350, train accuracy = 0.906250\n",
      "[2018-07-17 20:28:51.942742] Iteration 19500, train loss = 0.476315, train accuracy = 0.875000\n",
      "[2018-07-17 20:29:00.739651] Iteration 19600, train loss = 0.376107, train accuracy = 0.890625\n",
      "[2018-07-17 20:29:09.569417] Iteration 19700, train loss = 0.344179, train accuracy = 0.914062\n",
      "[2018-07-17 20:29:18.435755] Iteration 19800, train loss = 0.292605, train accuracy = 0.921875\n",
      "[2018-07-17 20:29:27.265232] Iteration 19900, train loss = 0.312302, train accuracy = 0.921875\n",
      "[2018-07-17 20:29:35.966877] Iteration 20000, train loss = 0.330625, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.847700\n",
      "[2018-07-17 20:29:47.278079] Iteration 20100, train loss = 0.396041, train accuracy = 0.875000\n",
      "[2018-07-17 20:29:55.913691] Iteration 20200, train loss = 0.372651, train accuracy = 0.898438\n",
      "[2018-07-17 20:30:04.603253] Iteration 20300, train loss = 0.339269, train accuracy = 0.914062\n",
      "[2018-07-17 20:30:13.208995] Iteration 20400, train loss = 0.411626, train accuracy = 0.867188\n",
      "[2018-07-17 20:30:21.802491] Iteration 20500, train loss = 0.290391, train accuracy = 0.937500\n",
      "[2018-07-17 20:30:30.530536] Iteration 20600, train loss = 0.416816, train accuracy = 0.882812\n",
      "[2018-07-17 20:30:39.213549] Iteration 20700, train loss = 0.442432, train accuracy = 0.898438\n",
      "[2018-07-17 20:30:47.945595] Iteration 20800, train loss = 0.386486, train accuracy = 0.875000\n",
      "[2018-07-17 20:30:56.615164] Iteration 20900, train loss = 0.374725, train accuracy = 0.875000\n",
      "[2018-07-17 20:31:05.250181] Iteration 21000, train loss = 0.242183, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.838700\n",
      "[2018-07-17 20:31:16.607200] Iteration 21100, train loss = 0.261304, train accuracy = 0.945312\n",
      "[2018-07-17 20:31:25.446942] Iteration 21200, train loss = 0.329799, train accuracy = 0.890625\n",
      "[2018-07-17 20:31:34.233844] Iteration 21300, train loss = 0.332110, train accuracy = 0.914062\n",
      "[2018-07-17 20:31:43.049975] Iteration 21400, train loss = 0.275686, train accuracy = 0.929688\n",
      "[2018-07-17 20:31:51.660980] Iteration 21500, train loss = 0.390242, train accuracy = 0.875000\n",
      "[2018-07-17 20:32:00.463873] Iteration 21600, train loss = 0.310650, train accuracy = 0.921875\n",
      "[2018-07-17 20:32:09.267181] Iteration 21700, train loss = 0.413295, train accuracy = 0.914062\n",
      "[2018-07-17 20:32:18.107495] Iteration 21800, train loss = 0.336170, train accuracy = 0.882812\n",
      "[2018-07-17 20:32:26.883450] Iteration 21900, train loss = 0.259176, train accuracy = 0.929688\n",
      "[2018-07-17 20:32:35.675919] Iteration 22000, train loss = 0.324253, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.816300\n",
      "[2018-07-17 20:32:47.037271] Iteration 22100, train loss = 0.370042, train accuracy = 0.898438\n",
      "[2018-07-17 20:32:55.800598] Iteration 22200, train loss = 0.386302, train accuracy = 0.906250\n",
      "[2018-07-17 20:33:04.518297] Iteration 22300, train loss = 0.425781, train accuracy = 0.882812\n",
      "[2018-07-17 20:33:13.313898] Iteration 22400, train loss = 0.390493, train accuracy = 0.882812\n",
      "[2018-07-17 20:33:22.110473] Iteration 22500, train loss = 0.341065, train accuracy = 0.906250\n",
      "[2018-07-17 20:33:30.891734] Iteration 22600, train loss = 0.488965, train accuracy = 0.859375\n",
      "[2018-07-17 20:33:39.623940] Iteration 22700, train loss = 0.293098, train accuracy = 0.906250\n",
      "[2018-07-17 20:33:48.354156] Iteration 22800, train loss = 0.299770, train accuracy = 0.929688\n",
      "[2018-07-17 20:33:57.074360] Iteration 22900, train loss = 0.239163, train accuracy = 0.945312\n",
      "[2018-07-17 20:34:05.668583] Iteration 23000, train loss = 0.368046, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.857200\n",
      "[2018-07-17 20:34:16.992930] Iteration 23100, train loss = 0.288548, train accuracy = 0.921875\n",
      "[2018-07-17 20:34:25.724166] Iteration 23200, train loss = 0.372513, train accuracy = 0.906250\n",
      "[2018-07-17 20:34:34.557003] Iteration 23300, train loss = 0.404151, train accuracy = 0.890625\n",
      "[2018-07-17 20:34:43.119658] Iteration 23400, train loss = 0.393078, train accuracy = 0.882812\n",
      "[2018-07-17 20:34:51.829571] Iteration 23500, train loss = 0.435420, train accuracy = 0.890625\n",
      "[2018-07-17 20:35:00.658781] Iteration 23600, train loss = 0.368269, train accuracy = 0.875000\n",
      "[2018-07-17 20:35:09.416047] Iteration 23700, train loss = 0.291259, train accuracy = 0.921875\n",
      "[2018-07-17 20:35:18.068641] Iteration 23800, train loss = 0.315503, train accuracy = 0.937500\n",
      "[2018-07-17 20:35:26.628669] Iteration 23900, train loss = 0.384617, train accuracy = 0.890625\n",
      "[2018-07-17 20:35:35.242872] Iteration 24000, train loss = 0.264805, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.852600\n",
      "[2018-07-17 20:35:46.597166] Iteration 24100, train loss = 0.338355, train accuracy = 0.906250\n",
      "[2018-07-17 20:35:55.450226] Iteration 24200, train loss = 0.370987, train accuracy = 0.898438\n",
      "[2018-07-17 20:36:04.295257] Iteration 24300, train loss = 0.361215, train accuracy = 0.882812\n",
      "[2018-07-17 20:36:12.991007] Iteration 24400, train loss = 0.299111, train accuracy = 0.914062\n",
      "[2018-07-17 20:36:21.820859] Iteration 24500, train loss = 0.315695, train accuracy = 0.914062\n",
      "[2018-07-17 20:36:30.522126] Iteration 24600, train loss = 0.550956, train accuracy = 0.828125\n",
      "[2018-07-17 20:36:39.301188] Iteration 24700, train loss = 0.368181, train accuracy = 0.898438\n",
      "[2018-07-17 20:36:47.991572] Iteration 24800, train loss = 0.274812, train accuracy = 0.929688\n",
      "[2018-07-17 20:36:56.793723] Iteration 24900, train loss = 0.269499, train accuracy = 0.953125\n",
      "[2018-07-17 20:37:05.437261] Iteration 25000, train loss = 0.396746, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.829500\n",
      "[2018-07-17 20:37:16.778137] Iteration 25100, train loss = 0.322968, train accuracy = 0.898438\n",
      "[2018-07-17 20:37:25.518355] Iteration 25200, train loss = 0.292970, train accuracy = 0.953125\n",
      "[2018-07-17 20:37:34.321201] Iteration 25300, train loss = 0.381505, train accuracy = 0.914062\n",
      "[2018-07-17 20:37:43.097602] Iteration 25400, train loss = 0.231765, train accuracy = 0.953125\n",
      "[2018-07-17 20:37:51.823730] Iteration 25500, train loss = 0.273959, train accuracy = 0.914062\n",
      "[2018-07-17 20:38:00.494915] Iteration 25600, train loss = 0.305318, train accuracy = 0.914062\n",
      "[2018-07-17 20:38:09.312846] Iteration 25700, train loss = 0.305531, train accuracy = 0.906250\n",
      "[2018-07-17 20:38:18.136676] Iteration 25800, train loss = 0.308740, train accuracy = 0.906250\n",
      "[2018-07-17 20:38:26.982617] Iteration 25900, train loss = 0.402694, train accuracy = 0.867188\n",
      "[2018-07-17 20:38:35.795766] Iteration 26000, train loss = 0.316459, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.822700\n",
      "[2018-07-17 20:38:47.068541] Iteration 26100, train loss = 0.358496, train accuracy = 0.882812\n",
      "[2018-07-17 20:38:55.891875] Iteration 26200, train loss = 0.334930, train accuracy = 0.914062\n",
      "[2018-07-17 20:39:04.671619] Iteration 26300, train loss = 0.369455, train accuracy = 0.906250\n",
      "[2018-07-17 20:39:13.463985] Iteration 26400, train loss = 0.325458, train accuracy = 0.906250\n",
      "[2018-07-17 20:39:22.138635] Iteration 26500, train loss = 0.257546, train accuracy = 0.937500\n",
      "[2018-07-17 20:39:30.943929] Iteration 26600, train loss = 0.402056, train accuracy = 0.882812\n",
      "[2018-07-17 20:39:39.702250] Iteration 26700, train loss = 0.279130, train accuracy = 0.960938\n",
      "[2018-07-17 20:39:48.546775] Iteration 26800, train loss = 0.262237, train accuracy = 0.929688\n",
      "[2018-07-17 20:39:57.231252] Iteration 26900, train loss = 0.283223, train accuracy = 0.890625\n",
      "[2018-07-17 20:40:05.712741] Iteration 27000, train loss = 0.365497, train accuracy = 0.898438\n",
      "Evaluating...\n",
      "Test accuracy = 0.846000\n",
      "[2018-07-17 20:40:17.004776] Iteration 27100, train loss = 0.444047, train accuracy = 0.851562\n",
      "[2018-07-17 20:40:25.700881] Iteration 27200, train loss = 0.399042, train accuracy = 0.859375\n",
      "[2018-07-17 20:40:34.539045] Iteration 27300, train loss = 0.277350, train accuracy = 0.914062\n",
      "[2018-07-17 20:40:43.314111] Iteration 27400, train loss = 0.310309, train accuracy = 0.914062\n",
      "[2018-07-17 20:40:52.017063] Iteration 27500, train loss = 0.394206, train accuracy = 0.875000\n",
      "[2018-07-17 20:41:00.675123] Iteration 27600, train loss = 0.335561, train accuracy = 0.929688\n",
      "[2018-07-17 20:41:09.140462] Iteration 27700, train loss = 0.284189, train accuracy = 0.929688\n",
      "[2018-07-17 20:41:17.712415] Iteration 27800, train loss = 0.380009, train accuracy = 0.890625\n",
      "[2018-07-17 20:41:26.338889] Iteration 27900, train loss = 0.304406, train accuracy = 0.914062\n",
      "[2018-07-17 20:41:34.950062] Iteration 28000, train loss = 0.345818, train accuracy = 0.882812\n",
      "Evaluating...\n",
      "Test accuracy = 0.843200\n",
      "[2018-07-17 20:41:46.146124] Iteration 28100, train loss = 0.399668, train accuracy = 0.882812\n",
      "[2018-07-17 20:41:54.976417] Iteration 28200, train loss = 0.316611, train accuracy = 0.898438\n",
      "[2018-07-17 20:42:03.607085] Iteration 28300, train loss = 0.334353, train accuracy = 0.906250\n",
      "[2018-07-17 20:42:12.188749] Iteration 28400, train loss = 0.370528, train accuracy = 0.859375\n",
      "[2018-07-17 20:42:20.856114] Iteration 28500, train loss = 0.383195, train accuracy = 0.906250\n",
      "[2018-07-17 20:42:29.706369] Iteration 28600, train loss = 0.402350, train accuracy = 0.898438\n",
      "[2018-07-17 20:42:38.547884] Iteration 28700, train loss = 0.398304, train accuracy = 0.867188\n",
      "[2018-07-17 20:42:47.129220] Iteration 28800, train loss = 0.295031, train accuracy = 0.929688\n",
      "[2018-07-17 20:42:55.878337] Iteration 28900, train loss = 0.321856, train accuracy = 0.914062\n",
      "[2018-07-17 20:43:04.606777] Iteration 29000, train loss = 0.377236, train accuracy = 0.890625\n",
      "Evaluating...\n",
      "Test accuracy = 0.842000\n",
      "[2018-07-17 20:43:15.804867] Iteration 29100, train loss = 0.292929, train accuracy = 0.929688\n",
      "[2018-07-17 20:43:24.621553] Iteration 29200, train loss = 0.390784, train accuracy = 0.875000\n",
      "[2018-07-17 20:43:33.408545] Iteration 29300, train loss = 0.353059, train accuracy = 0.921875\n",
      "[2018-07-17 20:43:42.092720] Iteration 29400, train loss = 0.367840, train accuracy = 0.906250\n",
      "[2018-07-17 20:43:50.863770] Iteration 29500, train loss = 0.408206, train accuracy = 0.890625\n",
      "[2018-07-17 20:43:59.363409] Iteration 29600, train loss = 0.357364, train accuracy = 0.882812\n",
      "[2018-07-17 20:44:08.050529] Iteration 29700, train loss = 0.241853, train accuracy = 0.937500\n",
      "[2018-07-17 20:44:16.773905] Iteration 29800, train loss = 0.420536, train accuracy = 0.859375\n",
      "[2018-07-17 20:44:25.567647] Iteration 29900, train loss = 0.369418, train accuracy = 0.906250\n",
      "[2018-07-17 20:44:34.401673] Iteration 30000, train loss = 0.330056, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.824200\n",
      "[2018-07-17 20:44:45.778677] Iteration 30100, train loss = 0.316636, train accuracy = 0.914062\n",
      "[2018-07-17 20:44:54.432290] Iteration 30200, train loss = 0.331186, train accuracy = 0.906250\n",
      "[2018-07-17 20:45:03.196976] Iteration 30300, train loss = 0.264576, train accuracy = 0.937500\n",
      "[2018-07-17 20:45:11.815489] Iteration 30400, train loss = 0.308235, train accuracy = 0.906250\n",
      "[2018-07-17 20:45:20.393215] Iteration 30500, train loss = 0.312239, train accuracy = 0.921875\n",
      "[2018-07-17 20:45:29.066823] Iteration 30600, train loss = 0.261458, train accuracy = 0.937500\n",
      "[2018-07-17 20:45:37.776794] Iteration 30700, train loss = 0.313668, train accuracy = 0.914062\n",
      "[2018-07-17 20:45:46.588266] Iteration 30800, train loss = 0.275367, train accuracy = 0.929688\n",
      "[2018-07-17 20:45:55.391291] Iteration 30900, train loss = 0.355133, train accuracy = 0.906250\n",
      "[2018-07-17 20:46:04.174808] Iteration 31000, train loss = 0.475710, train accuracy = 0.859375\n",
      "Evaluating...\n",
      "Test accuracy = 0.834900\n",
      "[2018-07-17 20:46:15.452505] Iteration 31100, train loss = 0.331495, train accuracy = 0.921875\n",
      "[2018-07-17 20:46:24.083520] Iteration 31200, train loss = 0.311184, train accuracy = 0.906250\n",
      "[2018-07-17 20:46:32.836947] Iteration 31300, train loss = 0.404582, train accuracy = 0.898438\n",
      "[2018-07-17 20:46:41.491849] Iteration 31400, train loss = 0.329011, train accuracy = 0.906250\n",
      "[2018-07-17 20:46:50.067911] Iteration 31500, train loss = 0.278758, train accuracy = 0.945312\n",
      "[2018-07-17 20:46:58.875692] Iteration 31600, train loss = 0.360126, train accuracy = 0.906250\n",
      "[2018-07-17 20:47:07.628695] Iteration 31700, train loss = 0.362537, train accuracy = 0.921875\n",
      "[2018-07-17 20:47:16.306279] Iteration 31800, train loss = 0.274579, train accuracy = 0.906250\n",
      "[2018-07-17 20:47:24.964194] Iteration 31900, train loss = 0.320142, train accuracy = 0.929688\n",
      "[2018-07-17 20:47:33.680255] Iteration 32000, train loss = 0.311808, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.854100\n",
      "[2018-07-17 20:47:44.904338] Iteration 32100, train loss = 0.264994, train accuracy = 0.929688\n",
      "[2018-07-17 20:47:53.480335] Iteration 32200, train loss = 0.368687, train accuracy = 0.890625\n",
      "[2018-07-17 20:48:02.247916] Iteration 32300, train loss = 0.420368, train accuracy = 0.898438\n",
      "[2018-07-17 20:48:10.944010] Iteration 32400, train loss = 0.350906, train accuracy = 0.890625\n",
      "[2018-07-17 20:48:19.772758] Iteration 32500, train loss = 0.327910, train accuracy = 0.921875\n",
      "[2018-07-17 20:48:28.504183] Iteration 32600, train loss = 0.334971, train accuracy = 0.898438\n",
      "[2018-07-17 20:48:37.346831] Iteration 32700, train loss = 0.281946, train accuracy = 0.937500\n",
      "[2018-07-17 20:48:46.005098] Iteration 32800, train loss = 0.331421, train accuracy = 0.906250\n",
      "[2018-07-17 20:48:54.675904] Iteration 32900, train loss = 0.327959, train accuracy = 0.929688\n",
      "[2018-07-17 20:49:03.352549] Iteration 33000, train loss = 0.329204, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.837500\n",
      "[2018-07-17 20:49:14.618158] Iteration 33100, train loss = 0.353833, train accuracy = 0.914062\n",
      "[2018-07-17 20:49:23.419452] Iteration 33200, train loss = 0.279014, train accuracy = 0.929688\n",
      "[2018-07-17 20:49:32.128401] Iteration 33300, train loss = 0.313437, train accuracy = 0.914062\n",
      "[2018-07-17 20:49:40.879458] Iteration 33400, train loss = 0.222455, train accuracy = 0.953125\n",
      "[2018-07-17 20:49:49.660506] Iteration 33500, train loss = 0.263878, train accuracy = 0.929688\n",
      "[2018-07-17 20:49:58.413666] Iteration 33600, train loss = 0.418566, train accuracy = 0.882812\n",
      "[2018-07-17 20:50:07.242877] Iteration 33700, train loss = 0.279377, train accuracy = 0.929688\n",
      "[2018-07-17 20:50:16.087824] Iteration 33800, train loss = 0.290475, train accuracy = 0.898438\n",
      "[2018-07-17 20:50:24.791710] Iteration 33900, train loss = 0.303872, train accuracy = 0.929688\n",
      "[2018-07-17 20:50:33.637035] Iteration 34000, train loss = 0.308814, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.841700\n",
      "[2018-07-17 20:50:44.873986] Iteration 34100, train loss = 0.314003, train accuracy = 0.929688\n",
      "[2018-07-17 20:50:53.668852] Iteration 34200, train loss = 0.295443, train accuracy = 0.921875\n",
      "[2018-07-17 20:51:02.399559] Iteration 34300, train loss = 0.434365, train accuracy = 0.867188\n",
      "[2018-07-17 20:51:10.891973] Iteration 34400, train loss = 0.299185, train accuracy = 0.914062\n",
      "[2018-07-17 20:51:19.568479] Iteration 34500, train loss = 0.341227, train accuracy = 0.921875\n",
      "[2018-07-17 20:51:28.363703] Iteration 34600, train loss = 0.277062, train accuracy = 0.914062\n",
      "[2018-07-17 20:51:37.103206] Iteration 34700, train loss = 0.234547, train accuracy = 0.945312\n",
      "[2018-07-17 20:51:45.727018] Iteration 34800, train loss = 0.349491, train accuracy = 0.929688\n",
      "[2018-07-17 20:51:54.426249] Iteration 34900, train loss = 0.248526, train accuracy = 0.953125\n",
      "[2018-07-17 20:52:03.172865] Iteration 35000, train loss = 0.265818, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.856600\n",
      "[2018-07-17 20:52:14.315458] Iteration 35100, train loss = 0.249466, train accuracy = 0.953125\n",
      "[2018-07-17 20:52:22.901110] Iteration 35200, train loss = 0.231229, train accuracy = 0.953125\n",
      "[2018-07-17 20:52:31.731534] Iteration 35300, train loss = 0.265729, train accuracy = 0.937500\n",
      "[2018-07-17 20:52:40.528476] Iteration 35400, train loss = 0.430215, train accuracy = 0.898438\n",
      "[2018-07-17 20:52:49.100017] Iteration 35500, train loss = 0.304442, train accuracy = 0.921875\n",
      "[2018-07-17 20:52:57.823687] Iteration 35600, train loss = 0.422882, train accuracy = 0.875000\n",
      "[2018-07-17 20:53:06.663785] Iteration 35700, train loss = 0.300149, train accuracy = 0.921875\n",
      "[2018-07-17 20:53:15.458066] Iteration 35800, train loss = 0.231041, train accuracy = 0.953125\n",
      "[2018-07-17 20:53:24.282854] Iteration 35900, train loss = 0.291650, train accuracy = 0.937500\n",
      "[2018-07-17 20:53:32.948457] Iteration 36000, train loss = 0.342682, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.827400\n",
      "[2018-07-17 20:53:44.270101] Iteration 36100, train loss = 0.308049, train accuracy = 0.898438\n",
      "[2018-07-17 20:53:52.877519] Iteration 36200, train loss = 0.297049, train accuracy = 0.921875\n",
      "[2018-07-17 20:54:01.488244] Iteration 36300, train loss = 0.333741, train accuracy = 0.914062\n",
      "[2018-07-17 20:54:09.954587] Iteration 36400, train loss = 0.339638, train accuracy = 0.898438\n",
      "[2018-07-17 20:54:18.436061] Iteration 36500, train loss = 0.239652, train accuracy = 0.937500\n",
      "[2018-07-17 20:54:27.098414] Iteration 36600, train loss = 0.363912, train accuracy = 0.906250\n",
      "[2018-07-17 20:54:35.831681] Iteration 36700, train loss = 0.296596, train accuracy = 0.937500\n",
      "[2018-07-17 20:54:44.463628] Iteration 36800, train loss = 0.261732, train accuracy = 0.968750\n",
      "[2018-07-17 20:54:53.008906] Iteration 36900, train loss = 0.307265, train accuracy = 0.929688\n",
      "[2018-07-17 20:55:01.779253] Iteration 37000, train loss = 0.219138, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.837800\n",
      "[2018-07-17 20:55:13.120613] Iteration 37100, train loss = 0.298293, train accuracy = 0.906250\n",
      "[2018-07-17 20:55:21.965057] Iteration 37200, train loss = 0.386496, train accuracy = 0.906250\n",
      "[2018-07-17 20:55:30.642170] Iteration 37300, train loss = 0.428667, train accuracy = 0.867188\n",
      "[2018-07-17 20:55:39.344220] Iteration 37400, train loss = 0.417298, train accuracy = 0.875000\n",
      "[2018-07-17 20:55:47.821771] Iteration 37500, train loss = 0.411953, train accuracy = 0.890625\n",
      "[2018-07-17 20:55:56.365260] Iteration 37600, train loss = 0.289754, train accuracy = 0.929688\n",
      "[2018-07-17 20:56:05.023467] Iteration 37700, train loss = 0.262311, train accuracy = 0.929688\n",
      "[2018-07-17 20:56:13.819370] Iteration 37800, train loss = 0.333029, train accuracy = 0.890625\n",
      "[2018-07-17 20:56:22.585554] Iteration 37900, train loss = 0.368575, train accuracy = 0.898438\n",
      "[2018-07-17 20:56:31.423891] Iteration 38000, train loss = 0.360529, train accuracy = 0.882812\n",
      "Evaluating...\n",
      "Test accuracy = 0.847700\n",
      "[2018-07-17 20:56:42.586884] Iteration 38100, train loss = 0.359242, train accuracy = 0.898438\n",
      "[2018-07-17 20:56:51.082129] Iteration 38200, train loss = 0.263804, train accuracy = 0.945312\n",
      "[2018-07-17 20:56:59.603768] Iteration 38300, train loss = 0.307265, train accuracy = 0.914062\n",
      "[2018-07-17 20:57:08.410700] Iteration 38400, train loss = 0.330000, train accuracy = 0.921875\n",
      "[2018-07-17 20:57:17.209297] Iteration 38500, train loss = 0.232682, train accuracy = 0.953125\n",
      "[2018-07-17 20:57:25.745764] Iteration 38600, train loss = 0.301007, train accuracy = 0.914062\n",
      "[2018-07-17 20:57:34.465319] Iteration 38700, train loss = 0.236593, train accuracy = 0.968750\n",
      "[2018-07-17 20:57:43.086744] Iteration 38800, train loss = 0.313843, train accuracy = 0.906250\n",
      "[2018-07-17 20:57:51.667374] Iteration 38900, train loss = 0.361521, train accuracy = 0.921875\n",
      "[2018-07-17 20:58:00.360268] Iteration 39000, train loss = 0.295106, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.852100\n",
      "[2018-07-17 20:58:11.664204] Iteration 39100, train loss = 0.411365, train accuracy = 0.882812\n",
      "[2018-07-17 20:58:20.487061] Iteration 39200, train loss = 0.378245, train accuracy = 0.898438\n",
      "[2018-07-17 20:58:29.285377] Iteration 39300, train loss = 0.337530, train accuracy = 0.914062\n",
      "[2018-07-17 20:58:38.051700] Iteration 39400, train loss = 0.288322, train accuracy = 0.921875\n",
      "[2018-07-17 20:58:46.863105] Iteration 39500, train loss = 0.392671, train accuracy = 0.890625\n",
      "[2018-07-17 20:58:55.640844] Iteration 39600, train loss = 0.356725, train accuracy = 0.898438\n",
      "[2018-07-17 20:59:04.348149] Iteration 39700, train loss = 0.333080, train accuracy = 0.906250\n",
      "[2018-07-17 20:59:13.053515] Iteration 39800, train loss = 0.314391, train accuracy = 0.914062\n",
      "[2018-07-17 20:59:21.752436] Iteration 39900, train loss = 0.255725, train accuracy = 0.953125\n",
      "[2018-07-17 20:59:30.575532] Iteration 40000, train loss = 0.383048, train accuracy = 0.890625\n",
      "Evaluating...\n",
      "Test accuracy = 0.836400\n",
      "[2018-07-17 20:59:41.608804] Iteration 40100, train loss = 0.347732, train accuracy = 0.906250\n",
      "[2018-07-17 20:59:50.119547] Iteration 40200, train loss = 0.244225, train accuracy = 0.945312\n",
      "[2018-07-17 20:59:58.677048] Iteration 40300, train loss = 0.291443, train accuracy = 0.921875\n",
      "[2018-07-17 21:00:07.486640] Iteration 40400, train loss = 0.263775, train accuracy = 0.937500\n",
      "[2018-07-17 21:00:16.223106] Iteration 40500, train loss = 0.300468, train accuracy = 0.914062\n",
      "[2018-07-17 21:00:24.843439] Iteration 40600, train loss = 0.286633, train accuracy = 0.906250\n",
      "[2018-07-17 21:00:33.583572] Iteration 40700, train loss = 0.355272, train accuracy = 0.890625\n",
      "[2018-07-17 21:00:42.128176] Iteration 40800, train loss = 0.400336, train accuracy = 0.890625\n",
      "[2018-07-17 21:00:50.857257] Iteration 40900, train loss = 0.388690, train accuracy = 0.875000\n",
      "[2018-07-17 21:00:59.687366] Iteration 41000, train loss = 0.343179, train accuracy = 0.914062\n",
      "Evaluating...\n",
      "Test accuracy = 0.821700\n",
      "[2018-07-17 21:01:11.081425] Iteration 41100, train loss = 0.306625, train accuracy = 0.906250\n",
      "[2018-07-17 21:01:19.877838] Iteration 41200, train loss = 0.343895, train accuracy = 0.906250\n",
      "[2018-07-17 21:01:28.670301] Iteration 41300, train loss = 0.266624, train accuracy = 0.921875\n",
      "[2018-07-17 21:01:37.388600] Iteration 41400, train loss = 0.280949, train accuracy = 0.929688\n",
      "[2018-07-17 21:01:46.143652] Iteration 41500, train loss = 0.319261, train accuracy = 0.914062\n",
      "[2018-07-17 21:01:54.990125] Iteration 41600, train loss = 0.249764, train accuracy = 0.953125\n",
      "[2018-07-17 21:02:03.766788] Iteration 41700, train loss = 0.247265, train accuracy = 0.921875\n",
      "[2018-07-17 21:02:12.515080] Iteration 41800, train loss = 0.271676, train accuracy = 0.914062\n",
      "[2018-07-17 21:02:21.350848] Iteration 41900, train loss = 0.261594, train accuracy = 0.945312\n",
      "[2018-07-17 21:02:30.216386] Iteration 42000, train loss = 0.443722, train accuracy = 0.867188\n",
      "Evaluating...\n",
      "Test accuracy = 0.795700\n",
      "[2018-07-17 21:02:41.562281] Iteration 42100, train loss = 0.240230, train accuracy = 0.945312\n",
      "[2018-07-17 21:02:50.328794] Iteration 42200, train loss = 0.343217, train accuracy = 0.890625\n",
      "[2018-07-17 21:02:59.175004] Iteration 42300, train loss = 0.214747, train accuracy = 0.953125\n",
      "[2018-07-17 21:03:07.996926] Iteration 42400, train loss = 0.363598, train accuracy = 0.890625\n",
      "[2018-07-17 21:03:16.693749] Iteration 42500, train loss = 0.280491, train accuracy = 0.921875\n",
      "[2018-07-17 21:03:25.421553] Iteration 42600, train loss = 0.393166, train accuracy = 0.906250\n",
      "[2018-07-17 21:03:34.073898] Iteration 42700, train loss = 0.263808, train accuracy = 0.945312\n",
      "[2018-07-17 21:03:42.779785] Iteration 42800, train loss = 0.399890, train accuracy = 0.867188\n",
      "[2018-07-17 21:03:51.530409] Iteration 42900, train loss = 0.431199, train accuracy = 0.875000\n",
      "[2018-07-17 21:04:00.322826] Iteration 43000, train loss = 0.300063, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.822700\n",
      "[2018-07-17 21:04:11.630444] Iteration 43100, train loss = 0.258333, train accuracy = 0.929688\n",
      "[2018-07-17 21:04:20.431838] Iteration 43200, train loss = 0.304361, train accuracy = 0.921875\n",
      "[2018-07-17 21:04:29.195447] Iteration 43300, train loss = 0.370403, train accuracy = 0.921875\n",
      "[2018-07-17 21:04:37.996050] Iteration 43400, train loss = 0.320947, train accuracy = 0.898438\n",
      "[2018-07-17 21:04:46.819311] Iteration 43500, train loss = 0.362049, train accuracy = 0.906250\n",
      "[2018-07-17 21:04:55.364171] Iteration 43600, train loss = 0.302694, train accuracy = 0.921875\n",
      "[2018-07-17 21:05:03.926221] Iteration 43700, train loss = 0.330441, train accuracy = 0.906250\n",
      "[2018-07-17 21:05:12.632978] Iteration 43800, train loss = 0.319694, train accuracy = 0.921875\n",
      "[2018-07-17 21:05:21.225014] Iteration 43900, train loss = 0.260815, train accuracy = 0.945312\n",
      "[2018-07-17 21:05:29.999734] Iteration 44000, train loss = 0.264869, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.806200\n",
      "[2018-07-17 21:05:41.361980] Iteration 44100, train loss = 0.257896, train accuracy = 0.929688\n",
      "[2018-07-17 21:05:50.086751] Iteration 44200, train loss = 0.251321, train accuracy = 0.937500\n",
      "[2018-07-17 21:05:58.918482] Iteration 44300, train loss = 0.447944, train accuracy = 0.875000\n",
      "[2018-07-17 21:06:07.753148] Iteration 44400, train loss = 0.374368, train accuracy = 0.890625\n",
      "[2018-07-17 21:06:16.489538] Iteration 44500, train loss = 0.339372, train accuracy = 0.882812\n",
      "[2018-07-17 21:06:25.278825] Iteration 44600, train loss = 0.283474, train accuracy = 0.937500\n",
      "[2018-07-17 21:06:33.891785] Iteration 44700, train loss = 0.284833, train accuracy = 0.953125\n",
      "[2018-07-17 21:06:42.709966] Iteration 44800, train loss = 0.209965, train accuracy = 0.968750\n",
      "[2018-07-17 21:06:51.563199] Iteration 44900, train loss = 0.257015, train accuracy = 0.929688\n",
      "[2018-07-17 21:07:00.258162] Iteration 45000, train loss = 0.338967, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.794400\n",
      "[2018-07-17 21:07:11.473899] Iteration 45100, train loss = 0.235628, train accuracy = 0.953125\n",
      "[2018-07-17 21:07:20.191523] Iteration 45200, train loss = 0.322118, train accuracy = 0.921875\n",
      "[2018-07-17 21:07:28.909802] Iteration 45300, train loss = 0.202523, train accuracy = 0.968750\n",
      "[2018-07-17 21:07:37.672534] Iteration 45400, train loss = 0.326880, train accuracy = 0.921875\n",
      "[2018-07-17 21:07:46.337531] Iteration 45500, train loss = 0.224832, train accuracy = 0.968750\n",
      "[2018-07-17 21:07:55.072458] Iteration 45600, train loss = 0.306074, train accuracy = 0.937500\n",
      "[2018-07-17 21:08:03.902312] Iteration 45700, train loss = 0.283811, train accuracy = 0.921875\n",
      "[2018-07-17 21:08:12.749208] Iteration 45800, train loss = 0.258059, train accuracy = 0.937500\n",
      "[2018-07-17 21:08:21.552606] Iteration 45900, train loss = 0.278664, train accuracy = 0.906250\n",
      "[2018-07-17 21:08:30.334144] Iteration 46000, train loss = 0.297183, train accuracy = 0.890625\n",
      "Evaluating...\n",
      "Test accuracy = 0.830100\n",
      "[2018-07-17 21:08:41.648094] Iteration 46100, train loss = 0.266493, train accuracy = 0.929688\n",
      "[2018-07-17 21:08:50.414028] Iteration 46200, train loss = 0.390466, train accuracy = 0.906250\n",
      "[2018-07-17 21:08:59.194032] Iteration 46300, train loss = 0.351625, train accuracy = 0.898438\n",
      "[2018-07-17 21:09:08.045900] Iteration 46400, train loss = 0.327576, train accuracy = 0.898438\n",
      "[2018-07-17 21:09:16.501019] Iteration 46500, train loss = 0.196973, train accuracy = 0.960938\n",
      "[2018-07-17 21:09:25.095739] Iteration 46600, train loss = 0.273946, train accuracy = 0.937500\n",
      "[2018-07-17 21:09:33.866574] Iteration 46700, train loss = 0.351984, train accuracy = 0.906250\n",
      "[2018-07-17 21:09:42.630353] Iteration 46800, train loss = 0.223406, train accuracy = 0.976562\n",
      "[2018-07-17 21:09:51.366971] Iteration 46900, train loss = 0.263745, train accuracy = 0.945312\n",
      "[2018-07-17 21:10:00.197690] Iteration 47000, train loss = 0.301128, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.860100\n",
      "[2018-07-17 21:10:11.486282] Iteration 47100, train loss = 0.364030, train accuracy = 0.906250\n",
      "[2018-07-17 21:10:20.277826] Iteration 47200, train loss = 0.267396, train accuracy = 0.929688\n",
      "[2018-07-17 21:10:28.883989] Iteration 47300, train loss = 0.353736, train accuracy = 0.890625\n",
      "[2018-07-17 21:10:37.513681] Iteration 47400, train loss = 0.259520, train accuracy = 0.953125\n",
      "[2018-07-17 21:10:46.236905] Iteration 47500, train loss = 0.270496, train accuracy = 0.937500\n",
      "[2018-07-17 21:10:55.070675] Iteration 47600, train loss = 0.240765, train accuracy = 0.953125\n",
      "[2018-07-17 21:11:03.920567] Iteration 47700, train loss = 0.444933, train accuracy = 0.851562\n",
      "[2018-07-17 21:11:12.750985] Iteration 47800, train loss = 0.241186, train accuracy = 0.945312\n",
      "[2018-07-17 21:11:21.549232] Iteration 47900, train loss = 0.249469, train accuracy = 0.937500\n",
      "[2018-07-17 21:11:30.365625] Iteration 48000, train loss = 0.252259, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.836700\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-17 21:11:41.721250] Iteration 48100, train loss = 0.287954, train accuracy = 0.929688\n",
      "[2018-07-17 21:11:50.534940] Iteration 48200, train loss = 0.281306, train accuracy = 0.914062\n",
      "[2018-07-17 21:11:59.064712] Iteration 48300, train loss = 0.290685, train accuracy = 0.914062\n",
      "[2018-07-17 21:12:07.794190] Iteration 48400, train loss = 0.282007, train accuracy = 0.953125\n",
      "[2018-07-17 21:12:16.595846] Iteration 48500, train loss = 0.212574, train accuracy = 0.960938\n",
      "[2018-07-17 21:12:25.238285] Iteration 48600, train loss = 0.327527, train accuracy = 0.921875\n",
      "[2018-07-17 21:12:33.979221] Iteration 48700, train loss = 0.342257, train accuracy = 0.882812\n",
      "[2018-07-17 21:12:42.784316] Iteration 48800, train loss = 0.249284, train accuracy = 0.929688\n",
      "[2018-07-17 21:12:51.594209] Iteration 48900, train loss = 0.261663, train accuracy = 0.929688\n",
      "[2018-07-17 21:13:00.339352] Iteration 49000, train loss = 0.262063, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.885100\n",
      "[2018-07-17 21:13:11.734267] Iteration 49100, train loss = 0.225903, train accuracy = 0.960938\n",
      "[2018-07-17 21:13:20.451386] Iteration 49200, train loss = 0.212113, train accuracy = 0.968750\n",
      "[2018-07-17 21:13:29.248619] Iteration 49300, train loss = 0.232627, train accuracy = 0.953125\n",
      "[2018-07-17 21:13:37.959871] Iteration 49400, train loss = 0.188101, train accuracy = 0.960938\n",
      "[2018-07-17 21:13:46.750746] Iteration 49500, train loss = 0.262682, train accuracy = 0.937500\n",
      "[2018-07-17 21:13:55.377779] Iteration 49600, train loss = 0.201885, train accuracy = 0.960938\n",
      "[2018-07-17 21:14:04.132196] Iteration 49700, train loss = 0.200688, train accuracy = 0.953125\n",
      "[2018-07-17 21:14:12.978890] Iteration 49800, train loss = 0.196638, train accuracy = 0.960938\n",
      "[2018-07-17 21:14:21.781335] Iteration 49900, train loss = 0.203207, train accuracy = 0.960938\n",
      "[2018-07-17 21:14:30.487037] Iteration 50000, train loss = 0.250856, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.883100\n",
      "[2018-07-17 21:14:41.676264] Iteration 50100, train loss = 0.248242, train accuracy = 0.929688\n",
      "[2018-07-17 21:14:50.210549] Iteration 50200, train loss = 0.287229, train accuracy = 0.914062\n",
      "[2018-07-17 21:14:58.828061] Iteration 50300, train loss = 0.251137, train accuracy = 0.929688\n",
      "[2018-07-17 21:15:07.614570] Iteration 50400, train loss = 0.279800, train accuracy = 0.937500\n",
      "[2018-07-17 21:15:16.380900] Iteration 50500, train loss = 0.236059, train accuracy = 0.929688\n",
      "[2018-07-17 21:15:25.025695] Iteration 50600, train loss = 0.252556, train accuracy = 0.921875\n",
      "[2018-07-17 21:15:33.681459] Iteration 50700, train loss = 0.259297, train accuracy = 0.960938\n",
      "[2018-07-17 21:15:42.255916] Iteration 50800, train loss = 0.295838, train accuracy = 0.929688\n",
      "[2018-07-17 21:15:50.842787] Iteration 50900, train loss = 0.205542, train accuracy = 0.945312\n",
      "[2018-07-17 21:15:59.474358] Iteration 51000, train loss = 0.263556, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.882400\n",
      "[2018-07-17 21:16:10.707792] Iteration 51100, train loss = 0.185426, train accuracy = 0.984375\n",
      "[2018-07-17 21:16:19.543289] Iteration 51200, train loss = 0.340620, train accuracy = 0.890625\n",
      "[2018-07-17 21:16:28.371762] Iteration 51300, train loss = 0.278477, train accuracy = 0.898438\n",
      "[2018-07-17 21:16:36.962386] Iteration 51400, train loss = 0.239831, train accuracy = 0.937500\n",
      "[2018-07-17 21:16:45.693015] Iteration 51500, train loss = 0.161200, train accuracy = 0.976562\n",
      "[2018-07-17 21:16:54.406822] Iteration 51600, train loss = 0.216255, train accuracy = 0.953125\n",
      "[2018-07-17 21:17:02.974277] Iteration 51700, train loss = 0.211315, train accuracy = 0.945312\n",
      "[2018-07-17 21:17:11.529444] Iteration 51800, train loss = 0.225297, train accuracy = 0.945312\n",
      "[2018-07-17 21:17:20.308998] Iteration 51900, train loss = 0.231712, train accuracy = 0.960938\n",
      "[2018-07-17 21:17:28.944141] Iteration 52000, train loss = 0.220913, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.884300\n",
      "[2018-07-17 21:17:40.301634] Iteration 52100, train loss = 0.216931, train accuracy = 0.945312\n",
      "[2018-07-17 21:17:49.088736] Iteration 52200, train loss = 0.208499, train accuracy = 0.960938\n",
      "[2018-07-17 21:17:57.629833] Iteration 52300, train loss = 0.251282, train accuracy = 0.953125\n",
      "[2018-07-17 21:18:06.450151] Iteration 52400, train loss = 0.250608, train accuracy = 0.937500\n",
      "[2018-07-17 21:18:15.296903] Iteration 52500, train loss = 0.194272, train accuracy = 0.960938\n",
      "[2018-07-17 21:18:24.032184] Iteration 52600, train loss = 0.258663, train accuracy = 0.937500\n",
      "[2018-07-17 21:18:32.537365] Iteration 52700, train loss = 0.242445, train accuracy = 0.945312\n",
      "[2018-07-17 21:18:41.124702] Iteration 52800, train loss = 0.317384, train accuracy = 0.921875\n",
      "[2018-07-17 21:18:49.955036] Iteration 52900, train loss = 0.225608, train accuracy = 0.945312\n",
      "[2018-07-17 21:18:58.681036] Iteration 53000, train loss = 0.221001, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.885000\n",
      "[2018-07-17 21:19:10.012449] Iteration 53100, train loss = 0.242278, train accuracy = 0.921875\n",
      "[2018-07-17 21:19:18.811138] Iteration 53200, train loss = 0.213321, train accuracy = 0.960938\n",
      "[2018-07-17 21:19:27.569318] Iteration 53300, train loss = 0.182928, train accuracy = 0.976562\n",
      "[2018-07-17 21:19:36.275224] Iteration 53400, train loss = 0.264336, train accuracy = 0.906250\n",
      "[2018-07-17 21:19:44.820033] Iteration 53500, train loss = 0.268109, train accuracy = 0.914062\n",
      "[2018-07-17 21:19:53.534605] Iteration 53600, train loss = 0.224429, train accuracy = 0.953125\n",
      "[2018-07-17 21:20:02.355082] Iteration 53700, train loss = 0.218418, train accuracy = 0.953125\n",
      "[2018-07-17 21:20:11.062245] Iteration 53800, train loss = 0.204637, train accuracy = 0.968750\n",
      "[2018-07-17 21:20:19.867639] Iteration 53900, train loss = 0.261277, train accuracy = 0.945312\n",
      "[2018-07-17 21:20:28.332560] Iteration 54000, train loss = 0.184216, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.882700\n",
      "[2018-07-17 21:20:39.599341] Iteration 54100, train loss = 0.242689, train accuracy = 0.953125\n",
      "[2018-07-17 21:20:48.426604] Iteration 54200, train loss = 0.172198, train accuracy = 0.968750\n",
      "[2018-07-17 21:20:57.103259] Iteration 54300, train loss = 0.234942, train accuracy = 0.968750\n",
      "[2018-07-17 21:21:05.753787] Iteration 54400, train loss = 0.259349, train accuracy = 0.929688\n",
      "[2018-07-17 21:21:14.421643] Iteration 54500, train loss = 0.221535, train accuracy = 0.945312\n",
      "[2018-07-17 21:21:23.226121] Iteration 54600, train loss = 0.267948, train accuracy = 0.929688\n",
      "[2018-07-17 21:21:32.007018] Iteration 54700, train loss = 0.338329, train accuracy = 0.906250\n",
      "[2018-07-17 21:21:40.789786] Iteration 54800, train loss = 0.244886, train accuracy = 0.921875\n",
      "[2018-07-17 21:21:49.620276] Iteration 54900, train loss = 0.283307, train accuracy = 0.937500\n",
      "[2018-07-17 21:21:58.452586] Iteration 55000, train loss = 0.251870, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.882900\n",
      "[2018-07-17 21:22:09.719429] Iteration 55100, train loss = 0.250841, train accuracy = 0.929688\n",
      "[2018-07-17 21:22:18.392451] Iteration 55200, train loss = 0.239076, train accuracy = 0.960938\n",
      "[2018-07-17 21:22:27.070595] Iteration 55300, train loss = 0.244792, train accuracy = 0.968750\n",
      "[2018-07-17 21:22:35.848894] Iteration 55400, train loss = 0.180428, train accuracy = 0.968750\n",
      "[2018-07-17 21:22:44.671702] Iteration 55500, train loss = 0.288874, train accuracy = 0.937500\n",
      "[2018-07-17 21:22:53.250090] Iteration 55600, train loss = 0.218027, train accuracy = 0.953125\n",
      "[2018-07-17 21:23:01.767000] Iteration 55700, train loss = 0.333739, train accuracy = 0.929688\n",
      "[2018-07-17 21:23:10.387989] Iteration 55800, train loss = 0.238035, train accuracy = 0.945312\n",
      "[2018-07-17 21:23:19.205858] Iteration 55900, train loss = 0.193675, train accuracy = 0.960938\n",
      "[2018-07-17 21:23:27.931443] Iteration 56000, train loss = 0.291405, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.883100\n",
      "[2018-07-17 21:23:39.174604] Iteration 56100, train loss = 0.231940, train accuracy = 0.945312\n",
      "[2018-07-17 21:23:47.993258] Iteration 56200, train loss = 0.275968, train accuracy = 0.929688\n",
      "[2018-07-17 21:23:56.670290] Iteration 56300, train loss = 0.267593, train accuracy = 0.929688\n",
      "[2018-07-17 21:24:05.268364] Iteration 56400, train loss = 0.196709, train accuracy = 0.976562\n",
      "[2018-07-17 21:24:13.918457] Iteration 56500, train loss = 0.287640, train accuracy = 0.929688\n",
      "[2018-07-17 21:24:22.632674] Iteration 56600, train loss = 0.197602, train accuracy = 0.968750\n",
      "[2018-07-17 21:24:31.217142] Iteration 56700, train loss = 0.219468, train accuracy = 0.960938\n",
      "[2018-07-17 21:24:40.021382] Iteration 56800, train loss = 0.290647, train accuracy = 0.937500\n",
      "[2018-07-17 21:24:48.828745] Iteration 56900, train loss = 0.306426, train accuracy = 0.906250\n",
      "[2018-07-17 21:24:57.435495] Iteration 57000, train loss = 0.387943, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.885200\n",
      "[2018-07-17 21:25:08.591559] Iteration 57100, train loss = 0.185959, train accuracy = 0.968750\n",
      "[2018-07-17 21:25:17.200606] Iteration 57200, train loss = 0.238979, train accuracy = 0.937500\n",
      "[2018-07-17 21:25:25.768628] Iteration 57300, train loss = 0.226724, train accuracy = 0.960938\n",
      "[2018-07-17 21:25:34.594604] Iteration 57400, train loss = 0.202280, train accuracy = 0.968750\n",
      "[2018-07-17 21:25:43.261894] Iteration 57500, train loss = 0.170924, train accuracy = 0.968750\n",
      "[2018-07-17 21:25:52.066859] Iteration 57600, train loss = 0.235719, train accuracy = 0.953125\n",
      "[2018-07-17 21:26:00.712592] Iteration 57700, train loss = 0.260172, train accuracy = 0.937500\n",
      "[2018-07-17 21:26:09.389137] Iteration 57800, train loss = 0.227081, train accuracy = 0.929688\n",
      "[2018-07-17 21:26:18.145876] Iteration 57900, train loss = 0.274832, train accuracy = 0.929688\n",
      "[2018-07-17 21:26:26.924744] Iteration 58000, train loss = 0.293297, train accuracy = 0.906250\n",
      "Evaluating...\n",
      "Test accuracy = 0.882900\n",
      "[2018-07-17 21:26:38.173973] Iteration 58100, train loss = 0.212710, train accuracy = 0.953125\n",
      "[2018-07-17 21:26:46.726189] Iteration 58200, train loss = 0.234461, train accuracy = 0.929688\n",
      "[2018-07-17 21:26:55.373622] Iteration 58300, train loss = 0.191264, train accuracy = 0.945312\n",
      "[2018-07-17 21:27:03.847167] Iteration 58400, train loss = 0.246866, train accuracy = 0.921875\n",
      "[2018-07-17 21:27:12.112248] Iteration 58500, train loss = 0.293070, train accuracy = 0.921875\n",
      "[2018-07-17 21:27:20.663861] Iteration 58600, train loss = 0.243640, train accuracy = 0.953125\n",
      "[2018-07-17 21:27:29.121434] Iteration 58700, train loss = 0.192932, train accuracy = 0.976562\n",
      "[2018-07-17 21:27:37.512456] Iteration 58800, train loss = 0.220820, train accuracy = 0.945312\n",
      "[2018-07-17 21:27:45.878002] Iteration 58900, train loss = 0.281946, train accuracy = 0.929688\n",
      "[2018-07-17 21:27:54.098397] Iteration 59000, train loss = 0.250593, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.882800\n",
      "[2018-07-17 21:28:04.727347] Iteration 59100, train loss = 0.233172, train accuracy = 0.953125\n",
      "[2018-07-17 21:28:13.094277] Iteration 59200, train loss = 0.211395, train accuracy = 0.937500\n",
      "[2018-07-17 21:28:21.324791] Iteration 59300, train loss = 0.282916, train accuracy = 0.945312\n",
      "[2018-07-17 21:28:29.553159] Iteration 59400, train loss = 0.237993, train accuracy = 0.968750\n",
      "[2018-07-17 21:28:37.964194] Iteration 59500, train loss = 0.244466, train accuracy = 0.937500\n",
      "[2018-07-17 21:28:46.334847] Iteration 59600, train loss = 0.215210, train accuracy = 0.945312\n",
      "[2018-07-17 21:28:54.687841] Iteration 59700, train loss = 0.246275, train accuracy = 0.929688\n",
      "[2018-07-17 21:29:02.970987] Iteration 59800, train loss = 0.185315, train accuracy = 0.968750\n",
      "[2018-07-17 21:29:11.415828] Iteration 59900, train loss = 0.384744, train accuracy = 0.898438\n",
      "[2018-07-17 21:29:19.864829] Iteration 60000, train loss = 0.258241, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.884700\n",
      "[2018-07-17 21:29:30.622629] Iteration 60100, train loss = 0.247326, train accuracy = 0.960938\n",
      "[2018-07-17 21:29:39.093621] Iteration 60200, train loss = 0.171534, train accuracy = 0.984375\n",
      "[2018-07-17 21:29:47.544547] Iteration 60300, train loss = 0.232212, train accuracy = 0.960938\n",
      "[2018-07-17 21:29:55.854622] Iteration 60400, train loss = 0.195500, train accuracy = 0.960938\n",
      "[2018-07-17 21:30:04.304294] Iteration 60500, train loss = 0.192899, train accuracy = 0.953125\n",
      "[2018-07-17 21:30:12.861321] Iteration 60600, train loss = 0.206730, train accuracy = 0.968750\n",
      "[2018-07-17 21:30:21.391668] Iteration 60700, train loss = 0.257560, train accuracy = 0.945312\n",
      "[2018-07-17 21:30:30.030659] Iteration 60800, train loss = 0.228006, train accuracy = 0.945312\n",
      "[2018-07-17 21:30:38.716470] Iteration 60900, train loss = 0.256210, train accuracy = 0.929688\n",
      "[2018-07-17 21:30:47.244135] Iteration 61000, train loss = 0.305338, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.882600\n",
      "[2018-07-17 21:30:58.293155] Iteration 61100, train loss = 0.299403, train accuracy = 0.929688\n",
      "[2018-07-17 21:31:07.047055] Iteration 61200, train loss = 0.330411, train accuracy = 0.921875\n",
      "[2018-07-17 21:31:15.855088] Iteration 61300, train loss = 0.280864, train accuracy = 0.945312\n",
      "[2018-07-17 21:31:24.438547] Iteration 61400, train loss = 0.343431, train accuracy = 0.898438\n",
      "[2018-07-17 21:31:33.225025] Iteration 61500, train loss = 0.220349, train accuracy = 0.960938\n",
      "[2018-07-17 21:31:42.052718] Iteration 61600, train loss = 0.207863, train accuracy = 0.960938\n",
      "[2018-07-17 21:31:50.815704] Iteration 61700, train loss = 0.178663, train accuracy = 0.968750\n",
      "[2018-07-17 21:31:59.556407] Iteration 61800, train loss = 0.214807, train accuracy = 0.945312\n",
      "[2018-07-17 21:32:08.260205] Iteration 61900, train loss = 0.284341, train accuracy = 0.914062\n",
      "[2018-07-17 21:32:17.105430] Iteration 62000, train loss = 0.177278, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.883300\n",
      "[2018-07-17 21:32:28.294076] Iteration 62100, train loss = 0.232220, train accuracy = 0.953125\n",
      "[2018-07-17 21:32:37.114935] Iteration 62200, train loss = 0.279343, train accuracy = 0.929688\n",
      "[2018-07-17 21:32:45.967823] Iteration 62300, train loss = 0.191265, train accuracy = 0.968750\n",
      "[2018-07-17 21:32:54.817627] Iteration 62400, train loss = 0.208775, train accuracy = 0.960938\n",
      "[2018-07-17 21:33:03.664629] Iteration 62500, train loss = 0.278613, train accuracy = 0.898438\n",
      "[2018-07-17 21:33:12.433895] Iteration 62600, train loss = 0.222814, train accuracy = 0.953125\n",
      "[2018-07-17 21:33:21.206606] Iteration 62700, train loss = 0.202995, train accuracy = 0.960938\n",
      "[2018-07-17 21:33:30.042714] Iteration 62800, train loss = 0.238629, train accuracy = 0.953125\n",
      "[2018-07-17 21:33:38.850559] Iteration 62900, train loss = 0.174670, train accuracy = 0.976562\n",
      "[2018-07-17 21:33:47.490973] Iteration 63000, train loss = 0.269481, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.884400\n",
      "[2018-07-17 21:33:58.826043] Iteration 63100, train loss = 0.253070, train accuracy = 0.921875\n",
      "[2018-07-17 21:34:07.420759] Iteration 63200, train loss = 0.234818, train accuracy = 0.960938\n",
      "[2018-07-17 21:34:16.149935] Iteration 63300, train loss = 0.318481, train accuracy = 0.921875\n",
      "[2018-07-17 21:34:24.707205] Iteration 63400, train loss = 0.207519, train accuracy = 0.960938\n",
      "[2018-07-17 21:34:33.532773] Iteration 63500, train loss = 0.233933, train accuracy = 0.953125\n",
      "[2018-07-17 21:34:42.272310] Iteration 63600, train loss = 0.261359, train accuracy = 0.921875\n",
      "[2018-07-17 21:34:51.106300] Iteration 63700, train loss = 0.311129, train accuracy = 0.929688\n",
      "[2018-07-17 21:34:59.815558] Iteration 63800, train loss = 0.196885, train accuracy = 0.960938\n",
      "[2018-07-17 21:35:08.637456] Iteration 63900, train loss = 0.227610, train accuracy = 0.921875\n",
      "[2018-07-17 21:35:17.461104] Iteration 64000, train loss = 0.204021, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.883000\n",
      "[2018-07-17 21:35:28.756695] Iteration 64100, train loss = 0.208092, train accuracy = 0.976562\n",
      "[2018-07-17 21:35:37.520057] Iteration 64200, train loss = 0.299560, train accuracy = 0.921875\n",
      "[2018-07-17 21:35:46.358657] Iteration 64300, train loss = 0.241673, train accuracy = 0.953125\n",
      "[2018-07-17 21:35:55.200311] Iteration 64400, train loss = 0.214846, train accuracy = 0.953125\n",
      "[2018-07-17 21:36:04.006995] Iteration 64500, train loss = 0.216643, train accuracy = 0.953125\n",
      "[2018-07-17 21:36:12.840215] Iteration 64600, train loss = 0.205276, train accuracy = 0.968750\n",
      "[2018-07-17 21:36:21.499625] Iteration 64700, train loss = 0.153303, train accuracy = 0.984375\n",
      "[2018-07-17 21:36:30.331406] Iteration 64800, train loss = 0.221651, train accuracy = 0.945312\n",
      "[2018-07-17 21:36:39.097316] Iteration 64900, train loss = 0.320482, train accuracy = 0.921875\n",
      "[2018-07-17 21:36:47.693876] Iteration 65000, train loss = 0.172248, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.883700\n",
      "[2018-07-17 21:36:58.948333] Iteration 65100, train loss = 0.242532, train accuracy = 0.953125\n",
      "[2018-07-17 21:37:07.671167] Iteration 65200, train loss = 0.319581, train accuracy = 0.914062\n",
      "[2018-07-17 21:37:16.448199] Iteration 65300, train loss = 0.278015, train accuracy = 0.953125\n",
      "[2018-07-17 21:37:25.063226] Iteration 65400, train loss = 0.193995, train accuracy = 0.960938\n",
      "[2018-07-17 21:37:33.591362] Iteration 65500, train loss = 0.227226, train accuracy = 0.937500\n",
      "[2018-07-17 21:37:42.254430] Iteration 65600, train loss = 0.269700, train accuracy = 0.921875\n",
      "[2018-07-17 21:37:51.033387] Iteration 65700, train loss = 0.211462, train accuracy = 0.945312\n",
      "[2018-07-17 21:37:59.661320] Iteration 65800, train loss = 0.273440, train accuracy = 0.937500\n",
      "[2018-07-17 21:38:08.408212] Iteration 65900, train loss = 0.241675, train accuracy = 0.929688\n",
      "[2018-07-17 21:38:17.268632] Iteration 66000, train loss = 0.333770, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.885000\n",
      "[2018-07-17 21:38:28.393345] Iteration 66100, train loss = 0.169774, train accuracy = 0.976562\n",
      "[2018-07-17 21:38:37.117838] Iteration 66200, train loss = 0.141243, train accuracy = 0.992188\n",
      "[2018-07-17 21:38:45.857753] Iteration 66300, train loss = 0.345838, train accuracy = 0.914062\n",
      "[2018-07-17 21:38:54.359576] Iteration 66400, train loss = 0.230869, train accuracy = 0.945312\n",
      "[2018-07-17 21:39:02.953698] Iteration 66500, train loss = 0.200829, train accuracy = 0.960938\n",
      "[2018-07-17 21:39:11.644669] Iteration 66600, train loss = 0.234921, train accuracy = 0.945312\n",
      "[2018-07-17 21:39:20.310103] Iteration 66700, train loss = 0.190115, train accuracy = 0.953125\n",
      "[2018-07-17 21:39:28.885747] Iteration 66800, train loss = 0.247182, train accuracy = 0.953125\n",
      "[2018-07-17 21:39:37.616200] Iteration 66900, train loss = 0.188856, train accuracy = 0.945312\n",
      "[2018-07-17 21:39:46.404504] Iteration 67000, train loss = 0.187456, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.884900\n",
      "[2018-07-17 21:39:57.735108] Iteration 67100, train loss = 0.264524, train accuracy = 0.929688\n",
      "[2018-07-17 21:40:06.535697] Iteration 67200, train loss = 0.199446, train accuracy = 0.968750\n",
      "[2018-07-17 21:40:15.287645] Iteration 67300, train loss = 0.249824, train accuracy = 0.921875\n",
      "[2018-07-17 21:40:24.043984] Iteration 67400, train loss = 0.178760, train accuracy = 0.968750\n",
      "[2018-07-17 21:40:32.785070] Iteration 67500, train loss = 0.286730, train accuracy = 0.890625\n",
      "[2018-07-17 21:40:41.480484] Iteration 67600, train loss = 0.261134, train accuracy = 0.937500\n",
      "[2018-07-17 21:40:50.308398] Iteration 67700, train loss = 0.209797, train accuracy = 0.953125\n",
      "[2018-07-17 21:40:59.101522] Iteration 67800, train loss = 0.221567, train accuracy = 0.953125\n",
      "[2018-07-17 21:41:07.920417] Iteration 67900, train loss = 0.198960, train accuracy = 0.968750\n",
      "[2018-07-17 21:41:16.626467] Iteration 68000, train loss = 0.225512, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.883400\n",
      "[2018-07-17 21:41:27.939926] Iteration 68100, train loss = 0.239152, train accuracy = 0.929688\n",
      "[2018-07-17 21:41:36.738332] Iteration 68200, train loss = 0.214133, train accuracy = 0.937500\n",
      "[2018-07-17 21:41:45.418332] Iteration 68300, train loss = 0.239310, train accuracy = 0.953125\n",
      "[2018-07-17 21:41:54.173954] Iteration 68400, train loss = 0.183125, train accuracy = 0.968750\n",
      "[2018-07-17 21:42:02.785631] Iteration 68500, train loss = 0.213948, train accuracy = 0.945312\n",
      "[2018-07-17 21:42:11.487078] Iteration 68600, train loss = 0.189041, train accuracy = 0.960938\n",
      "[2018-07-17 21:42:20.325838] Iteration 68700, train loss = 0.284196, train accuracy = 0.945312\n",
      "[2018-07-17 21:42:29.032113] Iteration 68800, train loss = 0.243211, train accuracy = 0.976562\n",
      "[2018-07-17 21:42:37.468220] Iteration 68900, train loss = 0.267120, train accuracy = 0.945312\n",
      "[2018-07-17 21:42:46.141415] Iteration 69000, train loss = 0.240848, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.883100\n",
      "[2018-07-17 21:42:57.504573] Iteration 69100, train loss = 0.206124, train accuracy = 0.953125\n",
      "[2018-07-17 21:43:06.353067] Iteration 69200, train loss = 0.196764, train accuracy = 0.960938\n",
      "[2018-07-17 21:43:15.021409] Iteration 69300, train loss = 0.165211, train accuracy = 0.976562\n",
      "[2018-07-17 21:43:23.635526] Iteration 69400, train loss = 0.143460, train accuracy = 0.984375\n",
      "[2018-07-17 21:43:32.418961] Iteration 69500, train loss = 0.192413, train accuracy = 0.960938\n",
      "[2018-07-17 21:43:41.176481] Iteration 69600, train loss = 0.181100, train accuracy = 0.976562\n",
      "[2018-07-17 21:43:49.739822] Iteration 69700, train loss = 0.326777, train accuracy = 0.921875\n",
      "[2018-07-17 21:43:58.475243] Iteration 69800, train loss = 0.207321, train accuracy = 0.953125\n",
      "[2018-07-17 21:44:07.129351] Iteration 69900, train loss = 0.208596, train accuracy = 0.953125\n",
      "[2018-07-17 21:44:15.929953] Iteration 70000, train loss = 0.253244, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.883600\n",
      "[2018-07-17 21:44:27.213566] Iteration 70100, train loss = 0.266411, train accuracy = 0.929688\n",
      "[2018-07-17 21:44:35.873191] Iteration 70200, train loss = 0.274191, train accuracy = 0.898438\n",
      "[2018-07-17 21:44:44.708823] Iteration 70300, train loss = 0.283054, train accuracy = 0.906250\n",
      "[2018-07-17 21:44:53.398874] Iteration 70400, train loss = 0.213120, train accuracy = 0.945312\n",
      "[2018-07-17 21:45:02.151916] Iteration 70500, train loss = 0.262582, train accuracy = 0.921875\n",
      "[2018-07-17 21:45:10.931946] Iteration 70600, train loss = 0.244711, train accuracy = 0.929688\n",
      "[2018-07-17 21:45:19.673932] Iteration 70700, train loss = 0.267174, train accuracy = 0.921875\n",
      "[2018-07-17 21:45:28.382241] Iteration 70800, train loss = 0.201448, train accuracy = 0.953125\n",
      "[2018-07-17 21:45:37.060268] Iteration 70900, train loss = 0.192553, train accuracy = 0.968750\n",
      "[2018-07-17 21:45:45.857144] Iteration 71000, train loss = 0.237838, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.886900\n",
      "[2018-07-17 21:45:57.072750] Iteration 71100, train loss = 0.181596, train accuracy = 0.953125\n",
      "[2018-07-17 21:46:05.883916] Iteration 71200, train loss = 0.201253, train accuracy = 0.976562\n",
      "[2018-07-17 21:46:14.562479] Iteration 71300, train loss = 0.215878, train accuracy = 0.968750\n",
      "[2018-07-17 21:46:23.375711] Iteration 71400, train loss = 0.247117, train accuracy = 0.937500\n",
      "[2018-07-17 21:46:32.232041] Iteration 71500, train loss = 0.295645, train accuracy = 0.937500\n",
      "[2018-07-17 21:46:41.034875] Iteration 71600, train loss = 0.284966, train accuracy = 0.945312\n",
      "[2018-07-17 21:46:49.869139] Iteration 71700, train loss = 0.205491, train accuracy = 0.953125\n",
      "[2018-07-17 21:46:58.603286] Iteration 71800, train loss = 0.189701, train accuracy = 0.953125\n",
      "[2018-07-17 21:47:07.445964] Iteration 71900, train loss = 0.158863, train accuracy = 0.984375\n",
      "[2018-07-17 21:47:16.254548] Iteration 72000, train loss = 0.236679, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.883500\n",
      "[2018-07-17 21:47:27.639094] Iteration 72100, train loss = 0.210401, train accuracy = 0.945312\n",
      "[2018-07-17 21:47:36.458368] Iteration 72200, train loss = 0.211531, train accuracy = 0.953125\n",
      "[2018-07-17 21:47:45.096515] Iteration 72300, train loss = 0.218102, train accuracy = 0.953125\n",
      "[2018-07-17 21:47:53.876004] Iteration 72400, train loss = 0.253649, train accuracy = 0.937500\n",
      "[2018-07-17 21:48:02.629959] Iteration 72500, train loss = 0.233208, train accuracy = 0.953125\n",
      "[2018-07-17 21:48:11.362765] Iteration 72600, train loss = 0.204434, train accuracy = 0.953125\n",
      "[2018-07-17 21:48:20.200961] Iteration 72700, train loss = 0.228598, train accuracy = 0.953125\n",
      "[2018-07-17 21:48:28.877501] Iteration 72800, train loss = 0.232700, train accuracy = 0.960938\n",
      "[2018-07-17 21:48:37.724838] Iteration 72900, train loss = 0.187429, train accuracy = 0.968750\n",
      "[2018-07-17 21:48:46.533053] Iteration 73000, train loss = 0.294581, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.882700\n",
      "[2018-07-17 21:48:57.826902] Iteration 73100, train loss = 0.140696, train accuracy = 0.992188\n",
      "[2018-07-17 21:49:06.517086] Iteration 73200, train loss = 0.210422, train accuracy = 0.968750\n",
      "[2018-07-17 21:49:15.344123] Iteration 73300, train loss = 0.232639, train accuracy = 0.937500\n",
      "[2018-07-17 21:49:24.055681] Iteration 73400, train loss = 0.306688, train accuracy = 0.937500\n",
      "[2018-07-17 21:49:32.667960] Iteration 73500, train loss = 0.294306, train accuracy = 0.929688\n",
      "[2018-07-17 21:49:41.443715] Iteration 73600, train loss = 0.231219, train accuracy = 0.937500\n",
      "[2018-07-17 21:49:50.251894] Iteration 73700, train loss = 0.249722, train accuracy = 0.945312\n",
      "[2018-07-17 21:49:59.044966] Iteration 73800, train loss = 0.208182, train accuracy = 0.960938\n",
      "[2018-07-17 21:50:07.870501] Iteration 73900, train loss = 0.212699, train accuracy = 0.937500\n",
      "[2018-07-17 21:50:16.705340] Iteration 74000, train loss = 0.235017, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.882800\n",
      "[2018-07-17 21:50:28.074794] Iteration 74100, train loss = 0.284840, train accuracy = 0.921875\n",
      "[2018-07-17 21:50:36.779688] Iteration 74200, train loss = 0.171886, train accuracy = 0.960938\n",
      "[2018-07-17 21:50:45.616881] Iteration 74300, train loss = 0.273891, train accuracy = 0.937500\n",
      "[2018-07-17 21:50:54.452705] Iteration 74400, train loss = 0.177566, train accuracy = 0.968750\n",
      "[2018-07-17 21:51:03.205990] Iteration 74500, train loss = 0.196540, train accuracy = 0.960938\n",
      "[2018-07-17 21:51:12.056537] Iteration 74600, train loss = 0.228524, train accuracy = 0.953125\n",
      "[2018-07-17 21:51:20.846160] Iteration 74700, train loss = 0.178817, train accuracy = 0.968750\n",
      "[2018-07-17 21:51:29.540914] Iteration 74800, train loss = 0.194459, train accuracy = 0.968750\n",
      "[2018-07-17 21:51:38.389198] Iteration 74900, train loss = 0.203761, train accuracy = 0.968750\n",
      "[2018-07-17 21:51:47.224192] Iteration 75000, train loss = 0.197084, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.883700\n",
      "[2018-07-17 21:51:58.621028] Iteration 75100, train loss = 0.201188, train accuracy = 0.968750\n",
      "[2018-07-17 21:52:07.397282] Iteration 75200, train loss = 0.229150, train accuracy = 0.953125\n",
      "[2018-07-17 21:52:16.136073] Iteration 75300, train loss = 0.276460, train accuracy = 0.953125\n",
      "[2018-07-17 21:52:24.875364] Iteration 75400, train loss = 0.187203, train accuracy = 0.976562\n",
      "[2018-07-17 21:52:33.387519] Iteration 75500, train loss = 0.255892, train accuracy = 0.960938\n",
      "[2018-07-17 21:52:42.178543] Iteration 75600, train loss = 0.167139, train accuracy = 0.976562\n",
      "[2018-07-17 21:52:50.928151] Iteration 75700, train loss = 0.214184, train accuracy = 0.968750\n",
      "[2018-07-17 21:52:59.712527] Iteration 75800, train loss = 0.249553, train accuracy = 0.945312\n",
      "[2018-07-17 21:53:08.425220] Iteration 75900, train loss = 0.160809, train accuracy = 0.984375\n",
      "[2018-07-17 21:53:17.195106] Iteration 76000, train loss = 0.177799, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.882900\n",
      "[2018-07-17 21:53:28.565679] Iteration 76100, train loss = 0.193438, train accuracy = 0.960938\n",
      "[2018-07-17 21:53:37.403941] Iteration 76200, train loss = 0.228841, train accuracy = 0.945312\n",
      "[2018-07-17 21:53:45.998982] Iteration 76300, train loss = 0.221190, train accuracy = 0.953125\n",
      "[2018-07-17 21:53:54.774931] Iteration 76400, train loss = 0.296909, train accuracy = 0.921875\n",
      "[2018-07-17 21:54:03.497419] Iteration 76500, train loss = 0.199670, train accuracy = 0.960938\n",
      "[2018-07-17 21:54:12.240412] Iteration 76600, train loss = 0.219926, train accuracy = 0.937500\n",
      "[2018-07-17 21:54:20.972221] Iteration 76700, train loss = 0.205603, train accuracy = 0.953125\n",
      "[2018-07-17 21:54:29.776846] Iteration 76800, train loss = 0.183331, train accuracy = 0.960938\n",
      "[2018-07-17 21:54:38.511836] Iteration 76900, train loss = 0.212200, train accuracy = 0.945312\n",
      "[2018-07-17 21:54:47.161680] Iteration 77000, train loss = 0.213797, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.884300\n",
      "[2018-07-17 21:54:58.468283] Iteration 77100, train loss = 0.283951, train accuracy = 0.921875\n",
      "[2018-07-17 21:55:07.295902] Iteration 77200, train loss = 0.279189, train accuracy = 0.929688\n",
      "[2018-07-17 21:55:16.087282] Iteration 77300, train loss = 0.295838, train accuracy = 0.906250\n",
      "[2018-07-17 21:55:24.924575] Iteration 77400, train loss = 0.214839, train accuracy = 0.960938\n",
      "[2018-07-17 21:55:33.735921] Iteration 77500, train loss = 0.252804, train accuracy = 0.960938\n",
      "[2018-07-17 21:55:42.364152] Iteration 77600, train loss = 0.219211, train accuracy = 0.945312\n",
      "[2018-07-17 21:55:50.998453] Iteration 77700, train loss = 0.266346, train accuracy = 0.929688\n",
      "[2018-07-17 21:55:59.568771] Iteration 77800, train loss = 0.276038, train accuracy = 0.929688\n",
      "[2018-07-17 21:56:08.252018] Iteration 77900, train loss = 0.241626, train accuracy = 0.945312\n",
      "[2018-07-17 21:56:16.911108] Iteration 78000, train loss = 0.222543, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.882600\n",
      "[2018-07-17 21:56:27.938914] Iteration 78100, train loss = 0.185946, train accuracy = 0.960938\n",
      "[2018-07-17 21:56:36.682205] Iteration 78200, train loss = 0.236391, train accuracy = 0.937500\n",
      "[2018-07-17 21:56:45.488144] Iteration 78300, train loss = 0.243207, train accuracy = 0.953125\n",
      "[2018-07-17 21:56:54.289098] Iteration 78400, train loss = 0.167468, train accuracy = 0.984375\n",
      "[2018-07-17 21:57:02.942240] Iteration 78500, train loss = 0.174024, train accuracy = 0.968750\n",
      "[2018-07-17 21:57:11.571549] Iteration 78600, train loss = 0.202287, train accuracy = 0.960938\n",
      "[2018-07-17 21:57:20.363404] Iteration 78700, train loss = 0.206794, train accuracy = 0.960938\n",
      "[2018-07-17 21:57:28.999565] Iteration 78800, train loss = 0.215203, train accuracy = 0.968750\n",
      "[2018-07-17 21:57:37.559947] Iteration 78900, train loss = 0.174746, train accuracy = 0.984375\n",
      "[2018-07-17 21:57:46.100056] Iteration 79000, train loss = 0.165554, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.883700\n",
      "[2018-07-17 21:57:57.421756] Iteration 79100, train loss = 0.225042, train accuracy = 0.937500\n",
      "[2018-07-17 21:58:06.235987] Iteration 79200, train loss = 0.252677, train accuracy = 0.914062\n",
      "[2018-07-17 21:58:15.086493] Iteration 79300, train loss = 0.280742, train accuracy = 0.921875\n",
      "[2018-07-17 21:58:23.786551] Iteration 79400, train loss = 0.146573, train accuracy = 0.984375\n",
      "[2018-07-17 21:58:32.616008] Iteration 79500, train loss = 0.285835, train accuracy = 0.906250\n",
      "[2018-07-17 21:58:41.357477] Iteration 79600, train loss = 0.215483, train accuracy = 0.960938\n",
      "[2018-07-17 21:58:50.036359] Iteration 79700, train loss = 0.194281, train accuracy = 0.960938\n",
      "[2018-07-17 21:58:58.754835] Iteration 79800, train loss = 0.188727, train accuracy = 0.976562\n",
      "[2018-07-17 21:59:07.582509] Iteration 79900, train loss = 0.179777, train accuracy = 0.968750\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四轮  量化  \n",
    "prune_rate = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.881900\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.15257302  0.          0.17163539  0.125       0.          0.\n",
      "  0.          0.         -0.25        0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,1)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-17 22:02:37.475118] Iteration 100, train loss = 2.528941, train accuracy = 0.250000\n",
      "[2018-07-17 22:02:43.942346] Iteration 200, train loss = 2.306299, train accuracy = 0.289062\n",
      "[2018-07-17 22:02:50.426330] Iteration 300, train loss = 2.526438, train accuracy = 0.242188\n",
      "[2018-07-17 22:02:56.905899] Iteration 400, train loss = 2.280803, train accuracy = 0.312500\n",
      "[2018-07-17 22:03:03.393365] Iteration 500, train loss = 2.456332, train accuracy = 0.250000\n",
      "[2018-07-17 22:03:09.885598] Iteration 600, train loss = 2.506089, train accuracy = 0.195312\n",
      "[2018-07-17 22:03:16.434381] Iteration 700, train loss = 2.316119, train accuracy = 0.289062\n",
      "[2018-07-17 22:03:23.011443] Iteration 800, train loss = 2.258167, train accuracy = 0.320312\n",
      "[2018-07-17 22:03:29.708654] Iteration 900, train loss = 2.485927, train accuracy = 0.257812\n",
      "[2018-07-17 22:03:36.444277] Iteration 1000, train loss = 2.514295, train accuracy = 0.203125\n",
      "Evaluating...\n",
      "Test accuracy = 0.275200\n",
      "[2018-07-17 22:03:45.663015] Iteration 1100, train loss = 2.393597, train accuracy = 0.234375\n",
      "[2018-07-17 22:03:52.506358] Iteration 1200, train loss = 2.529242, train accuracy = 0.226562\n",
      "[2018-07-17 22:03:59.287876] Iteration 1300, train loss = 2.416030, train accuracy = 0.265625\n",
      "[2018-07-17 22:04:06.025568] Iteration 1400, train loss = 2.183864, train accuracy = 0.351562\n",
      "[2018-07-17 22:04:13.192480] Iteration 1500, train loss = 2.545330, train accuracy = 0.210938\n",
      "[2018-07-17 22:04:20.245081] Iteration 1600, train loss = 2.606698, train accuracy = 0.218750\n",
      "[2018-07-17 22:04:27.397244] Iteration 1700, train loss = 2.493200, train accuracy = 0.312500\n",
      "[2018-07-17 22:04:34.562111] Iteration 1800, train loss = 2.344716, train accuracy = 0.281250\n",
      "[2018-07-17 22:04:41.671020] Iteration 1900, train loss = 2.382571, train accuracy = 0.210938\n",
      "[2018-07-17 22:04:48.809109] Iteration 2000, train loss = 2.333205, train accuracy = 0.296875\n",
      "Evaluating...\n",
      "Test accuracy = 0.274800\n",
      "[2018-07-17 22:04:58.465668] Iteration 2100, train loss = 2.350705, train accuracy = 0.296875\n",
      "[2018-07-17 22:05:05.618951] Iteration 2200, train loss = 2.496409, train accuracy = 0.273438\n",
      "[2018-07-17 22:05:12.648942] Iteration 2300, train loss = 2.559805, train accuracy = 0.218750\n",
      "[2018-07-17 22:05:19.377541] Iteration 2400, train loss = 2.646536, train accuracy = 0.234375\n",
      "[2018-07-17 22:05:26.202055] Iteration 2500, train loss = 2.451952, train accuracy = 0.218750\n",
      "[2018-07-17 22:05:33.032573] Iteration 2600, train loss = 2.349534, train accuracy = 0.234375\n",
      "[2018-07-17 22:05:40.156900] Iteration 2700, train loss = 2.762540, train accuracy = 0.218750\n",
      "[2018-07-17 22:05:47.168645] Iteration 2800, train loss = 2.795456, train accuracy = 0.242188\n",
      "[2018-07-17 22:05:54.103446] Iteration 2900, train loss = 2.601015, train accuracy = 0.203125\n",
      "[2018-07-17 22:06:01.206282] Iteration 3000, train loss = 2.492094, train accuracy = 0.265625\n",
      "Evaluating...\n",
      "Test accuracy = 0.276000\n",
      "[2018-07-17 22:06:10.841706] Iteration 3100, train loss = 2.405932, train accuracy = 0.304688\n",
      "[2018-07-17 22:06:17.818431] Iteration 3200, train loss = 2.369284, train accuracy = 0.289062\n",
      "[2018-07-17 22:06:24.903848] Iteration 3300, train loss = 2.309815, train accuracy = 0.257812\n",
      "[2018-07-17 22:06:32.002793] Iteration 3400, train loss = 2.386338, train accuracy = 0.250000\n",
      "[2018-07-17 22:06:39.101159] Iteration 3500, train loss = 2.411531, train accuracy = 0.273438\n",
      "[2018-07-17 22:06:46.249590] Iteration 3600, train loss = 2.510384, train accuracy = 0.273438\n",
      "[2018-07-17 22:06:53.379003] Iteration 3700, train loss = 2.283247, train accuracy = 0.296875\n",
      "[2018-07-17 22:07:00.373928] Iteration 3800, train loss = 2.554987, train accuracy = 0.218750\n",
      "[2018-07-17 22:07:07.135432] Iteration 3900, train loss = 2.390688, train accuracy = 0.265625\n",
      "[2018-07-17 22:07:13.943659] Iteration 4000, train loss = 2.510633, train accuracy = 0.171875\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:07:23.634855] Iteration 4100, train loss = 2.457313, train accuracy = 0.265625\n",
      "[2018-07-17 22:07:30.683298] Iteration 4200, train loss = 2.493700, train accuracy = 0.250000\n",
      "[2018-07-17 22:07:37.774881] Iteration 4300, train loss = 2.285460, train accuracy = 0.320312\n",
      "[2018-07-17 22:07:44.655490] Iteration 4400, train loss = 2.260354, train accuracy = 0.375000\n",
      "[2018-07-17 22:07:51.771737] Iteration 4500, train loss = 2.380392, train accuracy = 0.257812\n",
      "[2018-07-17 22:07:58.738790] Iteration 4600, train loss = 2.120859, train accuracy = 0.390625\n",
      "[2018-07-17 22:08:05.879134] Iteration 4700, train loss = 2.423798, train accuracy = 0.242188\n",
      "[2018-07-17 22:08:13.014592] Iteration 4800, train loss = 2.391633, train accuracy = 0.257812\n",
      "[2018-07-17 22:08:19.927131] Iteration 4900, train loss = 2.307702, train accuracy = 0.250000\n",
      "[2018-07-17 22:08:26.895193] Iteration 5000, train loss = 2.348808, train accuracy = 0.304688\n",
      "Evaluating...\n",
      "Test accuracy = 0.275900\n",
      "[2018-07-17 22:08:36.541426] Iteration 5100, train loss = 2.481478, train accuracy = 0.218750\n",
      "[2018-07-17 22:08:43.663032] Iteration 5200, train loss = 2.550649, train accuracy = 0.281250\n",
      "[2018-07-17 22:08:50.560377] Iteration 5300, train loss = 2.244770, train accuracy = 0.273438\n",
      "[2018-07-17 22:08:57.624082] Iteration 5400, train loss = 2.398143, train accuracy = 0.265625\n",
      "[2018-07-17 22:09:04.611339] Iteration 5500, train loss = 2.464037, train accuracy = 0.296875\n",
      "[2018-07-17 22:09:11.661144] Iteration 5600, train loss = 2.507096, train accuracy = 0.226562\n",
      "[2018-07-17 22:09:18.773297] Iteration 5700, train loss = 2.348540, train accuracy = 0.335938\n",
      "[2018-07-17 22:09:25.887035] Iteration 5800, train loss = 2.301864, train accuracy = 0.289062\n",
      "[2018-07-17 22:09:32.836909] Iteration 5900, train loss = 2.324766, train accuracy = 0.304688\n",
      "[2018-07-17 22:09:39.979494] Iteration 6000, train loss = 2.608197, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 22:09:49.615226] Iteration 6100, train loss = 2.424940, train accuracy = 0.257812\n",
      "[2018-07-17 22:09:56.635734] Iteration 6200, train loss = 2.465891, train accuracy = 0.289062\n",
      "[2018-07-17 22:10:03.567181] Iteration 6300, train loss = 2.286555, train accuracy = 0.328125\n",
      "[2018-07-17 22:10:10.651657] Iteration 6400, train loss = 2.486573, train accuracy = 0.257812\n",
      "[2018-07-17 22:10:17.756752] Iteration 6500, train loss = 2.343893, train accuracy = 0.304688\n",
      "[2018-07-17 22:10:24.893423] Iteration 6600, train loss = 2.527856, train accuracy = 0.265625\n",
      "[2018-07-17 22:10:31.961894] Iteration 6700, train loss = 2.504850, train accuracy = 0.234375\n",
      "[2018-07-17 22:10:39.066743] Iteration 6800, train loss = 2.517833, train accuracy = 0.226562\n",
      "[2018-07-17 22:10:46.173222] Iteration 6900, train loss = 2.531601, train accuracy = 0.226562\n",
      "[2018-07-17 22:10:53.318698] Iteration 7000, train loss = 2.390625, train accuracy = 0.289062\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 22:11:02.935772] Iteration 7100, train loss = 2.373710, train accuracy = 0.289062\n",
      "[2018-07-17 22:11:10.068258] Iteration 7200, train loss = 2.336376, train accuracy = 0.312500\n",
      "[2018-07-17 22:11:16.918104] Iteration 7300, train loss = 2.400218, train accuracy = 0.296875\n",
      "[2018-07-17 22:11:23.703847] Iteration 7400, train loss = 2.517645, train accuracy = 0.273438\n",
      "[2018-07-17 22:11:30.573041] Iteration 7500, train loss = 2.555519, train accuracy = 0.226562\n",
      "[2018-07-17 22:11:37.632537] Iteration 7600, train loss = 2.315299, train accuracy = 0.296875\n",
      "[2018-07-17 22:11:44.723011] Iteration 7700, train loss = 2.532755, train accuracy = 0.250000\n",
      "[2018-07-17 22:11:51.815248] Iteration 7800, train loss = 2.245107, train accuracy = 0.335938\n",
      "[2018-07-17 22:11:58.904963] Iteration 7900, train loss = 2.347735, train accuracy = 0.281250\n",
      "[2018-07-17 22:12:05.956717] Iteration 8000, train loss = 2.368491, train accuracy = 0.335938\n",
      "Evaluating...\n",
      "Test accuracy = 0.275500\n",
      "[2018-07-17 22:12:15.428179] Iteration 8100, train loss = 2.637316, train accuracy = 0.242188\n",
      "[2018-07-17 22:12:22.521586] Iteration 8200, train loss = 2.662863, train accuracy = 0.218750\n",
      "[2018-07-17 22:12:29.407134] Iteration 8300, train loss = 2.652955, train accuracy = 0.218750\n",
      "[2018-07-17 22:12:36.232599] Iteration 8400, train loss = 2.574907, train accuracy = 0.257812\n",
      "[2018-07-17 22:12:43.043398] Iteration 8500, train loss = 2.517748, train accuracy = 0.218750\n",
      "[2018-07-17 22:12:50.014817] Iteration 8600, train loss = 2.623605, train accuracy = 0.226562\n",
      "[2018-07-17 22:12:57.172107] Iteration 8700, train loss = 2.454099, train accuracy = 0.234375\n",
      "[2018-07-17 22:13:04.113835] Iteration 8800, train loss = 2.461586, train accuracy = 0.250000\n",
      "[2018-07-17 22:13:11.220829] Iteration 8900, train loss = 2.384401, train accuracy = 0.250000\n",
      "[2018-07-17 22:13:18.335812] Iteration 9000, train loss = 2.451933, train accuracy = 0.273438\n",
      "Evaluating...\n",
      "Test accuracy = 0.276100\n",
      "[2018-07-17 22:13:28.040301] Iteration 9100, train loss = 2.296053, train accuracy = 0.250000\n",
      "[2018-07-17 22:13:35.170575] Iteration 9200, train loss = 2.414448, train accuracy = 0.296875\n",
      "[2018-07-17 22:13:42.300694] Iteration 9300, train loss = 2.420121, train accuracy = 0.265625\n",
      "[2018-07-17 22:13:49.283144] Iteration 9400, train loss = 2.424380, train accuracy = 0.281250\n",
      "[2018-07-17 22:13:56.387370] Iteration 9500, train loss = 2.548963, train accuracy = 0.296875\n",
      "[2018-07-17 22:14:03.503976] Iteration 9600, train loss = 2.690348, train accuracy = 0.234375\n",
      "[2018-07-17 22:14:10.462970] Iteration 9700, train loss = 2.373693, train accuracy = 0.296875\n",
      "[2018-07-17 22:14:17.575577] Iteration 9800, train loss = 2.508795, train accuracy = 0.273438\n",
      "[2018-07-17 22:14:24.684571] Iteration 9900, train loss = 2.232362, train accuracy = 0.320312\n",
      "[2018-07-17 22:14:31.742151] Iteration 10000, train loss = 2.435919, train accuracy = 0.250000\n",
      "Evaluating...\n",
      "Test accuracy = 0.275500\n",
      "[2018-07-17 22:14:41.199928] Iteration 10100, train loss = 2.492604, train accuracy = 0.273438\n",
      "[2018-07-17 22:14:48.314020] Iteration 10200, train loss = 2.421279, train accuracy = 0.281250\n",
      "[2018-07-17 22:14:55.445297] Iteration 10300, train loss = 2.397962, train accuracy = 0.210938\n",
      "[2018-07-17 22:15:02.389433] Iteration 10400, train loss = 2.498652, train accuracy = 0.226562\n",
      "[2018-07-17 22:15:09.384386] Iteration 10500, train loss = 2.273670, train accuracy = 0.320312\n",
      "[2018-07-17 22:15:16.483680] Iteration 10600, train loss = 2.459412, train accuracy = 0.257812\n",
      "[2018-07-17 22:15:23.600983] Iteration 10700, train loss = 2.434259, train accuracy = 0.296875\n",
      "[2018-07-17 22:15:30.620826] Iteration 10800, train loss = 2.421561, train accuracy = 0.226562\n",
      "[2018-07-17 22:15:37.702107] Iteration 10900, train loss = 2.405125, train accuracy = 0.296875\n",
      "[2018-07-17 22:15:44.813871] Iteration 11000, train loss = 2.553144, train accuracy = 0.234375\n",
      "Evaluating...\n",
      "Test accuracy = 0.275400\n",
      "[2018-07-17 22:15:54.520676] Iteration 11100, train loss = 2.526702, train accuracy = 0.281250\n",
      "[2018-07-17 22:16:01.668113] Iteration 11200, train loss = 2.417079, train accuracy = 0.257812\n",
      "[2018-07-17 22:16:08.488958] Iteration 11300, train loss = 2.596757, train accuracy = 0.195312\n",
      "[2018-07-17 22:16:15.449813] Iteration 11400, train loss = 2.436998, train accuracy = 0.328125\n",
      "[2018-07-17 22:16:22.379373] Iteration 11500, train loss = 2.465658, train accuracy = 0.273438\n",
      "[2018-07-17 22:16:29.315226] Iteration 11600, train loss = 2.294558, train accuracy = 0.281250\n",
      "[2018-07-17 22:16:36.456507] Iteration 11700, train loss = 2.382038, train accuracy = 0.312500\n",
      "[2018-07-17 22:16:43.519102] Iteration 11800, train loss = 2.562476, train accuracy = 0.320312\n",
      "[2018-07-17 22:16:50.635652] Iteration 11900, train loss = 2.433986, train accuracy = 0.203125\n",
      "[2018-07-17 22:16:57.533651] Iteration 12000, train loss = 2.443380, train accuracy = 0.273438\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:17:07.185131] Iteration 12100, train loss = 2.524619, train accuracy = 0.281250\n",
      "[2018-07-17 22:17:14.246444] Iteration 12200, train loss = 2.206967, train accuracy = 0.296875\n",
      "[2018-07-17 22:17:21.333605] Iteration 12300, train loss = 2.237537, train accuracy = 0.257812\n",
      "[2018-07-17 22:17:28.209365] Iteration 12400, train loss = 2.332783, train accuracy = 0.257812\n",
      "[2018-07-17 22:17:35.252744] Iteration 12500, train loss = 2.461283, train accuracy = 0.281250\n",
      "[2018-07-17 22:17:42.358614] Iteration 12600, train loss = 2.266898, train accuracy = 0.304688\n",
      "[2018-07-17 22:17:49.302858] Iteration 12700, train loss = 2.386039, train accuracy = 0.281250\n",
      "[2018-07-17 22:17:56.217521] Iteration 12800, train loss = 2.412221, train accuracy = 0.304688\n",
      "[2018-07-17 22:18:03.304221] Iteration 12900, train loss = 2.501747, train accuracy = 0.203125\n",
      "[2018-07-17 22:18:10.301098] Iteration 13000, train loss = 2.263446, train accuracy = 0.273438\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 22:18:19.893569] Iteration 13100, train loss = 2.480235, train accuracy = 0.234375\n",
      "[2018-07-17 22:18:26.935536] Iteration 13200, train loss = 2.308810, train accuracy = 0.273438\n",
      "[2018-07-17 22:18:33.747411] Iteration 13300, train loss = 2.562742, train accuracy = 0.242188\n",
      "[2018-07-17 22:18:40.662620] Iteration 13400, train loss = 2.315493, train accuracy = 0.289062\n",
      "[2018-07-17 22:18:47.730717] Iteration 13500, train loss = 2.470849, train accuracy = 0.304688\n",
      "[2018-07-17 22:18:54.638951] Iteration 13600, train loss = 2.505940, train accuracy = 0.257812\n",
      "[2018-07-17 22:19:01.687659] Iteration 13700, train loss = 2.375432, train accuracy = 0.289062\n",
      "[2018-07-17 22:19:08.759281] Iteration 13800, train loss = 2.367844, train accuracy = 0.312500\n",
      "[2018-07-17 22:19:15.859926] Iteration 13900, train loss = 2.383322, train accuracy = 0.312500\n",
      "[2018-07-17 22:19:22.835975] Iteration 14000, train loss = 2.414783, train accuracy = 0.257812\n",
      "Evaluating...\n",
      "Test accuracy = 0.274900\n",
      "[2018-07-17 22:19:32.407400] Iteration 14100, train loss = 2.442790, train accuracy = 0.257812\n",
      "[2018-07-17 22:19:39.464412] Iteration 14200, train loss = 2.319576, train accuracy = 0.242188\n",
      "[2018-07-17 22:19:46.604264] Iteration 14300, train loss = 2.369394, train accuracy = 0.289062\n",
      "[2018-07-17 22:19:53.712659] Iteration 14400, train loss = 2.309197, train accuracy = 0.328125\n",
      "[2018-07-17 22:20:00.782146] Iteration 14500, train loss = 2.335499, train accuracy = 0.312500\n",
      "[2018-07-17 22:20:07.837395] Iteration 14600, train loss = 2.579324, train accuracy = 0.242188\n",
      "[2018-07-17 22:20:14.719049] Iteration 14700, train loss = 2.365770, train accuracy = 0.289062\n",
      "[2018-07-17 22:20:21.678642] Iteration 14800, train loss = 2.346894, train accuracy = 0.257812\n",
      "[2018-07-17 22:20:28.796232] Iteration 14900, train loss = 2.335898, train accuracy = 0.273438\n",
      "[2018-07-17 22:20:35.898959] Iteration 15000, train loss = 2.361304, train accuracy = 0.304688\n",
      "Evaluating...\n",
      "Test accuracy = 0.276400\n",
      "[2018-07-17 22:20:45.403098] Iteration 15100, train loss = 2.322223, train accuracy = 0.273438\n",
      "[2018-07-17 22:20:52.480222] Iteration 15200, train loss = 2.118511, train accuracy = 0.312500\n",
      "[2018-07-17 22:20:59.241010] Iteration 15300, train loss = 2.175824, train accuracy = 0.265625\n",
      "[2018-07-17 22:21:06.128315] Iteration 15400, train loss = 2.446614, train accuracy = 0.226562\n",
      "[2018-07-17 22:21:13.133247] Iteration 15500, train loss = 2.463441, train accuracy = 0.218750\n",
      "[2018-07-17 22:21:20.225245] Iteration 15600, train loss = 2.520153, train accuracy = 0.304688\n",
      "[2018-07-17 22:21:27.309340] Iteration 15700, train loss = 2.687470, train accuracy = 0.210938\n",
      "[2018-07-17 22:21:34.417478] Iteration 15800, train loss = 2.286314, train accuracy = 0.320312\n",
      "[2018-07-17 22:21:41.290075] Iteration 15900, train loss = 2.396588, train accuracy = 0.242188\n",
      "[2018-07-17 22:21:48.113442] Iteration 16000, train loss = 2.443395, train accuracy = 0.257812\n",
      "Evaluating...\n",
      "Test accuracy = 0.276200\n",
      "[2018-07-17 22:21:57.667824] Iteration 16100, train loss = 2.496969, train accuracy = 0.218750\n",
      "[2018-07-17 22:22:04.776047] Iteration 16200, train loss = 2.334353, train accuracy = 0.312500\n",
      "[2018-07-17 22:22:11.829117] Iteration 16300, train loss = 2.499156, train accuracy = 0.218750\n",
      "[2018-07-17 22:22:18.870472] Iteration 16400, train loss = 2.335793, train accuracy = 0.250000\n",
      "[2018-07-17 22:22:25.990000] Iteration 16500, train loss = 2.550508, train accuracy = 0.257812\n",
      "[2018-07-17 22:22:33.106187] Iteration 16600, train loss = 2.494791, train accuracy = 0.281250\n",
      "[2018-07-17 22:22:40.251702] Iteration 16700, train loss = 2.335464, train accuracy = 0.281250\n",
      "[2018-07-17 22:22:47.201100] Iteration 16800, train loss = 2.461290, train accuracy = 0.257812\n",
      "[2018-07-17 22:22:54.274342] Iteration 16900, train loss = 2.271813, train accuracy = 0.320312\n",
      "[2018-07-17 22:23:01.302228] Iteration 17000, train loss = 2.451095, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.276000\n",
      "[2018-07-17 22:23:10.821976] Iteration 17100, train loss = 2.678604, train accuracy = 0.250000\n",
      "[2018-07-17 22:23:17.794728] Iteration 17200, train loss = 2.335775, train accuracy = 0.296875\n",
      "[2018-07-17 22:23:24.895452] Iteration 17300, train loss = 2.574142, train accuracy = 0.195312\n",
      "[2018-07-17 22:23:31.873022] Iteration 17400, train loss = 2.451779, train accuracy = 0.203125\n",
      "[2018-07-17 22:23:38.696005] Iteration 17500, train loss = 2.543104, train accuracy = 0.218750\n",
      "[2018-07-17 22:23:45.736174] Iteration 17600, train loss = 2.723465, train accuracy = 0.203125\n",
      "[2018-07-17 22:23:52.855485] Iteration 17700, train loss = 2.384308, train accuracy = 0.304688\n",
      "[2018-07-17 22:23:59.935324] Iteration 17800, train loss = 2.559903, train accuracy = 0.281250\n",
      "[2018-07-17 22:24:06.889685] Iteration 17900, train loss = 2.350328, train accuracy = 0.320312\n",
      "[2018-07-17 22:24:13.900258] Iteration 18000, train loss = 2.458559, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 22:24:23.362176] Iteration 18100, train loss = 2.317165, train accuracy = 0.304688\n",
      "[2018-07-17 22:24:30.190774] Iteration 18200, train loss = 2.428573, train accuracy = 0.234375\n",
      "[2018-07-17 22:24:37.179446] Iteration 18300, train loss = 2.373482, train accuracy = 0.273438\n",
      "[2018-07-17 22:24:44.278981] Iteration 18400, train loss = 2.311887, train accuracy = 0.320312\n",
      "[2018-07-17 22:24:51.241659] Iteration 18500, train loss = 2.274074, train accuracy = 0.234375\n",
      "[2018-07-17 22:24:58.335409] Iteration 18600, train loss = 2.531288, train accuracy = 0.281250\n",
      "[2018-07-17 22:25:05.427371] Iteration 18700, train loss = 2.357980, train accuracy = 0.304688\n",
      "[2018-07-17 22:25:12.497216] Iteration 18800, train loss = 2.298405, train accuracy = 0.281250\n",
      "[2018-07-17 22:25:19.522494] Iteration 18900, train loss = 2.401142, train accuracy = 0.296875\n",
      "[2018-07-17 22:25:26.485821] Iteration 19000, train loss = 2.631731, train accuracy = 0.250000\n",
      "Evaluating...\n",
      "Test accuracy = 0.275400\n",
      "[2018-07-17 22:25:35.839066] Iteration 19100, train loss = 2.359616, train accuracy = 0.234375\n",
      "[2018-07-17 22:25:42.785390] Iteration 19200, train loss = 2.507355, train accuracy = 0.226562\n",
      "[2018-07-17 22:25:49.859537] Iteration 19300, train loss = 2.409512, train accuracy = 0.273438\n",
      "[2018-07-17 22:25:56.682844] Iteration 19400, train loss = 2.580282, train accuracy = 0.242188\n",
      "[2018-07-17 22:26:03.577469] Iteration 19500, train loss = 2.736297, train accuracy = 0.218750\n",
      "[2018-07-17 22:26:10.708868] Iteration 19600, train loss = 2.570087, train accuracy = 0.164062\n",
      "[2018-07-17 22:26:17.792246] Iteration 19700, train loss = 2.461274, train accuracy = 0.257812\n",
      "[2018-07-17 22:26:24.884500] Iteration 19800, train loss = 2.287838, train accuracy = 0.312500\n",
      "[2018-07-17 22:26:31.753277] Iteration 19900, train loss = 2.460653, train accuracy = 0.265625\n",
      "[2018-07-17 22:26:38.572054] Iteration 20000, train loss = 2.362152, train accuracy = 0.312500\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:26:48.100020] Iteration 20100, train loss = 2.507373, train accuracy = 0.296875\n",
      "[2018-07-17 22:26:55.112454] Iteration 20200, train loss = 2.672261, train accuracy = 0.218750\n",
      "[2018-07-17 22:27:02.105665] Iteration 20300, train loss = 2.234539, train accuracy = 0.351562\n",
      "[2018-07-17 22:27:09.176283] Iteration 20400, train loss = 2.412033, train accuracy = 0.296875\n",
      "[2018-07-17 22:27:16.255822] Iteration 20500, train loss = 2.351438, train accuracy = 0.281250\n",
      "[2018-07-17 22:27:23.349826] Iteration 20600, train loss = 2.356158, train accuracy = 0.296875\n",
      "[2018-07-17 22:27:30.332829] Iteration 20700, train loss = 2.491370, train accuracy = 0.281250\n",
      "[2018-07-17 22:27:37.339612] Iteration 20800, train loss = 2.340286, train accuracy = 0.242188\n",
      "[2018-07-17 22:27:44.432774] Iteration 20900, train loss = 2.616598, train accuracy = 0.226562\n",
      "[2018-07-17 22:27:51.332806] Iteration 21000, train loss = 2.402031, train accuracy = 0.250000\n",
      "Evaluating...\n",
      "Test accuracy = 0.274800\n",
      "[2018-07-17 22:28:00.977063] Iteration 21100, train loss = 2.572181, train accuracy = 0.226562\n",
      "[2018-07-17 22:28:08.087306] Iteration 21200, train loss = 2.395908, train accuracy = 0.320312\n",
      "[2018-07-17 22:28:14.903554] Iteration 21300, train loss = 2.381526, train accuracy = 0.289062\n",
      "[2018-07-17 22:28:21.917427] Iteration 21400, train loss = 2.234079, train accuracy = 0.273438\n",
      "[2018-07-17 22:28:29.005529] Iteration 21500, train loss = 2.297178, train accuracy = 0.312500\n",
      "[2018-07-17 22:28:36.100943] Iteration 21600, train loss = 2.651935, train accuracy = 0.218750\n",
      "[2018-07-17 22:28:43.044902] Iteration 21700, train loss = 2.532388, train accuracy = 0.265625\n",
      "[2018-07-17 22:28:50.018533] Iteration 21800, train loss = 2.470124, train accuracy = 0.281250\n",
      "[2018-07-17 22:28:56.994514] Iteration 21900, train loss = 2.511461, train accuracy = 0.226562\n",
      "[2018-07-17 22:29:04.129353] Iteration 22000, train loss = 2.358716, train accuracy = 0.273438\n",
      "Evaluating...\n",
      "Test accuracy = 0.275200\n",
      "[2018-07-17 22:29:13.750582] Iteration 22100, train loss = 2.434275, train accuracy = 0.242188\n",
      "[2018-07-17 22:29:20.854880] Iteration 22200, train loss = 2.417717, train accuracy = 0.281250\n",
      "[2018-07-17 22:29:27.975816] Iteration 22300, train loss = 2.486949, train accuracy = 0.250000\n",
      "[2018-07-17 22:29:35.063505] Iteration 22400, train loss = 2.439870, train accuracy = 0.296875\n",
      "[2018-07-17 22:29:42.164940] Iteration 22500, train loss = 2.538541, train accuracy = 0.242188\n",
      "[2018-07-17 22:29:49.316555] Iteration 22600, train loss = 2.574090, train accuracy = 0.210938\n",
      "[2018-07-17 22:29:56.372284] Iteration 22700, train loss = 2.386137, train accuracy = 0.273438\n",
      "[2018-07-17 22:30:03.500087] Iteration 22800, train loss = 2.442045, train accuracy = 0.273438\n",
      "[2018-07-17 22:30:10.583152] Iteration 22900, train loss = 2.568344, train accuracy = 0.203125\n",
      "[2018-07-17 22:30:17.666045] Iteration 23000, train loss = 2.624322, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275300\n",
      "[2018-07-17 22:30:27.310240] Iteration 23100, train loss = 2.453924, train accuracy = 0.289062\n",
      "[2018-07-17 22:30:34.365614] Iteration 23200, train loss = 2.342094, train accuracy = 0.273438\n",
      "[2018-07-17 22:30:41.487760] Iteration 23300, train loss = 2.354664, train accuracy = 0.242188\n",
      "[2018-07-17 22:30:48.383949] Iteration 23400, train loss = 2.407035, train accuracy = 0.289062\n",
      "[2018-07-17 22:30:55.516721] Iteration 23500, train loss = 2.409657, train accuracy = 0.281250\n",
      "[2018-07-17 22:31:02.604000] Iteration 23600, train loss = 2.395901, train accuracy = 0.210938\n",
      "[2018-07-17 22:31:09.672002] Iteration 23700, train loss = 2.552359, train accuracy = 0.265625\n",
      "[2018-07-17 22:31:16.801628] Iteration 23800, train loss = 2.557155, train accuracy = 0.257812\n",
      "[2018-07-17 22:31:23.910794] Iteration 23900, train loss = 2.371884, train accuracy = 0.257812\n",
      "[2018-07-17 22:31:31.042863] Iteration 24000, train loss = 2.434753, train accuracy = 0.304688\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:31:40.626786] Iteration 24100, train loss = 2.647771, train accuracy = 0.187500\n",
      "[2018-07-17 22:31:47.477166] Iteration 24200, train loss = 2.461336, train accuracy = 0.234375\n",
      "[2018-07-17 22:31:54.563322] Iteration 24300, train loss = 2.563113, train accuracy = 0.242188\n",
      "[2018-07-17 22:32:01.626084] Iteration 24400, train loss = 2.504135, train accuracy = 0.265625\n",
      "[2018-07-17 22:32:08.674210] Iteration 24500, train loss = 2.421598, train accuracy = 0.250000\n",
      "[2018-07-17 22:32:15.585120] Iteration 24600, train loss = 2.262383, train accuracy = 0.335938\n",
      "[2018-07-17 22:32:22.687469] Iteration 24700, train loss = 2.560568, train accuracy = 0.265625\n",
      "[2018-07-17 22:32:29.804097] Iteration 24800, train loss = 2.311103, train accuracy = 0.273438\n",
      "[2018-07-17 22:32:36.626557] Iteration 24900, train loss = 2.368575, train accuracy = 0.281250\n",
      "[2018-07-17 22:32:43.475084] Iteration 25000, train loss = 2.462112, train accuracy = 0.226562\n",
      "Evaluating...\n",
      "Test accuracy = 0.275300\n",
      "[2018-07-17 22:32:52.926607] Iteration 25100, train loss = 2.528797, train accuracy = 0.210938\n",
      "[2018-07-17 22:32:59.852494] Iteration 25200, train loss = 2.650926, train accuracy = 0.195312\n",
      "[2018-07-17 22:33:06.974630] Iteration 25300, train loss = 2.499625, train accuracy = 0.234375\n",
      "[2018-07-17 22:33:14.086995] Iteration 25400, train loss = 2.572934, train accuracy = 0.210938\n",
      "[2018-07-17 22:33:21.153949] Iteration 25500, train loss = 2.475664, train accuracy = 0.242188\n",
      "[2018-07-17 22:33:28.239852] Iteration 25600, train loss = 2.588233, train accuracy = 0.242188\n",
      "[2018-07-17 22:33:35.406459] Iteration 25700, train loss = 2.576258, train accuracy = 0.226562\n",
      "[2018-07-17 22:33:42.488528] Iteration 25800, train loss = 2.673473, train accuracy = 0.289062\n",
      "[2018-07-17 22:33:49.605507] Iteration 25900, train loss = 2.364792, train accuracy = 0.296875\n",
      "[2018-07-17 22:33:56.718614] Iteration 26000, train loss = 2.322713, train accuracy = 0.250000\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:34:06.351570] Iteration 26100, train loss = 2.328634, train accuracy = 0.328125\n",
      "[2018-07-17 22:34:13.432868] Iteration 26200, train loss = 2.328801, train accuracy = 0.242188\n",
      "[2018-07-17 22:34:20.498126] Iteration 26300, train loss = 2.314505, train accuracy = 0.273438\n",
      "[2018-07-17 22:34:27.629913] Iteration 26400, train loss = 2.399992, train accuracy = 0.257812\n",
      "[2018-07-17 22:34:34.714566] Iteration 26500, train loss = 2.789699, train accuracy = 0.210938\n",
      "[2018-07-17 22:34:41.810415] Iteration 26600, train loss = 2.380000, train accuracy = 0.289062\n",
      "[2018-07-17 22:34:48.915588] Iteration 26700, train loss = 2.616032, train accuracy = 0.265625\n",
      "[2018-07-17 22:34:55.819321] Iteration 26800, train loss = 2.432099, train accuracy = 0.234375\n",
      "[2018-07-17 22:35:02.927323] Iteration 26900, train loss = 2.506315, train accuracy = 0.296875\n",
      "[2018-07-17 22:35:10.072540] Iteration 27000, train loss = 2.544940, train accuracy = 0.257812\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:35:19.734668] Iteration 27100, train loss = 2.512269, train accuracy = 0.234375\n",
      "[2018-07-17 22:35:26.833243] Iteration 27200, train loss = 2.347806, train accuracy = 0.234375\n",
      "[2018-07-17 22:35:33.900404] Iteration 27300, train loss = 2.533632, train accuracy = 0.226562\n",
      "[2018-07-17 22:35:40.928075] Iteration 27400, train loss = 2.464288, train accuracy = 0.281250\n",
      "[2018-07-17 22:35:47.830590] Iteration 27500, train loss = 2.445703, train accuracy = 0.273438\n",
      "[2018-07-17 22:35:54.816678] Iteration 27600, train loss = 2.379226, train accuracy = 0.304688\n",
      "[2018-07-17 22:36:01.928233] Iteration 27700, train loss = 2.430531, train accuracy = 0.265625\n",
      "[2018-07-17 22:36:08.781275] Iteration 27800, train loss = 2.414970, train accuracy = 0.304688\n",
      "[2018-07-17 22:36:15.594194] Iteration 27900, train loss = 2.436534, train accuracy = 0.296875\n",
      "[2018-07-17 22:36:22.403133] Iteration 28000, train loss = 2.397455, train accuracy = 0.296875\n",
      "Evaluating...\n",
      "Test accuracy = 0.275300\n",
      "[2018-07-17 22:36:31.903652] Iteration 28100, train loss = 2.160132, train accuracy = 0.289062\n",
      "[2018-07-17 22:36:38.995105] Iteration 28200, train loss = 2.429483, train accuracy = 0.242188\n",
      "[2018-07-17 22:36:46.069396] Iteration 28300, train loss = 2.421027, train accuracy = 0.289062\n",
      "[2018-07-17 22:36:53.221492] Iteration 28400, train loss = 2.573611, train accuracy = 0.226562\n",
      "[2018-07-17 22:37:00.359031] Iteration 28500, train loss = 2.475159, train accuracy = 0.234375\n",
      "[2018-07-17 22:37:07.424469] Iteration 28600, train loss = 2.313097, train accuracy = 0.328125\n",
      "[2018-07-17 22:37:14.273403] Iteration 28700, train loss = 2.451154, train accuracy = 0.218750\n",
      "[2018-07-17 22:37:21.116104] Iteration 28800, train loss = 2.331161, train accuracy = 0.296875\n",
      "[2018-07-17 22:37:27.965616] Iteration 28900, train loss = 2.443653, train accuracy = 0.265625\n",
      "[2018-07-17 22:37:34.982182] Iteration 29000, train loss = 2.350885, train accuracy = 0.382812\n",
      "Evaluating...\n",
      "Test accuracy = 0.276300\n",
      "[2018-07-17 22:37:44.529562] Iteration 29100, train loss = 2.388987, train accuracy = 0.296875\n",
      "[2018-07-17 22:37:51.489998] Iteration 29200, train loss = 2.330799, train accuracy = 0.304688\n",
      "[2018-07-17 22:37:58.623341] Iteration 29300, train loss = 2.452343, train accuracy = 0.304688\n",
      "[2018-07-17 22:38:05.563910] Iteration 29400, train loss = 2.477371, train accuracy = 0.226562\n",
      "[2018-07-17 22:38:12.471800] Iteration 29500, train loss = 2.427695, train accuracy = 0.296875\n",
      "[2018-07-17 22:38:19.283838] Iteration 29600, train loss = 2.406639, train accuracy = 0.289062\n",
      "[2018-07-17 22:38:26.291304] Iteration 29700, train loss = 2.466728, train accuracy = 0.312500\n",
      "[2018-07-17 22:38:33.377628] Iteration 29800, train loss = 2.513599, train accuracy = 0.234375\n",
      "[2018-07-17 22:38:40.370769] Iteration 29900, train loss = 2.312119, train accuracy = 0.281250\n",
      "[2018-07-17 22:38:47.404147] Iteration 30000, train loss = 2.545281, train accuracy = 0.171875\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:38:57.020086] Iteration 30100, train loss = 2.343260, train accuracy = 0.328125\n",
      "[2018-07-17 22:39:04.155449] Iteration 30200, train loss = 2.610777, train accuracy = 0.210938\n",
      "[2018-07-17 22:39:10.955583] Iteration 30300, train loss = 2.347689, train accuracy = 0.304688\n",
      "[2018-07-17 22:39:17.800628] Iteration 30400, train loss = 2.406491, train accuracy = 0.265625\n",
      "[2018-07-17 22:39:24.742819] Iteration 30500, train loss = 2.661055, train accuracy = 0.171875\n",
      "[2018-07-17 22:39:31.828531] Iteration 30600, train loss = 2.393593, train accuracy = 0.265625\n",
      "[2018-07-17 22:39:38.979733] Iteration 30700, train loss = 2.529888, train accuracy = 0.242188\n",
      "[2018-07-17 22:39:46.109534] Iteration 30800, train loss = 2.608529, train accuracy = 0.273438\n",
      "[2018-07-17 22:39:53.084935] Iteration 30900, train loss = 2.354089, train accuracy = 0.367188\n",
      "[2018-07-17 22:40:00.197581] Iteration 31000, train loss = 2.544626, train accuracy = 0.218750\n",
      "Evaluating...\n",
      "Test accuracy = 0.275300\n",
      "[2018-07-17 22:40:09.823755] Iteration 31100, train loss = 2.376655, train accuracy = 0.250000\n",
      "[2018-07-17 22:40:16.725924] Iteration 31200, train loss = 2.494246, train accuracy = 0.265625\n",
      "[2018-07-17 22:40:23.519311] Iteration 31300, train loss = 2.508601, train accuracy = 0.281250\n",
      "[2018-07-17 22:40:30.619157] Iteration 31400, train loss = 2.586452, train accuracy = 0.281250\n",
      "[2018-07-17 22:40:37.697571] Iteration 31500, train loss = 2.565788, train accuracy = 0.273438\n",
      "[2018-07-17 22:40:44.821609] Iteration 31600, train loss = 2.385268, train accuracy = 0.257812\n",
      "[2018-07-17 22:40:51.862888] Iteration 31700, train loss = 2.462515, train accuracy = 0.257812\n",
      "[2018-07-17 22:40:58.754955] Iteration 31800, train loss = 2.625700, train accuracy = 0.257812\n",
      "[2018-07-17 22:41:05.582563] Iteration 31900, train loss = 2.600600, train accuracy = 0.273438\n",
      "[2018-07-17 22:41:12.394704] Iteration 32000, train loss = 2.288139, train accuracy = 0.320312\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 22:41:21.781502] Iteration 32100, train loss = 2.407221, train accuracy = 0.257812\n",
      "[2018-07-17 22:41:28.782111] Iteration 32200, train loss = 2.455934, train accuracy = 0.242188\n",
      "[2018-07-17 22:41:35.896354] Iteration 32300, train loss = 2.430559, train accuracy = 0.242188\n",
      "[2018-07-17 22:41:42.821673] Iteration 32400, train loss = 2.414942, train accuracy = 0.281250\n",
      "[2018-07-17 22:41:49.980316] Iteration 32500, train loss = 2.172170, train accuracy = 0.343750\n",
      "[2018-07-17 22:41:56.999950] Iteration 32600, train loss = 2.417298, train accuracy = 0.226562\n",
      "[2018-07-17 22:42:03.900339] Iteration 32700, train loss = 2.539592, train accuracy = 0.218750\n",
      "[2018-07-17 22:42:10.701261] Iteration 32800, train loss = 2.345258, train accuracy = 0.289062\n",
      "[2018-07-17 22:42:17.689116] Iteration 32900, train loss = 2.406229, train accuracy = 0.250000\n",
      "[2018-07-17 22:42:24.793968] Iteration 33000, train loss = 2.637311, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275000\n",
      "[2018-07-17 22:42:34.233049] Iteration 33100, train loss = 2.369335, train accuracy = 0.335938\n",
      "[2018-07-17 22:42:41.262508] Iteration 33200, train loss = 2.449537, train accuracy = 0.289062\n",
      "[2018-07-17 22:42:48.222572] Iteration 33300, train loss = 2.537446, train accuracy = 0.210938\n",
      "[2018-07-17 22:42:55.339697] Iteration 33400, train loss = 2.483605, train accuracy = 0.242188\n",
      "[2018-07-17 22:43:02.446260] Iteration 33500, train loss = 2.320637, train accuracy = 0.242188\n",
      "[2018-07-17 22:43:09.414134] Iteration 33600, train loss = 2.404036, train accuracy = 0.296875\n",
      "[2018-07-17 22:43:16.366132] Iteration 33700, train loss = 2.518164, train accuracy = 0.265625\n",
      "[2018-07-17 22:43:23.283412] Iteration 33800, train loss = 2.426232, train accuracy = 0.281250\n",
      "[2018-07-17 22:43:30.267106] Iteration 33900, train loss = 2.450707, train accuracy = 0.304688\n",
      "[2018-07-17 22:43:37.321390] Iteration 34000, train loss = 2.412223, train accuracy = 0.273438\n",
      "Evaluating...\n",
      "Test accuracy = 0.275100\n",
      "[2018-07-17 22:43:46.945984] Iteration 34100, train loss = 2.508133, train accuracy = 0.265625\n",
      "[2018-07-17 22:43:54.017376] Iteration 34200, train loss = 2.508096, train accuracy = 0.281250\n",
      "[2018-07-17 22:44:01.125189] Iteration 34300, train loss = 2.502331, train accuracy = 0.265625\n",
      "[2018-07-17 22:44:08.237800] Iteration 34400, train loss = 2.301719, train accuracy = 0.328125\n",
      "[2018-07-17 22:44:15.205228] Iteration 34500, train loss = 2.752878, train accuracy = 0.132812\n",
      "[2018-07-17 22:44:22.299132] Iteration 34600, train loss = 2.451373, train accuracy = 0.257812\n",
      "[2018-07-17 22:44:29.455873] Iteration 34700, train loss = 2.387929, train accuracy = 0.257812\n",
      "[2018-07-17 22:44:36.404467] Iteration 34800, train loss = 2.125620, train accuracy = 0.398438\n",
      "[2018-07-17 22:44:43.248333] Iteration 34900, train loss = 2.588903, train accuracy = 0.257812\n",
      "[2018-07-17 22:44:50.321498] Iteration 35000, train loss = 2.509317, train accuracy = 0.250000\n",
      "Evaluating...\n",
      "Test accuracy = 0.276100\n",
      "[2018-07-17 22:44:59.758253] Iteration 35100, train loss = 2.496397, train accuracy = 0.250000\n",
      "[2018-07-17 22:45:06.568647] Iteration 35200, train loss = 2.551144, train accuracy = 0.250000\n",
      "[2018-07-17 22:45:13.555866] Iteration 35300, train loss = 2.573763, train accuracy = 0.218750\n",
      "[2018-07-17 22:45:20.637366] Iteration 35400, train loss = 2.336549, train accuracy = 0.320312\n",
      "[2018-07-17 22:45:27.787490] Iteration 35500, train loss = 2.563149, train accuracy = 0.250000\n",
      "[2018-07-17 22:45:34.884978] Iteration 35600, train loss = 2.280929, train accuracy = 0.281250\n",
      "[2018-07-17 22:45:42.047489] Iteration 35700, train loss = 2.432049, train accuracy = 0.234375\n",
      "[2018-07-17 22:45:49.194403] Iteration 35800, train loss = 2.651841, train accuracy = 0.210938\n",
      "[2018-07-17 22:45:56.260293] Iteration 35900, train loss = 2.530559, train accuracy = 0.218750\n",
      "[2018-07-17 22:46:03.309337] Iteration 36000, train loss = 2.262374, train accuracy = 0.296875\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 22:46:12.682913] Iteration 36100, train loss = 2.443871, train accuracy = 0.289062\n",
      "[2018-07-17 22:46:19.794648] Iteration 36200, train loss = 2.396360, train accuracy = 0.250000\n",
      "[2018-07-17 22:46:26.632564] Iteration 36300, train loss = 2.264963, train accuracy = 0.281250\n",
      "[2018-07-17 22:46:33.710327] Iteration 36400, train loss = 2.364353, train accuracy = 0.296875\n",
      "[2018-07-17 22:46:40.852154] Iteration 36500, train loss = 2.496204, train accuracy = 0.218750\n",
      "[2018-07-17 22:46:47.669018] Iteration 36600, train loss = 2.596786, train accuracy = 0.289062\n",
      "[2018-07-17 22:46:54.733216] Iteration 36700, train loss = 2.652286, train accuracy = 0.281250\n",
      "[2018-07-17 22:47:01.801730] Iteration 36800, train loss = 2.656389, train accuracy = 0.210938\n",
      "[2018-07-17 22:47:08.912878] Iteration 36900, train loss = 2.475250, train accuracy = 0.203125\n",
      "[2018-07-17 22:47:15.972634] Iteration 37000, train loss = 2.655842, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 22:47:25.498077] Iteration 37100, train loss = 2.514417, train accuracy = 0.210938\n",
      "[2018-07-17 22:47:32.343887] Iteration 37200, train loss = 2.533338, train accuracy = 0.164062\n",
      "[2018-07-17 22:47:39.149769] Iteration 37300, train loss = 2.542769, train accuracy = 0.226562\n",
      "[2018-07-17 22:47:46.059969] Iteration 37400, train loss = 2.665332, train accuracy = 0.257812\n",
      "[2018-07-17 22:47:53.126895] Iteration 37500, train loss = 2.646569, train accuracy = 0.242188\n",
      "[2018-07-17 22:48:00.096688] Iteration 37600, train loss = 2.396006, train accuracy = 0.312500\n",
      "[2018-07-17 22:48:07.036988] Iteration 37700, train loss = 2.573311, train accuracy = 0.203125\n",
      "[2018-07-17 22:48:14.185526] Iteration 37800, train loss = 2.486645, train accuracy = 0.234375\n",
      "[2018-07-17 22:48:21.138402] Iteration 37900, train loss = 2.656843, train accuracy = 0.242188\n",
      "[2018-07-17 22:48:28.053131] Iteration 38000, train loss = 2.614169, train accuracy = 0.218750\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:48:37.441730] Iteration 38100, train loss = 2.443563, train accuracy = 0.273438\n",
      "[2018-07-17 22:48:44.468203] Iteration 38200, train loss = 2.467135, train accuracy = 0.234375\n",
      "[2018-07-17 22:48:51.458954] Iteration 38300, train loss = 2.574337, train accuracy = 0.281250\n",
      "[2018-07-17 22:48:58.416675] Iteration 38400, train loss = 2.439905, train accuracy = 0.257812\n",
      "[2018-07-17 22:49:05.534476] Iteration 38500, train loss = 2.501946, train accuracy = 0.296875\n",
      "[2018-07-17 22:49:12.656601] Iteration 38600, train loss = 2.370670, train accuracy = 0.304688\n",
      "[2018-07-17 22:49:19.715147] Iteration 38700, train loss = 2.424336, train accuracy = 0.289062\n",
      "[2018-07-17 22:49:26.672070] Iteration 38800, train loss = 2.181038, train accuracy = 0.351562\n",
      "[2018-07-17 22:49:33.705086] Iteration 38900, train loss = 2.727303, train accuracy = 0.187500\n",
      "[2018-07-17 22:49:40.703354] Iteration 39000, train loss = 2.551527, train accuracy = 0.234375\n",
      "Evaluating...\n",
      "Test accuracy = 0.275400\n",
      "[2018-07-17 22:49:50.293244] Iteration 39100, train loss = 2.253845, train accuracy = 0.289062\n",
      "[2018-07-17 22:49:57.274475] Iteration 39200, train loss = 2.502938, train accuracy = 0.218750\n",
      "[2018-07-17 22:50:04.162718] Iteration 39300, train loss = 2.354862, train accuracy = 0.289062\n",
      "[2018-07-17 22:50:10.956208] Iteration 39400, train loss = 2.278618, train accuracy = 0.304688\n",
      "[2018-07-17 22:50:18.043359] Iteration 39500, train loss = 2.229253, train accuracy = 0.351562\n",
      "[2018-07-17 22:50:25.130897] Iteration 39600, train loss = 2.323987, train accuracy = 0.304688\n",
      "[2018-07-17 22:50:32.216073] Iteration 39700, train loss = 2.398324, train accuracy = 0.281250\n",
      "[2018-07-17 22:50:39.291506] Iteration 39800, train loss = 2.642099, train accuracy = 0.203125\n",
      "[2018-07-17 22:50:46.200567] Iteration 39900, train loss = 2.287221, train accuracy = 0.335938\n",
      "[2018-07-17 22:50:53.035496] Iteration 40000, train loss = 2.398806, train accuracy = 0.218750\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:51:02.682372] Iteration 40100, train loss = 2.559593, train accuracy = 0.203125\n",
      "[2018-07-17 22:51:09.793200] Iteration 40200, train loss = 2.373515, train accuracy = 0.250000\n",
      "[2018-07-17 22:51:16.897367] Iteration 40300, train loss = 2.659330, train accuracy = 0.171875\n",
      "[2018-07-17 22:51:23.819224] Iteration 40400, train loss = 2.470603, train accuracy = 0.242188\n",
      "[2018-07-17 22:51:30.827471] Iteration 40500, train loss = 2.470212, train accuracy = 0.226562\n",
      "[2018-07-17 22:51:37.797383] Iteration 40600, train loss = 2.410767, train accuracy = 0.250000\n",
      "[2018-07-17 22:51:44.614133] Iteration 40700, train loss = 2.330017, train accuracy = 0.265625\n",
      "[2018-07-17 22:51:51.551367] Iteration 40800, train loss = 2.466426, train accuracy = 0.265625\n",
      "[2018-07-17 22:51:58.570797] Iteration 40900, train loss = 2.262988, train accuracy = 0.328125\n",
      "[2018-07-17 22:52:05.630372] Iteration 41000, train loss = 2.491737, train accuracy = 0.234375\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 22:52:15.293427] Iteration 41100, train loss = 2.386248, train accuracy = 0.304688\n",
      "[2018-07-17 22:52:22.416782] Iteration 41200, train loss = 2.525544, train accuracy = 0.218750\n",
      "[2018-07-17 22:52:29.377534] Iteration 41300, train loss = 2.336603, train accuracy = 0.281250\n",
      "[2018-07-17 22:52:36.269191] Iteration 41400, train loss = 2.295528, train accuracy = 0.335938\n",
      "[2018-07-17 22:52:43.347247] Iteration 41500, train loss = 2.731975, train accuracy = 0.171875\n",
      "[2018-07-17 22:52:50.413133] Iteration 41600, train loss = 2.471004, train accuracy = 0.265625\n",
      "[2018-07-17 22:52:57.496126] Iteration 41700, train loss = 2.435148, train accuracy = 0.289062\n",
      "[2018-07-17 22:53:04.389010] Iteration 41800, train loss = 2.420212, train accuracy = 0.296875\n",
      "[2018-07-17 22:53:11.252371] Iteration 41900, train loss = 2.209105, train accuracy = 0.257812\n",
      "[2018-07-17 22:53:18.333552] Iteration 42000, train loss = 2.460527, train accuracy = 0.265625\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 22:53:27.961776] Iteration 42100, train loss = 2.390046, train accuracy = 0.265625\n",
      "[2018-07-17 22:53:35.093862] Iteration 42200, train loss = 2.504610, train accuracy = 0.234375\n",
      "[2018-07-17 22:53:41.943682] Iteration 42300, train loss = 2.271806, train accuracy = 0.312500\n",
      "[2018-07-17 22:53:49.057216] Iteration 42400, train loss = 2.317985, train accuracy = 0.320312\n",
      "[2018-07-17 22:53:56.165827] Iteration 42500, train loss = 2.654455, train accuracy = 0.195312\n",
      "[2018-07-17 22:54:03.297601] Iteration 42600, train loss = 2.424986, train accuracy = 0.273438\n",
      "[2018-07-17 22:54:10.350092] Iteration 42700, train loss = 2.529175, train accuracy = 0.257812\n",
      "[2018-07-17 22:54:17.265825] Iteration 42800, train loss = 2.673724, train accuracy = 0.234375\n",
      "[2018-07-17 22:54:24.417744] Iteration 42900, train loss = 2.539806, train accuracy = 0.273438\n",
      "[2018-07-17 22:54:31.501664] Iteration 43000, train loss = 2.611266, train accuracy = 0.273438\n",
      "Evaluating...\n",
      "Test accuracy = 0.276200\n",
      "[2018-07-17 22:54:41.143622] Iteration 43100, train loss = 2.559259, train accuracy = 0.226562\n",
      "[2018-07-17 22:54:48.254473] Iteration 43200, train loss = 2.623033, train accuracy = 0.210938\n",
      "[2018-07-17 22:54:55.382491] Iteration 43300, train loss = 2.497411, train accuracy = 0.195312\n",
      "[2018-07-17 22:55:02.563387] Iteration 43400, train loss = 2.274321, train accuracy = 0.304688\n",
      "[2018-07-17 22:55:09.605639] Iteration 43500, train loss = 2.173456, train accuracy = 0.351562\n",
      "[2018-07-17 22:55:16.679801] Iteration 43600, train loss = 2.498454, train accuracy = 0.250000\n",
      "[2018-07-17 22:55:23.806728] Iteration 43700, train loss = 2.547056, train accuracy = 0.289062\n",
      "[2018-07-17 22:55:30.813823] Iteration 43800, train loss = 2.207286, train accuracy = 0.304688\n",
      "[2018-07-17 22:55:37.813469] Iteration 43900, train loss = 2.414992, train accuracy = 0.234375\n",
      "[2018-07-17 22:55:44.824529] Iteration 44000, train loss = 2.498783, train accuracy = 0.281250\n",
      "Evaluating...\n",
      "Test accuracy = 0.276000\n",
      "[2018-07-17 22:55:54.409857] Iteration 44100, train loss = 2.398869, train accuracy = 0.281250\n",
      "[2018-07-17 22:56:01.529253] Iteration 44200, train loss = 2.427253, train accuracy = 0.320312\n",
      "[2018-07-17 22:56:08.656957] Iteration 44300, train loss = 2.445206, train accuracy = 0.234375\n",
      "[2018-07-17 22:56:15.717815] Iteration 44400, train loss = 2.654713, train accuracy = 0.265625\n",
      "[2018-07-17 22:56:22.856416] Iteration 44500, train loss = 2.561665, train accuracy = 0.242188\n",
      "[2018-07-17 22:56:29.906550] Iteration 44600, train loss = 2.454012, train accuracy = 0.218750\n",
      "[2018-07-17 22:56:37.009343] Iteration 44700, train loss = 2.437277, train accuracy = 0.250000\n",
      "[2018-07-17 22:56:44.139641] Iteration 44800, train loss = 2.274698, train accuracy = 0.281250\n",
      "[2018-07-17 22:56:51.226676] Iteration 44900, train loss = 2.359809, train accuracy = 0.335938\n",
      "[2018-07-17 22:56:58.061931] Iteration 45000, train loss = 2.434764, train accuracy = 0.234375\n",
      "Evaluating...\n",
      "Test accuracy = 0.275400\n",
      "[2018-07-17 22:57:07.658209] Iteration 45100, train loss = 2.282453, train accuracy = 0.265625\n",
      "[2018-07-17 22:57:14.734640] Iteration 45200, train loss = 2.353407, train accuracy = 0.289062\n",
      "[2018-07-17 22:57:21.655153] Iteration 45300, train loss = 2.467660, train accuracy = 0.234375\n",
      "[2018-07-17 22:57:28.499601] Iteration 45400, train loss = 2.240029, train accuracy = 0.304688\n",
      "[2018-07-17 22:57:35.490762] Iteration 45500, train loss = 2.144865, train accuracy = 0.312500\n",
      "[2018-07-17 22:57:42.363209] Iteration 45600, train loss = 2.523102, train accuracy = 0.265625\n",
      "[2018-07-17 22:57:49.525928] Iteration 45700, train loss = 2.536573, train accuracy = 0.273438\n",
      "[2018-07-17 22:57:56.584207] Iteration 45800, train loss = 2.525986, train accuracy = 0.242188\n",
      "[2018-07-17 22:58:03.615376] Iteration 45900, train loss = 2.418209, train accuracy = 0.242188\n",
      "[2018-07-17 22:58:10.459693] Iteration 46000, train loss = 2.287493, train accuracy = 0.281250\n",
      "Evaluating...\n",
      "Test accuracy = 0.275300\n",
      "[2018-07-17 22:58:19.890556] Iteration 46100, train loss = 2.438680, train accuracy = 0.234375\n",
      "[2018-07-17 22:58:26.844094] Iteration 46200, train loss = 2.613224, train accuracy = 0.195312\n",
      "[2018-07-17 22:58:33.769039] Iteration 46300, train loss = 2.512687, train accuracy = 0.257812\n",
      "[2018-07-17 22:58:40.789133] Iteration 46400, train loss = 2.441273, train accuracy = 0.210938\n",
      "[2018-07-17 22:58:47.739038] Iteration 46500, train loss = 2.403615, train accuracy = 0.257812\n",
      "[2018-07-17 22:58:54.555519] Iteration 46600, train loss = 2.436501, train accuracy = 0.281250\n",
      "[2018-07-17 22:59:01.395892] Iteration 46700, train loss = 2.494306, train accuracy = 0.242188\n",
      "[2018-07-17 22:59:08.391853] Iteration 46800, train loss = 2.511086, train accuracy = 0.273438\n",
      "[2018-07-17 22:59:15.471565] Iteration 46900, train loss = 2.327959, train accuracy = 0.289062\n",
      "[2018-07-17 22:59:22.459932] Iteration 47000, train loss = 2.300800, train accuracy = 0.257812\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 22:59:31.882230] Iteration 47100, train loss = 2.651316, train accuracy = 0.203125\n",
      "[2018-07-17 22:59:38.817406] Iteration 47200, train loss = 2.305887, train accuracy = 0.296875\n",
      "[2018-07-17 22:59:45.603948] Iteration 47300, train loss = 2.714689, train accuracy = 0.218750\n",
      "[2018-07-17 22:59:52.658360] Iteration 47400, train loss = 2.322439, train accuracy = 0.265625\n",
      "[2018-07-17 22:59:59.581257] Iteration 47500, train loss = 2.294697, train accuracy = 0.312500\n",
      "[2018-07-17 23:00:06.378310] Iteration 47600, train loss = 2.518672, train accuracy = 0.242188\n",
      "[2018-07-17 23:00:13.222107] Iteration 47700, train loss = 2.549034, train accuracy = 0.234375\n",
      "[2018-07-17 23:00:20.025290] Iteration 47800, train loss = 2.457846, train accuracy = 0.250000\n",
      "[2018-07-17 23:00:26.858670] Iteration 47900, train loss = 2.483574, train accuracy = 0.250000\n",
      "[2018-07-17 23:00:33.614996] Iteration 48000, train loss = 2.373688, train accuracy = 0.296875\n",
      "Evaluating...\n",
      "Test accuracy = 0.275200\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-17 23:00:42.550706] Iteration 48100, train loss = 2.426863, train accuracy = 0.218750\n",
      "[2018-07-17 23:00:49.272880] Iteration 48200, train loss = 2.221800, train accuracy = 0.312500\n",
      "[2018-07-17 23:00:55.966591] Iteration 48300, train loss = 2.344639, train accuracy = 0.210938\n",
      "[2018-07-17 23:01:02.672450] Iteration 48400, train loss = 2.323571, train accuracy = 0.273438\n",
      "[2018-07-17 23:01:09.319801] Iteration 48500, train loss = 2.608263, train accuracy = 0.210938\n",
      "[2018-07-17 23:01:15.987840] Iteration 48600, train loss = 2.351049, train accuracy = 0.289062\n",
      "[2018-07-17 23:01:22.597596] Iteration 48700, train loss = 2.261433, train accuracy = 0.328125\n",
      "[2018-07-17 23:01:29.204238] Iteration 48800, train loss = 2.328183, train accuracy = 0.250000\n",
      "[2018-07-17 23:01:35.851756] Iteration 48900, train loss = 2.358118, train accuracy = 0.304688\n",
      "[2018-07-17 23:01:42.470979] Iteration 49000, train loss = 2.434676, train accuracy = 0.296875\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 23:01:51.351945] Iteration 49100, train loss = 2.539791, train accuracy = 0.257812\n",
      "[2018-07-17 23:01:57.983269] Iteration 49200, train loss = 2.418849, train accuracy = 0.304688\n",
      "[2018-07-17 23:02:04.604701] Iteration 49300, train loss = 2.409556, train accuracy = 0.257812\n",
      "[2018-07-17 23:02:11.195189] Iteration 49400, train loss = 2.265788, train accuracy = 0.289062\n",
      "[2018-07-17 23:02:17.814272] Iteration 49500, train loss = 2.305978, train accuracy = 0.320312\n",
      "[2018-07-17 23:02:24.423913] Iteration 49600, train loss = 2.462041, train accuracy = 0.273438\n",
      "[2018-07-17 23:02:31.059430] Iteration 49700, train loss = 2.423579, train accuracy = 0.281250\n",
      "[2018-07-17 23:02:37.688006] Iteration 49800, train loss = 2.383457, train accuracy = 0.242188\n",
      "[2018-07-17 23:02:44.308262] Iteration 49900, train loss = 2.690062, train accuracy = 0.250000\n",
      "[2018-07-17 23:02:50.880774] Iteration 50000, train loss = 2.416276, train accuracy = 0.320312\n",
      "Evaluating...\n",
      "Test accuracy = 0.275400\n",
      "[2018-07-17 23:02:59.764851] Iteration 50100, train loss = 2.333964, train accuracy = 0.273438\n",
      "[2018-07-17 23:03:06.372062] Iteration 50200, train loss = 2.745380, train accuracy = 0.203125\n",
      "[2018-07-17 23:03:12.981816] Iteration 50300, train loss = 2.357686, train accuracy = 0.273438\n",
      "[2018-07-17 23:03:19.579795] Iteration 50400, train loss = 2.706430, train accuracy = 0.203125\n",
      "[2018-07-17 23:03:26.177832] Iteration 50500, train loss = 2.388568, train accuracy = 0.296875\n",
      "[2018-07-17 23:03:32.791724] Iteration 50600, train loss = 2.605076, train accuracy = 0.195312\n",
      "[2018-07-17 23:03:39.400470] Iteration 50700, train loss = 2.503956, train accuracy = 0.218750\n",
      "[2018-07-17 23:03:45.989964] Iteration 50800, train loss = 2.530549, train accuracy = 0.257812\n",
      "[2018-07-17 23:03:52.591008] Iteration 50900, train loss = 2.256803, train accuracy = 0.289062\n",
      "[2018-07-17 23:03:59.163535] Iteration 51000, train loss = 2.463620, train accuracy = 0.203125\n",
      "Evaluating...\n",
      "Test accuracy = 0.276000\n",
      "[2018-07-17 23:04:07.997259] Iteration 51100, train loss = 2.594707, train accuracy = 0.265625\n",
      "[2018-07-17 23:04:14.576218] Iteration 51200, train loss = 2.408960, train accuracy = 0.234375\n",
      "[2018-07-17 23:04:21.182737] Iteration 51300, train loss = 2.365909, train accuracy = 0.281250\n",
      "[2018-07-17 23:04:27.768834] Iteration 51400, train loss = 2.426891, train accuracy = 0.281250\n",
      "[2018-07-17 23:04:34.364550] Iteration 51500, train loss = 2.314138, train accuracy = 0.296875\n",
      "[2018-07-17 23:04:40.939976] Iteration 51600, train loss = 2.436283, train accuracy = 0.265625\n",
      "[2018-07-17 23:04:47.542987] Iteration 51700, train loss = 2.472228, train accuracy = 0.250000\n",
      "[2018-07-17 23:04:54.120260] Iteration 51800, train loss = 2.524505, train accuracy = 0.156250\n",
      "[2018-07-17 23:05:00.738987] Iteration 51900, train loss = 2.170367, train accuracy = 0.375000\n",
      "[2018-07-17 23:05:07.324612] Iteration 52000, train loss = 2.336726, train accuracy = 0.289062\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 23:05:16.122652] Iteration 52100, train loss = 2.531010, train accuracy = 0.265625\n",
      "[2018-07-17 23:05:22.718455] Iteration 52200, train loss = 2.484514, train accuracy = 0.234375\n",
      "[2018-07-17 23:05:29.306516] Iteration 52300, train loss = 2.317262, train accuracy = 0.273438\n",
      "[2018-07-17 23:05:35.881559] Iteration 52400, train loss = 2.519259, train accuracy = 0.242188\n",
      "[2018-07-17 23:05:42.489579] Iteration 52500, train loss = 2.232921, train accuracy = 0.304688\n",
      "[2018-07-17 23:05:49.080739] Iteration 52600, train loss = 2.516159, train accuracy = 0.273438\n",
      "[2018-07-17 23:05:55.665499] Iteration 52700, train loss = 2.543583, train accuracy = 0.218750\n",
      "[2018-07-17 23:06:02.277584] Iteration 52800, train loss = 2.432533, train accuracy = 0.273438\n",
      "[2018-07-17 23:06:08.870173] Iteration 52900, train loss = 2.423475, train accuracy = 0.226562\n",
      "[2018-07-17 23:06:15.452172] Iteration 53000, train loss = 2.564825, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275500\n",
      "[2018-07-17 23:06:24.270865] Iteration 53100, train loss = 2.463956, train accuracy = 0.328125\n",
      "[2018-07-17 23:06:30.874147] Iteration 53200, train loss = 2.400867, train accuracy = 0.273438\n",
      "[2018-07-17 23:06:37.449885] Iteration 53300, train loss = 2.568630, train accuracy = 0.226562\n",
      "[2018-07-17 23:06:44.041410] Iteration 53400, train loss = 2.542937, train accuracy = 0.179688\n",
      "[2018-07-17 23:06:50.619316] Iteration 53500, train loss = 2.643101, train accuracy = 0.187500\n",
      "[2018-07-17 23:06:57.200904] Iteration 53600, train loss = 2.257174, train accuracy = 0.257812\n",
      "[2018-07-17 23:07:03.779716] Iteration 53700, train loss = 2.353196, train accuracy = 0.312500\n",
      "[2018-07-17 23:07:10.381886] Iteration 53800, train loss = 2.323169, train accuracy = 0.265625\n",
      "[2018-07-17 23:07:16.973810] Iteration 53900, train loss = 2.212034, train accuracy = 0.281250\n",
      "[2018-07-17 23:07:23.552246] Iteration 54000, train loss = 2.406554, train accuracy = 0.273438\n",
      "Evaluating...\n",
      "Test accuracy = 0.276000\n",
      "[2018-07-17 23:07:32.369849] Iteration 54100, train loss = 2.337021, train accuracy = 0.304688\n",
      "[2018-07-17 23:07:38.935344] Iteration 54200, train loss = 2.585709, train accuracy = 0.210938\n",
      "[2018-07-17 23:07:45.496038] Iteration 54300, train loss = 2.342612, train accuracy = 0.289062\n",
      "[2018-07-17 23:07:52.051819] Iteration 54400, train loss = 2.358136, train accuracy = 0.296875\n",
      "[2018-07-17 23:07:58.642558] Iteration 54500, train loss = 2.459222, train accuracy = 0.210938\n",
      "[2018-07-17 23:08:05.229770] Iteration 54600, train loss = 2.472709, train accuracy = 0.273438\n",
      "[2018-07-17 23:08:11.821154] Iteration 54700, train loss = 2.604039, train accuracy = 0.218750\n",
      "[2018-07-17 23:08:18.414145] Iteration 54800, train loss = 2.345640, train accuracy = 0.242188\n",
      "[2018-07-17 23:08:24.984953] Iteration 54900, train loss = 2.428951, train accuracy = 0.226562\n",
      "[2018-07-17 23:08:31.569178] Iteration 55000, train loss = 2.543598, train accuracy = 0.265625\n",
      "Evaluating...\n",
      "Test accuracy = 0.276000\n",
      "[2018-07-17 23:08:40.372452] Iteration 55100, train loss = 2.455368, train accuracy = 0.226562\n",
      "[2018-07-17 23:08:46.941208] Iteration 55200, train loss = 2.339510, train accuracy = 0.312500\n",
      "[2018-07-17 23:08:53.509245] Iteration 55300, train loss = 2.398415, train accuracy = 0.273438\n",
      "[2018-07-17 23:09:00.086991] Iteration 55400, train loss = 2.384465, train accuracy = 0.242188\n",
      "[2018-07-17 23:09:06.672704] Iteration 55500, train loss = 2.441790, train accuracy = 0.234375\n",
      "[2018-07-17 23:09:13.223912] Iteration 55600, train loss = 2.409353, train accuracy = 0.265625\n",
      "[2018-07-17 23:09:19.811804] Iteration 55700, train loss = 2.502455, train accuracy = 0.296875\n",
      "[2018-07-17 23:09:26.381879] Iteration 55800, train loss = 2.348352, train accuracy = 0.289062\n",
      "[2018-07-17 23:09:32.971172] Iteration 55900, train loss = 2.407123, train accuracy = 0.242188\n",
      "[2018-07-17 23:09:39.550462] Iteration 56000, train loss = 2.335725, train accuracy = 0.226562\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 23:09:48.358912] Iteration 56100, train loss = 2.419034, train accuracy = 0.226562\n",
      "[2018-07-17 23:09:54.918225] Iteration 56200, train loss = 2.486068, train accuracy = 0.234375\n",
      "[2018-07-17 23:10:01.494238] Iteration 56300, train loss = 2.409241, train accuracy = 0.265625\n",
      "[2018-07-17 23:10:08.086217] Iteration 56400, train loss = 2.364316, train accuracy = 0.257812\n",
      "[2018-07-17 23:10:14.675117] Iteration 56500, train loss = 2.292511, train accuracy = 0.250000\n",
      "[2018-07-17 23:10:21.249259] Iteration 56600, train loss = 2.523341, train accuracy = 0.234375\n",
      "[2018-07-17 23:10:27.835389] Iteration 56700, train loss = 2.262276, train accuracy = 0.289062\n",
      "[2018-07-17 23:10:34.414751] Iteration 56800, train loss = 2.559244, train accuracy = 0.257812\n",
      "[2018-07-17 23:10:41.002000] Iteration 56900, train loss = 2.672979, train accuracy = 0.195312\n",
      "[2018-07-17 23:10:47.579731] Iteration 57000, train loss = 2.534660, train accuracy = 0.203125\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 23:10:56.380365] Iteration 57100, train loss = 2.398966, train accuracy = 0.304688\n",
      "[2018-07-17 23:11:02.961913] Iteration 57200, train loss = 2.347682, train accuracy = 0.304688\n",
      "[2018-07-17 23:11:09.540006] Iteration 57300, train loss = 2.561844, train accuracy = 0.195312\n",
      "[2018-07-17 23:11:16.107908] Iteration 57400, train loss = 2.429488, train accuracy = 0.218750\n",
      "[2018-07-17 23:11:22.677662] Iteration 57500, train loss = 2.570723, train accuracy = 0.273438\n",
      "[2018-07-17 23:11:29.222529] Iteration 57600, train loss = 2.270120, train accuracy = 0.312500\n",
      "[2018-07-17 23:11:35.807297] Iteration 57700, train loss = 2.372665, train accuracy = 0.296875\n",
      "[2018-07-17 23:11:42.397895] Iteration 57800, train loss = 2.462937, train accuracy = 0.312500\n",
      "[2018-07-17 23:11:48.977942] Iteration 57900, train loss = 2.573731, train accuracy = 0.203125\n",
      "[2018-07-17 23:11:55.551394] Iteration 58000, train loss = 2.292596, train accuracy = 0.320312\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 23:12:04.362310] Iteration 58100, train loss = 2.571923, train accuracy = 0.187500\n",
      "[2018-07-17 23:12:10.919001] Iteration 58200, train loss = 2.549483, train accuracy = 0.203125\n",
      "[2018-07-17 23:12:17.473995] Iteration 58300, train loss = 2.520084, train accuracy = 0.250000\n",
      "[2018-07-17 23:12:24.040817] Iteration 58400, train loss = 2.333829, train accuracy = 0.273438\n",
      "[2018-07-17 23:12:30.611915] Iteration 58500, train loss = 2.231181, train accuracy = 0.312500\n",
      "[2018-07-17 23:12:37.171423] Iteration 58600, train loss = 2.465393, train accuracy = 0.242188\n",
      "[2018-07-17 23:12:43.751861] Iteration 58700, train loss = 2.284178, train accuracy = 0.320312\n",
      "[2018-07-17 23:12:50.323251] Iteration 58800, train loss = 2.492921, train accuracy = 0.203125\n",
      "[2018-07-17 23:12:56.904080] Iteration 58900, train loss = 2.519226, train accuracy = 0.234375\n",
      "[2018-07-17 23:13:03.492903] Iteration 59000, train loss = 2.175163, train accuracy = 0.367188\n",
      "Evaluating...\n",
      "Test accuracy = 0.276200\n",
      "[2018-07-17 23:13:12.307756] Iteration 59100, train loss = 2.651707, train accuracy = 0.250000\n",
      "[2018-07-17 23:13:18.868906] Iteration 59200, train loss = 2.486998, train accuracy = 0.234375\n",
      "[2018-07-17 23:13:25.431352] Iteration 59300, train loss = 2.242051, train accuracy = 0.320312\n",
      "[2018-07-17 23:13:31.989474] Iteration 59400, train loss = 2.415743, train accuracy = 0.218750\n",
      "[2018-07-17 23:13:38.579994] Iteration 59500, train loss = 2.368207, train accuracy = 0.242188\n",
      "[2018-07-17 23:13:45.161921] Iteration 59600, train loss = 2.458158, train accuracy = 0.289062\n",
      "[2018-07-17 23:13:51.737392] Iteration 59700, train loss = 2.395122, train accuracy = 0.265625\n",
      "[2018-07-17 23:13:58.312324] Iteration 59800, train loss = 2.263444, train accuracy = 0.343750\n",
      "[2018-07-17 23:14:04.881466] Iteration 59900, train loss = 2.396639, train accuracy = 0.242188\n",
      "[2018-07-17 23:14:11.443126] Iteration 60000, train loss = 2.417200, train accuracy = 0.226562\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 23:14:20.239666] Iteration 60100, train loss = 2.395694, train accuracy = 0.273438\n",
      "[2018-07-17 23:14:26.805995] Iteration 60200, train loss = 2.579399, train accuracy = 0.242188\n",
      "[2018-07-17 23:14:33.363257] Iteration 60300, train loss = 2.504135, train accuracy = 0.226562\n",
      "[2018-07-17 23:14:39.928308] Iteration 60400, train loss = 2.356403, train accuracy = 0.289062\n",
      "[2018-07-17 23:14:46.487876] Iteration 60500, train loss = 2.408055, train accuracy = 0.273438\n",
      "[2018-07-17 23:14:53.060420] Iteration 60600, train loss = 2.472069, train accuracy = 0.265625\n",
      "[2018-07-17 23:14:59.630573] Iteration 60700, train loss = 2.457684, train accuracy = 0.226562\n",
      "[2018-07-17 23:15:06.197309] Iteration 60800, train loss = 2.531837, train accuracy = 0.203125\n",
      "[2018-07-17 23:15:12.738925] Iteration 60900, train loss = 2.425883, train accuracy = 0.320312\n",
      "[2018-07-17 23:15:19.322423] Iteration 61000, train loss = 2.403378, train accuracy = 0.210938\n",
      "Evaluating...\n",
      "Test accuracy = 0.275400\n",
      "[2018-07-17 23:15:28.120956] Iteration 61100, train loss = 2.397310, train accuracy = 0.273438\n",
      "[2018-07-17 23:15:34.695897] Iteration 61200, train loss = 2.480679, train accuracy = 0.242188\n",
      "[2018-07-17 23:15:41.263509] Iteration 61300, train loss = 2.617800, train accuracy = 0.265625\n",
      "[2018-07-17 23:15:47.805662] Iteration 61400, train loss = 2.320248, train accuracy = 0.257812\n",
      "[2018-07-17 23:15:54.381469] Iteration 61500, train loss = 2.362251, train accuracy = 0.226562\n",
      "[2018-07-17 23:16:00.966189] Iteration 61600, train loss = 2.642228, train accuracy = 0.195312\n",
      "[2018-07-17 23:16:07.523181] Iteration 61700, train loss = 2.644562, train accuracy = 0.210938\n",
      "[2018-07-17 23:16:14.069183] Iteration 61800, train loss = 2.283074, train accuracy = 0.304688\n",
      "[2018-07-17 23:16:20.642711] Iteration 61900, train loss = 2.399278, train accuracy = 0.195312\n",
      "[2018-07-17 23:16:27.227964] Iteration 62000, train loss = 2.323323, train accuracy = 0.304688\n",
      "Evaluating...\n",
      "Test accuracy = 0.275100\n",
      "[2018-07-17 23:16:35.992927] Iteration 62100, train loss = 2.296894, train accuracy = 0.312500\n",
      "[2018-07-17 23:16:42.557838] Iteration 62200, train loss = 2.363504, train accuracy = 0.218750\n",
      "[2018-07-17 23:16:49.142188] Iteration 62300, train loss = 2.500059, train accuracy = 0.242188\n",
      "[2018-07-17 23:16:55.708356] Iteration 62400, train loss = 2.598741, train accuracy = 0.203125\n",
      "[2018-07-17 23:17:02.274322] Iteration 62500, train loss = 2.466659, train accuracy = 0.273438\n",
      "[2018-07-17 23:17:08.837357] Iteration 62600, train loss = 2.633212, train accuracy = 0.203125\n",
      "[2018-07-17 23:17:15.401539] Iteration 62700, train loss = 2.604103, train accuracy = 0.226562\n",
      "[2018-07-17 23:17:21.958290] Iteration 62800, train loss = 2.615153, train accuracy = 0.265625\n",
      "[2018-07-17 23:17:28.517065] Iteration 62900, train loss = 2.633105, train accuracy = 0.210938\n",
      "[2018-07-17 23:17:35.086170] Iteration 63000, train loss = 2.698498, train accuracy = 0.195312\n",
      "Evaluating...\n",
      "Test accuracy = 0.275300\n",
      "[2018-07-17 23:17:43.890912] Iteration 63100, train loss = 2.461196, train accuracy = 0.273438\n",
      "[2018-07-17 23:17:50.430658] Iteration 63200, train loss = 2.469643, train accuracy = 0.265625\n",
      "[2018-07-17 23:17:56.984187] Iteration 63300, train loss = 2.435514, train accuracy = 0.289062\n",
      "[2018-07-17 23:18:03.531947] Iteration 63400, train loss = 2.284279, train accuracy = 0.289062\n",
      "[2018-07-17 23:18:10.104310] Iteration 63500, train loss = 2.383232, train accuracy = 0.257812\n",
      "[2018-07-17 23:18:16.679037] Iteration 63600, train loss = 2.495296, train accuracy = 0.289062\n",
      "[2018-07-17 23:18:23.251040] Iteration 63700, train loss = 2.340315, train accuracy = 0.234375\n",
      "[2018-07-17 23:18:29.829828] Iteration 63800, train loss = 2.644395, train accuracy = 0.226562\n",
      "[2018-07-17 23:18:36.376310] Iteration 63900, train loss = 2.439733, train accuracy = 0.281250\n",
      "[2018-07-17 23:18:42.942711] Iteration 64000, train loss = 2.537097, train accuracy = 0.289062\n",
      "Evaluating...\n",
      "Test accuracy = 0.275900\n",
      "[2018-07-17 23:18:51.733733] Iteration 64100, train loss = 2.361811, train accuracy = 0.273438\n",
      "[2018-07-17 23:18:58.295637] Iteration 64200, train loss = 2.423437, train accuracy = 0.257812\n",
      "[2018-07-17 23:19:04.844090] Iteration 64300, train loss = 2.341011, train accuracy = 0.320312\n",
      "[2018-07-17 23:19:11.420843] Iteration 64400, train loss = 2.435596, train accuracy = 0.296875\n",
      "[2018-07-17 23:19:17.986816] Iteration 64500, train loss = 2.339297, train accuracy = 0.304688\n",
      "[2018-07-17 23:19:24.570934] Iteration 64600, train loss = 2.602351, train accuracy = 0.242188\n",
      "[2018-07-17 23:19:31.127069] Iteration 64700, train loss = 2.387302, train accuracy = 0.289062\n",
      "[2018-07-17 23:19:37.696444] Iteration 64800, train loss = 2.479062, train accuracy = 0.242188\n",
      "[2018-07-17 23:19:44.272578] Iteration 64900, train loss = 2.430464, train accuracy = 0.265625\n",
      "[2018-07-17 23:19:50.842899] Iteration 65000, train loss = 2.562223, train accuracy = 0.289062\n",
      "Evaluating...\n",
      "Test accuracy = 0.275200\n",
      "[2018-07-17 23:19:59.640507] Iteration 65100, train loss = 2.232776, train accuracy = 0.359375\n",
      "[2018-07-17 23:20:06.210018] Iteration 65200, train loss = 2.599022, train accuracy = 0.250000\n",
      "[2018-07-17 23:20:12.786316] Iteration 65300, train loss = 2.622868, train accuracy = 0.195312\n",
      "[2018-07-17 23:20:19.346387] Iteration 65400, train loss = 2.498603, train accuracy = 0.226562\n",
      "[2018-07-17 23:20:25.903641] Iteration 65500, train loss = 2.427826, train accuracy = 0.312500\n",
      "[2018-07-17 23:20:32.485561] Iteration 65600, train loss = 2.419775, train accuracy = 0.195312\n",
      "[2018-07-17 23:20:39.034539] Iteration 65700, train loss = 2.198397, train accuracy = 0.343750\n",
      "[2018-07-17 23:20:45.579700] Iteration 65800, train loss = 2.381572, train accuracy = 0.257812\n",
      "[2018-07-17 23:20:52.152627] Iteration 65900, train loss = 2.199880, train accuracy = 0.343750\n",
      "[2018-07-17 23:20:58.699838] Iteration 66000, train loss = 2.388860, train accuracy = 0.234375\n",
      "Evaluating...\n",
      "Test accuracy = 0.275700\n",
      "[2018-07-17 23:21:07.501749] Iteration 66100, train loss = 2.518629, train accuracy = 0.250000\n",
      "[2018-07-17 23:21:14.059107] Iteration 66200, train loss = 2.471650, train accuracy = 0.289062\n",
      "[2018-07-17 23:21:20.633971] Iteration 66300, train loss = 2.426858, train accuracy = 0.304688\n",
      "[2018-07-17 23:21:27.211982] Iteration 66400, train loss = 2.265107, train accuracy = 0.320312\n",
      "[2018-07-17 23:21:33.770844] Iteration 66500, train loss = 2.378980, train accuracy = 0.273438\n",
      "[2018-07-17 23:21:40.333626] Iteration 66600, train loss = 2.564830, train accuracy = 0.203125\n",
      "[2018-07-17 23:21:46.904474] Iteration 66700, train loss = 2.300071, train accuracy = 0.242188\n",
      "[2018-07-17 23:21:53.478564] Iteration 66800, train loss = 2.484633, train accuracy = 0.218750\n",
      "[2018-07-17 23:22:00.060751] Iteration 66900, train loss = 2.579771, train accuracy = 0.218750\n",
      "[2018-07-17 23:22:06.622368] Iteration 67000, train loss = 2.461350, train accuracy = 0.257812\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 23:22:15.413466] Iteration 67100, train loss = 2.498172, train accuracy = 0.250000\n",
      "[2018-07-17 23:22:21.958517] Iteration 67200, train loss = 2.566969, train accuracy = 0.281250\n",
      "[2018-07-17 23:22:28.522596] Iteration 67300, train loss = 2.333479, train accuracy = 0.296875\n",
      "[2018-07-17 23:22:35.080190] Iteration 67400, train loss = 2.379252, train accuracy = 0.281250\n",
      "[2018-07-17 23:22:41.633856] Iteration 67500, train loss = 2.395985, train accuracy = 0.242188\n",
      "[2018-07-17 23:22:48.190634] Iteration 67600, train loss = 2.606893, train accuracy = 0.242188\n",
      "[2018-07-17 23:22:54.750947] Iteration 67700, train loss = 2.368544, train accuracy = 0.289062\n",
      "[2018-07-17 23:23:01.313877] Iteration 67800, train loss = 2.496880, train accuracy = 0.289062\n",
      "[2018-07-17 23:23:07.888521] Iteration 67900, train loss = 2.356791, train accuracy = 0.289062\n",
      "[2018-07-17 23:23:14.454647] Iteration 68000, train loss = 2.443884, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 23:23:23.254450] Iteration 68100, train loss = 2.259196, train accuracy = 0.304688\n",
      "[2018-07-17 23:23:29.817999] Iteration 68200, train loss = 2.544679, train accuracy = 0.195312\n",
      "[2018-07-17 23:23:36.361087] Iteration 68300, train loss = 2.559528, train accuracy = 0.187500\n",
      "[2018-07-17 23:23:42.929198] Iteration 68400, train loss = 2.426032, train accuracy = 0.257812\n",
      "[2018-07-17 23:23:49.504514] Iteration 68500, train loss = 2.305899, train accuracy = 0.281250\n",
      "[2018-07-17 23:23:56.053982] Iteration 68600, train loss = 2.387665, train accuracy = 0.289062\n",
      "[2018-07-17 23:24:02.607532] Iteration 68700, train loss = 2.539737, train accuracy = 0.265625\n",
      "[2018-07-17 23:24:09.159497] Iteration 68800, train loss = 2.437680, train accuracy = 0.281250\n",
      "[2018-07-17 23:24:15.725539] Iteration 68900, train loss = 2.418379, train accuracy = 0.281250\n",
      "[2018-07-17 23:24:22.292328] Iteration 69000, train loss = 2.337265, train accuracy = 0.289062\n",
      "Evaluating...\n",
      "Test accuracy = 0.274600\n",
      "[2018-07-17 23:24:31.095442] Iteration 69100, train loss = 2.494064, train accuracy = 0.226562\n",
      "[2018-07-17 23:24:37.650357] Iteration 69200, train loss = 2.349646, train accuracy = 0.195312\n",
      "[2018-07-17 23:24:44.208648] Iteration 69300, train loss = 2.339594, train accuracy = 0.257812\n",
      "[2018-07-17 23:24:50.746871] Iteration 69400, train loss = 2.423298, train accuracy = 0.234375\n",
      "[2018-07-17 23:24:57.294616] Iteration 69500, train loss = 2.473953, train accuracy = 0.265625\n",
      "[2018-07-17 23:25:03.860092] Iteration 69600, train loss = 2.540709, train accuracy = 0.234375\n",
      "[2018-07-17 23:25:10.426919] Iteration 69700, train loss = 2.464254, train accuracy = 0.218750\n",
      "[2018-07-17 23:25:16.996096] Iteration 69800, train loss = 2.621370, train accuracy = 0.234375\n",
      "[2018-07-17 23:25:23.559550] Iteration 69900, train loss = 2.395994, train accuracy = 0.289062\n",
      "[2018-07-17 23:25:30.139914] Iteration 70000, train loss = 2.519996, train accuracy = 0.195312\n",
      "Evaluating...\n",
      "Test accuracy = 0.275900\n",
      "[2018-07-17 23:25:38.942863] Iteration 70100, train loss = 2.243532, train accuracy = 0.312500\n",
      "[2018-07-17 23:25:45.515967] Iteration 70200, train loss = 2.504707, train accuracy = 0.289062\n",
      "[2018-07-17 23:25:52.063980] Iteration 70300, train loss = 2.330316, train accuracy = 0.281250\n",
      "[2018-07-17 23:25:58.628149] Iteration 70400, train loss = 2.191516, train accuracy = 0.289062\n",
      "[2018-07-17 23:26:05.185556] Iteration 70500, train loss = 2.346059, train accuracy = 0.265625\n",
      "[2018-07-17 23:26:11.751379] Iteration 70600, train loss = 2.498306, train accuracy = 0.257812\n",
      "[2018-07-17 23:26:18.318149] Iteration 70700, train loss = 2.292990, train accuracy = 0.281250\n",
      "[2018-07-17 23:26:24.892333] Iteration 70800, train loss = 2.409132, train accuracy = 0.242188\n",
      "[2018-07-17 23:26:31.427957] Iteration 70900, train loss = 2.325355, train accuracy = 0.281250\n",
      "[2018-07-17 23:26:37.994449] Iteration 71000, train loss = 2.514364, train accuracy = 0.257812\n",
      "Evaluating...\n",
      "Test accuracy = 0.275800\n",
      "[2018-07-17 23:26:46.774041] Iteration 71100, train loss = 2.570926, train accuracy = 0.289062\n",
      "[2018-07-17 23:26:53.339452] Iteration 71200, train loss = 2.537650, train accuracy = 0.218750\n",
      "[2018-07-17 23:26:59.898883] Iteration 71300, train loss = 2.425300, train accuracy = 0.273438\n",
      "[2018-07-17 23:27:06.465429] Iteration 71400, train loss = 2.631756, train accuracy = 0.164062\n",
      "[2018-07-17 23:27:13.018402] Iteration 71500, train loss = 2.273223, train accuracy = 0.312500\n",
      "[2018-07-17 23:27:19.563539] Iteration 71600, train loss = 2.601803, train accuracy = 0.234375\n",
      "[2018-07-17 23:27:26.119540] Iteration 71700, train loss = 2.485627, train accuracy = 0.265625\n",
      "[2018-07-17 23:27:32.663256] Iteration 71800, train loss = 2.655075, train accuracy = 0.187500\n",
      "[2018-07-17 23:27:39.230441] Iteration 71900, train loss = 2.441655, train accuracy = 0.273438\n",
      "[2018-07-17 23:27:45.817496] Iteration 72000, train loss = 2.292882, train accuracy = 0.304688\n",
      "Evaluating...\n",
      "Test accuracy = 0.275200\n",
      "[2018-07-17 23:27:54.652430] Iteration 72100, train loss = 2.456172, train accuracy = 0.265625\n",
      "[2018-07-17 23:28:01.210474] Iteration 72200, train loss = 2.733515, train accuracy = 0.164062\n",
      "[2018-07-17 23:28:07.775891] Iteration 72300, train loss = 2.369593, train accuracy = 0.265625\n",
      "[2018-07-17 23:28:14.338969] Iteration 72400, train loss = 2.333243, train accuracy = 0.359375\n",
      "[2018-07-17 23:28:20.912033] Iteration 72500, train loss = 2.329951, train accuracy = 0.281250\n",
      "[2018-07-17 23:28:27.441783] Iteration 72600, train loss = 2.524296, train accuracy = 0.226562\n",
      "[2018-07-17 23:28:33.995963] Iteration 72700, train loss = 2.460403, train accuracy = 0.281250\n",
      "[2018-07-17 23:28:40.559859] Iteration 72800, train loss = 2.394114, train accuracy = 0.289062\n",
      "[2018-07-17 23:28:47.132591] Iteration 72900, train loss = 2.544410, train accuracy = 0.265625\n",
      "[2018-07-17 23:28:53.692294] Iteration 73000, train loss = 2.252257, train accuracy = 0.328125\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 23:29:02.472254] Iteration 73100, train loss = 2.350127, train accuracy = 0.304688\n",
      "[2018-07-17 23:29:09.026648] Iteration 73200, train loss = 2.500833, train accuracy = 0.265625\n",
      "[2018-07-17 23:29:15.597607] Iteration 73300, train loss = 2.591747, train accuracy = 0.242188\n",
      "[2018-07-17 23:29:22.157268] Iteration 73400, train loss = 2.555580, train accuracy = 0.218750\n",
      "[2018-07-17 23:29:28.727100] Iteration 73500, train loss = 2.235714, train accuracy = 0.289062\n",
      "[2018-07-17 23:29:35.323755] Iteration 73600, train loss = 2.324086, train accuracy = 0.343750\n",
      "[2018-07-17 23:29:41.882240] Iteration 73700, train loss = 2.410928, train accuracy = 0.289062\n",
      "[2018-07-17 23:29:48.461353] Iteration 73800, train loss = 2.448972, train accuracy = 0.273438\n",
      "[2018-07-17 23:29:55.026401] Iteration 73900, train loss = 2.572777, train accuracy = 0.250000\n",
      "[2018-07-17 23:30:01.612862] Iteration 74000, train loss = 2.472452, train accuracy = 0.226562\n",
      "Evaluating...\n",
      "Test accuracy = 0.275900\n",
      "[2018-07-17 23:30:10.425817] Iteration 74100, train loss = 2.333572, train accuracy = 0.281250\n",
      "[2018-07-17 23:30:16.991824] Iteration 74200, train loss = 2.136315, train accuracy = 0.335938\n",
      "[2018-07-17 23:30:23.563981] Iteration 74300, train loss = 2.415572, train accuracy = 0.257812\n",
      "[2018-07-17 23:30:30.131235] Iteration 74400, train loss = 2.372462, train accuracy = 0.250000\n",
      "[2018-07-17 23:30:36.706714] Iteration 74500, train loss = 2.504142, train accuracy = 0.218750\n",
      "[2018-07-17 23:30:43.278782] Iteration 74600, train loss = 2.633014, train accuracy = 0.242188\n",
      "[2018-07-17 23:30:49.840599] Iteration 74700, train loss = 2.535136, train accuracy = 0.265625\n",
      "[2018-07-17 23:30:56.432094] Iteration 74800, train loss = 2.858250, train accuracy = 0.164062\n",
      "[2018-07-17 23:31:02.994827] Iteration 74900, train loss = 2.584243, train accuracy = 0.226562\n",
      "[2018-07-17 23:31:09.560777] Iteration 75000, train loss = 2.353165, train accuracy = 0.296875\n",
      "Evaluating...\n",
      "Test accuracy = 0.275400\n",
      "[2018-07-17 23:31:18.361028] Iteration 75100, train loss = 2.417190, train accuracy = 0.257812\n",
      "[2018-07-17 23:31:24.931841] Iteration 75200, train loss = 2.483135, train accuracy = 0.273438\n",
      "[2018-07-17 23:31:31.505292] Iteration 75300, train loss = 2.458379, train accuracy = 0.281250\n",
      "[2018-07-17 23:31:38.091469] Iteration 75400, train loss = 2.589465, train accuracy = 0.210938\n",
      "[2018-07-17 23:31:44.678779] Iteration 75500, train loss = 2.530698, train accuracy = 0.265625\n",
      "[2018-07-17 23:31:51.241433] Iteration 75600, train loss = 2.334686, train accuracy = 0.304688\n",
      "[2018-07-17 23:31:57.829131] Iteration 75700, train loss = 2.402546, train accuracy = 0.289062\n",
      "[2018-07-17 23:32:04.410477] Iteration 75800, train loss = 2.453317, train accuracy = 0.234375\n",
      "[2018-07-17 23:32:10.993921] Iteration 75900, train loss = 2.359934, train accuracy = 0.312500\n",
      "[2018-07-17 23:32:17.560801] Iteration 76000, train loss = 2.539107, train accuracy = 0.242188\n",
      "Evaluating...\n",
      "Test accuracy = 0.275300\n",
      "[2018-07-17 23:32:26.368283] Iteration 76100, train loss = 2.532579, train accuracy = 0.289062\n",
      "[2018-07-17 23:32:32.947085] Iteration 76200, train loss = 2.290906, train accuracy = 0.304688\n",
      "[2018-07-17 23:32:39.503012] Iteration 76300, train loss = 2.548284, train accuracy = 0.257812\n",
      "[2018-07-17 23:32:46.058955] Iteration 76400, train loss = 2.372795, train accuracy = 0.320312\n",
      "[2018-07-17 23:32:52.641134] Iteration 76500, train loss = 2.424971, train accuracy = 0.250000\n",
      "[2018-07-17 23:32:59.223559] Iteration 76600, train loss = 2.591282, train accuracy = 0.281250\n",
      "[2018-07-17 23:33:05.770865] Iteration 76700, train loss = 2.338325, train accuracy = 0.265625\n",
      "[2018-07-17 23:33:12.335784] Iteration 76800, train loss = 2.439173, train accuracy = 0.234375\n",
      "[2018-07-17 23:33:18.908432] Iteration 76900, train loss = 2.153836, train accuracy = 0.328125\n",
      "[2018-07-17 23:33:25.482833] Iteration 77000, train loss = 2.351268, train accuracy = 0.289062\n",
      "Evaluating...\n",
      "Test accuracy = 0.275600\n",
      "[2018-07-17 23:33:34.298602] Iteration 77100, train loss = 2.706123, train accuracy = 0.203125\n",
      "[2018-07-17 23:33:40.840135] Iteration 77200, train loss = 2.424578, train accuracy = 0.265625\n",
      "[2018-07-17 23:33:47.410520] Iteration 77300, train loss = 2.288819, train accuracy = 0.296875\n",
      "[2018-07-17 23:33:53.993146] Iteration 77400, train loss = 2.317863, train accuracy = 0.320312\n",
      "[2018-07-17 23:34:00.554781] Iteration 77500, train loss = 2.286144, train accuracy = 0.289062\n",
      "[2018-07-17 23:34:07.110454] Iteration 77600, train loss = 2.332514, train accuracy = 0.281250\n",
      "[2018-07-17 23:34:13.656488] Iteration 77700, train loss = 2.384908, train accuracy = 0.281250\n",
      "[2018-07-17 23:34:20.239782] Iteration 77800, train loss = 2.476045, train accuracy = 0.265625\n",
      "[2018-07-17 23:34:26.822757] Iteration 77900, train loss = 2.480496, train accuracy = 0.273438\n",
      "[2018-07-17 23:34:33.394407] Iteration 78000, train loss = 2.319232, train accuracy = 0.265625\n",
      "Evaluating...\n",
      "Test accuracy = 0.275200\n",
      "[2018-07-17 23:34:42.176413] Iteration 78100, train loss = 2.502300, train accuracy = 0.226562\n",
      "[2018-07-17 23:34:48.752610] Iteration 78200, train loss = 2.446195, train accuracy = 0.273438\n",
      "[2018-07-17 23:34:55.306701] Iteration 78300, train loss = 2.459427, train accuracy = 0.265625\n",
      "[2018-07-17 23:35:01.875938] Iteration 78400, train loss = 2.415313, train accuracy = 0.273438\n",
      "[2018-07-17 23:35:08.437957] Iteration 78500, train loss = 2.240031, train accuracy = 0.289062\n",
      "[2018-07-17 23:35:14.999918] Iteration 78600, train loss = 2.610129, train accuracy = 0.164062\n",
      "[2018-07-17 23:35:21.571377] Iteration 78700, train loss = 2.545678, train accuracy = 0.234375\n",
      "[2018-07-17 23:35:28.139109] Iteration 78800, train loss = 2.373024, train accuracy = 0.265625\n",
      "[2018-07-17 23:35:34.708889] Iteration 78900, train loss = 2.477326, train accuracy = 0.195312\n",
      "[2018-07-17 23:35:41.266804] Iteration 79000, train loss = 2.475553, train accuracy = 0.289062\n",
      "Evaluating...\n",
      "Test accuracy = 0.275500\n",
      "[2018-07-17 23:35:50.059137] Iteration 79100, train loss = 2.368857, train accuracy = 0.234375\n",
      "[2018-07-17 23:35:56.602944] Iteration 79200, train loss = 2.258693, train accuracy = 0.265625\n",
      "[2018-07-17 23:36:03.169544] Iteration 79300, train loss = 2.508255, train accuracy = 0.218750\n",
      "[2018-07-17 23:36:09.709095] Iteration 79400, train loss = 2.375070, train accuracy = 0.257812\n",
      "[2018-07-17 23:36:16.279490] Iteration 79500, train loss = 2.643482, train accuracy = 0.218750\n",
      "[2018-07-17 23:36:22.846781] Iteration 79600, train loss = 2.494187, train accuracy = 0.242188\n",
      "[2018-07-17 23:36:29.397675] Iteration 79700, train loss = 2.566394, train accuracy = 0.234375\n",
      "[2018-07-17 23:36:35.970970] Iteration 79800, train loss = 2.593914, train accuracy = 0.242188\n",
      "[2018-07-17 23:36:42.553557] Iteration 79900, train loss = 2.263525, train accuracy = 0.382812\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune后的准确率\n",
      "Test accuracy = 0.275400\n"
     ]
    }
   ],
   "source": [
    "print('prune后的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.125  0.     0.125  0.125  0.     0.     0.     0.    -0.25   0.   ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
