{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "# import ipdb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('residual_net_n', 5, '')\n",
    "tf.app.flags.DEFINE_string('train_tf_path', './data/train.tf', '')\n",
    "tf.app.flags.DEFINE_string('val_tf_path', './data/test.tf', '')\n",
    "tf.app.flags.DEFINE_integer('train_batch_size', 128, '')\n",
    "tf.app.flags.DEFINE_integer('val_batch_size', 100, '')\n",
    "tf.app.flags.DEFINE_float('weight_decay', 0.0005, 'Weight decay')\n",
    "tf.app.flags.DEFINE_integer('summary_interval', 100, 'Interval for summary.')\n",
    "tf.app.flags.DEFINE_integer('val_interval', 1000, 'Interval for evaluation.')\n",
    "tf.app.flags.DEFINE_integer('max_steps', 80000, 'Maximum number of iterations.')\n",
    "tf.app.flags.DEFINE_integer('save_interval', 5000, '')\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_embedding(label, n_classes):\n",
    "  \"\"\"\n",
    "  One-hot embedding\n",
    "  Args:\n",
    "    label: int32 tensor [B]\n",
    "    n_classes: int32, number of classes\n",
    "  Return:\n",
    "    embedding: tensor [B x n_classes]\n",
    "  \"\"\"\n",
    "  embedding_params = np.eye(n_classes, dtype=np.float32)\n",
    "  with tf.device('/cpu:0'):\n",
    "    params = tf.constant(embedding_params)\n",
    "    embedding = tf.gather(params, label)\n",
    "  return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, n_in, n_out, k, s, p='SAME', bias=False, scope='conv'):\n",
    "  with tf.variable_scope(scope):\n",
    "    kernel = tf.Variable(\n",
    "      tf.truncated_normal([k, k, n_in, n_out],\n",
    "        stddev=math.sqrt(2/(k*k*n_in))),\n",
    "      name='weight')\n",
    "    tf.add_to_collection('weights', kernel)\n",
    "    conv = tf.nn.conv2d(x, kernel, [1,s,s,1], padding=p)\n",
    "    if bias:\n",
    "      bias = tf.get_variable('bias', [n_out], initializer=tf.constant_initializer(0.0))\n",
    "      tf.add_to_collection('biases', bias)\n",
    "      conv = tf.nn.bias_add(conv, bias)\n",
    "  return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, scope='bn', affine=True):\n",
    "  \"\"\"\n",
    "  Batch normalization on convolutional maps.\n",
    "  Args:\n",
    "    x: Tensor, 4D BHWD input maps\n",
    "    n_out: integer, depth of input maps\n",
    "    phase_train: boolean tf.Variable, true indicates training phase\n",
    "    scope: string, variable scope\n",
    "    affine: whether to affine-transform outputs\n",
    "  Return:\n",
    "    normed: batch-normalized maps\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope):\n",
    "    beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "      name='beta', trainable=True)\n",
    "    gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "      name='gamma', trainable=affine)\n",
    "    tf.add_to_collection('biases', beta)\n",
    "    tf.add_to_collection('weights', gamma)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "\n",
    "    def mean_var_with_update():\n",
    "      ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "      with tf.control_dependencies([ema_apply_op]):\n",
    "        return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "      mean_var_with_update,\n",
    "      lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var, \n",
    "      beta, gamma, 1e-3, affine)\n",
    "  return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, n_in, n_out, subsample, phase_train, scope='res_block'):\n",
    "  with tf.variable_scope(scope):\n",
    "    if subsample:\n",
    "      y = conv2d(x, n_in, n_out, 3, 2, 'SAME', False, scope='conv_1')\n",
    "      shortcut = conv2d(x, n_in, n_out, 3, 2, 'SAME',\n",
    "                False, scope='shortcut')\n",
    "    else:\n",
    "      y = conv2d(x, n_in, n_out, 3, 1, 'SAME', False, scope='conv_1')\n",
    "      shortcut = tf.identity(x, name='shortcut')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_1')\n",
    "    y = tf.nn.relu(y, name='relu_1')\n",
    "    y = conv2d(y, n_out, n_out, 3, 1, 'SAME', True, scope='conv_2')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_2')\n",
    "    y = y + shortcut\n",
    "    y = tf.nn.relu(y, name='relu_2')\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_group(x, n_in, n_out, n, first_subsample, phase_train, scope='res_group'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = residual_block(x, n_in, n_out, first_subsample, phase_train, scope='block_1')\n",
    "    for i in range(n - 1):\n",
    "      y = residual_block(y, n_out, n_out, False, phase_train, scope='block_%d' % (i + 2))\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_net(x, n, n_classes, phase_train, scope='res_net'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = conv2d(x, 3, 16, 3, 1, 'SAME', False, scope='conv_init')\n",
    "    y = batch_norm(y, 16, phase_train, scope='bn_init')\n",
    "    y = tf.nn.relu(y, name='relu_init')\n",
    "    y = residual_group(y, 16, 16, n, False, phase_train, scope='group_1')\n",
    "    y = residual_group(y, 16, 32, n, True, phase_train, scope='group_2')\n",
    "    y = residual_group(y, 32, 64, n, True, phase_train, scope='group_3')\n",
    "#     y = conv2d(y, 64, n_classes, 1, 1, 'SAME', True, scope='conv_last')\n",
    "    y = tf.nn.avg_pool(y, [1, 8, 8, 1], [1, 1, 1, 1], 'VALID', name='avg_pool')\n",
    "    y = tf.reshape(y, [-1, 64])\n",
    "    w = tf.get_variable(name='weight_fc', shape=[64, n_classes], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    tf.add_to_collection('weights', w)\n",
    "    b = tf.get_variable(name='weight_biase', shape=[n_classes], initializer=tf.constant_initializer(0))\n",
    "    tf.add_to_collection('last_biases', b)\n",
    "    y = tf.matmul(y, w) + b\n",
    "#     y = tf.squeeze(y, squeeze_dims=[1, 2])\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _loss(logits, labels, scope='loss'):\n",
    "  with tf.variable_scope(scope):\n",
    "    # entropy loss\n",
    "    targets = one_hot_embedding(labels, 10)\n",
    "    entropy_loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),\n",
    "      name='entropy_loss')\n",
    "    tf.add_to_collection('losses', entropy_loss)\n",
    "    # weight l2 decay loss\n",
    "    weight_l2_losses = [tf.nn.l2_loss(o) for o in tf.get_collection('weights')]\n",
    "    weight_decay_loss = FLAGS.weight_decay*tf.add_n(weight_l2_losses)\n",
    "    tf.add_to_collection('losses', weight_decay_loss)\n",
    "  # for var in tf.get_collection('losses'):\n",
    "    # tf.scalar_summary('losses/' + var.op.name, var)\n",
    "  # total loss\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _accuracy(logits, gt_label, scope='accuracy'):\n",
    "  with tf.variable_scope(scope):\n",
    "    pred_label = tf.argmax(logits, 1)\n",
    "    acc = 1.0 - tf.nn.zero_fraction(\n",
    "      tf.cast(tf.equal(pred_label, gt_label), tf.int32))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_op(loss, global_step, learning_rate):\n",
    "  params = tf.trainable_variables()\n",
    "  gradients = tf.gradients(loss, params, name='gradients')\n",
    "  optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "  update = optim.apply_gradients(zip(gradients, params))\n",
    "  with tf.control_dependencies([update]):\n",
    "    train_op = tf.no_op(name='train_op')\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar10_input_stream(records_path):\n",
    "  reader = tf.TFRecordReader()\n",
    "  filename_queue = tf.train.string_input_producer([records_path], None)\n",
    "  _, record_value = reader.read(filename_queue)\n",
    "  features = tf.parse_single_example(record_value,\n",
    "    {\n",
    "      'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "  image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "  image = tf.reshape(image, [32,32,3])\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  label = tf.cast(features['label'], tf.int64)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "  # meanstd = joblib.load(FLAGS.mean_std_path)\n",
    "  # mean, std = meanstd['mean'], meanstd['std']\n",
    "  mean = [ 125.30690002,122.95014954,113.86599731]\n",
    "  std = [ 62.9932518,62.08860397,66.70500946]\n",
    "  normed_image = (image - mean) / std\n",
    "  return normed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_distort_image(image):\n",
    "  distorted_image = image\n",
    "  distorted_image = tf.image.pad_to_bounding_box(\n",
    "    image, 4, 4, 40, 40)  # pad 4 pixels to each side\n",
    "  distorted_image = tf.random_crop(distorted_image, [32, 32, 3])\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "  return distorted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_batch(train_records_path, batch_size):\n",
    "  with tf.variable_scope('train_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      train_image, train_label = cifar10_input_stream(train_records_path)\n",
    "      train_image = normalize_image(train_image)\n",
    "      train_image = random_distort_image(train_image)\n",
    "      train_image_batch, train_label_batch = tf.train.shuffle_batch(\n",
    "        [train_image, train_label], batch_size=batch_size, num_threads=4,\n",
    "        capacity=50000,\n",
    "        min_after_dequeue=1000)\n",
    "  return train_image_batch, train_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_validation_batch(test_records_path, batch_size):\n",
    "  with tf.variable_scope('evaluate_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      test_image, test_label = cifar10_input_stream(test_records_path)\n",
    "      test_image = normalize_image(test_image)\n",
    "      test_image_batch, test_label_batch = tf.train.batch(\n",
    "        [test_image, test_label], batch_size=batch_size, num_threads=1,\n",
    "        capacity=10000)\n",
    "  return test_image_batch, test_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5533cdbb8cb6>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "train_image_batch, train_label_batch = make_train_batch(FLAGS.train_tf_path, FLAGS.train_batch_size)\n",
    "val_image_batch, val_label_batch = make_validation_batch(FLAGS.val_tf_path, FLAGS.val_batch_size)\n",
    "\n",
    "image_batch, label_batch = control_flow_ops.cond(phase_train,lambda: (train_image_batch, train_label_batch),lambda: (val_image_batch, val_label_batch))\n",
    "\n",
    "\n",
    "logits = residual_net(image_batch, FLAGS.residual_net_n, 10, phase_train)\n",
    "\n",
    "\n",
    "loss = _loss(logits, label_batch)\n",
    "accuracy = _accuracy(logits, label_batch)\n",
    "\n",
    "# train one step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "INFO:tensorflow:Restoring parameters from ./full_precision/res32/model/res.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-train_batch/input_producer-train_batch/input_producer/input_producer_EnqueueMany, started daemon 140035923896064)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140035932288768)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140036551620352)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140047894419200)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140035915503360)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/input_producer-evaluate_batch/input_producer/input_producer_EnqueueMany, started daemon 140035907110656)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/batch/fifo_queue-evaluate_batch/batch/fifo_queue_enqueue, started daemon 140035898717952)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "print('Initializing...')\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'./full_precision/res32/model/res.ckpt')\n",
    "\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Test accuracy = 0.924600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# validation\n",
    "\n",
    "print('Evaluating...')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "  fetches = [logits, label_batch, loss]\n",
    "  session_outputs = sess.run(\n",
    "    fetches, {phase_train.name: False})\n",
    "  val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "  val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "  val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(\n",
    "  pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_prune_on_grads(grads_and_vars, dict_nzidx):\n",
    "    for key, nzidx in dict_nzidx.items():\n",
    "        count = 0\n",
    "        for grad, var in grads_and_vars:\n",
    "            if var.name == key:\n",
    "                nzidx_obj = tf.cast(tf.constant(sess.run(dict_nzidx[key])), tf.float32)\n",
    "                grads_and_vars[count] = (tf.multiply(nzidx_obj, grad), var)\n",
    "            count += 1\n",
    "    return grads_and_vars\n",
    "\n",
    "def apply_inq(weights, inq_dict, var_name, prune_rate):  \n",
    "    for target in var_name:\n",
    "        wl = target\n",
    "        bit = 16\n",
    "\n",
    "        weight_obj = weights[wl]\n",
    "        weight_arr = sess.run(weight_obj)\n",
    "\n",
    "        weight_rest = np.reshape(weight_arr, [-1])\n",
    "        dic_tem = np.reshape(sess.run(inq_dict[wl]), [-1])\n",
    "        idx_rest = np.flip(np.argsort(abs(np.reshape(weight_rest, [-1]))), 0)\n",
    "        num_prune = int(len(weight_rest) * prune_rate)\n",
    "        weight_toINQ = weight_rest[idx_rest[:num_prune]]\n",
    "\n",
    "        n1 = (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        n2 = n1 + 1 - bit / 4\n",
    "        upper_bound = 2 ** (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        lower_bound = 2 ** (n1 + 1 - bit / 4)\n",
    "\n",
    "        weight_toINQ[abs(weight_toINQ) < lower_bound] = 0\n",
    "        weight_toINQ[weight_toINQ != 0] = 2 ** (np.floor(np.log2(abs(weight_toINQ[weight_toINQ != 0] * 4 / 3)))) * np.sign(weight_toINQ[weight_toINQ != 0])\n",
    "\n",
    "        weight_rest[idx_rest[:num_prune]] = weight_toINQ\n",
    "        weight_arr = np.reshape(weight_rest, np.shape(weight_arr))\n",
    "        dic_tem[idx_rest[:num_prune]] = np.zeros_like(dic_tem[idx_rest[:num_prune]])\n",
    "        inq_dict[wl] = tf.cast(np.reshape(dic_tem, np.shape(sess.run(inq_dict[wl]))), tf.float32)\n",
    "        sess.run(weights[wl].assign(weight_arr))\n",
    "    return inq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一轮  量化\n",
    "prune_rate =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.924600\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.02709051 -0.08279994  0.01822233  0.11905745 -0.00915685 -0.03560071\n",
      "  0.01750009  0.03826123  0.00807592 -0.10065438]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.5)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-16 16:40:26.762136] Iteration 100, train loss = 0.151927, train accuracy = 1.000000\n",
      "[2018-07-16 16:40:32.397298] Iteration 200, train loss = 0.177482, train accuracy = 0.984375\n",
      "[2018-07-16 16:40:38.045405] Iteration 300, train loss = 0.157973, train accuracy = 0.992188\n",
      "[2018-07-16 16:40:43.706615] Iteration 400, train loss = 0.163516, train accuracy = 0.984375\n",
      "[2018-07-16 16:40:49.388834] Iteration 500, train loss = 0.180150, train accuracy = 0.976562\n",
      "[2018-07-16 16:40:55.050119] Iteration 600, train loss = 0.205976, train accuracy = 0.968750\n",
      "[2018-07-16 16:41:00.692573] Iteration 700, train loss = 0.164587, train accuracy = 0.992188\n",
      "[2018-07-16 16:41:06.330189] Iteration 800, train loss = 0.156320, train accuracy = 0.992188\n",
      "[2018-07-16 16:41:11.973087] Iteration 900, train loss = 0.209756, train accuracy = 0.976562\n",
      "[2018-07-16 16:41:17.634695] Iteration 1000, train loss = 0.142290, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920500\n",
      "[2018-07-16 16:41:24.947136] Iteration 1100, train loss = 0.141200, train accuracy = 1.000000\n",
      "[2018-07-16 16:41:30.579506] Iteration 1200, train loss = 0.155091, train accuracy = 0.992188\n",
      "[2018-07-16 16:41:36.231034] Iteration 1300, train loss = 0.171801, train accuracy = 0.984375\n",
      "[2018-07-16 16:41:41.892986] Iteration 1400, train loss = 0.192524, train accuracy = 0.976562\n",
      "[2018-07-16 16:41:47.601287] Iteration 1500, train loss = 0.140202, train accuracy = 1.000000\n",
      "[2018-07-16 16:41:53.260935] Iteration 1600, train loss = 0.136220, train accuracy = 1.000000\n",
      "[2018-07-16 16:41:58.959874] Iteration 1700, train loss = 0.154813, train accuracy = 0.992188\n",
      "[2018-07-16 16:42:04.618596] Iteration 1800, train loss = 0.212643, train accuracy = 0.968750\n",
      "[2018-07-16 16:42:10.265217] Iteration 1900, train loss = 0.141784, train accuracy = 1.000000\n",
      "[2018-07-16 16:42:15.922182] Iteration 2000, train loss = 0.162220, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916100\n",
      "[2018-07-16 16:42:23.242870] Iteration 2100, train loss = 0.137364, train accuracy = 1.000000\n",
      "[2018-07-16 16:42:28.917289] Iteration 2200, train loss = 0.155239, train accuracy = 0.992188\n",
      "[2018-07-16 16:42:34.589297] Iteration 2300, train loss = 0.155852, train accuracy = 0.992188\n",
      "[2018-07-16 16:42:40.262122] Iteration 2400, train loss = 0.152988, train accuracy = 0.992188\n",
      "[2018-07-16 16:42:45.904586] Iteration 2500, train loss = 0.149606, train accuracy = 0.992188\n",
      "[2018-07-16 16:42:51.557027] Iteration 2600, train loss = 0.142329, train accuracy = 1.000000\n",
      "[2018-07-16 16:42:57.203997] Iteration 2700, train loss = 0.149277, train accuracy = 0.992188\n",
      "[2018-07-16 16:43:02.852090] Iteration 2800, train loss = 0.144202, train accuracy = 1.000000\n",
      "[2018-07-16 16:43:08.505755] Iteration 2900, train loss = 0.138024, train accuracy = 1.000000\n",
      "[2018-07-16 16:43:14.176971] Iteration 3000, train loss = 0.172367, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.920000\n",
      "[2018-07-16 16:43:21.456402] Iteration 3100, train loss = 0.138576, train accuracy = 1.000000\n",
      "[2018-07-16 16:43:27.133414] Iteration 3200, train loss = 0.148358, train accuracy = 0.992188\n",
      "[2018-07-16 16:43:33.043597] Iteration 3300, train loss = 0.164583, train accuracy = 0.984375\n",
      "[2018-07-16 16:43:38.859993] Iteration 3400, train loss = 0.151458, train accuracy = 0.992188\n",
      "[2018-07-16 16:43:44.574608] Iteration 3500, train loss = 0.160063, train accuracy = 0.992188\n",
      "[2018-07-16 16:43:50.297187] Iteration 3600, train loss = 0.144961, train accuracy = 1.000000\n",
      "[2018-07-16 16:43:56.039206] Iteration 3700, train loss = 0.141682, train accuracy = 1.000000\n",
      "[2018-07-16 16:44:01.753024] Iteration 3800, train loss = 0.144532, train accuracy = 0.992188\n",
      "[2018-07-16 16:44:07.434594] Iteration 3900, train loss = 0.163359, train accuracy = 0.992188\n",
      "[2018-07-16 16:44:13.160957] Iteration 4000, train loss = 0.142785, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920500\n",
      "[2018-07-16 16:44:20.649937] Iteration 4100, train loss = 0.149968, train accuracy = 1.000000\n",
      "[2018-07-16 16:44:26.324699] Iteration 4200, train loss = 0.151170, train accuracy = 1.000000\n",
      "[2018-07-16 16:44:31.983130] Iteration 4300, train loss = 0.157680, train accuracy = 0.992188\n",
      "[2018-07-16 16:44:37.638174] Iteration 4400, train loss = 0.155281, train accuracy = 0.984375\n",
      "[2018-07-16 16:44:43.311158] Iteration 4500, train loss = 0.159552, train accuracy = 0.992188\n",
      "[2018-07-16 16:44:49.014683] Iteration 4600, train loss = 0.146515, train accuracy = 1.000000\n",
      "[2018-07-16 16:44:54.715169] Iteration 4700, train loss = 0.151752, train accuracy = 0.992188\n",
      "[2018-07-16 16:45:00.471447] Iteration 4800, train loss = 0.183476, train accuracy = 0.984375\n",
      "[2018-07-16 16:45:06.220791] Iteration 4900, train loss = 0.145827, train accuracy = 1.000000\n",
      "[2018-07-16 16:45:11.939913] Iteration 5000, train loss = 0.149014, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 16:45:19.323764] Iteration 5100, train loss = 0.142614, train accuracy = 0.992188\n",
      "[2018-07-16 16:45:24.985770] Iteration 5200, train loss = 0.158907, train accuracy = 0.992188\n",
      "[2018-07-16 16:45:30.673358] Iteration 5300, train loss = 0.155877, train accuracy = 0.992188\n",
      "[2018-07-16 16:45:36.325920] Iteration 5400, train loss = 0.149090, train accuracy = 1.000000\n",
      "[2018-07-16 16:45:41.989511] Iteration 5500, train loss = 0.149172, train accuracy = 1.000000\n",
      "[2018-07-16 16:45:47.616428] Iteration 5600, train loss = 0.170861, train accuracy = 0.984375\n",
      "[2018-07-16 16:45:53.319539] Iteration 5700, train loss = 0.149573, train accuracy = 1.000000\n",
      "[2018-07-16 16:45:59.024504] Iteration 5800, train loss = 0.137196, train accuracy = 1.000000\n",
      "[2018-07-16 16:46:04.744591] Iteration 5900, train loss = 0.156814, train accuracy = 0.992188\n",
      "[2018-07-16 16:46:10.428359] Iteration 6000, train loss = 0.141873, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921400\n",
      "[2018-07-16 16:46:17.785626] Iteration 6100, train loss = 0.137212, train accuracy = 1.000000\n",
      "[2018-07-16 16:46:23.486748] Iteration 6200, train loss = 0.144175, train accuracy = 1.000000\n",
      "[2018-07-16 16:46:29.213631] Iteration 6300, train loss = 0.141265, train accuracy = 1.000000\n",
      "[2018-07-16 16:46:34.921837] Iteration 6400, train loss = 0.145665, train accuracy = 1.000000\n",
      "[2018-07-16 16:46:40.649617] Iteration 6500, train loss = 0.138678, train accuracy = 1.000000\n",
      "[2018-07-16 16:46:46.335435] Iteration 6600, train loss = 0.153003, train accuracy = 0.992188\n",
      "[2018-07-16 16:46:52.050827] Iteration 6700, train loss = 0.143001, train accuracy = 0.992188\n",
      "[2018-07-16 16:46:57.725472] Iteration 6800, train loss = 0.144511, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:03.437389] Iteration 6900, train loss = 0.144773, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:09.174845] Iteration 7000, train loss = 0.151955, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.920700\n",
      "[2018-07-16 16:47:16.584818] Iteration 7100, train loss = 0.153155, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:22.318457] Iteration 7200, train loss = 0.149531, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:28.054480] Iteration 7300, train loss = 0.138695, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:33.767061] Iteration 7400, train loss = 0.146992, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:39.496858] Iteration 7500, train loss = 0.137242, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:45.209681] Iteration 7600, train loss = 0.141549, train accuracy = 1.000000\n",
      "[2018-07-16 16:47:50.905647] Iteration 7700, train loss = 0.172129, train accuracy = 0.984375\n",
      "[2018-07-16 16:47:56.636375] Iteration 7800, train loss = 0.135794, train accuracy = 1.000000\n",
      "[2018-07-16 16:48:02.346762] Iteration 7900, train loss = 0.142698, train accuracy = 0.992188\n",
      "[2018-07-16 16:48:08.046738] Iteration 8000, train loss = 0.146519, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922500\n",
      "[2018-07-16 16:48:15.442553] Iteration 8100, train loss = 0.148358, train accuracy = 0.992188\n",
      "[2018-07-16 16:48:21.106411] Iteration 8200, train loss = 0.142202, train accuracy = 1.000000\n",
      "[2018-07-16 16:48:26.784849] Iteration 8300, train loss = 0.140636, train accuracy = 1.000000\n",
      "[2018-07-16 16:48:32.472259] Iteration 8400, train loss = 0.138612, train accuracy = 1.000000\n",
      "[2018-07-16 16:48:38.152231] Iteration 8500, train loss = 0.156428, train accuracy = 0.992188\n",
      "[2018-07-16 16:48:43.834756] Iteration 8600, train loss = 0.141002, train accuracy = 1.000000\n",
      "[2018-07-16 16:48:49.509216] Iteration 8700, train loss = 0.149268, train accuracy = 0.992188\n",
      "[2018-07-16 16:48:55.193721] Iteration 8800, train loss = 0.136518, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:00.869006] Iteration 8900, train loss = 0.137148, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:06.538879] Iteration 9000, train loss = 0.151873, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.920900\n",
      "[2018-07-16 16:49:13.895834] Iteration 9100, train loss = 0.133932, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:19.572751] Iteration 9200, train loss = 0.143111, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:25.235734] Iteration 9300, train loss = 0.136378, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:30.920631] Iteration 9400, train loss = 0.139192, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:36.607188] Iteration 9500, train loss = 0.161606, train accuracy = 0.992188\n",
      "[2018-07-16 16:49:42.293662] Iteration 9600, train loss = 0.158555, train accuracy = 0.992188\n",
      "[2018-07-16 16:49:47.975447] Iteration 9700, train loss = 0.144227, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:53.681492] Iteration 9800, train loss = 0.139721, train accuracy = 1.000000\n",
      "[2018-07-16 16:49:59.374286] Iteration 9900, train loss = 0.160057, train accuracy = 0.992188\n",
      "[2018-07-16 16:50:05.044249] Iteration 10000, train loss = 0.154247, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922800\n",
      "[2018-07-16 16:50:12.420448] Iteration 10100, train loss = 0.156762, train accuracy = 0.992188\n",
      "[2018-07-16 16:50:18.125344] Iteration 10200, train loss = 0.137403, train accuracy = 1.000000\n",
      "[2018-07-16 16:50:23.824480] Iteration 10300, train loss = 0.141548, train accuracy = 1.000000\n",
      "[2018-07-16 16:50:29.506643] Iteration 10400, train loss = 0.145519, train accuracy = 1.000000\n",
      "[2018-07-16 16:50:35.178000] Iteration 10500, train loss = 0.134992, train accuracy = 1.000000\n",
      "[2018-07-16 16:50:40.878862] Iteration 10600, train loss = 0.137494, train accuracy = 1.000000\n",
      "[2018-07-16 16:50:46.557531] Iteration 10700, train loss = 0.138628, train accuracy = 1.000000\n",
      "[2018-07-16 16:50:52.234622] Iteration 10800, train loss = 0.137812, train accuracy = 1.000000\n",
      "[2018-07-16 16:50:57.909298] Iteration 10900, train loss = 0.153899, train accuracy = 1.000000\n",
      "[2018-07-16 16:51:03.591687] Iteration 11000, train loss = 0.136370, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921600\n",
      "[2018-07-16 16:51:11.041654] Iteration 11100, train loss = 0.143738, train accuracy = 0.992188\n",
      "[2018-07-16 16:51:16.778306] Iteration 11200, train loss = 0.138221, train accuracy = 1.000000\n",
      "[2018-07-16 16:51:22.427301] Iteration 11300, train loss = 0.159733, train accuracy = 0.984375\n",
      "[2018-07-16 16:51:28.112431] Iteration 11400, train loss = 0.155787, train accuracy = 0.992188\n",
      "[2018-07-16 16:51:33.791703] Iteration 11500, train loss = 0.136309, train accuracy = 1.000000\n",
      "[2018-07-16 16:51:39.464172] Iteration 11600, train loss = 0.147809, train accuracy = 0.992188\n",
      "[2018-07-16 16:51:45.136602] Iteration 11700, train loss = 0.142289, train accuracy = 1.000000\n",
      "[2018-07-16 16:51:50.814546] Iteration 11800, train loss = 0.135368, train accuracy = 1.000000\n",
      "[2018-07-16 16:51:56.486809] Iteration 11900, train loss = 0.136202, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:02.164872] Iteration 12000, train loss = 0.160528, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 16:52:09.520247] Iteration 12100, train loss = 0.137873, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:15.181791] Iteration 12200, train loss = 0.139898, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:20.857787] Iteration 12300, train loss = 0.148990, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:26.522414] Iteration 12400, train loss = 0.138577, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:32.193591] Iteration 12500, train loss = 0.144136, train accuracy = 0.992188\n",
      "[2018-07-16 16:52:37.873031] Iteration 12600, train loss = 0.136142, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:43.554325] Iteration 12700, train loss = 0.138776, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:49.235753] Iteration 12800, train loss = 0.133711, train accuracy = 1.000000\n",
      "[2018-07-16 16:52:54.917676] Iteration 12900, train loss = 0.133206, train accuracy = 1.000000\n",
      "[2018-07-16 16:53:00.586979] Iteration 13000, train loss = 0.143246, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.920500\n",
      "[2018-07-16 16:53:07.930259] Iteration 13100, train loss = 0.146797, train accuracy = 0.992188\n",
      "[2018-07-16 16:53:13.603587] Iteration 13200, train loss = 0.158068, train accuracy = 0.992188\n",
      "[2018-07-16 16:53:19.285577] Iteration 13300, train loss = 0.136928, train accuracy = 1.000000\n",
      "[2018-07-16 16:53:24.961233] Iteration 13400, train loss = 0.135953, train accuracy = 1.000000\n",
      "[2018-07-16 16:53:30.627219] Iteration 13500, train loss = 0.134989, train accuracy = 1.000000\n",
      "[2018-07-16 16:53:36.300430] Iteration 13600, train loss = 0.161722, train accuracy = 0.992188\n",
      "[2018-07-16 16:53:41.979558] Iteration 13700, train loss = 0.141975, train accuracy = 1.000000\n",
      "[2018-07-16 16:53:47.658938] Iteration 13800, train loss = 0.141370, train accuracy = 1.000000\n",
      "[2018-07-16 16:53:53.336195] Iteration 13900, train loss = 0.143291, train accuracy = 1.000000\n",
      "[2018-07-16 16:53:59.016053] Iteration 14000, train loss = 0.136912, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923800\n",
      "[2018-07-16 16:54:06.374937] Iteration 14100, train loss = 0.155563, train accuracy = 0.992188\n",
      "[2018-07-16 16:54:12.039197] Iteration 14200, train loss = 0.137702, train accuracy = 1.000000\n",
      "[2018-07-16 16:54:17.717011] Iteration 14300, train loss = 0.145599, train accuracy = 0.992188\n",
      "[2018-07-16 16:54:23.382719] Iteration 14400, train loss = 0.140467, train accuracy = 1.000000\n",
      "[2018-07-16 16:54:29.046137] Iteration 14500, train loss = 0.145576, train accuracy = 0.992188\n",
      "[2018-07-16 16:54:34.724292] Iteration 14600, train loss = 0.141885, train accuracy = 1.000000\n",
      "[2018-07-16 16:54:40.397590] Iteration 14700, train loss = 0.153841, train accuracy = 0.984375\n",
      "[2018-07-16 16:54:46.067278] Iteration 14800, train loss = 0.147842, train accuracy = 0.992188\n",
      "[2018-07-16 16:54:51.746968] Iteration 14900, train loss = 0.141560, train accuracy = 1.000000\n",
      "[2018-07-16 16:54:57.417034] Iteration 15000, train loss = 0.135358, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922300\n",
      "[2018-07-16 16:55:04.768651] Iteration 15100, train loss = 0.145762, train accuracy = 1.000000\n",
      "[2018-07-16 16:55:10.458005] Iteration 15200, train loss = 0.144457, train accuracy = 1.000000\n",
      "[2018-07-16 16:55:16.130055] Iteration 15300, train loss = 0.142181, train accuracy = 1.000000\n",
      "[2018-07-16 16:55:21.811462] Iteration 15400, train loss = 0.164736, train accuracy = 0.984375\n",
      "[2018-07-16 16:55:27.482787] Iteration 15500, train loss = 0.138409, train accuracy = 1.000000\n",
      "[2018-07-16 16:55:33.179954] Iteration 15600, train loss = 0.133814, train accuracy = 1.000000\n",
      "[2018-07-16 16:55:38.857292] Iteration 15700, train loss = 0.146833, train accuracy = 0.992188\n",
      "[2018-07-16 16:55:44.524552] Iteration 15800, train loss = 0.132382, train accuracy = 1.000000\n",
      "[2018-07-16 16:55:50.190595] Iteration 15900, train loss = 0.134891, train accuracy = 1.000000\n",
      "[2018-07-16 16:55:55.875845] Iteration 16000, train loss = 0.138488, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922800\n",
      "[2018-07-16 16:56:03.216367] Iteration 16100, train loss = 0.144735, train accuracy = 1.000000\n",
      "[2018-07-16 16:56:08.898119] Iteration 16200, train loss = 0.160251, train accuracy = 0.992188\n",
      "[2018-07-16 16:56:14.574710] Iteration 16300, train loss = 0.171736, train accuracy = 0.992188\n",
      "[2018-07-16 16:56:20.254423] Iteration 16400, train loss = 0.142405, train accuracy = 0.992188\n",
      "[2018-07-16 16:56:25.934979] Iteration 16500, train loss = 0.159739, train accuracy = 0.992188\n",
      "[2018-07-16 16:56:31.710082] Iteration 16600, train loss = 0.136215, train accuracy = 1.000000\n",
      "[2018-07-16 16:56:37.425564] Iteration 16700, train loss = 0.137947, train accuracy = 1.000000\n",
      "[2018-07-16 16:56:43.129366] Iteration 16800, train loss = 0.135921, train accuracy = 1.000000\n",
      "[2018-07-16 16:56:48.832752] Iteration 16900, train loss = 0.137463, train accuracy = 1.000000\n",
      "[2018-07-16 16:56:54.536407] Iteration 17000, train loss = 0.136676, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 16:57:01.967746] Iteration 17100, train loss = 0.137778, train accuracy = 1.000000\n",
      "[2018-07-16 16:57:07.681788] Iteration 17200, train loss = 0.155880, train accuracy = 0.984375\n",
      "[2018-07-16 16:57:13.401681] Iteration 17300, train loss = 0.134857, train accuracy = 1.000000\n",
      "[2018-07-16 16:57:19.108688] Iteration 17400, train loss = 0.137802, train accuracy = 1.000000\n",
      "[2018-07-16 16:57:24.820826] Iteration 17500, train loss = 0.137747, train accuracy = 1.000000\n",
      "[2018-07-16 16:57:30.519198] Iteration 17600, train loss = 0.152889, train accuracy = 0.992188\n",
      "[2018-07-16 16:57:36.253232] Iteration 17700, train loss = 0.142894, train accuracy = 0.992188\n",
      "[2018-07-16 16:57:42.010776] Iteration 17800, train loss = 0.135603, train accuracy = 1.000000\n",
      "[2018-07-16 16:57:47.735452] Iteration 17900, train loss = 0.136244, train accuracy = 1.000000\n",
      "[2018-07-16 16:57:53.452291] Iteration 18000, train loss = 0.198603, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 16:58:00.814932] Iteration 18100, train loss = 0.135267, train accuracy = 1.000000\n",
      "[2018-07-16 16:58:06.489660] Iteration 18200, train loss = 0.147180, train accuracy = 0.992188\n",
      "[2018-07-16 16:58:12.164687] Iteration 18300, train loss = 0.133624, train accuracy = 1.000000\n",
      "[2018-07-16 16:58:17.836433] Iteration 18400, train loss = 0.150606, train accuracy = 0.992188\n",
      "[2018-07-16 16:58:23.508255] Iteration 18500, train loss = 0.143121, train accuracy = 1.000000\n",
      "[2018-07-16 16:58:29.174871] Iteration 18600, train loss = 0.147513, train accuracy = 0.992188\n",
      "[2018-07-16 16:58:34.855218] Iteration 18700, train loss = 0.133531, train accuracy = 1.000000\n",
      "[2018-07-16 16:58:40.515736] Iteration 18800, train loss = 0.134318, train accuracy = 1.000000\n",
      "[2018-07-16 16:58:46.178859] Iteration 18900, train loss = 0.140672, train accuracy = 1.000000\n",
      "[2018-07-16 16:58:51.857840] Iteration 19000, train loss = 0.148614, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.923700\n",
      "[2018-07-16 16:58:59.199335] Iteration 19100, train loss = 0.141789, train accuracy = 0.992188\n",
      "[2018-07-16 16:59:04.868832] Iteration 19200, train loss = 0.137713, train accuracy = 1.000000\n",
      "[2018-07-16 16:59:10.542965] Iteration 19300, train loss = 0.139137, train accuracy = 1.000000\n",
      "[2018-07-16 16:59:16.212583] Iteration 19400, train loss = 0.136944, train accuracy = 1.000000\n",
      "[2018-07-16 16:59:21.878310] Iteration 19500, train loss = 0.139854, train accuracy = 1.000000\n",
      "[2018-07-16 16:59:27.549338] Iteration 19600, train loss = 0.143733, train accuracy = 1.000000\n",
      "[2018-07-16 16:59:33.225061] Iteration 19700, train loss = 0.136012, train accuracy = 1.000000\n",
      "[2018-07-16 16:59:38.900521] Iteration 19800, train loss = 0.137705, train accuracy = 1.000000\n",
      "[2018-07-16 16:59:44.595400] Iteration 19900, train loss = 0.169059, train accuracy = 0.992188\n",
      "[2018-07-16 16:59:50.268587] Iteration 20000, train loss = 0.141511, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 16:59:57.619124] Iteration 20100, train loss = 0.135974, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:03.285041] Iteration 20200, train loss = 0.140129, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:08.966622] Iteration 20300, train loss = 0.142899, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:14.643265] Iteration 20400, train loss = 0.133036, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:20.315929] Iteration 20500, train loss = 0.145677, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:25.996124] Iteration 20600, train loss = 0.134496, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:31.679377] Iteration 20700, train loss = 0.142711, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:37.347394] Iteration 20800, train loss = 0.134451, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:43.031566] Iteration 20900, train loss = 0.131844, train accuracy = 1.000000\n",
      "[2018-07-16 17:00:48.716670] Iteration 21000, train loss = 0.137787, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921400\n",
      "[2018-07-16 17:00:56.073186] Iteration 21100, train loss = 0.134902, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:01.741855] Iteration 21200, train loss = 0.167033, train accuracy = 0.984375\n",
      "[2018-07-16 17:01:07.416005] Iteration 21300, train loss = 0.140265, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:13.090336] Iteration 21400, train loss = 0.141324, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:18.766245] Iteration 21500, train loss = 0.137368, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:24.449782] Iteration 21600, train loss = 0.135673, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:30.125608] Iteration 21700, train loss = 0.134665, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:35.794355] Iteration 21800, train loss = 0.137908, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:41.468493] Iteration 21900, train loss = 0.136228, train accuracy = 1.000000\n",
      "[2018-07-16 17:01:47.137016] Iteration 22000, train loss = 0.143197, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923100\n",
      "[2018-07-16 17:01:54.525183] Iteration 22100, train loss = 0.138912, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:00.182473] Iteration 22200, train loss = 0.132019, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:05.860559] Iteration 22300, train loss = 0.136704, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:11.525577] Iteration 22400, train loss = 0.131473, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:17.208091] Iteration 22500, train loss = 0.135503, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:22.889681] Iteration 22600, train loss = 0.134387, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:28.575052] Iteration 22700, train loss = 0.134252, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:34.265421] Iteration 22800, train loss = 0.133775, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:39.945522] Iteration 22900, train loss = 0.136566, train accuracy = 1.000000\n",
      "[2018-07-16 17:02:45.620132] Iteration 23000, train loss = 0.136506, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 17:02:52.981938] Iteration 23100, train loss = 0.153012, train accuracy = 0.984375\n",
      "[2018-07-16 17:02:58.649837] Iteration 23200, train loss = 0.145073, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:04.313365] Iteration 23300, train loss = 0.135671, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:09.986708] Iteration 23400, train loss = 0.137134, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:15.667392] Iteration 23500, train loss = 0.135841, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:21.323460] Iteration 23600, train loss = 0.137892, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:26.994186] Iteration 23700, train loss = 0.135294, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:32.655717] Iteration 23800, train loss = 0.147408, train accuracy = 0.992188\n",
      "[2018-07-16 17:03:38.335589] Iteration 23900, train loss = 0.136872, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:44.002097] Iteration 24000, train loss = 0.136842, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923500\n",
      "[2018-07-16 17:03:51.355970] Iteration 24100, train loss = 0.136924, train accuracy = 1.000000\n",
      "[2018-07-16 17:03:57.032640] Iteration 24200, train loss = 0.136876, train accuracy = 1.000000\n",
      "[2018-07-16 17:04:02.705551] Iteration 24300, train loss = 0.147974, train accuracy = 0.992188\n",
      "[2018-07-16 17:04:08.381984] Iteration 24400, train loss = 0.157393, train accuracy = 1.000000\n",
      "[2018-07-16 17:04:14.051448] Iteration 24500, train loss = 0.159807, train accuracy = 0.992188\n",
      "[2018-07-16 17:04:19.731795] Iteration 24600, train loss = 0.145021, train accuracy = 0.992188\n",
      "[2018-07-16 17:04:25.410510] Iteration 24700, train loss = 0.132129, train accuracy = 1.000000\n",
      "[2018-07-16 17:04:31.085681] Iteration 24800, train loss = 0.139053, train accuracy = 1.000000\n",
      "[2018-07-16 17:04:36.783021] Iteration 24900, train loss = 0.167594, train accuracy = 0.992188\n",
      "[2018-07-16 17:04:42.457867] Iteration 25000, train loss = 0.135773, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923100\n",
      "[2018-07-16 17:04:49.810804] Iteration 25100, train loss = 0.132904, train accuracy = 1.000000\n",
      "[2018-07-16 17:04:55.487470] Iteration 25200, train loss = 0.150877, train accuracy = 0.992188\n",
      "[2018-07-16 17:05:01.149944] Iteration 25300, train loss = 0.145419, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:06.830877] Iteration 25400, train loss = 0.137028, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:12.493516] Iteration 25500, train loss = 0.138243, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:18.166374] Iteration 25600, train loss = 0.139604, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:23.837042] Iteration 25700, train loss = 0.139585, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:29.505582] Iteration 25800, train loss = 0.134286, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:35.183306] Iteration 25900, train loss = 0.146118, train accuracy = 0.992188\n",
      "[2018-07-16 17:05:40.849795] Iteration 26000, train loss = 0.142167, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.925200\n",
      "[2018-07-16 17:05:48.186013] Iteration 26100, train loss = 0.144633, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:53.865763] Iteration 26200, train loss = 0.140115, train accuracy = 1.000000\n",
      "[2018-07-16 17:05:59.534437] Iteration 26300, train loss = 0.141436, train accuracy = 0.992188\n",
      "[2018-07-16 17:06:05.211150] Iteration 26400, train loss = 0.133094, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:10.885405] Iteration 26500, train loss = 0.138368, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:16.552382] Iteration 26600, train loss = 0.137206, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:22.228713] Iteration 26700, train loss = 0.136689, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:27.906248] Iteration 26800, train loss = 0.141199, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:33.598102] Iteration 26900, train loss = 0.134395, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:39.279114] Iteration 27000, train loss = 0.140456, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922800\n",
      "[2018-07-16 17:06:46.647035] Iteration 27100, train loss = 0.136843, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:52.321598] Iteration 27200, train loss = 0.132901, train accuracy = 1.000000\n",
      "[2018-07-16 17:06:57.990715] Iteration 27300, train loss = 0.148144, train accuracy = 0.992188\n",
      "[2018-07-16 17:07:03.674237] Iteration 27400, train loss = 0.133213, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:09.359718] Iteration 27500, train loss = 0.140965, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:15.039835] Iteration 27600, train loss = 0.132660, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:20.719154] Iteration 27700, train loss = 0.136447, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:26.381558] Iteration 27800, train loss = 0.137045, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:32.046392] Iteration 27900, train loss = 0.133710, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:37.735911] Iteration 28000, train loss = 0.142757, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923900\n",
      "[2018-07-16 17:07:45.086361] Iteration 28100, train loss = 0.139181, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:50.760789] Iteration 28200, train loss = 0.138012, train accuracy = 1.000000\n",
      "[2018-07-16 17:07:56.447745] Iteration 28300, train loss = 0.144467, train accuracy = 0.992188\n",
      "[2018-07-16 17:08:02.126754] Iteration 28400, train loss = 0.134736, train accuracy = 1.000000\n",
      "[2018-07-16 17:08:07.802467] Iteration 28500, train loss = 0.135399, train accuracy = 1.000000\n",
      "[2018-07-16 17:08:13.476483] Iteration 28600, train loss = 0.133842, train accuracy = 1.000000\n",
      "[2018-07-16 17:08:19.146118] Iteration 28700, train loss = 0.136052, train accuracy = 1.000000\n",
      "[2018-07-16 17:08:24.819940] Iteration 28800, train loss = 0.148312, train accuracy = 0.992188\n",
      "[2018-07-16 17:08:30.507744] Iteration 28900, train loss = 0.132386, train accuracy = 1.000000\n",
      "[2018-07-16 17:08:36.174238] Iteration 29000, train loss = 0.137869, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923300\n",
      "[2018-07-16 17:08:43.520967] Iteration 29100, train loss = 0.141856, train accuracy = 1.000000\n",
      "[2018-07-16 17:08:49.195010] Iteration 29200, train loss = 0.133593, train accuracy = 1.000000\n",
      "[2018-07-16 17:08:54.864465] Iteration 29300, train loss = 0.135582, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:00.546073] Iteration 29400, train loss = 0.133811, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:06.224082] Iteration 29500, train loss = 0.148924, train accuracy = 0.992188\n",
      "[2018-07-16 17:09:11.910279] Iteration 29600, train loss = 0.138798, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:17.597319] Iteration 29700, train loss = 0.136249, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:23.260570] Iteration 29800, train loss = 0.131480, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:28.940801] Iteration 29900, train loss = 0.135458, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:34.620993] Iteration 30000, train loss = 0.138145, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921600\n",
      "[2018-07-16 17:09:41.966219] Iteration 30100, train loss = 0.136100, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:47.642050] Iteration 30200, train loss = 0.138422, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:53.317554] Iteration 30300, train loss = 0.138596, train accuracy = 1.000000\n",
      "[2018-07-16 17:09:58.994499] Iteration 30400, train loss = 0.131935, train accuracy = 1.000000\n",
      "[2018-07-16 17:10:04.667612] Iteration 30500, train loss = 0.156712, train accuracy = 0.992188\n",
      "[2018-07-16 17:10:10.339703] Iteration 30600, train loss = 0.139666, train accuracy = 1.000000\n",
      "[2018-07-16 17:10:16.007804] Iteration 30700, train loss = 0.133694, train accuracy = 1.000000\n",
      "[2018-07-16 17:10:21.671800] Iteration 30800, train loss = 0.133806, train accuracy = 1.000000\n",
      "[2018-07-16 17:10:27.352212] Iteration 30900, train loss = 0.145155, train accuracy = 0.992188\n",
      "[2018-07-16 17:10:33.021271] Iteration 31000, train loss = 0.134688, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923700\n",
      "[2018-07-16 17:10:40.373234] Iteration 31100, train loss = 0.133227, train accuracy = 1.000000\n",
      "[2018-07-16 17:10:46.038612] Iteration 31200, train loss = 0.136326, train accuracy = 1.000000\n",
      "[2018-07-16 17:10:51.708136] Iteration 31300, train loss = 0.152271, train accuracy = 0.992188\n",
      "[2018-07-16 17:10:57.393552] Iteration 31400, train loss = 0.168805, train accuracy = 0.984375\n",
      "[2018-07-16 17:11:03.088497] Iteration 31500, train loss = 0.132882, train accuracy = 1.000000\n",
      "[2018-07-16 17:11:08.751149] Iteration 31600, train loss = 0.132860, train accuracy = 1.000000\n",
      "[2018-07-16 17:11:14.430113] Iteration 31700, train loss = 0.152207, train accuracy = 0.992188\n",
      "[2018-07-16 17:11:20.100670] Iteration 31800, train loss = 0.149682, train accuracy = 0.992188\n",
      "[2018-07-16 17:11:25.772950] Iteration 31900, train loss = 0.134817, train accuracy = 1.000000\n",
      "[2018-07-16 17:11:31.440245] Iteration 32000, train loss = 0.133847, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923400\n",
      "[2018-07-16 17:11:38.792659] Iteration 32100, train loss = 0.141684, train accuracy = 1.000000\n",
      "[2018-07-16 17:11:44.469636] Iteration 32200, train loss = 0.134367, train accuracy = 1.000000\n",
      "[2018-07-16 17:11:50.136924] Iteration 32300, train loss = 0.137749, train accuracy = 1.000000\n",
      "[2018-07-16 17:11:55.829571] Iteration 32400, train loss = 0.131838, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:01.506359] Iteration 32500, train loss = 0.135670, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:07.173873] Iteration 32600, train loss = 0.135500, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:12.847677] Iteration 32700, train loss = 0.132278, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:18.518029] Iteration 32800, train loss = 0.144911, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:24.185959] Iteration 32900, train loss = 0.135657, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:29.865847] Iteration 33000, train loss = 0.139490, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 17:12:37.222484] Iteration 33100, train loss = 0.135639, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:42.897128] Iteration 33200, train loss = 0.134660, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:48.584465] Iteration 33300, train loss = 0.137343, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:54.281273] Iteration 33400, train loss = 0.137310, train accuracy = 1.000000\n",
      "[2018-07-16 17:12:59.949113] Iteration 33500, train loss = 0.135268, train accuracy = 1.000000\n",
      "[2018-07-16 17:13:05.632086] Iteration 33600, train loss = 0.133283, train accuracy = 1.000000\n",
      "[2018-07-16 17:13:11.318812] Iteration 33700, train loss = 0.136268, train accuracy = 1.000000\n",
      "[2018-07-16 17:13:16.986191] Iteration 33800, train loss = 0.138954, train accuracy = 1.000000\n",
      "[2018-07-16 17:13:22.669718] Iteration 33900, train loss = 0.134296, train accuracy = 1.000000\n",
      "[2018-07-16 17:13:28.349883] Iteration 34000, train loss = 0.132705, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.925100\n",
      "[2018-07-16 17:13:35.693902] Iteration 34100, train loss = 0.143685, train accuracy = 0.992188\n",
      "[2018-07-16 17:13:41.371148] Iteration 34200, train loss = 0.142951, train accuracy = 0.992188\n",
      "[2018-07-16 17:13:47.047094] Iteration 34300, train loss = 0.133607, train accuracy = 1.000000\n",
      "[2018-07-16 17:13:52.746033] Iteration 34400, train loss = 0.134979, train accuracy = 1.000000\n",
      "[2018-07-16 17:13:58.421521] Iteration 34500, train loss = 0.137106, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:04.110449] Iteration 34600, train loss = 0.136151, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:09.777550] Iteration 34700, train loss = 0.141887, train accuracy = 0.992188\n",
      "[2018-07-16 17:14:15.468388] Iteration 34800, train loss = 0.132442, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:21.147229] Iteration 34900, train loss = 0.135458, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:26.813526] Iteration 35000, train loss = 0.141499, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922300\n",
      "[2018-07-16 17:14:34.188895] Iteration 35100, train loss = 0.138432, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:39.860547] Iteration 35200, train loss = 0.131698, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:45.529988] Iteration 35300, train loss = 0.135653, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:51.214961] Iteration 35400, train loss = 0.140590, train accuracy = 1.000000\n",
      "[2018-07-16 17:14:56.888838] Iteration 35500, train loss = 0.133943, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:02.580074] Iteration 35600, train loss = 0.137105, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:08.264065] Iteration 35700, train loss = 0.135050, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:13.945816] Iteration 35800, train loss = 0.135677, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:19.615726] Iteration 35900, train loss = 0.132710, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:25.298369] Iteration 36000, train loss = 0.139310, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.924000\n",
      "[2018-07-16 17:15:32.655397] Iteration 36100, train loss = 0.132361, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:38.316713] Iteration 36200, train loss = 0.142701, train accuracy = 0.992188\n",
      "[2018-07-16 17:15:44.001871] Iteration 36300, train loss = 0.131112, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:49.669331] Iteration 36400, train loss = 0.136565, train accuracy = 1.000000\n",
      "[2018-07-16 17:15:55.345112] Iteration 36500, train loss = 0.136562, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:01.024679] Iteration 36600, train loss = 0.137971, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:06.699900] Iteration 36700, train loss = 0.163755, train accuracy = 0.984375\n",
      "[2018-07-16 17:16:12.377174] Iteration 36800, train loss = 0.138163, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:18.056367] Iteration 36900, train loss = 0.143849, train accuracy = 0.992188\n",
      "[2018-07-16 17:16:23.733551] Iteration 37000, train loss = 0.133428, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923400\n",
      "[2018-07-16 17:16:31.090004] Iteration 37100, train loss = 0.132637, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:36.750888] Iteration 37200, train loss = 0.135265, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:42.437141] Iteration 37300, train loss = 0.133158, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:48.120759] Iteration 37400, train loss = 0.136088, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:53.793514] Iteration 37500, train loss = 0.149172, train accuracy = 1.000000\n",
      "[2018-07-16 17:16:59.470719] Iteration 37600, train loss = 0.141778, train accuracy = 0.992188\n",
      "[2018-07-16 17:17:05.146822] Iteration 37700, train loss = 0.136691, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:10.825106] Iteration 37800, train loss = 0.136290, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:16.503998] Iteration 37900, train loss = 0.135420, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:22.167170] Iteration 38000, train loss = 0.132345, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923500\n",
      "[2018-07-16 17:17:29.510613] Iteration 38100, train loss = 0.133006, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:35.169747] Iteration 38200, train loss = 0.135498, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:40.832322] Iteration 38300, train loss = 0.133337, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:46.502776] Iteration 38400, train loss = 0.136108, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:52.182355] Iteration 38500, train loss = 0.132723, train accuracy = 1.000000\n",
      "[2018-07-16 17:17:57.873472] Iteration 38600, train loss = 0.136593, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:03.539913] Iteration 38700, train loss = 0.137022, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:09.216226] Iteration 38800, train loss = 0.132383, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:14.898976] Iteration 38900, train loss = 0.138515, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:20.561220] Iteration 39000, train loss = 0.133155, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.924700\n",
      "[2018-07-16 17:18:27.903395] Iteration 39100, train loss = 0.134597, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:33.568822] Iteration 39200, train loss = 0.147596, train accuracy = 0.984375\n",
      "[2018-07-16 17:18:39.273253] Iteration 39300, train loss = 0.132872, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:44.941610] Iteration 39400, train loss = 0.133454, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:50.611719] Iteration 39500, train loss = 0.133738, train accuracy = 1.000000\n",
      "[2018-07-16 17:18:56.294402] Iteration 39600, train loss = 0.136595, train accuracy = 1.000000\n",
      "[2018-07-16 17:19:01.957818] Iteration 39700, train loss = 0.137336, train accuracy = 0.992188\n",
      "[2018-07-16 17:19:07.628719] Iteration 39800, train loss = 0.131031, train accuracy = 1.000000\n",
      "[2018-07-16 17:19:13.317910] Iteration 39900, train loss = 0.134699, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "curr_lr = 0\n",
    "for step in range(40000):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二轮 量化\n",
    "prune_rate = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.923200\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.04147975 -0.0625     -0.01364486  0.125       0.01460984 -0.03125\n",
      "  0.02252148  0.03125     0.01663994 -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.75)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-16 17:20:17.702219] Iteration 100, train loss = 0.184745, train accuracy = 0.976562\n",
      "[2018-07-16 17:20:23.315353] Iteration 200, train loss = 0.151817, train accuracy = 0.992188\n",
      "[2018-07-16 17:20:28.926629] Iteration 300, train loss = 0.154841, train accuracy = 0.992188\n",
      "[2018-07-16 17:20:34.552548] Iteration 400, train loss = 0.172313, train accuracy = 0.984375\n",
      "[2018-07-16 17:20:40.176353] Iteration 500, train loss = 0.179677, train accuracy = 0.976562\n",
      "[2018-07-16 17:20:45.813841] Iteration 600, train loss = 0.167317, train accuracy = 0.984375\n",
      "[2018-07-16 17:20:51.437417] Iteration 700, train loss = 0.136904, train accuracy = 1.000000\n",
      "[2018-07-16 17:20:57.060942] Iteration 800, train loss = 0.149174, train accuracy = 0.992188\n",
      "[2018-07-16 17:21:02.688855] Iteration 900, train loss = 0.164953, train accuracy = 0.992188\n",
      "[2018-07-16 17:21:08.328934] Iteration 1000, train loss = 0.140093, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.917700\n",
      "[2018-07-16 17:21:15.632367] Iteration 1100, train loss = 0.166900, train accuracy = 0.984375\n",
      "[2018-07-16 17:21:21.266715] Iteration 1200, train loss = 0.150385, train accuracy = 0.992188\n",
      "[2018-07-16 17:21:26.899541] Iteration 1300, train loss = 0.139284, train accuracy = 1.000000\n",
      "[2018-07-16 17:21:32.529573] Iteration 1400, train loss = 0.132932, train accuracy = 1.000000\n",
      "[2018-07-16 17:21:38.152310] Iteration 1500, train loss = 0.167369, train accuracy = 0.984375\n",
      "[2018-07-16 17:21:43.767631] Iteration 1600, train loss = 0.137934, train accuracy = 1.000000\n",
      "[2018-07-16 17:21:49.399924] Iteration 1700, train loss = 0.160538, train accuracy = 0.984375\n",
      "[2018-07-16 17:21:55.025985] Iteration 1800, train loss = 0.146902, train accuracy = 1.000000\n",
      "[2018-07-16 17:22:00.661405] Iteration 1900, train loss = 0.168219, train accuracy = 0.984375\n",
      "[2018-07-16 17:22:06.285196] Iteration 2000, train loss = 0.148613, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.918600\n",
      "[2018-07-16 17:22:13.584715] Iteration 2100, train loss = 0.141154, train accuracy = 1.000000\n",
      "[2018-07-16 17:22:19.204761] Iteration 2200, train loss = 0.145141, train accuracy = 1.000000\n",
      "[2018-07-16 17:22:24.822970] Iteration 2300, train loss = 0.150375, train accuracy = 0.992188\n",
      "[2018-07-16 17:22:30.443281] Iteration 2400, train loss = 0.180588, train accuracy = 0.992188\n",
      "[2018-07-16 17:22:36.071546] Iteration 2500, train loss = 0.143191, train accuracy = 1.000000\n",
      "[2018-07-16 17:22:41.696824] Iteration 2600, train loss = 0.162030, train accuracy = 0.984375\n",
      "[2018-07-16 17:22:47.312024] Iteration 2700, train loss = 0.169301, train accuracy = 0.984375\n",
      "[2018-07-16 17:22:52.914744] Iteration 2800, train loss = 0.149341, train accuracy = 0.992188\n",
      "[2018-07-16 17:22:58.554133] Iteration 2900, train loss = 0.136794, train accuracy = 1.000000\n",
      "[2018-07-16 17:23:04.191668] Iteration 3000, train loss = 0.155106, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.917000\n",
      "[2018-07-16 17:23:11.497777] Iteration 3100, train loss = 0.161790, train accuracy = 0.992188\n",
      "[2018-07-16 17:23:17.128875] Iteration 3200, train loss = 0.144211, train accuracy = 0.992188\n",
      "[2018-07-16 17:23:22.764900] Iteration 3300, train loss = 0.172231, train accuracy = 0.984375\n",
      "[2018-07-16 17:23:28.397050] Iteration 3400, train loss = 0.161977, train accuracy = 0.976562\n",
      "[2018-07-16 17:23:34.018356] Iteration 3500, train loss = 0.141050, train accuracy = 1.000000\n",
      "[2018-07-16 17:23:39.639786] Iteration 3600, train loss = 0.137090, train accuracy = 1.000000\n",
      "[2018-07-16 17:23:45.285519] Iteration 3700, train loss = 0.147669, train accuracy = 0.984375\n",
      "[2018-07-16 17:23:50.924240] Iteration 3800, train loss = 0.145737, train accuracy = 0.992188\n",
      "[2018-07-16 17:23:56.559258] Iteration 3900, train loss = 0.157539, train accuracy = 0.992188\n",
      "[2018-07-16 17:24:02.189252] Iteration 4000, train loss = 0.136065, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.919400\n",
      "[2018-07-16 17:24:09.498055] Iteration 4100, train loss = 0.147018, train accuracy = 0.992188\n",
      "[2018-07-16 17:24:15.126942] Iteration 4200, train loss = 0.142804, train accuracy = 1.000000\n",
      "[2018-07-16 17:24:20.761395] Iteration 4300, train loss = 0.131828, train accuracy = 1.000000\n",
      "[2018-07-16 17:24:26.396824] Iteration 4400, train loss = 0.151223, train accuracy = 1.000000\n",
      "[2018-07-16 17:24:32.038141] Iteration 4500, train loss = 0.139791, train accuracy = 1.000000\n",
      "[2018-07-16 17:24:37.663401] Iteration 4600, train loss = 0.139214, train accuracy = 1.000000\n",
      "[2018-07-16 17:24:43.309243] Iteration 4700, train loss = 0.148395, train accuracy = 0.992188\n",
      "[2018-07-16 17:24:48.947494] Iteration 4800, train loss = 0.141945, train accuracy = 1.000000\n",
      "[2018-07-16 17:24:54.585438] Iteration 4900, train loss = 0.134283, train accuracy = 1.000000\n",
      "[2018-07-16 17:25:00.232051] Iteration 5000, train loss = 0.167160, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.919800\n",
      "[2018-07-16 17:25:07.541106] Iteration 5100, train loss = 0.138295, train accuracy = 1.000000\n",
      "[2018-07-16 17:25:13.178078] Iteration 5200, train loss = 0.151831, train accuracy = 0.992188\n",
      "[2018-07-16 17:25:18.808855] Iteration 5300, train loss = 0.150695, train accuracy = 0.984375\n",
      "[2018-07-16 17:25:24.447417] Iteration 5400, train loss = 0.139546, train accuracy = 1.000000\n",
      "[2018-07-16 17:25:30.081693] Iteration 5500, train loss = 0.140333, train accuracy = 0.992188\n",
      "[2018-07-16 17:25:35.713954] Iteration 5600, train loss = 0.137348, train accuracy = 1.000000\n",
      "[2018-07-16 17:25:41.345002] Iteration 5700, train loss = 0.149724, train accuracy = 0.992188\n",
      "[2018-07-16 17:25:46.986857] Iteration 5800, train loss = 0.134068, train accuracy = 1.000000\n",
      "[2018-07-16 17:25:52.623172] Iteration 5900, train loss = 0.167780, train accuracy = 0.976562\n",
      "[2018-07-16 17:25:58.281758] Iteration 6000, train loss = 0.136858, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.919100\n",
      "[2018-07-16 17:26:05.615819] Iteration 6100, train loss = 0.158725, train accuracy = 0.992188\n",
      "[2018-07-16 17:26:11.286609] Iteration 6200, train loss = 0.145896, train accuracy = 0.992188\n",
      "[2018-07-16 17:26:16.950152] Iteration 6300, train loss = 0.136761, train accuracy = 1.000000\n",
      "[2018-07-16 17:26:22.597055] Iteration 6400, train loss = 0.144222, train accuracy = 1.000000\n",
      "[2018-07-16 17:26:28.269363] Iteration 6500, train loss = 0.138251, train accuracy = 1.000000\n",
      "[2018-07-16 17:26:33.936816] Iteration 6600, train loss = 0.151155, train accuracy = 0.992188\n",
      "[2018-07-16 17:26:39.599396] Iteration 6700, train loss = 0.150254, train accuracy = 0.992188\n",
      "[2018-07-16 17:26:45.270244] Iteration 6800, train loss = 0.142481, train accuracy = 0.992188\n",
      "[2018-07-16 17:26:50.900931] Iteration 6900, train loss = 0.138320, train accuracy = 0.992188\n",
      "[2018-07-16 17:26:56.542500] Iteration 7000, train loss = 0.158708, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.919600\n",
      "[2018-07-16 17:27:03.849699] Iteration 7100, train loss = 0.147188, train accuracy = 0.992188\n",
      "[2018-07-16 17:27:09.469113] Iteration 7200, train loss = 0.138317, train accuracy = 1.000000\n",
      "[2018-07-16 17:27:15.097990] Iteration 7300, train loss = 0.172253, train accuracy = 0.984375\n",
      "[2018-07-16 17:27:20.735154] Iteration 7400, train loss = 0.148173, train accuracy = 0.992188\n",
      "[2018-07-16 17:27:26.382611] Iteration 7500, train loss = 0.145337, train accuracy = 1.000000\n",
      "[2018-07-16 17:27:32.034536] Iteration 7600, train loss = 0.139793, train accuracy = 1.000000\n",
      "[2018-07-16 17:27:37.681576] Iteration 7700, train loss = 0.140952, train accuracy = 0.992188\n",
      "[2018-07-16 17:27:43.325826] Iteration 7800, train loss = 0.147820, train accuracy = 0.992188\n",
      "[2018-07-16 17:27:48.976288] Iteration 7900, train loss = 0.152199, train accuracy = 0.984375\n",
      "[2018-07-16 17:27:54.613423] Iteration 8000, train loss = 0.136254, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921100\n",
      "[2018-07-16 17:28:01.934441] Iteration 8100, train loss = 0.148273, train accuracy = 1.000000\n",
      "[2018-07-16 17:28:07.552293] Iteration 8200, train loss = 0.138317, train accuracy = 0.992188\n",
      "[2018-07-16 17:28:13.182373] Iteration 8300, train loss = 0.132887, train accuracy = 1.000000\n",
      "[2018-07-16 17:28:18.829491] Iteration 8400, train loss = 0.132909, train accuracy = 1.000000\n",
      "[2018-07-16 17:28:24.463928] Iteration 8500, train loss = 0.135115, train accuracy = 1.000000\n",
      "[2018-07-16 17:28:30.121175] Iteration 8600, train loss = 0.151733, train accuracy = 0.984375\n",
      "[2018-07-16 17:28:35.765349] Iteration 8700, train loss = 0.164974, train accuracy = 0.984375\n",
      "[2018-07-16 17:28:41.391050] Iteration 8800, train loss = 0.134727, train accuracy = 1.000000\n",
      "[2018-07-16 17:28:47.017591] Iteration 8900, train loss = 0.142281, train accuracy = 0.992188\n",
      "[2018-07-16 17:28:52.655606] Iteration 9000, train loss = 0.143886, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921000\n",
      "[2018-07-16 17:28:59.950065] Iteration 9100, train loss = 0.144985, train accuracy = 0.992188\n",
      "[2018-07-16 17:29:05.592941] Iteration 9200, train loss = 0.129910, train accuracy = 1.000000\n",
      "[2018-07-16 17:29:11.228145] Iteration 9300, train loss = 0.133096, train accuracy = 1.000000\n",
      "[2018-07-16 17:29:16.864128] Iteration 9400, train loss = 0.133728, train accuracy = 1.000000\n",
      "[2018-07-16 17:29:22.487143] Iteration 9500, train loss = 0.141151, train accuracy = 0.992188\n",
      "[2018-07-16 17:29:28.126845] Iteration 9600, train loss = 0.147582, train accuracy = 0.992188\n",
      "[2018-07-16 17:29:33.760134] Iteration 9700, train loss = 0.139589, train accuracy = 1.000000\n",
      "[2018-07-16 17:29:39.398880] Iteration 9800, train loss = 0.136429, train accuracy = 1.000000\n",
      "[2018-07-16 17:29:45.034190] Iteration 9900, train loss = 0.144333, train accuracy = 1.000000\n",
      "[2018-07-16 17:29:50.670137] Iteration 10000, train loss = 0.144600, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.923000\n",
      "[2018-07-16 17:29:57.985147] Iteration 10100, train loss = 0.145332, train accuracy = 0.992188\n",
      "[2018-07-16 17:30:03.629133] Iteration 10200, train loss = 0.141982, train accuracy = 1.000000\n",
      "[2018-07-16 17:30:09.258694] Iteration 10300, train loss = 0.146818, train accuracy = 0.992188\n",
      "[2018-07-16 17:30:14.879301] Iteration 10400, train loss = 0.139190, train accuracy = 1.000000\n",
      "[2018-07-16 17:30:20.507894] Iteration 10500, train loss = 0.134527, train accuracy = 1.000000\n",
      "[2018-07-16 17:30:26.133714] Iteration 10600, train loss = 0.145006, train accuracy = 1.000000\n",
      "[2018-07-16 17:30:31.754334] Iteration 10700, train loss = 0.129894, train accuracy = 1.000000\n",
      "[2018-07-16 17:30:37.386554] Iteration 10800, train loss = 0.135423, train accuracy = 1.000000\n",
      "[2018-07-16 17:30:43.008842] Iteration 10900, train loss = 0.132270, train accuracy = 1.000000\n",
      "[2018-07-16 17:30:48.646595] Iteration 11000, train loss = 0.134382, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 17:30:55.947968] Iteration 11100, train loss = 0.131515, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:01.576438] Iteration 11200, train loss = 0.146442, train accuracy = 0.992188\n",
      "[2018-07-16 17:31:07.202732] Iteration 11300, train loss = 0.135606, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:12.837736] Iteration 11400, train loss = 0.134618, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:18.463361] Iteration 11500, train loss = 0.133810, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:24.087788] Iteration 11600, train loss = 0.144281, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:29.718691] Iteration 11700, train loss = 0.137890, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:35.352752] Iteration 11800, train loss = 0.136201, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:40.995330] Iteration 11900, train loss = 0.137779, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:46.626867] Iteration 12000, train loss = 0.138516, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920100\n",
      "[2018-07-16 17:31:53.930916] Iteration 12100, train loss = 0.138785, train accuracy = 1.000000\n",
      "[2018-07-16 17:31:59.558191] Iteration 12200, train loss = 0.136079, train accuracy = 1.000000\n",
      "[2018-07-16 17:32:05.184826] Iteration 12300, train loss = 0.143892, train accuracy = 1.000000\n",
      "[2018-07-16 17:32:10.813265] Iteration 12400, train loss = 0.136156, train accuracy = 1.000000\n",
      "[2018-07-16 17:32:16.436932] Iteration 12500, train loss = 0.154954, train accuracy = 0.992188\n",
      "[2018-07-16 17:32:22.074217] Iteration 12600, train loss = 0.162275, train accuracy = 0.992188\n",
      "[2018-07-16 17:32:27.708012] Iteration 12700, train loss = 0.137452, train accuracy = 1.000000\n",
      "[2018-07-16 17:32:33.343782] Iteration 12800, train loss = 0.142857, train accuracy = 1.000000\n",
      "[2018-07-16 17:32:38.974449] Iteration 12900, train loss = 0.141859, train accuracy = 0.992188\n",
      "[2018-07-16 17:32:44.602026] Iteration 13000, train loss = 0.144516, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.920000\n",
      "[2018-07-16 17:32:51.919566] Iteration 13100, train loss = 0.137130, train accuracy = 1.000000\n",
      "[2018-07-16 17:32:57.546569] Iteration 13200, train loss = 0.137092, train accuracy = 1.000000\n",
      "[2018-07-16 17:33:03.176685] Iteration 13300, train loss = 0.145440, train accuracy = 0.992188\n",
      "[2018-07-16 17:33:08.799653] Iteration 13400, train loss = 0.132121, train accuracy = 1.000000\n",
      "[2018-07-16 17:33:14.426771] Iteration 13500, train loss = 0.134685, train accuracy = 1.000000\n",
      "[2018-07-16 17:33:20.054450] Iteration 13600, train loss = 0.142651, train accuracy = 1.000000\n",
      "[2018-07-16 17:33:25.707026] Iteration 13700, train loss = 0.135645, train accuracy = 1.000000\n",
      "[2018-07-16 17:33:31.346642] Iteration 13800, train loss = 0.153206, train accuracy = 0.992188\n",
      "[2018-07-16 17:33:36.988572] Iteration 13900, train loss = 0.133253, train accuracy = 1.000000\n",
      "[2018-07-16 17:33:42.623979] Iteration 14000, train loss = 0.135095, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921400\n",
      "[2018-07-16 17:33:49.923073] Iteration 14100, train loss = 0.148235, train accuracy = 0.992188\n",
      "[2018-07-16 17:33:55.563824] Iteration 14200, train loss = 0.139049, train accuracy = 1.000000\n",
      "[2018-07-16 17:34:01.200236] Iteration 14300, train loss = 0.142877, train accuracy = 0.992188\n",
      "[2018-07-16 17:34:06.829144] Iteration 14400, train loss = 0.133708, train accuracy = 1.000000\n",
      "[2018-07-16 17:34:12.451004] Iteration 14500, train loss = 0.134196, train accuracy = 1.000000\n",
      "[2018-07-16 17:34:18.082655] Iteration 14600, train loss = 0.144116, train accuracy = 0.992188\n",
      "[2018-07-16 17:34:23.716653] Iteration 14700, train loss = 0.134351, train accuracy = 1.000000\n",
      "[2018-07-16 17:34:29.351524] Iteration 14800, train loss = 0.174377, train accuracy = 0.976562\n",
      "[2018-07-16 17:34:34.988729] Iteration 14900, train loss = 0.136345, train accuracy = 0.992188\n",
      "[2018-07-16 17:34:40.613190] Iteration 15000, train loss = 0.136122, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920400\n",
      "[2018-07-16 17:34:47.928163] Iteration 15100, train loss = 0.135253, train accuracy = 1.000000\n",
      "[2018-07-16 17:34:53.554236] Iteration 15200, train loss = 0.137175, train accuracy = 1.000000\n",
      "[2018-07-16 17:34:59.192595] Iteration 15300, train loss = 0.136972, train accuracy = 1.000000\n",
      "[2018-07-16 17:35:04.822624] Iteration 15400, train loss = 0.148412, train accuracy = 0.992188\n",
      "[2018-07-16 17:35:10.459634] Iteration 15500, train loss = 0.149178, train accuracy = 0.992188\n",
      "[2018-07-16 17:35:16.099880] Iteration 15600, train loss = 0.132855, train accuracy = 1.000000\n",
      "[2018-07-16 17:35:21.731559] Iteration 15700, train loss = 0.148399, train accuracy = 1.000000\n",
      "[2018-07-16 17:35:27.365865] Iteration 15800, train loss = 0.136940, train accuracy = 1.000000\n",
      "[2018-07-16 17:35:33.002325] Iteration 15900, train loss = 0.135790, train accuracy = 1.000000\n",
      "[2018-07-16 17:35:38.635805] Iteration 16000, train loss = 0.170249, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.921900\n",
      "[2018-07-16 17:35:45.950925] Iteration 16100, train loss = 0.131906, train accuracy = 1.000000\n",
      "[2018-07-16 17:35:51.585334] Iteration 16200, train loss = 0.141460, train accuracy = 0.992188\n",
      "[2018-07-16 17:35:57.216521] Iteration 16300, train loss = 0.133532, train accuracy = 1.000000\n",
      "[2018-07-16 17:36:02.854560] Iteration 16400, train loss = 0.155112, train accuracy = 0.992188\n",
      "[2018-07-16 17:36:08.485317] Iteration 16500, train loss = 0.164444, train accuracy = 0.984375\n",
      "[2018-07-16 17:36:14.112773] Iteration 16600, train loss = 0.130595, train accuracy = 1.000000\n",
      "[2018-07-16 17:36:19.766400] Iteration 16700, train loss = 0.140313, train accuracy = 1.000000\n",
      "[2018-07-16 17:36:25.410098] Iteration 16800, train loss = 0.132267, train accuracy = 1.000000\n",
      "[2018-07-16 17:36:31.031224] Iteration 16900, train loss = 0.136896, train accuracy = 1.000000\n",
      "[2018-07-16 17:36:36.668567] Iteration 17000, train loss = 0.169913, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.920400\n",
      "[2018-07-16 17:36:43.973519] Iteration 17100, train loss = 0.142708, train accuracy = 0.992188\n",
      "[2018-07-16 17:36:49.610191] Iteration 17200, train loss = 0.150995, train accuracy = 0.992188\n",
      "[2018-07-16 17:36:55.239307] Iteration 17300, train loss = 0.146034, train accuracy = 0.992188\n",
      "[2018-07-16 17:37:00.874754] Iteration 17400, train loss = 0.134253, train accuracy = 1.000000\n",
      "[2018-07-16 17:37:06.505209] Iteration 17500, train loss = 0.138881, train accuracy = 1.000000\n",
      "[2018-07-16 17:37:12.127051] Iteration 17600, train loss = 0.157619, train accuracy = 0.992188\n",
      "[2018-07-16 17:37:17.757956] Iteration 17700, train loss = 0.156735, train accuracy = 0.992188\n",
      "[2018-07-16 17:37:23.384644] Iteration 17800, train loss = 0.150248, train accuracy = 0.984375\n",
      "[2018-07-16 17:37:29.021962] Iteration 17900, train loss = 0.133920, train accuracy = 1.000000\n",
      "[2018-07-16 17:37:34.666010] Iteration 18000, train loss = 0.140540, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921100\n",
      "[2018-07-16 17:37:41.983749] Iteration 18100, train loss = 0.157687, train accuracy = 0.984375\n",
      "[2018-07-16 17:37:47.617177] Iteration 18200, train loss = 0.135670, train accuracy = 1.000000\n",
      "[2018-07-16 17:37:53.249988] Iteration 18300, train loss = 0.139132, train accuracy = 1.000000\n",
      "[2018-07-16 17:37:58.871984] Iteration 18400, train loss = 0.137423, train accuracy = 1.000000\n",
      "[2018-07-16 17:38:04.512151] Iteration 18500, train loss = 0.144748, train accuracy = 0.992188\n",
      "[2018-07-16 17:38:10.146552] Iteration 18600, train loss = 0.152307, train accuracy = 0.992188\n",
      "[2018-07-16 17:38:15.785520] Iteration 18700, train loss = 0.140203, train accuracy = 1.000000\n",
      "[2018-07-16 17:38:21.414730] Iteration 18800, train loss = 0.154355, train accuracy = 0.976562\n",
      "[2018-07-16 17:38:27.050328] Iteration 18900, train loss = 0.169593, train accuracy = 0.984375\n",
      "[2018-07-16 17:38:32.688278] Iteration 19000, train loss = 0.140129, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 17:38:39.995107] Iteration 19100, train loss = 0.130319, train accuracy = 1.000000\n",
      "[2018-07-16 17:38:45.627982] Iteration 19200, train loss = 0.138456, train accuracy = 1.000000\n",
      "[2018-07-16 17:38:51.262459] Iteration 19300, train loss = 0.145439, train accuracy = 0.992188\n",
      "[2018-07-16 17:38:56.884249] Iteration 19400, train loss = 0.141496, train accuracy = 1.000000\n",
      "[2018-07-16 17:39:02.513467] Iteration 19500, train loss = 0.140903, train accuracy = 0.992188\n",
      "[2018-07-16 17:39:08.159872] Iteration 19600, train loss = 0.159713, train accuracy = 0.984375\n",
      "[2018-07-16 17:39:13.792443] Iteration 19700, train loss = 0.141073, train accuracy = 0.992188\n",
      "[2018-07-16 17:39:19.423708] Iteration 19800, train loss = 0.144226, train accuracy = 0.992188\n",
      "[2018-07-16 17:39:25.055407] Iteration 19900, train loss = 0.141042, train accuracy = 1.000000\n",
      "[2018-07-16 17:39:30.686070] Iteration 20000, train loss = 0.154088, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922300\n",
      "[2018-07-16 17:39:37.991712] Iteration 20100, train loss = 0.132269, train accuracy = 1.000000\n",
      "[2018-07-16 17:39:43.630712] Iteration 20200, train loss = 0.150991, train accuracy = 0.992188\n",
      "[2018-07-16 17:39:49.252715] Iteration 20300, train loss = 0.133336, train accuracy = 1.000000\n",
      "[2018-07-16 17:39:54.881465] Iteration 20400, train loss = 0.135069, train accuracy = 1.000000\n",
      "[2018-07-16 17:40:00.507602] Iteration 20500, train loss = 0.134674, train accuracy = 1.000000\n",
      "[2018-07-16 17:40:06.153009] Iteration 20600, train loss = 0.132141, train accuracy = 1.000000\n",
      "[2018-07-16 17:40:11.800198] Iteration 20700, train loss = 0.166541, train accuracy = 0.976562\n",
      "[2018-07-16 17:40:17.437114] Iteration 20800, train loss = 0.139668, train accuracy = 1.000000\n",
      "[2018-07-16 17:40:23.071472] Iteration 20900, train loss = 0.135939, train accuracy = 1.000000\n",
      "[2018-07-16 17:40:28.692853] Iteration 21000, train loss = 0.133491, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921200\n",
      "[2018-07-16 17:40:36.092330] Iteration 21100, train loss = 0.135000, train accuracy = 1.000000\n",
      "[2018-07-16 17:40:41.732531] Iteration 21200, train loss = 0.160085, train accuracy = 0.984375\n",
      "[2018-07-16 17:40:47.364350] Iteration 21300, train loss = 0.160573, train accuracy = 0.992188\n",
      "[2018-07-16 17:40:53.003755] Iteration 21400, train loss = 0.157686, train accuracy = 0.984375\n",
      "[2018-07-16 17:40:58.634932] Iteration 21500, train loss = 0.134759, train accuracy = 1.000000\n",
      "[2018-07-16 17:41:04.265536] Iteration 21600, train loss = 0.131605, train accuracy = 1.000000\n",
      "[2018-07-16 17:41:09.904960] Iteration 21700, train loss = 0.156797, train accuracy = 1.000000\n",
      "[2018-07-16 17:41:15.542416] Iteration 21800, train loss = 0.142693, train accuracy = 0.992188\n",
      "[2018-07-16 17:41:21.181734] Iteration 21900, train loss = 0.135540, train accuracy = 1.000000\n",
      "[2018-07-16 17:41:26.810570] Iteration 22000, train loss = 0.131731, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920200\n",
      "[2018-07-16 17:41:34.124399] Iteration 22100, train loss = 0.152929, train accuracy = 0.992188\n",
      "[2018-07-16 17:41:39.756419] Iteration 22200, train loss = 0.162649, train accuracy = 0.984375\n",
      "[2018-07-16 17:41:45.390418] Iteration 22300, train loss = 0.131659, train accuracy = 1.000000\n",
      "[2018-07-16 17:41:51.014383] Iteration 22400, train loss = 0.136488, train accuracy = 1.000000\n",
      "[2018-07-16 17:41:56.647577] Iteration 22500, train loss = 0.130758, train accuracy = 1.000000\n",
      "[2018-07-16 17:42:02.269630] Iteration 22600, train loss = 0.146570, train accuracy = 0.992188\n",
      "[2018-07-16 17:42:07.903186] Iteration 22700, train loss = 0.145390, train accuracy = 0.992188\n",
      "[2018-07-16 17:42:13.525715] Iteration 22800, train loss = 0.130388, train accuracy = 1.000000\n",
      "[2018-07-16 17:42:19.150765] Iteration 22900, train loss = 0.149265, train accuracy = 0.992188\n",
      "[2018-07-16 17:42:24.779438] Iteration 23000, train loss = 0.136497, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921200\n",
      "[2018-07-16 17:42:32.083968] Iteration 23100, train loss = 0.138612, train accuracy = 1.000000\n",
      "[2018-07-16 17:42:37.713541] Iteration 23200, train loss = 0.144382, train accuracy = 0.992188\n",
      "[2018-07-16 17:42:43.350419] Iteration 23300, train loss = 0.146699, train accuracy = 1.000000\n",
      "[2018-07-16 17:42:48.977579] Iteration 23400, train loss = 0.141994, train accuracy = 1.000000\n",
      "[2018-07-16 17:42:54.602666] Iteration 23500, train loss = 0.139843, train accuracy = 0.992188\n",
      "[2018-07-16 17:43:00.236223] Iteration 23600, train loss = 0.140931, train accuracy = 1.000000\n",
      "[2018-07-16 17:43:05.859140] Iteration 23700, train loss = 0.154996, train accuracy = 0.984375\n",
      "[2018-07-16 17:43:11.477170] Iteration 23800, train loss = 0.139214, train accuracy = 1.000000\n",
      "[2018-07-16 17:43:17.110350] Iteration 23900, train loss = 0.151014, train accuracy = 0.984375\n",
      "[2018-07-16 17:43:22.732853] Iteration 24000, train loss = 0.143273, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 17:43:30.037914] Iteration 24100, train loss = 0.134694, train accuracy = 1.000000\n",
      "[2018-07-16 17:43:35.682805] Iteration 24200, train loss = 0.132559, train accuracy = 1.000000\n",
      "[2018-07-16 17:43:41.309484] Iteration 24300, train loss = 0.141630, train accuracy = 1.000000\n",
      "[2018-07-16 17:43:46.950130] Iteration 24400, train loss = 0.147747, train accuracy = 0.992188\n",
      "[2018-07-16 17:43:52.578117] Iteration 24500, train loss = 0.180082, train accuracy = 0.976562\n",
      "[2018-07-16 17:43:58.209236] Iteration 24600, train loss = 0.139131, train accuracy = 1.000000\n",
      "[2018-07-16 17:44:03.828047] Iteration 24700, train loss = 0.135131, train accuracy = 1.000000\n",
      "[2018-07-16 17:44:09.457543] Iteration 24800, train loss = 0.133196, train accuracy = 1.000000\n",
      "[2018-07-16 17:44:15.087547] Iteration 24900, train loss = 0.137476, train accuracy = 0.992188\n",
      "[2018-07-16 17:44:20.732004] Iteration 25000, train loss = 0.148050, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921200\n",
      "[2018-07-16 17:44:28.036892] Iteration 25100, train loss = 0.137091, train accuracy = 1.000000\n",
      "[2018-07-16 17:44:33.672855] Iteration 25200, train loss = 0.144510, train accuracy = 0.992188\n",
      "[2018-07-16 17:44:39.295026] Iteration 25300, train loss = 0.147988, train accuracy = 0.992188\n",
      "[2018-07-16 17:44:44.949125] Iteration 25400, train loss = 0.143164, train accuracy = 0.992188\n",
      "[2018-07-16 17:44:50.580572] Iteration 25500, train loss = 0.133306, train accuracy = 1.000000\n",
      "[2018-07-16 17:44:56.210985] Iteration 25600, train loss = 0.140573, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:01.831896] Iteration 25700, train loss = 0.138591, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:07.464310] Iteration 25800, train loss = 0.130999, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:13.087162] Iteration 25900, train loss = 0.147739, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:18.721298] Iteration 26000, train loss = 0.145318, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 17:45:26.021577] Iteration 26100, train loss = 0.130328, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:31.647054] Iteration 26200, train loss = 0.135758, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:37.287719] Iteration 26300, train loss = 0.133470, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:42.915559] Iteration 26400, train loss = 0.138642, train accuracy = 0.992188\n",
      "[2018-07-16 17:45:48.542695] Iteration 26500, train loss = 0.134610, train accuracy = 1.000000\n",
      "[2018-07-16 17:45:54.165342] Iteration 26600, train loss = 0.153921, train accuracy = 0.984375\n",
      "[2018-07-16 17:45:59.805825] Iteration 26700, train loss = 0.144748, train accuracy = 0.992188\n",
      "[2018-07-16 17:46:05.441493] Iteration 26800, train loss = 0.132032, train accuracy = 1.000000\n",
      "[2018-07-16 17:46:11.079527] Iteration 26900, train loss = 0.141584, train accuracy = 0.992188\n",
      "[2018-07-16 17:46:16.708714] Iteration 27000, train loss = 0.132148, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.919700\n",
      "[2018-07-16 17:46:24.020134] Iteration 27100, train loss = 0.145508, train accuracy = 1.000000\n",
      "[2018-07-16 17:46:29.649363] Iteration 27200, train loss = 0.139176, train accuracy = 1.000000\n",
      "[2018-07-16 17:46:35.277673] Iteration 27300, train loss = 0.132175, train accuracy = 1.000000\n",
      "[2018-07-16 17:46:40.903882] Iteration 27400, train loss = 0.133678, train accuracy = 1.000000\n",
      "[2018-07-16 17:46:46.532084] Iteration 27500, train loss = 0.163542, train accuracy = 0.992188\n",
      "[2018-07-16 17:46:52.171291] Iteration 27600, train loss = 0.142061, train accuracy = 0.992188\n",
      "[2018-07-16 17:46:57.796949] Iteration 27700, train loss = 0.142795, train accuracy = 0.992188\n",
      "[2018-07-16 17:47:03.440694] Iteration 27800, train loss = 0.163520, train accuracy = 0.984375\n",
      "[2018-07-16 17:47:09.068978] Iteration 27900, train loss = 0.133541, train accuracy = 1.000000\n",
      "[2018-07-16 17:47:14.693333] Iteration 28000, train loss = 0.139341, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921200\n",
      "[2018-07-16 17:47:22.006292] Iteration 28100, train loss = 0.134952, train accuracy = 1.000000\n",
      "[2018-07-16 17:47:27.643843] Iteration 28200, train loss = 0.136147, train accuracy = 1.000000\n",
      "[2018-07-16 17:47:33.280900] Iteration 28300, train loss = 0.134109, train accuracy = 1.000000\n",
      "[2018-07-16 17:47:38.913204] Iteration 28400, train loss = 0.144623, train accuracy = 0.992188\n",
      "[2018-07-16 17:47:44.546318] Iteration 28500, train loss = 0.164317, train accuracy = 0.984375\n",
      "[2018-07-16 17:47:50.178726] Iteration 28600, train loss = 0.133682, train accuracy = 1.000000\n",
      "[2018-07-16 17:47:55.808687] Iteration 28700, train loss = 0.132856, train accuracy = 1.000000\n",
      "[2018-07-16 17:48:01.435772] Iteration 28800, train loss = 0.129702, train accuracy = 1.000000\n",
      "[2018-07-16 17:48:07.064457] Iteration 28900, train loss = 0.151290, train accuracy = 0.992188\n",
      "[2018-07-16 17:48:12.700709] Iteration 29000, train loss = 0.129935, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921100\n",
      "[2018-07-16 17:48:20.002055] Iteration 29100, train loss = 0.176004, train accuracy = 0.992188\n",
      "[2018-07-16 17:48:25.645248] Iteration 29200, train loss = 0.138778, train accuracy = 0.992188\n",
      "[2018-07-16 17:48:31.277496] Iteration 29300, train loss = 0.149047, train accuracy = 0.992188\n",
      "[2018-07-16 17:48:36.923801] Iteration 29400, train loss = 0.151197, train accuracy = 0.992188\n",
      "[2018-07-16 17:48:42.551326] Iteration 29500, train loss = 0.135735, train accuracy = 1.000000\n",
      "[2018-07-16 17:48:48.189698] Iteration 29600, train loss = 0.133643, train accuracy = 1.000000\n",
      "[2018-07-16 17:48:53.828517] Iteration 29700, train loss = 0.136015, train accuracy = 1.000000\n",
      "[2018-07-16 17:48:59.444378] Iteration 29800, train loss = 0.134005, train accuracy = 1.000000\n",
      "[2018-07-16 17:49:05.090390] Iteration 29900, train loss = 0.142045, train accuracy = 0.992188\n",
      "[2018-07-16 17:49:10.725051] Iteration 30000, train loss = 0.140194, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920600\n",
      "[2018-07-16 17:49:18.041307] Iteration 30100, train loss = 0.130746, train accuracy = 1.000000\n",
      "[2018-07-16 17:49:23.678472] Iteration 30200, train loss = 0.141687, train accuracy = 1.000000\n",
      "[2018-07-16 17:49:29.315778] Iteration 30300, train loss = 0.138261, train accuracy = 0.992188\n",
      "[2018-07-16 17:49:34.950213] Iteration 30400, train loss = 0.134631, train accuracy = 1.000000\n",
      "[2018-07-16 17:49:40.591115] Iteration 30500, train loss = 0.141235, train accuracy = 1.000000\n",
      "[2018-07-16 17:49:46.222441] Iteration 30600, train loss = 0.139350, train accuracy = 1.000000\n",
      "[2018-07-16 17:49:51.867787] Iteration 30700, train loss = 0.133033, train accuracy = 1.000000\n",
      "[2018-07-16 17:49:57.501529] Iteration 30800, train loss = 0.136964, train accuracy = 1.000000\n",
      "[2018-07-16 17:50:03.146002] Iteration 30900, train loss = 0.143019, train accuracy = 1.000000\n",
      "[2018-07-16 17:50:08.788509] Iteration 31000, train loss = 0.142162, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 17:50:16.110173] Iteration 31100, train loss = 0.137971, train accuracy = 1.000000\n",
      "[2018-07-16 17:50:21.741289] Iteration 31200, train loss = 0.131371, train accuracy = 1.000000\n",
      "[2018-07-16 17:50:27.385613] Iteration 31300, train loss = 0.153074, train accuracy = 0.992188\n",
      "[2018-07-16 17:50:33.012760] Iteration 31400, train loss = 0.152360, train accuracy = 0.992188\n",
      "[2018-07-16 17:50:38.648789] Iteration 31500, train loss = 0.131547, train accuracy = 1.000000\n",
      "[2018-07-16 17:50:44.280533] Iteration 31600, train loss = 0.162744, train accuracy = 0.984375\n",
      "[2018-07-16 17:50:49.905262] Iteration 31700, train loss = 0.157170, train accuracy = 0.992188\n",
      "[2018-07-16 17:50:55.532706] Iteration 31800, train loss = 0.146833, train accuracy = 0.992188\n",
      "[2018-07-16 17:51:01.159237] Iteration 31900, train loss = 0.137184, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:06.799418] Iteration 32000, train loss = 0.140614, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921100\n",
      "[2018-07-16 17:51:14.133731] Iteration 32100, train loss = 0.133410, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:19.772575] Iteration 32200, train loss = 0.139112, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:25.413563] Iteration 32300, train loss = 0.140634, train accuracy = 0.992188\n",
      "[2018-07-16 17:51:31.040541] Iteration 32400, train loss = 0.134991, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:36.672292] Iteration 32500, train loss = 0.140289, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:42.305970] Iteration 32600, train loss = 0.135079, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:47.931593] Iteration 32700, train loss = 0.144706, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:53.559138] Iteration 32800, train loss = 0.137780, train accuracy = 1.000000\n",
      "[2018-07-16 17:51:59.199913] Iteration 32900, train loss = 0.158786, train accuracy = 0.992188\n",
      "[2018-07-16 17:52:04.827603] Iteration 33000, train loss = 0.133028, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 17:52:12.246839] Iteration 33100, train loss = 0.137805, train accuracy = 1.000000\n",
      "[2018-07-16 17:52:17.895034] Iteration 33200, train loss = 0.132623, train accuracy = 1.000000\n",
      "[2018-07-16 17:52:23.532232] Iteration 33300, train loss = 0.134006, train accuracy = 1.000000\n",
      "[2018-07-16 17:52:29.167741] Iteration 33400, train loss = 0.152499, train accuracy = 0.984375\n",
      "[2018-07-16 17:52:34.801724] Iteration 33500, train loss = 0.131379, train accuracy = 1.000000\n",
      "[2018-07-16 17:52:40.435221] Iteration 33600, train loss = 0.138288, train accuracy = 1.000000\n",
      "[2018-07-16 17:52:46.065820] Iteration 33700, train loss = 0.136517, train accuracy = 1.000000\n",
      "[2018-07-16 17:52:51.707206] Iteration 33800, train loss = 0.130645, train accuracy = 1.000000\n",
      "[2018-07-16 17:52:57.339339] Iteration 33900, train loss = 0.131489, train accuracy = 1.000000\n",
      "[2018-07-16 17:53:02.959964] Iteration 34000, train loss = 0.169065, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.920400\n",
      "[2018-07-16 17:53:10.253690] Iteration 34100, train loss = 0.130196, train accuracy = 1.000000\n",
      "[2018-07-16 17:53:15.898026] Iteration 34200, train loss = 0.138941, train accuracy = 1.000000\n",
      "[2018-07-16 17:53:21.532093] Iteration 34300, train loss = 0.145996, train accuracy = 0.992188\n",
      "[2018-07-16 17:53:27.161784] Iteration 34400, train loss = 0.144282, train accuracy = 0.992188\n",
      "[2018-07-16 17:53:32.808714] Iteration 34500, train loss = 0.144298, train accuracy = 1.000000\n",
      "[2018-07-16 17:53:38.438557] Iteration 34600, train loss = 0.137300, train accuracy = 1.000000\n",
      "[2018-07-16 17:53:44.074658] Iteration 34700, train loss = 0.133600, train accuracy = 1.000000\n",
      "[2018-07-16 17:53:49.709144] Iteration 34800, train loss = 0.131183, train accuracy = 1.000000\n",
      "[2018-07-16 17:53:55.343634] Iteration 34900, train loss = 0.150815, train accuracy = 0.992188\n",
      "[2018-07-16 17:54:00.974699] Iteration 35000, train loss = 0.145543, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 17:54:08.301850] Iteration 35100, train loss = 0.134339, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:13.962290] Iteration 35200, train loss = 0.132758, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:19.597709] Iteration 35300, train loss = 0.138144, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:25.218994] Iteration 35400, train loss = 0.137203, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:30.861724] Iteration 35500, train loss = 0.147616, train accuracy = 0.992188\n",
      "[2018-07-16 17:54:36.502453] Iteration 35600, train loss = 0.135918, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:42.132614] Iteration 35700, train loss = 0.133820, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:47.764687] Iteration 35800, train loss = 0.137603, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:53.401566] Iteration 35900, train loss = 0.138333, train accuracy = 1.000000\n",
      "[2018-07-16 17:54:59.042046] Iteration 36000, train loss = 0.136206, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.919900\n",
      "[2018-07-16 17:55:06.355823] Iteration 36100, train loss = 0.155586, train accuracy = 0.992188\n",
      "[2018-07-16 17:55:11.992580] Iteration 36200, train loss = 0.139745, train accuracy = 1.000000\n",
      "[2018-07-16 17:55:17.624884] Iteration 36300, train loss = 0.138621, train accuracy = 1.000000\n",
      "[2018-07-16 17:55:23.270310] Iteration 36400, train loss = 0.134580, train accuracy = 1.000000\n",
      "[2018-07-16 17:55:28.916789] Iteration 36500, train loss = 0.133543, train accuracy = 1.000000\n",
      "[2018-07-16 17:55:34.551752] Iteration 36600, train loss = 0.136790, train accuracy = 1.000000\n",
      "[2018-07-16 17:55:40.180046] Iteration 36700, train loss = 0.154681, train accuracy = 0.992188\n",
      "[2018-07-16 17:55:45.824563] Iteration 36800, train loss = 0.133884, train accuracy = 1.000000\n",
      "[2018-07-16 17:55:51.457522] Iteration 36900, train loss = 0.135090, train accuracy = 1.000000\n",
      "[2018-07-16 17:55:57.097736] Iteration 37000, train loss = 0.134269, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922500\n",
      "[2018-07-16 17:56:04.407194] Iteration 37100, train loss = 0.133139, train accuracy = 1.000000\n",
      "[2018-07-16 17:56:10.024405] Iteration 37200, train loss = 0.134788, train accuracy = 1.000000\n",
      "[2018-07-16 17:56:15.654093] Iteration 37300, train loss = 0.135335, train accuracy = 1.000000\n",
      "[2018-07-16 17:56:21.288799] Iteration 37400, train loss = 0.134636, train accuracy = 1.000000\n",
      "[2018-07-16 17:56:26.929356] Iteration 37500, train loss = 0.138299, train accuracy = 1.000000\n",
      "[2018-07-16 17:56:32.558659] Iteration 37600, train loss = 0.144346, train accuracy = 0.992188\n",
      "[2018-07-16 17:56:38.198219] Iteration 37700, train loss = 0.133521, train accuracy = 1.000000\n",
      "[2018-07-16 17:56:43.844607] Iteration 37800, train loss = 0.143243, train accuracy = 0.992188\n",
      "[2018-07-16 17:56:49.490590] Iteration 37900, train loss = 0.133860, train accuracy = 1.000000\n",
      "[2018-07-16 17:56:55.126054] Iteration 38000, train loss = 0.133500, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922600\n",
      "[2018-07-16 17:57:02.438932] Iteration 38100, train loss = 0.148395, train accuracy = 0.992188\n",
      "[2018-07-16 17:57:08.092871] Iteration 38200, train loss = 0.130868, train accuracy = 1.000000\n",
      "[2018-07-16 17:57:13.751132] Iteration 38300, train loss = 0.144754, train accuracy = 0.992188\n",
      "[2018-07-16 17:57:19.391379] Iteration 38400, train loss = 0.138698, train accuracy = 1.000000\n",
      "[2018-07-16 17:57:25.017286] Iteration 38500, train loss = 0.135407, train accuracy = 1.000000\n",
      "[2018-07-16 17:57:30.663297] Iteration 38600, train loss = 0.132535, train accuracy = 1.000000\n",
      "[2018-07-16 17:57:36.285726] Iteration 38700, train loss = 0.136246, train accuracy = 1.000000\n",
      "[2018-07-16 17:57:41.916764] Iteration 38800, train loss = 0.150409, train accuracy = 0.992188\n",
      "[2018-07-16 17:57:47.562641] Iteration 38900, train loss = 0.172810, train accuracy = 0.984375\n",
      "[2018-07-16 17:57:53.198007] Iteration 39000, train loss = 0.134397, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.919400\n",
      "[2018-07-16 17:58:00.512072] Iteration 39100, train loss = 0.135433, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:06.153830] Iteration 39200, train loss = 0.134759, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:11.783598] Iteration 39300, train loss = 0.131722, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:17.416609] Iteration 39400, train loss = 0.131359, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:23.049875] Iteration 39500, train loss = 0.133004, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:28.668768] Iteration 39600, train loss = 0.146499, train accuracy = 0.992188\n",
      "[2018-07-16 17:58:34.313556] Iteration 39700, train loss = 0.129743, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:39.939658] Iteration 39800, train loss = 0.145381, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:45.579629] Iteration 39900, train loss = 0.136455, train accuracy = 1.000000\n",
      "[2018-07-16 17:58:51.209287] Iteration 40000, train loss = 0.129799, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920700\n",
      "[2018-07-16 17:58:58.528340] Iteration 40100, train loss = 0.144317, train accuracy = 1.000000\n",
      "[2018-07-16 17:59:04.172660] Iteration 40200, train loss = 0.151761, train accuracy = 0.992188\n",
      "[2018-07-16 17:59:09.809622] Iteration 40300, train loss = 0.161658, train accuracy = 0.992188\n",
      "[2018-07-16 17:59:15.437474] Iteration 40400, train loss = 0.134247, train accuracy = 1.000000\n",
      "[2018-07-16 17:59:21.065553] Iteration 40500, train loss = 0.145289, train accuracy = 0.992188\n",
      "[2018-07-16 17:59:26.705025] Iteration 40600, train loss = 0.136081, train accuracy = 1.000000\n",
      "[2018-07-16 17:59:32.367064] Iteration 40700, train loss = 0.135695, train accuracy = 1.000000\n",
      "[2018-07-16 17:59:38.010930] Iteration 40800, train loss = 0.132399, train accuracy = 1.000000\n",
      "[2018-07-16 17:59:43.649450] Iteration 40900, train loss = 0.150546, train accuracy = 0.984375\n",
      "[2018-07-16 17:59:49.270808] Iteration 41000, train loss = 0.136851, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 17:59:56.562990] Iteration 41100, train loss = 0.137654, train accuracy = 1.000000\n",
      "[2018-07-16 18:00:02.188763] Iteration 41200, train loss = 0.133354, train accuracy = 1.000000\n",
      "[2018-07-16 18:00:07.813440] Iteration 41300, train loss = 0.137391, train accuracy = 1.000000\n",
      "[2018-07-16 18:00:13.443718] Iteration 41400, train loss = 0.134615, train accuracy = 1.000000\n",
      "[2018-07-16 18:00:19.076320] Iteration 41500, train loss = 0.141529, train accuracy = 0.992188\n",
      "[2018-07-16 18:00:24.705920] Iteration 41600, train loss = 0.144692, train accuracy = 0.992188\n",
      "[2018-07-16 18:00:30.334932] Iteration 41700, train loss = 0.134561, train accuracy = 1.000000\n",
      "[2018-07-16 18:00:35.978362] Iteration 41800, train loss = 0.133916, train accuracy = 1.000000\n",
      "[2018-07-16 18:00:41.614423] Iteration 41900, train loss = 0.133871, train accuracy = 1.000000\n",
      "[2018-07-16 18:00:47.238759] Iteration 42000, train loss = 0.133121, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921500\n",
      "[2018-07-16 18:00:54.542181] Iteration 42100, train loss = 0.134176, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:00.174575] Iteration 42200, train loss = 0.135845, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:05.802347] Iteration 42300, train loss = 0.140584, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:11.435941] Iteration 42400, train loss = 0.137152, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:17.070509] Iteration 42500, train loss = 0.133263, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:22.713412] Iteration 42600, train loss = 0.139393, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:28.364711] Iteration 42700, train loss = 0.148705, train accuracy = 0.992188\n",
      "[2018-07-16 18:01:33.996119] Iteration 42800, train loss = 0.153308, train accuracy = 0.984375\n",
      "[2018-07-16 18:01:39.620452] Iteration 42900, train loss = 0.133160, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:45.256728] Iteration 43000, train loss = 0.136578, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.919800\n",
      "[2018-07-16 18:01:52.576595] Iteration 43100, train loss = 0.132281, train accuracy = 1.000000\n",
      "[2018-07-16 18:01:58.219461] Iteration 43200, train loss = 0.136688, train accuracy = 1.000000\n",
      "[2018-07-16 18:02:03.864291] Iteration 43300, train loss = 0.135845, train accuracy = 1.000000\n",
      "[2018-07-16 18:02:09.498854] Iteration 43400, train loss = 0.172758, train accuracy = 0.984375\n",
      "[2018-07-16 18:02:15.121204] Iteration 43500, train loss = 0.158432, train accuracy = 0.992188\n",
      "[2018-07-16 18:02:20.761792] Iteration 43600, train loss = 0.135459, train accuracy = 1.000000\n",
      "[2018-07-16 18:02:26.401806] Iteration 43700, train loss = 0.141793, train accuracy = 0.992188\n",
      "[2018-07-16 18:02:32.030180] Iteration 43800, train loss = 0.169610, train accuracy = 0.984375\n",
      "[2018-07-16 18:02:37.668890] Iteration 43900, train loss = 0.166742, train accuracy = 0.992188\n",
      "[2018-07-16 18:02:43.315895] Iteration 44000, train loss = 0.133063, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 18:02:50.624784] Iteration 44100, train loss = 0.138292, train accuracy = 1.000000\n",
      "[2018-07-16 18:02:56.269984] Iteration 44200, train loss = 0.137294, train accuracy = 1.000000\n",
      "[2018-07-16 18:03:01.911386] Iteration 44300, train loss = 0.139402, train accuracy = 1.000000\n",
      "[2018-07-16 18:03:07.542373] Iteration 44400, train loss = 0.132710, train accuracy = 1.000000\n",
      "[2018-07-16 18:03:13.182673] Iteration 44500, train loss = 0.135862, train accuracy = 1.000000\n",
      "[2018-07-16 18:03:18.826461] Iteration 44600, train loss = 0.146264, train accuracy = 0.992188\n",
      "[2018-07-16 18:03:24.463096] Iteration 44700, train loss = 0.145747, train accuracy = 1.000000\n",
      "[2018-07-16 18:03:30.106624] Iteration 44800, train loss = 0.135159, train accuracy = 1.000000\n",
      "[2018-07-16 18:03:35.746505] Iteration 44900, train loss = 0.146052, train accuracy = 0.992188\n",
      "[2018-07-16 18:03:41.377303] Iteration 45000, train loss = 0.155437, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.919600\n",
      "[2018-07-16 18:03:48.670891] Iteration 45100, train loss = 0.147460, train accuracy = 0.992188\n",
      "[2018-07-16 18:03:54.301567] Iteration 45200, train loss = 0.137713, train accuracy = 1.000000\n",
      "[2018-07-16 18:03:59.935533] Iteration 45300, train loss = 0.133321, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:05.581418] Iteration 45400, train loss = 0.135379, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:11.205476] Iteration 45500, train loss = 0.136133, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:16.838632] Iteration 45600, train loss = 0.139722, train accuracy = 0.992188\n",
      "[2018-07-16 18:04:22.477863] Iteration 45700, train loss = 0.134282, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:28.107423] Iteration 45800, train loss = 0.132155, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:33.735155] Iteration 45900, train loss = 0.129628, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:39.361327] Iteration 46000, train loss = 0.131696, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921000\n",
      "[2018-07-16 18:04:46.674145] Iteration 46100, train loss = 0.140058, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:52.302842] Iteration 46200, train loss = 0.132522, train accuracy = 1.000000\n",
      "[2018-07-16 18:04:57.927016] Iteration 46300, train loss = 0.141154, train accuracy = 0.992188\n",
      "[2018-07-16 18:05:03.555343] Iteration 46400, train loss = 0.136788, train accuracy = 1.000000\n",
      "[2018-07-16 18:05:09.199189] Iteration 46500, train loss = 0.135035, train accuracy = 1.000000\n",
      "[2018-07-16 18:05:14.825756] Iteration 46600, train loss = 0.132944, train accuracy = 1.000000\n",
      "[2018-07-16 18:05:20.455311] Iteration 46700, train loss = 0.137694, train accuracy = 1.000000\n",
      "[2018-07-16 18:05:26.080706] Iteration 46800, train loss = 0.138942, train accuracy = 1.000000\n",
      "[2018-07-16 18:05:31.714054] Iteration 46900, train loss = 0.149790, train accuracy = 0.992188\n",
      "[2018-07-16 18:05:37.348732] Iteration 47000, train loss = 0.133146, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 18:05:44.665301] Iteration 47100, train loss = 0.148862, train accuracy = 0.992188\n",
      "[2018-07-16 18:05:50.290529] Iteration 47200, train loss = 0.134532, train accuracy = 1.000000\n",
      "[2018-07-16 18:05:55.909571] Iteration 47300, train loss = 0.135039, train accuracy = 1.000000\n",
      "[2018-07-16 18:06:01.539715] Iteration 47400, train loss = 0.138341, train accuracy = 1.000000\n",
      "[2018-07-16 18:06:07.176486] Iteration 47500, train loss = 0.133092, train accuracy = 1.000000\n",
      "[2018-07-16 18:06:12.803561] Iteration 47600, train loss = 0.136191, train accuracy = 1.000000\n",
      "[2018-07-16 18:06:18.437715] Iteration 47700, train loss = 0.138107, train accuracy = 1.000000\n",
      "[2018-07-16 18:06:24.064603] Iteration 47800, train loss = 0.140441, train accuracy = 0.992188\n",
      "[2018-07-16 18:06:29.707968] Iteration 47900, train loss = 0.146118, train accuracy = 0.992188\n",
      "[2018-07-16 18:06:35.335855] Iteration 48000, train loss = 0.148472, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-16 18:06:42.650379] Iteration 48100, train loss = 0.145427, train accuracy = 0.992188\n",
      "[2018-07-16 18:06:48.294728] Iteration 48200, train loss = 0.135702, train accuracy = 1.000000\n",
      "[2018-07-16 18:06:53.930617] Iteration 48300, train loss = 0.148890, train accuracy = 0.992188\n",
      "[2018-07-16 18:06:59.571870] Iteration 48400, train loss = 0.129697, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:05.210850] Iteration 48500, train loss = 0.132554, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:10.844609] Iteration 48600, train loss = 0.143063, train accuracy = 0.992188\n",
      "[2018-07-16 18:07:16.480367] Iteration 48700, train loss = 0.134921, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:22.133440] Iteration 48800, train loss = 0.131782, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:27.759545] Iteration 48900, train loss = 0.130332, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:33.392964] Iteration 49000, train loss = 0.136207, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923200\n",
      "[2018-07-16 18:07:40.698840] Iteration 49100, train loss = 0.137680, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:46.330753] Iteration 49200, train loss = 0.136805, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:51.961016] Iteration 49300, train loss = 0.137326, train accuracy = 1.000000\n",
      "[2018-07-16 18:07:57.593013] Iteration 49400, train loss = 0.164388, train accuracy = 0.992188\n",
      "[2018-07-16 18:08:03.220263] Iteration 49500, train loss = 0.152829, train accuracy = 0.992188\n",
      "[2018-07-16 18:08:08.849530] Iteration 49600, train loss = 0.133154, train accuracy = 1.000000\n",
      "[2018-07-16 18:08:14.475253] Iteration 49700, train loss = 0.132000, train accuracy = 1.000000\n",
      "[2018-07-16 18:08:20.102942] Iteration 49800, train loss = 0.135752, train accuracy = 1.000000\n",
      "[2018-07-16 18:08:25.738014] Iteration 49900, train loss = 0.147679, train accuracy = 0.992188\n",
      "[2018-07-16 18:08:31.368402] Iteration 50000, train loss = 0.148337, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.923400\n",
      "[2018-07-16 18:08:38.673118] Iteration 50100, train loss = 0.138207, train accuracy = 1.000000\n",
      "[2018-07-16 18:08:44.300701] Iteration 50200, train loss = 0.132760, train accuracy = 1.000000\n",
      "[2018-07-16 18:08:49.934860] Iteration 50300, train loss = 0.151359, train accuracy = 0.992188\n",
      "[2018-07-16 18:08:55.572208] Iteration 50400, train loss = 0.133943, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:01.199975] Iteration 50500, train loss = 0.136418, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:06.844463] Iteration 50600, train loss = 0.137685, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:12.487654] Iteration 50700, train loss = 0.137439, train accuracy = 0.992188\n",
      "[2018-07-16 18:09:18.130449] Iteration 50800, train loss = 0.136114, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:23.766224] Iteration 50900, train loss = 0.139787, train accuracy = 0.992188\n",
      "[2018-07-16 18:09:29.404041] Iteration 51000, train loss = 0.138147, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923300\n",
      "[2018-07-16 18:09:36.706673] Iteration 51100, train loss = 0.139607, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:42.354297] Iteration 51200, train loss = 0.132882, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:47.992230] Iteration 51300, train loss = 0.136951, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:53.642641] Iteration 51400, train loss = 0.137611, train accuracy = 1.000000\n",
      "[2018-07-16 18:09:59.268804] Iteration 51500, train loss = 0.142144, train accuracy = 0.992188\n",
      "[2018-07-16 18:10:04.895133] Iteration 51600, train loss = 0.136276, train accuracy = 1.000000\n",
      "[2018-07-16 18:10:10.533113] Iteration 51700, train loss = 0.140366, train accuracy = 0.992188\n",
      "[2018-07-16 18:10:16.162295] Iteration 51800, train loss = 0.134272, train accuracy = 1.000000\n",
      "[2018-07-16 18:10:21.790226] Iteration 51900, train loss = 0.148613, train accuracy = 0.984375\n",
      "[2018-07-16 18:10:27.419261] Iteration 52000, train loss = 0.133872, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923000\n",
      "[2018-07-16 18:10:34.742951] Iteration 52100, train loss = 0.136875, train accuracy = 1.000000\n",
      "[2018-07-16 18:10:40.385085] Iteration 52200, train loss = 0.147249, train accuracy = 1.000000\n",
      "[2018-07-16 18:10:46.014366] Iteration 52300, train loss = 0.134142, train accuracy = 1.000000\n",
      "[2018-07-16 18:10:51.635303] Iteration 52400, train loss = 0.133181, train accuracy = 1.000000\n",
      "[2018-07-16 18:10:57.266768] Iteration 52500, train loss = 0.135001, train accuracy = 1.000000\n",
      "[2018-07-16 18:11:02.901697] Iteration 52600, train loss = 0.136745, train accuracy = 1.000000\n",
      "[2018-07-16 18:11:08.537753] Iteration 52700, train loss = 0.142254, train accuracy = 0.992188\n",
      "[2018-07-16 18:11:14.168585] Iteration 52800, train loss = 0.134161, train accuracy = 1.000000\n",
      "[2018-07-16 18:11:19.796702] Iteration 52900, train loss = 0.132892, train accuracy = 1.000000\n",
      "[2018-07-16 18:11:25.422817] Iteration 53000, train loss = 0.133533, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 18:11:32.739325] Iteration 53100, train loss = 0.139723, train accuracy = 0.992188\n",
      "[2018-07-16 18:11:38.378584] Iteration 53200, train loss = 0.130403, train accuracy = 1.000000\n",
      "[2018-07-16 18:11:44.002861] Iteration 53300, train loss = 0.151194, train accuracy = 0.984375\n",
      "[2018-07-16 18:11:49.643824] Iteration 53400, train loss = 0.129839, train accuracy = 1.000000\n",
      "[2018-07-16 18:11:55.281305] Iteration 53500, train loss = 0.131451, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:00.925022] Iteration 53600, train loss = 0.141306, train accuracy = 0.992188\n",
      "[2018-07-16 18:12:06.548507] Iteration 53700, train loss = 0.134454, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:12.182347] Iteration 53800, train loss = 0.130529, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:17.821390] Iteration 53900, train loss = 0.131106, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:23.450335] Iteration 54000, train loss = 0.142499, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922400\n",
      "[2018-07-16 18:12:30.760467] Iteration 54100, train loss = 0.137854, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:36.392909] Iteration 54200, train loss = 0.131381, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:42.030297] Iteration 54300, train loss = 0.136734, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:47.660128] Iteration 54400, train loss = 0.131392, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:53.309085] Iteration 54500, train loss = 0.136956, train accuracy = 1.000000\n",
      "[2018-07-16 18:12:58.938159] Iteration 54600, train loss = 0.155598, train accuracy = 0.992188\n",
      "[2018-07-16 18:13:04.570561] Iteration 54700, train loss = 0.143241, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:10.211095] Iteration 54800, train loss = 0.132889, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:15.828331] Iteration 54900, train loss = 0.134483, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:21.486949] Iteration 55000, train loss = 0.134777, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 18:13:28.796732] Iteration 55100, train loss = 0.130848, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:34.429522] Iteration 55200, train loss = 0.143622, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:40.071968] Iteration 55300, train loss = 0.137484, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:45.705190] Iteration 55400, train loss = 0.134646, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:51.336994] Iteration 55500, train loss = 0.133328, train accuracy = 1.000000\n",
      "[2018-07-16 18:13:56.964922] Iteration 55600, train loss = 0.133855, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:02.605760] Iteration 55700, train loss = 0.131739, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:08.233110] Iteration 55800, train loss = 0.161848, train accuracy = 0.992188\n",
      "[2018-07-16 18:14:13.864423] Iteration 55900, train loss = 0.131489, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:19.498938] Iteration 56000, train loss = 0.131381, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923400\n",
      "[2018-07-16 18:14:26.835105] Iteration 56100, train loss = 0.132352, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:32.463108] Iteration 56200, train loss = 0.134343, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:38.094948] Iteration 56300, train loss = 0.134441, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:43.722510] Iteration 56400, train loss = 0.133639, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:49.348205] Iteration 56500, train loss = 0.132873, train accuracy = 1.000000\n",
      "[2018-07-16 18:14:54.978460] Iteration 56600, train loss = 0.134366, train accuracy = 1.000000\n",
      "[2018-07-16 18:15:00.596909] Iteration 56700, train loss = 0.137894, train accuracy = 1.000000\n",
      "[2018-07-16 18:15:06.241885] Iteration 56800, train loss = 0.139817, train accuracy = 1.000000\n",
      "[2018-07-16 18:15:11.874229] Iteration 56900, train loss = 0.140447, train accuracy = 1.000000\n",
      "[2018-07-16 18:15:17.497424] Iteration 57000, train loss = 0.133954, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922400\n",
      "[2018-07-16 18:15:24.808367] Iteration 57100, train loss = 0.147922, train accuracy = 0.992188\n",
      "[2018-07-16 18:15:30.437907] Iteration 57200, train loss = 0.139507, train accuracy = 0.992188\n",
      "[2018-07-16 18:15:36.089019] Iteration 57300, train loss = 0.133439, train accuracy = 1.000000\n",
      "[2018-07-16 18:15:41.723180] Iteration 57400, train loss = 0.136040, train accuracy = 1.000000\n",
      "[2018-07-16 18:15:47.349448] Iteration 57500, train loss = 0.134017, train accuracy = 1.000000\n",
      "[2018-07-16 18:15:52.983500] Iteration 57600, train loss = 0.157619, train accuracy = 0.992188\n",
      "[2018-07-16 18:15:58.612516] Iteration 57700, train loss = 0.139202, train accuracy = 1.000000\n",
      "[2018-07-16 18:16:04.238211] Iteration 57800, train loss = 0.131830, train accuracy = 1.000000\n",
      "[2018-07-16 18:16:09.879918] Iteration 57900, train loss = 0.163307, train accuracy = 0.984375\n",
      "[2018-07-16 18:16:15.528414] Iteration 58000, train loss = 0.148085, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922500\n",
      "[2018-07-16 18:16:22.833587] Iteration 58100, train loss = 0.133199, train accuracy = 1.000000\n",
      "[2018-07-16 18:16:28.480051] Iteration 58200, train loss = 0.132015, train accuracy = 1.000000\n",
      "[2018-07-16 18:16:34.122171] Iteration 58300, train loss = 0.137856, train accuracy = 1.000000\n",
      "[2018-07-16 18:16:39.740697] Iteration 58400, train loss = 0.131028, train accuracy = 1.000000\n",
      "[2018-07-16 18:16:45.374472] Iteration 58500, train loss = 0.150007, train accuracy = 0.992188\n",
      "[2018-07-16 18:16:51.006041] Iteration 58600, train loss = 0.132493, train accuracy = 1.000000\n",
      "[2018-07-16 18:16:56.641996] Iteration 58700, train loss = 0.133243, train accuracy = 1.000000\n",
      "[2018-07-16 18:17:02.276818] Iteration 58800, train loss = 0.151795, train accuracy = 0.992188\n",
      "[2018-07-16 18:17:07.910129] Iteration 58900, train loss = 0.132726, train accuracy = 1.000000\n",
      "[2018-07-16 18:17:13.542487] Iteration 59000, train loss = 0.132616, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922200\n",
      "[2018-07-16 18:17:20.857070] Iteration 59100, train loss = 0.142012, train accuracy = 0.992188\n",
      "[2018-07-16 18:17:26.497167] Iteration 59200, train loss = 0.134855, train accuracy = 1.000000\n",
      "[2018-07-16 18:17:32.135970] Iteration 59300, train loss = 0.140980, train accuracy = 1.000000\n",
      "[2018-07-16 18:17:37.765215] Iteration 59400, train loss = 0.133594, train accuracy = 1.000000\n",
      "[2018-07-16 18:17:43.392256] Iteration 59500, train loss = 0.139532, train accuracy = 1.000000\n",
      "[2018-07-16 18:17:49.022468] Iteration 59600, train loss = 0.142361, train accuracy = 0.992188\n",
      "[2018-07-16 18:17:54.648911] Iteration 59700, train loss = 0.136049, train accuracy = 1.000000\n",
      "[2018-07-16 18:18:00.280649] Iteration 59800, train loss = 0.155701, train accuracy = 0.992188\n",
      "[2018-07-16 18:18:05.924648] Iteration 59900, train loss = 0.134742, train accuracy = 1.000000\n",
      "[2018-07-16 18:18:11.567103] Iteration 60000, train loss = 0.136642, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 18:18:18.871169] Iteration 60100, train loss = 0.136236, train accuracy = 1.000000\n",
      "[2018-07-16 18:18:24.507365] Iteration 60200, train loss = 0.156128, train accuracy = 0.984375\n",
      "[2018-07-16 18:18:30.145653] Iteration 60300, train loss = 0.139647, train accuracy = 0.992188\n",
      "[2018-07-16 18:18:35.787122] Iteration 60400, train loss = 0.142847, train accuracy = 0.992188\n",
      "[2018-07-16 18:18:41.430427] Iteration 60500, train loss = 0.134226, train accuracy = 1.000000\n",
      "[2018-07-16 18:18:47.069982] Iteration 60600, train loss = 0.132369, train accuracy = 1.000000\n",
      "[2018-07-16 18:18:52.700422] Iteration 60700, train loss = 0.137756, train accuracy = 1.000000\n",
      "[2018-07-16 18:18:58.328254] Iteration 60800, train loss = 0.138573, train accuracy = 0.992188\n",
      "[2018-07-16 18:19:03.963027] Iteration 60900, train loss = 0.142921, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:09.610663] Iteration 61000, train loss = 0.139287, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922200\n",
      "[2018-07-16 18:19:16.916886] Iteration 61100, train loss = 0.132952, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:22.550025] Iteration 61200, train loss = 0.131530, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:28.193319] Iteration 61300, train loss = 0.132117, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:33.821439] Iteration 61400, train loss = 0.136502, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:39.458577] Iteration 61500, train loss = 0.131438, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:45.100267] Iteration 61600, train loss = 0.131030, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:50.732611] Iteration 61700, train loss = 0.133721, train accuracy = 1.000000\n",
      "[2018-07-16 18:19:56.369953] Iteration 61800, train loss = 0.153452, train accuracy = 0.992188\n",
      "[2018-07-16 18:20:01.991404] Iteration 61900, train loss = 0.133946, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:07.622367] Iteration 62000, train loss = 0.157519, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922400\n",
      "[2018-07-16 18:20:14.924878] Iteration 62100, train loss = 0.136302, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:20.551121] Iteration 62200, train loss = 0.143447, train accuracy = 0.992188\n",
      "[2018-07-16 18:20:26.182049] Iteration 62300, train loss = 0.132127, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:31.813702] Iteration 62400, train loss = 0.134111, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:37.443588] Iteration 62500, train loss = 0.132662, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:43.081115] Iteration 62600, train loss = 0.133194, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:48.711326] Iteration 62700, train loss = 0.138077, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:54.334489] Iteration 62800, train loss = 0.132888, train accuracy = 1.000000\n",
      "[2018-07-16 18:20:59.975071] Iteration 62900, train loss = 0.130113, train accuracy = 1.000000\n",
      "[2018-07-16 18:21:05.597852] Iteration 63000, train loss = 0.132454, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922200\n",
      "[2018-07-16 18:21:12.913672] Iteration 63100, train loss = 0.141387, train accuracy = 0.992188\n",
      "[2018-07-16 18:21:18.558534] Iteration 63200, train loss = 0.137951, train accuracy = 1.000000\n",
      "[2018-07-16 18:21:24.207009] Iteration 63300, train loss = 0.151395, train accuracy = 0.992188\n",
      "[2018-07-16 18:21:29.837902] Iteration 63400, train loss = 0.142459, train accuracy = 0.992188\n",
      "[2018-07-16 18:21:35.462920] Iteration 63500, train loss = 0.131338, train accuracy = 1.000000\n",
      "[2018-07-16 18:21:41.093362] Iteration 63600, train loss = 0.137381, train accuracy = 1.000000\n",
      "[2018-07-16 18:21:46.738644] Iteration 63700, train loss = 0.140099, train accuracy = 0.992188\n",
      "[2018-07-16 18:21:52.363187] Iteration 63800, train loss = 0.134639, train accuracy = 1.000000\n",
      "[2018-07-16 18:21:57.988088] Iteration 63900, train loss = 0.134527, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:03.615791] Iteration 64000, train loss = 0.134487, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922400\n",
      "[2018-07-16 18:22:10.922644] Iteration 64100, train loss = 0.132813, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:16.558780] Iteration 64200, train loss = 0.131004, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:22.188414] Iteration 64300, train loss = 0.138506, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:27.819205] Iteration 64400, train loss = 0.134281, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:33.436050] Iteration 64500, train loss = 0.134353, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:39.063655] Iteration 64600, train loss = 0.132928, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:44.694421] Iteration 64700, train loss = 0.140115, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:50.332844] Iteration 64800, train loss = 0.142088, train accuracy = 1.000000\n",
      "[2018-07-16 18:22:55.976094] Iteration 64900, train loss = 0.146279, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:01.618619] Iteration 65000, train loss = 0.137031, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922600\n",
      "[2018-07-16 18:23:08.937961] Iteration 65100, train loss = 0.130172, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:14.577652] Iteration 65200, train loss = 0.145293, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:20.211447] Iteration 65300, train loss = 0.135405, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:25.842986] Iteration 65400, train loss = 0.132372, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:31.485570] Iteration 65500, train loss = 0.136443, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:37.123228] Iteration 65600, train loss = 0.142938, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:42.750560] Iteration 65700, train loss = 0.132695, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:48.395364] Iteration 65800, train loss = 0.131175, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:54.028136] Iteration 65900, train loss = 0.135338, train accuracy = 1.000000\n",
      "[2018-07-16 18:23:59.654452] Iteration 66000, train loss = 0.137149, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 18:24:06.973392] Iteration 66100, train loss = 0.129926, train accuracy = 1.000000\n",
      "[2018-07-16 18:24:12.611625] Iteration 66200, train loss = 0.133911, train accuracy = 1.000000\n",
      "[2018-07-16 18:24:18.240194] Iteration 66300, train loss = 0.140546, train accuracy = 0.992188\n",
      "[2018-07-16 18:24:23.875357] Iteration 66400, train loss = 0.133989, train accuracy = 1.000000\n",
      "[2018-07-16 18:24:29.496464] Iteration 66500, train loss = 0.144520, train accuracy = 0.992188\n",
      "[2018-07-16 18:24:35.121794] Iteration 66600, train loss = 0.133911, train accuracy = 1.000000\n",
      "[2018-07-16 18:24:40.759067] Iteration 66700, train loss = 0.135490, train accuracy = 1.000000\n",
      "[2018-07-16 18:24:46.381114] Iteration 66800, train loss = 0.132307, train accuracy = 1.000000\n",
      "[2018-07-16 18:24:52.012191] Iteration 66900, train loss = 0.134296, train accuracy = 1.000000\n",
      "[2018-07-16 18:24:57.641709] Iteration 67000, train loss = 0.135152, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922600\n",
      "[2018-07-16 18:25:05.015297] Iteration 67100, train loss = 0.136482, train accuracy = 1.000000\n",
      "[2018-07-16 18:25:10.666402] Iteration 67200, train loss = 0.141271, train accuracy = 0.992188\n",
      "[2018-07-16 18:25:16.305892] Iteration 67300, train loss = 0.130482, train accuracy = 1.000000\n",
      "[2018-07-16 18:25:21.928787] Iteration 67400, train loss = 0.132379, train accuracy = 1.000000\n",
      "[2018-07-16 18:25:27.562816] Iteration 67500, train loss = 0.136699, train accuracy = 1.000000\n",
      "[2018-07-16 18:25:33.184168] Iteration 67600, train loss = 0.155617, train accuracy = 0.984375\n",
      "[2018-07-16 18:25:38.812317] Iteration 67700, train loss = 0.134224, train accuracy = 1.000000\n",
      "[2018-07-16 18:25:44.443795] Iteration 67800, train loss = 0.136059, train accuracy = 1.000000\n",
      "[2018-07-16 18:25:50.077874] Iteration 67900, train loss = 0.138621, train accuracy = 1.000000\n",
      "[2018-07-16 18:25:55.723427] Iteration 68000, train loss = 0.140694, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 18:26:03.042638] Iteration 68100, train loss = 0.130676, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:08.683315] Iteration 68200, train loss = 0.141912, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:14.307805] Iteration 68300, train loss = 0.133117, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:19.943215] Iteration 68400, train loss = 0.131475, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:25.581971] Iteration 68500, train loss = 0.130426, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:31.217708] Iteration 68600, train loss = 0.130807, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:36.862910] Iteration 68700, train loss = 0.137226, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:42.501346] Iteration 68800, train loss = 0.131722, train accuracy = 1.000000\n",
      "[2018-07-16 18:26:48.132098] Iteration 68900, train loss = 0.144212, train accuracy = 0.992188\n",
      "[2018-07-16 18:26:53.773910] Iteration 69000, train loss = 0.135348, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 18:27:01.081611] Iteration 69100, train loss = 0.130951, train accuracy = 1.000000\n",
      "[2018-07-16 18:27:06.732004] Iteration 69200, train loss = 0.130827, train accuracy = 1.000000\n",
      "[2018-07-16 18:27:12.365737] Iteration 69300, train loss = 0.132162, train accuracy = 1.000000\n",
      "[2018-07-16 18:27:18.009955] Iteration 69400, train loss = 0.155444, train accuracy = 0.992188\n",
      "[2018-07-16 18:27:23.645342] Iteration 69500, train loss = 0.135673, train accuracy = 1.000000\n",
      "[2018-07-16 18:27:29.278845] Iteration 69600, train loss = 0.140790, train accuracy = 0.992188\n",
      "[2018-07-16 18:27:34.909592] Iteration 69700, train loss = 0.136326, train accuracy = 1.000000\n",
      "[2018-07-16 18:27:40.549097] Iteration 69800, train loss = 0.136365, train accuracy = 1.000000\n",
      "[2018-07-16 18:27:46.174366] Iteration 69900, train loss = 0.134850, train accuracy = 1.000000\n",
      "[2018-07-16 18:27:51.809870] Iteration 70000, train loss = 0.138663, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 18:27:59.123618] Iteration 70100, train loss = 0.144374, train accuracy = 0.992188\n",
      "[2018-07-16 18:28:04.766347] Iteration 70200, train loss = 0.131547, train accuracy = 1.000000\n",
      "[2018-07-16 18:28:10.410498] Iteration 70300, train loss = 0.149324, train accuracy = 0.992188\n",
      "[2018-07-16 18:28:16.039737] Iteration 70400, train loss = 0.129809, train accuracy = 1.000000\n",
      "[2018-07-16 18:28:21.678135] Iteration 70500, train loss = 0.135303, train accuracy = 1.000000\n",
      "[2018-07-16 18:28:27.317592] Iteration 70600, train loss = 0.142335, train accuracy = 0.992188\n",
      "[2018-07-16 18:28:32.963162] Iteration 70700, train loss = 0.140059, train accuracy = 0.992188\n",
      "[2018-07-16 18:28:38.597990] Iteration 70800, train loss = 0.130994, train accuracy = 1.000000\n",
      "[2018-07-16 18:28:44.233390] Iteration 70900, train loss = 0.136218, train accuracy = 1.000000\n",
      "[2018-07-16 18:28:49.850185] Iteration 71000, train loss = 0.139104, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 18:28:57.160326] Iteration 71100, train loss = 0.135066, train accuracy = 1.000000\n",
      "[2018-07-16 18:29:02.783342] Iteration 71200, train loss = 0.134266, train accuracy = 1.000000\n",
      "[2018-07-16 18:29:08.414078] Iteration 71300, train loss = 0.131964, train accuracy = 1.000000\n",
      "[2018-07-16 18:29:14.069329] Iteration 71400, train loss = 0.174013, train accuracy = 0.992188\n",
      "[2018-07-16 18:29:19.716686] Iteration 71500, train loss = 0.136463, train accuracy = 1.000000\n",
      "[2018-07-16 18:29:25.348035] Iteration 71600, train loss = 0.131184, train accuracy = 1.000000\n",
      "[2018-07-16 18:29:30.978622] Iteration 71700, train loss = 0.131552, train accuracy = 1.000000\n",
      "[2018-07-16 18:29:36.609937] Iteration 71800, train loss = 0.137892, train accuracy = 1.000000\n",
      "[2018-07-16 18:29:42.229784] Iteration 71900, train loss = 0.154885, train accuracy = 0.992188\n",
      "[2018-07-16 18:29:47.864888] Iteration 72000, train loss = 0.133942, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 18:29:55.172505] Iteration 72100, train loss = 0.133453, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:00.815238] Iteration 72200, train loss = 0.130584, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:06.446137] Iteration 72300, train loss = 0.134122, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:12.081101] Iteration 72400, train loss = 0.133088, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:17.713234] Iteration 72500, train loss = 0.148052, train accuracy = 0.992188\n",
      "[2018-07-16 18:30:23.358476] Iteration 72600, train loss = 0.132926, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:28.993567] Iteration 72700, train loss = 0.131298, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:34.632778] Iteration 72800, train loss = 0.152755, train accuracy = 0.984375\n",
      "[2018-07-16 18:30:40.278983] Iteration 72900, train loss = 0.139710, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:45.901948] Iteration 73000, train loss = 0.132683, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921900\n",
      "[2018-07-16 18:30:53.214022] Iteration 73100, train loss = 0.131024, train accuracy = 1.000000\n",
      "[2018-07-16 18:30:58.853520] Iteration 73200, train loss = 0.142541, train accuracy = 1.000000\n",
      "[2018-07-16 18:31:04.508246] Iteration 73300, train loss = 0.135920, train accuracy = 1.000000\n",
      "[2018-07-16 18:31:10.128530] Iteration 73400, train loss = 0.149383, train accuracy = 0.992188\n",
      "[2018-07-16 18:31:15.760780] Iteration 73500, train loss = 0.142212, train accuracy = 0.992188\n",
      "[2018-07-16 18:31:21.372583] Iteration 73600, train loss = 0.130771, train accuracy = 1.000000\n",
      "[2018-07-16 18:31:27.010631] Iteration 73700, train loss = 0.134494, train accuracy = 1.000000\n",
      "[2018-07-16 18:31:32.650819] Iteration 73800, train loss = 0.136765, train accuracy = 1.000000\n",
      "[2018-07-16 18:31:38.284498] Iteration 73900, train loss = 0.132711, train accuracy = 1.000000\n",
      "[2018-07-16 18:31:43.925125] Iteration 74000, train loss = 0.133970, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 18:31:51.231159] Iteration 74100, train loss = 0.131544, train accuracy = 1.000000\n",
      "[2018-07-16 18:31:56.857426] Iteration 74200, train loss = 0.140825, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:02.494955] Iteration 74300, train loss = 0.136694, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:08.141245] Iteration 74400, train loss = 0.136289, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:13.780959] Iteration 74500, train loss = 0.138255, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:19.419908] Iteration 74600, train loss = 0.158454, train accuracy = 0.992188\n",
      "[2018-07-16 18:32:25.054165] Iteration 74700, train loss = 0.133654, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:30.690775] Iteration 74800, train loss = 0.136152, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:36.323842] Iteration 74900, train loss = 0.136877, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:41.964053] Iteration 75000, train loss = 0.137125, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921300\n",
      "[2018-07-16 18:32:49.279102] Iteration 75100, train loss = 0.143337, train accuracy = 1.000000\n",
      "[2018-07-16 18:32:54.907662] Iteration 75200, train loss = 0.147065, train accuracy = 0.992188\n",
      "[2018-07-16 18:33:00.551589] Iteration 75300, train loss = 0.136307, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:06.180539] Iteration 75400, train loss = 0.138452, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:11.816471] Iteration 75500, train loss = 0.131185, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:17.450214] Iteration 75600, train loss = 0.135624, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:23.083405] Iteration 75700, train loss = 0.135586, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:28.724602] Iteration 75800, train loss = 0.136654, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:34.382798] Iteration 75900, train loss = 0.138765, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:40.023777] Iteration 76000, train loss = 0.134478, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 18:33:47.339995] Iteration 76100, train loss = 0.143804, train accuracy = 0.992188\n",
      "[2018-07-16 18:33:52.977286] Iteration 76200, train loss = 0.138772, train accuracy = 1.000000\n",
      "[2018-07-16 18:33:58.615927] Iteration 76300, train loss = 0.134067, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:04.246750] Iteration 76400, train loss = 0.140546, train accuracy = 0.992188\n",
      "[2018-07-16 18:34:09.880967] Iteration 76500, train loss = 0.129974, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:15.515601] Iteration 76600, train loss = 0.131531, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:21.147448] Iteration 76700, train loss = 0.131734, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:26.776582] Iteration 76800, train loss = 0.133809, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:32.433028] Iteration 76900, train loss = 0.139677, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:38.068867] Iteration 77000, train loss = 0.135564, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921500\n",
      "[2018-07-16 18:34:45.379682] Iteration 77100, train loss = 0.137227, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:51.012446] Iteration 77200, train loss = 0.136347, train accuracy = 1.000000\n",
      "[2018-07-16 18:34:56.642834] Iteration 77300, train loss = 0.135424, train accuracy = 1.000000\n",
      "[2018-07-16 18:35:02.269372] Iteration 77400, train loss = 0.141116, train accuracy = 0.992188\n",
      "[2018-07-16 18:35:07.906445] Iteration 77500, train loss = 0.131701, train accuracy = 1.000000\n",
      "[2018-07-16 18:35:13.542360] Iteration 77600, train loss = 0.132149, train accuracy = 1.000000\n",
      "[2018-07-16 18:35:19.169953] Iteration 77700, train loss = 0.147856, train accuracy = 0.992188\n",
      "[2018-07-16 18:35:24.803609] Iteration 77800, train loss = 0.133037, train accuracy = 1.000000\n",
      "[2018-07-16 18:35:30.455266] Iteration 77900, train loss = 0.136955, train accuracy = 1.000000\n",
      "[2018-07-16 18:35:36.090679] Iteration 78000, train loss = 0.132059, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 18:35:43.409760] Iteration 78100, train loss = 0.145682, train accuracy = 0.992188\n",
      "[2018-07-16 18:35:49.033752] Iteration 78200, train loss = 0.133048, train accuracy = 1.000000\n",
      "[2018-07-16 18:35:54.664542] Iteration 78300, train loss = 0.137756, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:00.297688] Iteration 78400, train loss = 0.143366, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:05.922816] Iteration 78500, train loss = 0.135970, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:11.541404] Iteration 78600, train loss = 0.132855, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:17.178367] Iteration 78700, train loss = 0.136251, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:22.802491] Iteration 78800, train loss = 0.143592, train accuracy = 0.992188\n",
      "[2018-07-16 18:36:28.429249] Iteration 78900, train loss = 0.134570, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:34.072886] Iteration 79000, train loss = 0.148723, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921000\n",
      "[2018-07-16 18:36:41.476601] Iteration 79100, train loss = 0.130510, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:47.111562] Iteration 79200, train loss = 0.143880, train accuracy = 0.992188\n",
      "[2018-07-16 18:36:52.749082] Iteration 79300, train loss = 0.136079, train accuracy = 1.000000\n",
      "[2018-07-16 18:36:58.399339] Iteration 79400, train loss = 0.138241, train accuracy = 1.000000\n",
      "[2018-07-16 18:37:04.034528] Iteration 79500, train loss = 0.135751, train accuracy = 1.000000\n",
      "[2018-07-16 18:37:09.661944] Iteration 79600, train loss = 0.132575, train accuracy = 1.000000\n",
      "[2018-07-16 18:37:15.303279] Iteration 79700, train loss = 0.135395, train accuracy = 1.000000\n",
      "[2018-07-16 18:37:20.934387] Iteration 79800, train loss = 0.132617, train accuracy = 1.000000\n",
      "[2018-07-16 18:37:26.569016] Iteration 79900, train loss = 0.136242, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三轮  量化\n",
    "prune_rate = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.921700\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.03125    -0.0625      0.00782731  0.125       0.0318545  -0.03125\n",
      "  0.015625    0.03125     0.01987953 -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.85)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-16 18:38:55.357575] Iteration 100, train loss = 0.152917, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:01.016905] Iteration 200, train loss = 0.142545, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:06.656253] Iteration 300, train loss = 0.147076, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:12.300169] Iteration 400, train loss = 0.140761, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:17.966714] Iteration 500, train loss = 0.159800, train accuracy = 0.992188\n",
      "[2018-07-16 18:39:23.617357] Iteration 600, train loss = 0.153749, train accuracy = 0.992188\n",
      "[2018-07-16 18:39:29.257151] Iteration 700, train loss = 0.136645, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:34.923850] Iteration 800, train loss = 0.129963, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:40.562526] Iteration 900, train loss = 0.146600, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:46.236006] Iteration 1000, train loss = 0.148306, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.917800\n",
      "[2018-07-16 18:39:53.567891] Iteration 1100, train loss = 0.139657, train accuracy = 1.000000\n",
      "[2018-07-16 18:39:59.221583] Iteration 1200, train loss = 0.136953, train accuracy = 1.000000\n",
      "[2018-07-16 18:40:04.869871] Iteration 1300, train loss = 0.150729, train accuracy = 0.992188\n",
      "[2018-07-16 18:40:10.523195] Iteration 1400, train loss = 0.156671, train accuracy = 0.992188\n",
      "[2018-07-16 18:40:16.177274] Iteration 1500, train loss = 0.133281, train accuracy = 1.000000\n",
      "[2018-07-16 18:40:21.832667] Iteration 1600, train loss = 0.136614, train accuracy = 1.000000\n",
      "[2018-07-16 18:40:27.482775] Iteration 1700, train loss = 0.142561, train accuracy = 1.000000\n",
      "[2018-07-16 18:40:33.146820] Iteration 1800, train loss = 0.161035, train accuracy = 0.984375\n",
      "[2018-07-16 18:40:38.810185] Iteration 1900, train loss = 0.145551, train accuracy = 0.992188\n",
      "[2018-07-16 18:40:44.448368] Iteration 2000, train loss = 0.144468, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916800\n",
      "[2018-07-16 18:40:51.850826] Iteration 2100, train loss = 0.141820, train accuracy = 0.992188\n",
      "[2018-07-16 18:40:57.504992] Iteration 2200, train loss = 0.138118, train accuracy = 1.000000\n",
      "[2018-07-16 18:41:03.166924] Iteration 2300, train loss = 0.133167, train accuracy = 1.000000\n",
      "[2018-07-16 18:41:08.831633] Iteration 2400, train loss = 0.155701, train accuracy = 0.984375\n",
      "[2018-07-16 18:41:14.470988] Iteration 2500, train loss = 0.144831, train accuracy = 0.984375\n",
      "[2018-07-16 18:41:20.116134] Iteration 2600, train loss = 0.138543, train accuracy = 1.000000\n",
      "[2018-07-16 18:41:25.765013] Iteration 2700, train loss = 0.152359, train accuracy = 0.984375\n",
      "[2018-07-16 18:41:31.416484] Iteration 2800, train loss = 0.144359, train accuracy = 1.000000\n",
      "[2018-07-16 18:41:37.075559] Iteration 2900, train loss = 0.131562, train accuracy = 1.000000\n",
      "[2018-07-16 18:41:42.739615] Iteration 3000, train loss = 0.140545, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.919000\n",
      "[2018-07-16 18:41:50.081103] Iteration 3100, train loss = 0.160029, train accuracy = 0.984375\n",
      "[2018-07-16 18:41:55.725466] Iteration 3200, train loss = 0.145427, train accuracy = 0.992188\n",
      "[2018-07-16 18:42:01.377408] Iteration 3300, train loss = 0.141877, train accuracy = 1.000000\n",
      "[2018-07-16 18:42:07.023308] Iteration 3400, train loss = 0.149985, train accuracy = 0.992188\n",
      "[2018-07-16 18:42:12.690293] Iteration 3500, train loss = 0.139653, train accuracy = 1.000000\n",
      "[2018-07-16 18:42:18.342645] Iteration 3600, train loss = 0.179494, train accuracy = 0.984375\n",
      "[2018-07-16 18:42:24.000900] Iteration 3700, train loss = 0.140739, train accuracy = 1.000000\n",
      "[2018-07-16 18:42:29.655303] Iteration 3800, train loss = 0.163697, train accuracy = 0.992188\n",
      "[2018-07-16 18:42:35.311922] Iteration 3900, train loss = 0.157982, train accuracy = 0.992188\n",
      "[2018-07-16 18:42:40.975877] Iteration 4000, train loss = 0.133603, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.918800\n",
      "[2018-07-16 18:42:48.308478] Iteration 4100, train loss = 0.138550, train accuracy = 1.000000\n",
      "[2018-07-16 18:42:53.961082] Iteration 4200, train loss = 0.159458, train accuracy = 0.992188\n",
      "[2018-07-16 18:42:59.620772] Iteration 4300, train loss = 0.166538, train accuracy = 0.984375\n",
      "[2018-07-16 18:43:05.271939] Iteration 4400, train loss = 0.138503, train accuracy = 1.000000\n",
      "[2018-07-16 18:43:10.938724] Iteration 4500, train loss = 0.174914, train accuracy = 0.992188\n",
      "[2018-07-16 18:43:16.603060] Iteration 4600, train loss = 0.145399, train accuracy = 1.000000\n",
      "[2018-07-16 18:43:22.256839] Iteration 4700, train loss = 0.136966, train accuracy = 1.000000\n",
      "[2018-07-16 18:43:27.902058] Iteration 4800, train loss = 0.137564, train accuracy = 1.000000\n",
      "[2018-07-16 18:43:33.557572] Iteration 4900, train loss = 0.134340, train accuracy = 1.000000\n",
      "[2018-07-16 18:43:39.204214] Iteration 5000, train loss = 0.136814, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921100\n",
      "[2018-07-16 18:43:46.520575] Iteration 5100, train loss = 0.142439, train accuracy = 0.992188\n",
      "[2018-07-16 18:43:52.166556] Iteration 5200, train loss = 0.133927, train accuracy = 1.000000\n",
      "[2018-07-16 18:43:57.828385] Iteration 5300, train loss = 0.147680, train accuracy = 0.992188\n",
      "[2018-07-16 18:44:03.509185] Iteration 5400, train loss = 0.139373, train accuracy = 1.000000\n",
      "[2018-07-16 18:44:09.171395] Iteration 5500, train loss = 0.145112, train accuracy = 0.992188\n",
      "[2018-07-16 18:44:14.836942] Iteration 5600, train loss = 0.143549, train accuracy = 1.000000\n",
      "[2018-07-16 18:44:20.490888] Iteration 5700, train loss = 0.137309, train accuracy = 1.000000\n",
      "[2018-07-16 18:44:26.136781] Iteration 5800, train loss = 0.137310, train accuracy = 1.000000\n",
      "[2018-07-16 18:44:31.799717] Iteration 5900, train loss = 0.149752, train accuracy = 0.992188\n",
      "[2018-07-16 18:44:37.449205] Iteration 6000, train loss = 0.137760, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920000\n",
      "[2018-07-16 18:44:44.785871] Iteration 6100, train loss = 0.136190, train accuracy = 1.000000\n",
      "[2018-07-16 18:44:50.448160] Iteration 6200, train loss = 0.152316, train accuracy = 0.984375\n",
      "[2018-07-16 18:44:56.111967] Iteration 6300, train loss = 0.130677, train accuracy = 1.000000\n",
      "[2018-07-16 18:45:01.774735] Iteration 6400, train loss = 0.148065, train accuracy = 0.992188\n",
      "[2018-07-16 18:45:07.436763] Iteration 6500, train loss = 0.148636, train accuracy = 1.000000\n",
      "[2018-07-16 18:45:13.108219] Iteration 6600, train loss = 0.130130, train accuracy = 1.000000\n",
      "[2018-07-16 18:45:18.757003] Iteration 6700, train loss = 0.157403, train accuracy = 0.992188\n",
      "[2018-07-16 18:45:24.411746] Iteration 6800, train loss = 0.139072, train accuracy = 1.000000\n",
      "[2018-07-16 18:45:30.069217] Iteration 6900, train loss = 0.162024, train accuracy = 0.992188\n",
      "[2018-07-16 18:45:35.722696] Iteration 7000, train loss = 0.139862, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920300\n",
      "[2018-07-16 18:45:43.067104] Iteration 7100, train loss = 0.176993, train accuracy = 0.992188\n",
      "[2018-07-16 18:45:48.721854] Iteration 7200, train loss = 0.149548, train accuracy = 0.992188\n",
      "[2018-07-16 18:45:54.379953] Iteration 7300, train loss = 0.137461, train accuracy = 1.000000\n",
      "[2018-07-16 18:46:00.026313] Iteration 7400, train loss = 0.145298, train accuracy = 0.992188\n",
      "[2018-07-16 18:46:05.691940] Iteration 7500, train loss = 0.157822, train accuracy = 0.984375\n",
      "[2018-07-16 18:46:11.348706] Iteration 7600, train loss = 0.136801, train accuracy = 1.000000\n",
      "[2018-07-16 18:46:17.005445] Iteration 7700, train loss = 0.236083, train accuracy = 0.968750\n",
      "[2018-07-16 18:46:22.662732] Iteration 7800, train loss = 0.133131, train accuracy = 1.000000\n",
      "[2018-07-16 18:46:28.315322] Iteration 7900, train loss = 0.136507, train accuracy = 1.000000\n",
      "[2018-07-16 18:46:33.977112] Iteration 8000, train loss = 0.150341, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.920500\n",
      "[2018-07-16 18:46:41.309694] Iteration 8100, train loss = 0.137173, train accuracy = 1.000000\n",
      "[2018-07-16 18:46:46.968728] Iteration 8200, train loss = 0.131815, train accuracy = 1.000000\n",
      "[2018-07-16 18:46:52.631653] Iteration 8300, train loss = 0.163770, train accuracy = 0.992188\n",
      "[2018-07-16 18:46:58.284788] Iteration 8400, train loss = 0.139462, train accuracy = 1.000000\n",
      "[2018-07-16 18:47:03.948900] Iteration 8500, train loss = 0.177429, train accuracy = 0.992188\n",
      "[2018-07-16 18:47:09.599388] Iteration 8600, train loss = 0.145166, train accuracy = 0.992188\n",
      "[2018-07-16 18:47:15.256850] Iteration 8700, train loss = 0.141885, train accuracy = 0.992188\n",
      "[2018-07-16 18:47:20.921883] Iteration 8800, train loss = 0.149069, train accuracy = 0.992188\n",
      "[2018-07-16 18:47:26.572840] Iteration 8900, train loss = 0.137664, train accuracy = 1.000000\n",
      "[2018-07-16 18:47:32.227112] Iteration 9000, train loss = 0.147547, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.920300\n",
      "[2018-07-16 18:47:39.561648] Iteration 9100, train loss = 0.131823, train accuracy = 1.000000\n",
      "[2018-07-16 18:47:45.224795] Iteration 9200, train loss = 0.141253, train accuracy = 0.992188\n",
      "[2018-07-16 18:47:50.882307] Iteration 9300, train loss = 0.161344, train accuracy = 0.992188\n",
      "[2018-07-16 18:47:56.537852] Iteration 9400, train loss = 0.155137, train accuracy = 0.992188\n",
      "[2018-07-16 18:48:02.188869] Iteration 9500, train loss = 0.146790, train accuracy = 0.992188\n",
      "[2018-07-16 18:48:07.855331] Iteration 9600, train loss = 0.137129, train accuracy = 1.000000\n",
      "[2018-07-16 18:48:13.517627] Iteration 9700, train loss = 0.134187, train accuracy = 1.000000\n",
      "[2018-07-16 18:48:19.181244] Iteration 9800, train loss = 0.135980, train accuracy = 1.000000\n",
      "[2018-07-16 18:48:24.835593] Iteration 9900, train loss = 0.144813, train accuracy = 0.992188\n",
      "[2018-07-16 18:48:30.491497] Iteration 10000, train loss = 0.141422, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920600\n",
      "[2018-07-16 18:48:37.839020] Iteration 10100, train loss = 0.153813, train accuracy = 0.992188\n",
      "[2018-07-16 18:48:43.505064] Iteration 10200, train loss = 0.139203, train accuracy = 1.000000\n",
      "[2018-07-16 18:48:49.160497] Iteration 10300, train loss = 0.143220, train accuracy = 0.992188\n",
      "[2018-07-16 18:48:54.838027] Iteration 10400, train loss = 0.144005, train accuracy = 0.992188\n",
      "[2018-07-16 18:49:00.510275] Iteration 10500, train loss = 0.132107, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:06.164975] Iteration 10600, train loss = 0.138465, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:11.808107] Iteration 10700, train loss = 0.149490, train accuracy = 0.992188\n",
      "[2018-07-16 18:49:17.476929] Iteration 10800, train loss = 0.131641, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:23.136225] Iteration 10900, train loss = 0.135392, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:28.788641] Iteration 11000, train loss = 0.134398, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920900\n",
      "[2018-07-16 18:49:36.135381] Iteration 11100, train loss = 0.143567, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:41.786824] Iteration 11200, train loss = 0.137325, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:47.440948] Iteration 11300, train loss = 0.140297, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:53.096838] Iteration 11400, train loss = 0.135433, train accuracy = 1.000000\n",
      "[2018-07-16 18:49:58.752172] Iteration 11500, train loss = 0.132600, train accuracy = 1.000000\n",
      "[2018-07-16 18:50:04.412176] Iteration 11600, train loss = 0.156612, train accuracy = 0.984375\n",
      "[2018-07-16 18:50:10.056638] Iteration 11700, train loss = 0.136046, train accuracy = 1.000000\n",
      "[2018-07-16 18:50:15.713815] Iteration 11800, train loss = 0.142026, train accuracy = 1.000000\n",
      "[2018-07-16 18:50:21.371261] Iteration 11900, train loss = 0.143962, train accuracy = 1.000000\n",
      "[2018-07-16 18:50:27.031586] Iteration 12000, train loss = 0.152351, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.920400\n",
      "[2018-07-16 18:50:34.359761] Iteration 12100, train loss = 0.133947, train accuracy = 1.000000\n",
      "[2018-07-16 18:50:40.003126] Iteration 12200, train loss = 0.144899, train accuracy = 0.992188\n",
      "[2018-07-16 18:50:45.666429] Iteration 12300, train loss = 0.133350, train accuracy = 1.000000\n",
      "[2018-07-16 18:50:51.331691] Iteration 12400, train loss = 0.139377, train accuracy = 1.000000\n",
      "[2018-07-16 18:50:56.992636] Iteration 12500, train loss = 0.142324, train accuracy = 0.992188\n",
      "[2018-07-16 18:51:02.651276] Iteration 12600, train loss = 0.142988, train accuracy = 0.992188\n",
      "[2018-07-16 18:51:08.311370] Iteration 12700, train loss = 0.146186, train accuracy = 1.000000\n",
      "[2018-07-16 18:51:13.965930] Iteration 12800, train loss = 0.149509, train accuracy = 0.992188\n",
      "[2018-07-16 18:51:19.628884] Iteration 12900, train loss = 0.132967, train accuracy = 1.000000\n",
      "[2018-07-16 18:51:25.305775] Iteration 13000, train loss = 0.135386, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921900\n",
      "[2018-07-16 18:51:32.640483] Iteration 13100, train loss = 0.135197, train accuracy = 1.000000\n",
      "[2018-07-16 18:51:38.314818] Iteration 13200, train loss = 0.137157, train accuracy = 1.000000\n",
      "[2018-07-16 18:51:43.988015] Iteration 13300, train loss = 0.138589, train accuracy = 1.000000\n",
      "[2018-07-16 18:51:49.666602] Iteration 13400, train loss = 0.140363, train accuracy = 0.992188\n",
      "[2018-07-16 18:51:55.325819] Iteration 13500, train loss = 0.135327, train accuracy = 1.000000\n",
      "[2018-07-16 18:52:00.996126] Iteration 13600, train loss = 0.145664, train accuracy = 0.992188\n",
      "[2018-07-16 18:52:06.660696] Iteration 13700, train loss = 0.134850, train accuracy = 1.000000\n",
      "[2018-07-16 18:52:12.329889] Iteration 13800, train loss = 0.131065, train accuracy = 1.000000\n",
      "[2018-07-16 18:52:17.997612] Iteration 13900, train loss = 0.156411, train accuracy = 0.984375\n",
      "[2018-07-16 18:52:23.670221] Iteration 14000, train loss = 0.154065, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.920600\n",
      "[2018-07-16 18:52:31.016153] Iteration 14100, train loss = 0.144909, train accuracy = 0.992188\n",
      "[2018-07-16 18:52:36.628413] Iteration 14200, train loss = 0.136999, train accuracy = 1.000000\n",
      "[2018-07-16 18:52:42.272386] Iteration 14300, train loss = 0.132184, train accuracy = 1.000000\n",
      "[2018-07-16 18:52:47.925571] Iteration 14400, train loss = 0.138584, train accuracy = 1.000000\n",
      "[2018-07-16 18:52:53.588162] Iteration 14500, train loss = 0.145735, train accuracy = 0.992188\n",
      "[2018-07-16 18:52:59.237810] Iteration 14600, train loss = 0.141936, train accuracy = 0.992188\n",
      "[2018-07-16 18:53:04.900531] Iteration 14700, train loss = 0.137870, train accuracy = 0.992188\n",
      "[2018-07-16 18:53:10.567933] Iteration 14800, train loss = 0.145265, train accuracy = 1.000000\n",
      "[2018-07-16 18:53:16.228358] Iteration 14900, train loss = 0.155419, train accuracy = 0.992188\n",
      "[2018-07-16 18:53:21.884495] Iteration 15000, train loss = 0.143331, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.920400\n",
      "[2018-07-16 18:53:29.232559] Iteration 15100, train loss = 0.148509, train accuracy = 0.992188\n",
      "[2018-07-16 18:53:34.913202] Iteration 15200, train loss = 0.143397, train accuracy = 0.992188\n",
      "[2018-07-16 18:53:40.599215] Iteration 15300, train loss = 0.143759, train accuracy = 0.992188\n",
      "[2018-07-16 18:53:46.255299] Iteration 15400, train loss = 0.131159, train accuracy = 1.000000\n",
      "[2018-07-16 18:53:51.931121] Iteration 15500, train loss = 0.135509, train accuracy = 1.000000\n",
      "[2018-07-16 18:53:57.600293] Iteration 15600, train loss = 0.137067, train accuracy = 1.000000\n",
      "[2018-07-16 18:54:03.283779] Iteration 15700, train loss = 0.152759, train accuracy = 0.984375\n",
      "[2018-07-16 18:54:08.953113] Iteration 15800, train loss = 0.141074, train accuracy = 1.000000\n",
      "[2018-07-16 18:54:14.617219] Iteration 15900, train loss = 0.134457, train accuracy = 1.000000\n",
      "[2018-07-16 18:54:20.273660] Iteration 16000, train loss = 0.150593, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921000\n",
      "[2018-07-16 18:54:27.605800] Iteration 16100, train loss = 0.134302, train accuracy = 1.000000\n",
      "[2018-07-16 18:54:33.275031] Iteration 16200, train loss = 0.135901, train accuracy = 1.000000\n",
      "[2018-07-16 18:54:38.934525] Iteration 16300, train loss = 0.141977, train accuracy = 1.000000\n",
      "[2018-07-16 18:54:44.592385] Iteration 16400, train loss = 0.135110, train accuracy = 1.000000\n",
      "[2018-07-16 18:54:50.250987] Iteration 16500, train loss = 0.142224, train accuracy = 0.992188\n",
      "[2018-07-16 18:54:55.906189] Iteration 16600, train loss = 0.142713, train accuracy = 0.992188\n",
      "[2018-07-16 18:55:01.553032] Iteration 16700, train loss = 0.137830, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:07.220861] Iteration 16800, train loss = 0.137872, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:12.883955] Iteration 16900, train loss = 0.136641, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:18.547673] Iteration 17000, train loss = 0.132937, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 18:55:25.883161] Iteration 17100, train loss = 0.147146, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:31.558995] Iteration 17200, train loss = 0.131182, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:37.234305] Iteration 17300, train loss = 0.131301, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:42.897462] Iteration 17400, train loss = 0.138871, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:48.541860] Iteration 17500, train loss = 0.136943, train accuracy = 1.000000\n",
      "[2018-07-16 18:55:54.206591] Iteration 17600, train loss = 0.141772, train accuracy = 0.992188\n",
      "[2018-07-16 18:55:59.864601] Iteration 17700, train loss = 0.129777, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:05.527610] Iteration 17800, train loss = 0.133884, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:11.190652] Iteration 17900, train loss = 0.137303, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:16.847497] Iteration 18000, train loss = 0.130997, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921100\n",
      "[2018-07-16 18:56:24.172586] Iteration 18100, train loss = 0.129722, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:29.829117] Iteration 18200, train loss = 0.143840, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:35.488742] Iteration 18300, train loss = 0.130779, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:41.146754] Iteration 18400, train loss = 0.134563, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:46.807034] Iteration 18500, train loss = 0.133816, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:52.467199] Iteration 18600, train loss = 0.134294, train accuracy = 1.000000\n",
      "[2018-07-16 18:56:58.130198] Iteration 18700, train loss = 0.135124, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:03.790795] Iteration 18800, train loss = 0.132236, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:09.445319] Iteration 18900, train loss = 0.132815, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:15.104185] Iteration 19000, train loss = 0.139040, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922200\n",
      "[2018-07-16 18:57:22.442116] Iteration 19100, train loss = 0.135764, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:28.099084] Iteration 19200, train loss = 0.140037, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:33.746225] Iteration 19300, train loss = 0.134250, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:39.406017] Iteration 19400, train loss = 0.137462, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:45.050907] Iteration 19500, train loss = 0.142454, train accuracy = 1.000000\n",
      "[2018-07-16 18:57:50.710882] Iteration 19600, train loss = 0.144185, train accuracy = 0.992188\n",
      "[2018-07-16 18:57:56.363572] Iteration 19700, train loss = 0.142121, train accuracy = 1.000000\n",
      "[2018-07-16 18:58:02.013086] Iteration 19800, train loss = 0.136305, train accuracy = 0.992188\n",
      "[2018-07-16 18:58:07.686916] Iteration 19900, train loss = 0.157976, train accuracy = 0.992188\n",
      "[2018-07-16 18:58:13.327925] Iteration 20000, train loss = 0.139963, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921000\n",
      "[2018-07-16 18:58:20.641166] Iteration 20100, train loss = 0.129737, train accuracy = 1.000000\n",
      "[2018-07-16 18:58:26.291577] Iteration 20200, train loss = 0.138312, train accuracy = 1.000000\n",
      "[2018-07-16 18:58:31.948148] Iteration 20300, train loss = 0.133749, train accuracy = 1.000000\n",
      "[2018-07-16 18:58:37.612945] Iteration 20400, train loss = 0.133362, train accuracy = 1.000000\n",
      "[2018-07-16 18:58:43.268425] Iteration 20500, train loss = 0.135445, train accuracy = 1.000000\n",
      "[2018-07-16 18:58:48.927997] Iteration 20600, train loss = 0.136318, train accuracy = 1.000000\n",
      "[2018-07-16 18:58:54.591437] Iteration 20700, train loss = 0.153005, train accuracy = 0.984375\n",
      "[2018-07-16 18:59:00.253538] Iteration 20800, train loss = 0.136320, train accuracy = 1.000000\n",
      "[2018-07-16 18:59:05.922578] Iteration 20900, train loss = 0.142468, train accuracy = 0.992188\n",
      "[2018-07-16 18:59:11.579385] Iteration 21000, train loss = 0.136624, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 18:59:18.919610] Iteration 21100, train loss = 0.132461, train accuracy = 1.000000\n",
      "[2018-07-16 18:59:24.577958] Iteration 21200, train loss = 0.142301, train accuracy = 1.000000\n",
      "[2018-07-16 18:59:30.236918] Iteration 21300, train loss = 0.140292, train accuracy = 0.992188\n",
      "[2018-07-16 18:59:35.884972] Iteration 21400, train loss = 0.142637, train accuracy = 1.000000\n",
      "[2018-07-16 18:59:41.544834] Iteration 21500, train loss = 0.129482, train accuracy = 1.000000\n",
      "[2018-07-16 18:59:47.205800] Iteration 21600, train loss = 0.143998, train accuracy = 0.992188\n",
      "[2018-07-16 18:59:52.865762] Iteration 21700, train loss = 0.135482, train accuracy = 1.000000\n",
      "[2018-07-16 18:59:58.527073] Iteration 21800, train loss = 0.145819, train accuracy = 0.992188\n",
      "[2018-07-16 19:00:04.181420] Iteration 21900, train loss = 0.137119, train accuracy = 1.000000\n",
      "[2018-07-16 19:00:09.835885] Iteration 22000, train loss = 0.133132, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922400\n",
      "[2018-07-16 19:00:17.179589] Iteration 22100, train loss = 0.134577, train accuracy = 1.000000\n",
      "[2018-07-16 19:00:22.838644] Iteration 22200, train loss = 0.145148, train accuracy = 0.992188\n",
      "[2018-07-16 19:00:28.489139] Iteration 22300, train loss = 0.133470, train accuracy = 1.000000\n",
      "[2018-07-16 19:00:34.161964] Iteration 22400, train loss = 0.131961, train accuracy = 1.000000\n",
      "[2018-07-16 19:00:39.820997] Iteration 22500, train loss = 0.132047, train accuracy = 1.000000\n",
      "[2018-07-16 19:00:45.475448] Iteration 22600, train loss = 0.150780, train accuracy = 0.992188\n",
      "[2018-07-16 19:00:51.137512] Iteration 22700, train loss = 0.140046, train accuracy = 1.000000\n",
      "[2018-07-16 19:00:56.799825] Iteration 22800, train loss = 0.135945, train accuracy = 1.000000\n",
      "[2018-07-16 19:01:02.464059] Iteration 22900, train loss = 0.161123, train accuracy = 0.992188\n",
      "[2018-07-16 19:01:08.134672] Iteration 23000, train loss = 0.138828, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 19:01:15.465012] Iteration 23100, train loss = 0.136936, train accuracy = 1.000000\n",
      "[2018-07-16 19:01:21.120838] Iteration 23200, train loss = 0.147965, train accuracy = 0.992188\n",
      "[2018-07-16 19:01:26.760300] Iteration 23300, train loss = 0.138585, train accuracy = 0.992188\n",
      "[2018-07-16 19:01:32.424373] Iteration 23400, train loss = 0.142528, train accuracy = 1.000000\n",
      "[2018-07-16 19:01:38.087229] Iteration 23500, train loss = 0.137248, train accuracy = 1.000000\n",
      "[2018-07-16 19:01:43.763789] Iteration 23600, train loss = 0.172603, train accuracy = 0.984375\n",
      "[2018-07-16 19:01:49.437777] Iteration 23700, train loss = 0.139565, train accuracy = 1.000000\n",
      "[2018-07-16 19:01:55.111332] Iteration 23800, train loss = 0.144661, train accuracy = 0.992188\n",
      "[2018-07-16 19:02:00.775441] Iteration 23900, train loss = 0.140843, train accuracy = 1.000000\n",
      "[2018-07-16 19:02:06.428913] Iteration 24000, train loss = 0.138662, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 19:02:13.755395] Iteration 24100, train loss = 0.134003, train accuracy = 1.000000\n",
      "[2018-07-16 19:02:19.422638] Iteration 24200, train loss = 0.149995, train accuracy = 1.000000\n",
      "[2018-07-16 19:02:25.075939] Iteration 24300, train loss = 0.151207, train accuracy = 0.992188\n",
      "[2018-07-16 19:02:30.747622] Iteration 24400, train loss = 0.131221, train accuracy = 1.000000\n",
      "[2018-07-16 19:02:36.410272] Iteration 24500, train loss = 0.142545, train accuracy = 0.992188\n",
      "[2018-07-16 19:02:42.075752] Iteration 24600, train loss = 0.150280, train accuracy = 0.992188\n",
      "[2018-07-16 19:02:47.733529] Iteration 24700, train loss = 0.137314, train accuracy = 1.000000\n",
      "[2018-07-16 19:02:53.401835] Iteration 24800, train loss = 0.131624, train accuracy = 1.000000\n",
      "[2018-07-16 19:02:59.085497] Iteration 24900, train loss = 0.133404, train accuracy = 1.000000\n",
      "[2018-07-16 19:03:04.750804] Iteration 25000, train loss = 0.138503, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921900\n",
      "[2018-07-16 19:03:12.075503] Iteration 25100, train loss = 0.143211, train accuracy = 0.992188\n",
      "[2018-07-16 19:03:17.727918] Iteration 25200, train loss = 0.136323, train accuracy = 1.000000\n",
      "[2018-07-16 19:03:23.391415] Iteration 25300, train loss = 0.137515, train accuracy = 1.000000\n",
      "[2018-07-16 19:03:29.059793] Iteration 25400, train loss = 0.132207, train accuracy = 1.000000\n",
      "[2018-07-16 19:03:34.726696] Iteration 25500, train loss = 0.142494, train accuracy = 0.992188\n",
      "[2018-07-16 19:03:40.377591] Iteration 25600, train loss = 0.131170, train accuracy = 1.000000\n",
      "[2018-07-16 19:03:46.027692] Iteration 25700, train loss = 0.136260, train accuracy = 1.000000\n",
      "[2018-07-16 19:03:51.684116] Iteration 25800, train loss = 0.140097, train accuracy = 1.000000\n",
      "[2018-07-16 19:03:57.331951] Iteration 25900, train loss = 0.131021, train accuracy = 1.000000\n",
      "[2018-07-16 19:04:02.982164] Iteration 26000, train loss = 0.139546, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 19:04:10.310313] Iteration 26100, train loss = 0.146036, train accuracy = 0.992188\n",
      "[2018-07-16 19:04:15.964336] Iteration 26200, train loss = 0.150367, train accuracy = 0.984375\n",
      "[2018-07-16 19:04:21.631343] Iteration 26300, train loss = 0.138884, train accuracy = 1.000000\n",
      "[2018-07-16 19:04:27.289611] Iteration 26400, train loss = 0.135193, train accuracy = 0.992188\n",
      "[2018-07-16 19:04:32.945772] Iteration 26500, train loss = 0.133031, train accuracy = 1.000000\n",
      "[2018-07-16 19:04:38.602662] Iteration 26600, train loss = 0.131548, train accuracy = 1.000000\n",
      "[2018-07-16 19:04:44.258687] Iteration 26700, train loss = 0.145788, train accuracy = 0.992188\n",
      "[2018-07-16 19:04:49.922201] Iteration 26800, train loss = 0.150883, train accuracy = 0.992188\n",
      "[2018-07-16 19:04:55.586037] Iteration 26900, train loss = 0.151892, train accuracy = 0.992188\n",
      "[2018-07-16 19:05:01.240041] Iteration 27000, train loss = 0.129816, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 19:05:08.589717] Iteration 27100, train loss = 0.132412, train accuracy = 1.000000\n",
      "[2018-07-16 19:05:14.246978] Iteration 27200, train loss = 0.136223, train accuracy = 1.000000\n",
      "[2018-07-16 19:05:19.918644] Iteration 27300, train loss = 0.132394, train accuracy = 1.000000\n",
      "[2018-07-16 19:05:25.587693] Iteration 27400, train loss = 0.155622, train accuracy = 0.992188\n",
      "[2018-07-16 19:05:31.237831] Iteration 27500, train loss = 0.161297, train accuracy = 0.992188\n",
      "[2018-07-16 19:05:36.902786] Iteration 27600, train loss = 0.134009, train accuracy = 1.000000\n",
      "[2018-07-16 19:05:42.563840] Iteration 27700, train loss = 0.133247, train accuracy = 1.000000\n",
      "[2018-07-16 19:05:48.228903] Iteration 27800, train loss = 0.141190, train accuracy = 1.000000\n",
      "[2018-07-16 19:05:53.889206] Iteration 27900, train loss = 0.133064, train accuracy = 1.000000\n",
      "[2018-07-16 19:05:59.540298] Iteration 28000, train loss = 0.136451, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-16 19:06:06.905269] Iteration 28100, train loss = 0.148787, train accuracy = 0.992188\n",
      "[2018-07-16 19:06:12.571360] Iteration 28200, train loss = 0.131638, train accuracy = 1.000000\n",
      "[2018-07-16 19:06:18.230500] Iteration 28300, train loss = 0.149150, train accuracy = 0.992188\n",
      "[2018-07-16 19:06:23.886623] Iteration 28400, train loss = 0.139254, train accuracy = 1.000000\n",
      "[2018-07-16 19:06:29.556693] Iteration 28500, train loss = 0.138446, train accuracy = 1.000000\n",
      "[2018-07-16 19:06:35.207890] Iteration 28600, train loss = 0.137169, train accuracy = 0.992188\n",
      "[2018-07-16 19:06:40.872148] Iteration 28700, train loss = 0.130532, train accuracy = 1.000000\n",
      "[2018-07-16 19:06:46.523403] Iteration 28800, train loss = 0.143377, train accuracy = 1.000000\n",
      "[2018-07-16 19:06:52.183020] Iteration 28900, train loss = 0.137002, train accuracy = 0.992188\n",
      "[2018-07-16 19:06:57.844529] Iteration 29000, train loss = 0.135347, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:07:05.166332] Iteration 29100, train loss = 0.134268, train accuracy = 1.000000\n",
      "[2018-07-16 19:07:10.841849] Iteration 29200, train loss = 0.140089, train accuracy = 1.000000\n",
      "[2018-07-16 19:07:16.505530] Iteration 29300, train loss = 0.138580, train accuracy = 1.000000\n",
      "[2018-07-16 19:07:22.163910] Iteration 29400, train loss = 0.145998, train accuracy = 0.992188\n",
      "[2018-07-16 19:07:27.828916] Iteration 29500, train loss = 0.143056, train accuracy = 0.984375\n",
      "[2018-07-16 19:07:33.493456] Iteration 29600, train loss = 0.130983, train accuracy = 1.000000\n",
      "[2018-07-16 19:07:39.158443] Iteration 29700, train loss = 0.154379, train accuracy = 0.992188\n",
      "[2018-07-16 19:07:44.808560] Iteration 29800, train loss = 0.137841, train accuracy = 1.000000\n",
      "[2018-07-16 19:07:50.461057] Iteration 29900, train loss = 0.140355, train accuracy = 1.000000\n",
      "[2018-07-16 19:07:56.117987] Iteration 30000, train loss = 0.131737, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922600\n",
      "[2018-07-16 19:08:03.463342] Iteration 30100, train loss = 0.131085, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:09.117768] Iteration 30200, train loss = 0.131619, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:14.782824] Iteration 30300, train loss = 0.141367, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:20.427853] Iteration 30400, train loss = 0.132156, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:26.088004] Iteration 30500, train loss = 0.143275, train accuracy = 0.992188\n",
      "[2018-07-16 19:08:31.737535] Iteration 30600, train loss = 0.133044, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:37.397931] Iteration 30700, train loss = 0.137571, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:43.055181] Iteration 30800, train loss = 0.133148, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:48.718067] Iteration 30900, train loss = 0.137462, train accuracy = 1.000000\n",
      "[2018-07-16 19:08:54.376540] Iteration 31000, train loss = 0.133057, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921600\n",
      "[2018-07-16 19:09:01.712536] Iteration 31100, train loss = 0.131993, train accuracy = 1.000000\n",
      "[2018-07-16 19:09:07.369902] Iteration 31200, train loss = 0.133224, train accuracy = 1.000000\n",
      "[2018-07-16 19:09:13.043020] Iteration 31300, train loss = 0.163570, train accuracy = 0.992188\n",
      "[2018-07-16 19:09:18.723822] Iteration 31400, train loss = 0.136858, train accuracy = 1.000000\n",
      "[2018-07-16 19:09:24.387146] Iteration 31500, train loss = 0.137109, train accuracy = 0.992188\n",
      "[2018-07-16 19:09:30.045737] Iteration 31600, train loss = 0.154489, train accuracy = 0.992188\n",
      "[2018-07-16 19:09:35.703001] Iteration 31700, train loss = 0.133149, train accuracy = 1.000000\n",
      "[2018-07-16 19:09:41.365119] Iteration 31800, train loss = 0.141357, train accuracy = 0.992188\n",
      "[2018-07-16 19:09:47.018218] Iteration 31900, train loss = 0.146759, train accuracy = 0.992188\n",
      "[2018-07-16 19:09:52.682430] Iteration 32000, train loss = 0.140144, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921600\n",
      "[2018-07-16 19:10:00.024817] Iteration 32100, train loss = 0.136086, train accuracy = 1.000000\n",
      "[2018-07-16 19:10:05.676617] Iteration 32200, train loss = 0.143925, train accuracy = 0.992188\n",
      "[2018-07-16 19:10:11.338344] Iteration 32300, train loss = 0.145452, train accuracy = 0.992188\n",
      "[2018-07-16 19:10:17.009314] Iteration 32400, train loss = 0.138301, train accuracy = 1.000000\n",
      "[2018-07-16 19:10:22.685077] Iteration 32500, train loss = 0.133658, train accuracy = 1.000000\n",
      "[2018-07-16 19:10:28.338699] Iteration 32600, train loss = 0.132272, train accuracy = 1.000000\n",
      "[2018-07-16 19:10:33.995818] Iteration 32700, train loss = 0.135553, train accuracy = 1.000000\n",
      "[2018-07-16 19:10:39.662617] Iteration 32800, train loss = 0.153061, train accuracy = 0.992188\n",
      "[2018-07-16 19:10:45.323609] Iteration 32900, train loss = 0.143247, train accuracy = 0.992188\n",
      "[2018-07-16 19:10:50.980530] Iteration 33000, train loss = 0.133356, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 19:10:58.324593] Iteration 33100, train loss = 0.161816, train accuracy = 0.976562\n",
      "[2018-07-16 19:11:03.971361] Iteration 33200, train loss = 0.136329, train accuracy = 1.000000\n",
      "[2018-07-16 19:11:09.624190] Iteration 33300, train loss = 0.129682, train accuracy = 1.000000\n",
      "[2018-07-16 19:11:15.279917] Iteration 33400, train loss = 0.149410, train accuracy = 1.000000\n",
      "[2018-07-16 19:11:20.944317] Iteration 33500, train loss = 0.142818, train accuracy = 1.000000\n",
      "[2018-07-16 19:11:26.602832] Iteration 33600, train loss = 0.146498, train accuracy = 0.992188\n",
      "[2018-07-16 19:11:32.266764] Iteration 33700, train loss = 0.130194, train accuracy = 1.000000\n",
      "[2018-07-16 19:11:37.935598] Iteration 33800, train loss = 0.131244, train accuracy = 1.000000\n",
      "[2018-07-16 19:11:43.590539] Iteration 33900, train loss = 0.145745, train accuracy = 0.992188\n",
      "[2018-07-16 19:11:49.258429] Iteration 34000, train loss = 0.136167, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923600\n",
      "[2018-07-16 19:11:56.615777] Iteration 34100, train loss = 0.137059, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:02.287063] Iteration 34200, train loss = 0.135188, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:07.945527] Iteration 34300, train loss = 0.138272, train accuracy = 0.992188\n",
      "[2018-07-16 19:12:13.592366] Iteration 34400, train loss = 0.138014, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:19.244877] Iteration 34500, train loss = 0.132056, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:24.940254] Iteration 34600, train loss = 0.132690, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:30.601560] Iteration 34700, train loss = 0.130758, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:36.259424] Iteration 34800, train loss = 0.133732, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:41.918157] Iteration 34900, train loss = 0.130765, train accuracy = 1.000000\n",
      "[2018-07-16 19:12:47.578468] Iteration 35000, train loss = 0.133454, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:12:54.908591] Iteration 35100, train loss = 0.140720, train accuracy = 1.000000\n",
      "[2018-07-16 19:13:00.565995] Iteration 35200, train loss = 0.139424, train accuracy = 1.000000\n",
      "[2018-07-16 19:13:06.216977] Iteration 35300, train loss = 0.135727, train accuracy = 1.000000\n",
      "[2018-07-16 19:13:11.876493] Iteration 35400, train loss = 0.134816, train accuracy = 1.000000\n",
      "[2018-07-16 19:13:17.525422] Iteration 35500, train loss = 0.138537, train accuracy = 1.000000\n",
      "[2018-07-16 19:13:23.174782] Iteration 35600, train loss = 0.145793, train accuracy = 0.992188\n",
      "[2018-07-16 19:13:28.834832] Iteration 35700, train loss = 0.154808, train accuracy = 0.984375\n",
      "[2018-07-16 19:13:34.495652] Iteration 35800, train loss = 0.133824, train accuracy = 1.000000\n",
      "[2018-07-16 19:13:40.154651] Iteration 35900, train loss = 0.136428, train accuracy = 1.000000\n",
      "[2018-07-16 19:13:45.812669] Iteration 36000, train loss = 0.133134, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921400\n",
      "[2018-07-16 19:13:53.158498] Iteration 36100, train loss = 0.140290, train accuracy = 0.992188\n",
      "[2018-07-16 19:13:58.802976] Iteration 36200, train loss = 0.140381, train accuracy = 1.000000\n",
      "[2018-07-16 19:14:04.461369] Iteration 36300, train loss = 0.143008, train accuracy = 0.992188\n",
      "[2018-07-16 19:14:10.126703] Iteration 36400, train loss = 0.132394, train accuracy = 1.000000\n",
      "[2018-07-16 19:14:15.788457] Iteration 36500, train loss = 0.157614, train accuracy = 0.992188\n",
      "[2018-07-16 19:14:21.434672] Iteration 36600, train loss = 0.133293, train accuracy = 1.000000\n",
      "[2018-07-16 19:14:27.095714] Iteration 36700, train loss = 0.139984, train accuracy = 0.992188\n",
      "[2018-07-16 19:14:32.779751] Iteration 36800, train loss = 0.149440, train accuracy = 0.992188\n",
      "[2018-07-16 19:14:38.439227] Iteration 36900, train loss = 0.145638, train accuracy = 0.992188\n",
      "[2018-07-16 19:14:44.083417] Iteration 37000, train loss = 0.136434, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920800\n",
      "[2018-07-16 19:14:51.419032] Iteration 37100, train loss = 0.132651, train accuracy = 1.000000\n",
      "[2018-07-16 19:14:57.081755] Iteration 37200, train loss = 0.137907, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:02.723194] Iteration 37300, train loss = 0.147527, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:08.377738] Iteration 37400, train loss = 0.130913, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:14.023723] Iteration 37500, train loss = 0.133630, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:19.698315] Iteration 37600, train loss = 0.133722, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:25.345024] Iteration 37700, train loss = 0.147169, train accuracy = 0.992188\n",
      "[2018-07-16 19:15:31.010959] Iteration 37800, train loss = 0.134880, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:36.680843] Iteration 37900, train loss = 0.137411, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:42.344466] Iteration 38000, train loss = 0.132587, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921200\n",
      "[2018-07-16 19:15:49.670006] Iteration 38100, train loss = 0.141762, train accuracy = 1.000000\n",
      "[2018-07-16 19:15:55.333813] Iteration 38200, train loss = 0.141043, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:00.991857] Iteration 38300, train loss = 0.134262, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:06.642414] Iteration 38400, train loss = 0.130204, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:12.308365] Iteration 38500, train loss = 0.140108, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:17.964278] Iteration 38600, train loss = 0.139885, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:23.625018] Iteration 38700, train loss = 0.130293, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:29.290281] Iteration 38800, train loss = 0.135321, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:34.941004] Iteration 38900, train loss = 0.143525, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:40.599068] Iteration 39000, train loss = 0.152999, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922500\n",
      "[2018-07-16 19:16:47.956228] Iteration 39100, train loss = 0.137207, train accuracy = 1.000000\n",
      "[2018-07-16 19:16:53.616761] Iteration 39200, train loss = 0.144661, train accuracy = 0.992188\n",
      "[2018-07-16 19:16:59.277791] Iteration 39300, train loss = 0.137489, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:04.933740] Iteration 39400, train loss = 0.131754, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:10.595887] Iteration 39500, train loss = 0.136885, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:16.257013] Iteration 39600, train loss = 0.132082, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:21.913662] Iteration 39700, train loss = 0.130551, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:27.566613] Iteration 39800, train loss = 0.131790, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:33.215271] Iteration 39900, train loss = 0.135991, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:38.878046] Iteration 40000, train loss = 0.133247, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.924600\n",
      "[2018-07-16 19:17:46.211205] Iteration 40100, train loss = 0.133182, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:51.869046] Iteration 40200, train loss = 0.130715, train accuracy = 1.000000\n",
      "[2018-07-16 19:17:57.529002] Iteration 40300, train loss = 0.139225, train accuracy = 1.000000\n",
      "[2018-07-16 19:18:03.184836] Iteration 40400, train loss = 0.136818, train accuracy = 1.000000\n",
      "[2018-07-16 19:18:08.830423] Iteration 40500, train loss = 0.138215, train accuracy = 1.000000\n",
      "[2018-07-16 19:18:14.499177] Iteration 40600, train loss = 0.136012, train accuracy = 1.000000\n",
      "[2018-07-16 19:18:20.163628] Iteration 40700, train loss = 0.148107, train accuracy = 0.992188\n",
      "[2018-07-16 19:18:25.826005] Iteration 40800, train loss = 0.132037, train accuracy = 1.000000\n",
      "[2018-07-16 19:18:31.489501] Iteration 40900, train loss = 0.130875, train accuracy = 1.000000\n",
      "[2018-07-16 19:18:37.139421] Iteration 41000, train loss = 0.135569, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 19:18:44.488284] Iteration 41100, train loss = 0.145236, train accuracy = 0.992188\n",
      "[2018-07-16 19:18:50.147932] Iteration 41200, train loss = 0.157152, train accuracy = 0.992188\n",
      "[2018-07-16 19:18:55.807033] Iteration 41300, train loss = 0.149135, train accuracy = 0.992188\n",
      "[2018-07-16 19:19:01.460037] Iteration 41400, train loss = 0.142735, train accuracy = 0.992188\n",
      "[2018-07-16 19:19:07.121140] Iteration 41500, train loss = 0.147093, train accuracy = 0.992188\n",
      "[2018-07-16 19:19:12.775957] Iteration 41600, train loss = 0.134361, train accuracy = 1.000000\n",
      "[2018-07-16 19:19:18.432661] Iteration 41700, train loss = 0.134162, train accuracy = 1.000000\n",
      "[2018-07-16 19:19:24.082306] Iteration 41800, train loss = 0.136276, train accuracy = 1.000000\n",
      "[2018-07-16 19:19:29.744582] Iteration 41900, train loss = 0.132196, train accuracy = 1.000000\n",
      "[2018-07-16 19:19:35.398210] Iteration 42000, train loss = 0.130969, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923800\n",
      "[2018-07-16 19:19:42.739819] Iteration 42100, train loss = 0.144568, train accuracy = 0.992188\n",
      "[2018-07-16 19:19:48.399520] Iteration 42200, train loss = 0.133512, train accuracy = 1.000000\n",
      "[2018-07-16 19:19:54.060562] Iteration 42300, train loss = 0.132233, train accuracy = 1.000000\n",
      "[2018-07-16 19:19:59.720960] Iteration 42400, train loss = 0.179791, train accuracy = 0.984375\n",
      "[2018-07-16 19:20:05.382997] Iteration 42500, train loss = 0.134518, train accuracy = 1.000000\n",
      "[2018-07-16 19:20:11.041702] Iteration 42600, train loss = 0.144311, train accuracy = 0.992188\n",
      "[2018-07-16 19:20:16.702750] Iteration 42700, train loss = 0.132821, train accuracy = 1.000000\n",
      "[2018-07-16 19:20:22.370965] Iteration 42800, train loss = 0.130011, train accuracy = 1.000000\n",
      "[2018-07-16 19:20:28.033964] Iteration 42900, train loss = 0.142795, train accuracy = 0.992188\n",
      "[2018-07-16 19:20:33.691530] Iteration 43000, train loss = 0.130979, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 19:20:41.028955] Iteration 43100, train loss = 0.137512, train accuracy = 1.000000\n",
      "[2018-07-16 19:20:46.673205] Iteration 43200, train loss = 0.140944, train accuracy = 1.000000\n",
      "[2018-07-16 19:20:52.333258] Iteration 43300, train loss = 0.130850, train accuracy = 1.000000\n",
      "[2018-07-16 19:20:57.987852] Iteration 43400, train loss = 0.138999, train accuracy = 0.992188\n",
      "[2018-07-16 19:21:03.651845] Iteration 43500, train loss = 0.132897, train accuracy = 1.000000\n",
      "[2018-07-16 19:21:09.308866] Iteration 43600, train loss = 0.136671, train accuracy = 1.000000\n",
      "[2018-07-16 19:21:14.970398] Iteration 43700, train loss = 0.132280, train accuracy = 1.000000\n",
      "[2018-07-16 19:21:20.633976] Iteration 43800, train loss = 0.149242, train accuracy = 0.992188\n",
      "[2018-07-16 19:21:26.281979] Iteration 43900, train loss = 0.135761, train accuracy = 1.000000\n",
      "[2018-07-16 19:21:31.931128] Iteration 44000, train loss = 0.132274, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922900\n",
      "[2018-07-16 19:21:39.262273] Iteration 44100, train loss = 0.131519, train accuracy = 1.000000\n",
      "[2018-07-16 19:21:44.927976] Iteration 44200, train loss = 0.130064, train accuracy = 1.000000\n",
      "[2018-07-16 19:21:50.600265] Iteration 44300, train loss = 0.136874, train accuracy = 1.000000\n",
      "[2018-07-16 19:21:56.257947] Iteration 44400, train loss = 0.135957, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:01.918029] Iteration 44500, train loss = 0.141818, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:07.578643] Iteration 44600, train loss = 0.145762, train accuracy = 0.992188\n",
      "[2018-07-16 19:22:13.248271] Iteration 44700, train loss = 0.134674, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:18.919717] Iteration 44800, train loss = 0.128957, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:24.577670] Iteration 44900, train loss = 0.134292, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:30.231795] Iteration 45000, train loss = 0.133593, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920800\n",
      "[2018-07-16 19:22:37.565523] Iteration 45100, train loss = 0.135891, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:43.219636] Iteration 45200, train loss = 0.143922, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:48.894526] Iteration 45300, train loss = 0.138456, train accuracy = 1.000000\n",
      "[2018-07-16 19:22:54.550472] Iteration 45400, train loss = 0.148966, train accuracy = 0.992188\n",
      "[2018-07-16 19:23:00.209280] Iteration 45500, train loss = 0.137778, train accuracy = 1.000000\n",
      "[2018-07-16 19:23:05.866021] Iteration 45600, train loss = 0.134159, train accuracy = 1.000000\n",
      "[2018-07-16 19:23:11.521374] Iteration 45700, train loss = 0.142178, train accuracy = 0.992188\n",
      "[2018-07-16 19:23:17.170721] Iteration 45800, train loss = 0.130868, train accuracy = 1.000000\n",
      "[2018-07-16 19:23:22.824383] Iteration 45900, train loss = 0.133361, train accuracy = 1.000000\n",
      "[2018-07-16 19:23:28.481970] Iteration 46000, train loss = 0.134133, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923900\n",
      "[2018-07-16 19:23:35.810752] Iteration 46100, train loss = 0.143755, train accuracy = 0.992188\n",
      "[2018-07-16 19:23:41.472085] Iteration 46200, train loss = 0.132711, train accuracy = 1.000000\n",
      "[2018-07-16 19:23:47.132335] Iteration 46300, train loss = 0.136638, train accuracy = 1.000000\n",
      "[2018-07-16 19:23:52.786062] Iteration 46400, train loss = 0.151512, train accuracy = 0.992188\n",
      "[2018-07-16 19:23:58.445331] Iteration 46500, train loss = 0.137055, train accuracy = 1.000000\n",
      "[2018-07-16 19:24:04.104781] Iteration 46600, train loss = 0.138764, train accuracy = 1.000000\n",
      "[2018-07-16 19:24:09.765675] Iteration 46700, train loss = 0.133914, train accuracy = 1.000000\n",
      "[2018-07-16 19:24:15.424181] Iteration 46800, train loss = 0.149166, train accuracy = 0.992188\n",
      "[2018-07-16 19:24:21.085228] Iteration 46900, train loss = 0.130336, train accuracy = 1.000000\n",
      "[2018-07-16 19:24:26.736802] Iteration 47000, train loss = 0.135358, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922200\n",
      "[2018-07-16 19:24:34.086181] Iteration 47100, train loss = 0.136149, train accuracy = 1.000000\n",
      "[2018-07-16 19:24:39.729778] Iteration 47200, train loss = 0.140751, train accuracy = 1.000000\n",
      "[2018-07-16 19:24:45.387866] Iteration 47300, train loss = 0.132936, train accuracy = 1.000000\n",
      "[2018-07-16 19:24:51.039308] Iteration 47400, train loss = 0.137535, train accuracy = 0.992188\n",
      "[2018-07-16 19:24:56.701119] Iteration 47500, train loss = 0.136677, train accuracy = 1.000000\n",
      "[2018-07-16 19:25:02.329247] Iteration 47600, train loss = 0.156338, train accuracy = 0.984375\n",
      "[2018-07-16 19:25:07.997634] Iteration 47700, train loss = 0.134463, train accuracy = 1.000000\n",
      "[2018-07-16 19:25:13.658021] Iteration 47800, train loss = 0.138886, train accuracy = 1.000000\n",
      "[2018-07-16 19:25:19.327839] Iteration 47900, train loss = 0.150402, train accuracy = 0.992188\n",
      "[2018-07-16 19:25:24.984993] Iteration 48000, train loss = 0.131947, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923100\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-16 19:25:32.304966] Iteration 48100, train loss = 0.138964, train accuracy = 0.992188\n",
      "[2018-07-16 19:25:37.971062] Iteration 48200, train loss = 0.131615, train accuracy = 1.000000\n",
      "[2018-07-16 19:25:43.626164] Iteration 48300, train loss = 0.134163, train accuracy = 1.000000\n",
      "[2018-07-16 19:25:49.281399] Iteration 48400, train loss = 0.139914, train accuracy = 1.000000\n",
      "[2018-07-16 19:25:54.935970] Iteration 48500, train loss = 0.133342, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:00.597880] Iteration 48600, train loss = 0.131463, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:06.245010] Iteration 48700, train loss = 0.136025, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:11.907073] Iteration 48800, train loss = 0.131123, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:17.560068] Iteration 48900, train loss = 0.138616, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:23.231083] Iteration 49000, train loss = 0.131332, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923300\n",
      "[2018-07-16 19:26:30.553435] Iteration 49100, train loss = 0.146202, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:36.218632] Iteration 49200, train loss = 0.131149, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:41.882166] Iteration 49300, train loss = 0.132524, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:47.542604] Iteration 49400, train loss = 0.142907, train accuracy = 0.992188\n",
      "[2018-07-16 19:26:53.214266] Iteration 49500, train loss = 0.131379, train accuracy = 1.000000\n",
      "[2018-07-16 19:26:58.858940] Iteration 49600, train loss = 0.141801, train accuracy = 1.000000\n",
      "[2018-07-16 19:27:04.505489] Iteration 49700, train loss = 0.135219, train accuracy = 1.000000\n",
      "[2018-07-16 19:27:10.163714] Iteration 49800, train loss = 0.132318, train accuracy = 1.000000\n",
      "[2018-07-16 19:27:15.810249] Iteration 49900, train loss = 0.131370, train accuracy = 1.000000\n",
      "[2018-07-16 19:27:21.452689] Iteration 50000, train loss = 0.134022, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923100\n",
      "[2018-07-16 19:27:28.789559] Iteration 50100, train loss = 0.132140, train accuracy = 1.000000\n",
      "[2018-07-16 19:27:34.450579] Iteration 50200, train loss = 0.133203, train accuracy = 1.000000\n",
      "[2018-07-16 19:27:40.102401] Iteration 50300, train loss = 0.159996, train accuracy = 0.984375\n",
      "[2018-07-16 19:27:45.766037] Iteration 50400, train loss = 0.139028, train accuracy = 1.000000\n",
      "[2018-07-16 19:27:51.416489] Iteration 50500, train loss = 0.159890, train accuracy = 0.992188\n",
      "[2018-07-16 19:27:57.072430] Iteration 50600, train loss = 0.133778, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:02.716247] Iteration 50700, train loss = 0.136310, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:08.380799] Iteration 50800, train loss = 0.135568, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:14.040708] Iteration 50900, train loss = 0.131868, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:19.703682] Iteration 51000, train loss = 0.130548, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922300\n",
      "[2018-07-16 19:28:27.017607] Iteration 51100, train loss = 0.138208, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:32.673536] Iteration 51200, train loss = 0.142591, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:38.336273] Iteration 51300, train loss = 0.164058, train accuracy = 0.984375\n",
      "[2018-07-16 19:28:44.009503] Iteration 51400, train loss = 0.140287, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:49.649973] Iteration 51500, train loss = 0.131431, train accuracy = 1.000000\n",
      "[2018-07-16 19:28:55.306610] Iteration 51600, train loss = 0.132899, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:00.952712] Iteration 51700, train loss = 0.144110, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:06.611863] Iteration 51800, train loss = 0.135706, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:12.282301] Iteration 51900, train loss = 0.140099, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:17.942473] Iteration 52000, train loss = 0.133844, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 19:29:25.277150] Iteration 52100, train loss = 0.136635, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:30.929194] Iteration 52200, train loss = 0.131915, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:36.585155] Iteration 52300, train loss = 0.132288, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:42.248993] Iteration 52400, train loss = 0.130181, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:47.911918] Iteration 52500, train loss = 0.139414, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:53.561546] Iteration 52600, train loss = 0.133453, train accuracy = 1.000000\n",
      "[2018-07-16 19:29:59.212391] Iteration 52700, train loss = 0.133456, train accuracy = 1.000000\n",
      "[2018-07-16 19:30:04.854789] Iteration 52800, train loss = 0.147311, train accuracy = 0.992188\n",
      "[2018-07-16 19:30:10.503826] Iteration 52900, train loss = 0.134994, train accuracy = 1.000000\n",
      "[2018-07-16 19:30:16.145383] Iteration 53000, train loss = 0.160595, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.922500\n",
      "[2018-07-16 19:30:23.492697] Iteration 53100, train loss = 0.152102, train accuracy = 0.984375\n",
      "[2018-07-16 19:30:29.155332] Iteration 53200, train loss = 0.131107, train accuracy = 1.000000\n",
      "[2018-07-16 19:30:34.802115] Iteration 53300, train loss = 0.131938, train accuracy = 1.000000\n",
      "[2018-07-16 19:30:40.456291] Iteration 53400, train loss = 0.133511, train accuracy = 1.000000\n",
      "[2018-07-16 19:30:46.120117] Iteration 53500, train loss = 0.138843, train accuracy = 1.000000\n",
      "[2018-07-16 19:30:51.778894] Iteration 53600, train loss = 0.135371, train accuracy = 1.000000\n",
      "[2018-07-16 19:30:57.440742] Iteration 53700, train loss = 0.136998, train accuracy = 1.000000\n",
      "[2018-07-16 19:31:03.092589] Iteration 53800, train loss = 0.131827, train accuracy = 1.000000\n",
      "[2018-07-16 19:31:08.745067] Iteration 53900, train loss = 0.137056, train accuracy = 1.000000\n",
      "[2018-07-16 19:31:14.399966] Iteration 54000, train loss = 0.140624, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 19:31:21.719235] Iteration 54100, train loss = 0.145859, train accuracy = 0.992188\n",
      "[2018-07-16 19:31:27.366213] Iteration 54200, train loss = 0.136847, train accuracy = 1.000000\n",
      "[2018-07-16 19:31:33.018010] Iteration 54300, train loss = 0.130440, train accuracy = 1.000000\n",
      "[2018-07-16 19:31:38.665909] Iteration 54400, train loss = 0.136214, train accuracy = 1.000000\n",
      "[2018-07-16 19:31:44.318810] Iteration 54500, train loss = 0.132056, train accuracy = 1.000000\n",
      "[2018-07-16 19:31:49.984431] Iteration 54600, train loss = 0.142226, train accuracy = 0.992188\n",
      "[2018-07-16 19:31:55.636101] Iteration 54700, train loss = 0.135360, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:01.281977] Iteration 54800, train loss = 0.129752, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:06.939425] Iteration 54900, train loss = 0.131281, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:12.593823] Iteration 55000, train loss = 0.138756, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922600\n",
      "[2018-07-16 19:32:19.939616] Iteration 55100, train loss = 0.133529, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:25.593107] Iteration 55200, train loss = 0.137108, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:31.249069] Iteration 55300, train loss = 0.146233, train accuracy = 0.992188\n",
      "[2018-07-16 19:32:36.919401] Iteration 55400, train loss = 0.130736, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:42.573285] Iteration 55500, train loss = 0.131389, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:48.246124] Iteration 55600, train loss = 0.140580, train accuracy = 0.992188\n",
      "[2018-07-16 19:32:53.904945] Iteration 55700, train loss = 0.130818, train accuracy = 1.000000\n",
      "[2018-07-16 19:32:59.562685] Iteration 55800, train loss = 0.131596, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:05.220556] Iteration 55900, train loss = 0.139015, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:10.874033] Iteration 56000, train loss = 0.133851, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921400\n",
      "[2018-07-16 19:33:18.209247] Iteration 56100, train loss = 0.132022, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:23.859405] Iteration 56200, train loss = 0.130220, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:29.545363] Iteration 56300, train loss = 0.136112, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:35.198441] Iteration 56400, train loss = 0.142406, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:40.868023] Iteration 56500, train loss = 0.139516, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:46.544411] Iteration 56600, train loss = 0.147875, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:52.204479] Iteration 56700, train loss = 0.133135, train accuracy = 1.000000\n",
      "[2018-07-16 19:33:57.859495] Iteration 56800, train loss = 0.139199, train accuracy = 0.992188\n",
      "[2018-07-16 19:34:03.516741] Iteration 56900, train loss = 0.144730, train accuracy = 1.000000\n",
      "[2018-07-16 19:34:09.165125] Iteration 57000, train loss = 0.143468, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921900\n",
      "[2018-07-16 19:34:16.510380] Iteration 57100, train loss = 0.135079, train accuracy = 1.000000\n",
      "[2018-07-16 19:34:22.163476] Iteration 57200, train loss = 0.141951, train accuracy = 0.992188\n",
      "[2018-07-16 19:34:27.805953] Iteration 57300, train loss = 0.142309, train accuracy = 0.992188\n",
      "[2018-07-16 19:34:33.447982] Iteration 57400, train loss = 0.133109, train accuracy = 1.000000\n",
      "[2018-07-16 19:34:39.117846] Iteration 57500, train loss = 0.133039, train accuracy = 1.000000\n",
      "[2018-07-16 19:34:44.765336] Iteration 57600, train loss = 0.135101, train accuracy = 1.000000\n",
      "[2018-07-16 19:34:50.423171] Iteration 57700, train loss = 0.134428, train accuracy = 1.000000\n",
      "[2018-07-16 19:34:56.081131] Iteration 57800, train loss = 0.131418, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:01.743831] Iteration 57900, train loss = 0.129578, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:07.403685] Iteration 58000, train loss = 0.139291, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921600\n",
      "[2018-07-16 19:35:14.718554] Iteration 58100, train loss = 0.130137, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:20.371551] Iteration 58200, train loss = 0.132493, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:26.030984] Iteration 58300, train loss = 0.130850, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:31.711022] Iteration 58400, train loss = 0.131643, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:37.375246] Iteration 58500, train loss = 0.134587, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:43.019414] Iteration 58600, train loss = 0.141163, train accuracy = 0.992188\n",
      "[2018-07-16 19:35:48.672658] Iteration 58700, train loss = 0.131526, train accuracy = 1.000000\n",
      "[2018-07-16 19:35:54.333296] Iteration 58800, train loss = 0.132576, train accuracy = 1.000000\n",
      "[2018-07-16 19:36:00.016649] Iteration 58900, train loss = 0.163408, train accuracy = 0.992188\n",
      "[2018-07-16 19:36:05.673121] Iteration 59000, train loss = 0.141482, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 19:36:13.012923] Iteration 59100, train loss = 0.131853, train accuracy = 1.000000\n",
      "[2018-07-16 19:36:18.681725] Iteration 59200, train loss = 0.136711, train accuracy = 1.000000\n",
      "[2018-07-16 19:36:24.346138] Iteration 59300, train loss = 0.140396, train accuracy = 0.992188\n",
      "[2018-07-16 19:36:30.001613] Iteration 59400, train loss = 0.130077, train accuracy = 1.000000\n",
      "[2018-07-16 19:36:35.649358] Iteration 59500, train loss = 0.142469, train accuracy = 0.992188\n",
      "[2018-07-16 19:36:41.302868] Iteration 59600, train loss = 0.143894, train accuracy = 0.992188\n",
      "[2018-07-16 19:36:46.954284] Iteration 59700, train loss = 0.147734, train accuracy = 0.992188\n",
      "[2018-07-16 19:36:52.610763] Iteration 59800, train loss = 0.135005, train accuracy = 1.000000\n",
      "[2018-07-16 19:36:58.274042] Iteration 59900, train loss = 0.142027, train accuracy = 0.992188\n",
      "[2018-07-16 19:37:03.936868] Iteration 60000, train loss = 0.130821, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922400\n",
      "[2018-07-16 19:37:11.280481] Iteration 60100, train loss = 0.145694, train accuracy = 0.992188\n",
      "[2018-07-16 19:37:16.925707] Iteration 60200, train loss = 0.133601, train accuracy = 1.000000\n",
      "[2018-07-16 19:37:22.576056] Iteration 60300, train loss = 0.142428, train accuracy = 1.000000\n",
      "[2018-07-16 19:37:28.223750] Iteration 60400, train loss = 0.137122, train accuracy = 1.000000\n",
      "[2018-07-16 19:37:33.889865] Iteration 60500, train loss = 0.129354, train accuracy = 1.000000\n",
      "[2018-07-16 19:37:39.549830] Iteration 60600, train loss = 0.145050, train accuracy = 0.992188\n",
      "[2018-07-16 19:37:45.217286] Iteration 60700, train loss = 0.136397, train accuracy = 1.000000\n",
      "[2018-07-16 19:37:50.872654] Iteration 60800, train loss = 0.132017, train accuracy = 1.000000\n",
      "[2018-07-16 19:37:56.539085] Iteration 60900, train loss = 0.153562, train accuracy = 0.984375\n",
      "[2018-07-16 19:38:02.193406] Iteration 61000, train loss = 0.138554, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921500\n",
      "[2018-07-16 19:38:09.524668] Iteration 61100, train loss = 0.134570, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:15.187202] Iteration 61200, train loss = 0.131325, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:20.844827] Iteration 61300, train loss = 0.133003, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:26.519855] Iteration 61400, train loss = 0.136842, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:32.178848] Iteration 61500, train loss = 0.138048, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:37.835661] Iteration 61600, train loss = 0.133166, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:43.485482] Iteration 61700, train loss = 0.134117, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:49.143537] Iteration 61800, train loss = 0.135192, train accuracy = 1.000000\n",
      "[2018-07-16 19:38:54.800134] Iteration 61900, train loss = 0.129634, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:00.471024] Iteration 62000, train loss = 0.135446, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.922100\n",
      "[2018-07-16 19:39:07.795191] Iteration 62100, train loss = 0.134284, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:13.454898] Iteration 62200, train loss = 0.133612, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:19.107446] Iteration 62300, train loss = 0.133310, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:24.761095] Iteration 62400, train loss = 0.133276, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:30.411677] Iteration 62500, train loss = 0.132515, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:36.054346] Iteration 62600, train loss = 0.134195, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:41.715208] Iteration 62700, train loss = 0.133743, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:47.369065] Iteration 62800, train loss = 0.142644, train accuracy = 0.992188\n",
      "[2018-07-16 19:39:53.026085] Iteration 62900, train loss = 0.130447, train accuracy = 1.000000\n",
      "[2018-07-16 19:39:58.688767] Iteration 63000, train loss = 0.133629, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 19:40:06.032721] Iteration 63100, train loss = 0.140970, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:11.685212] Iteration 63200, train loss = 0.131104, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:17.349471] Iteration 63300, train loss = 0.132869, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:23.019716] Iteration 63400, train loss = 0.133213, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:28.678227] Iteration 63500, train loss = 0.130365, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:34.328377] Iteration 63600, train loss = 0.130970, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:39.976362] Iteration 63700, train loss = 0.135677, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:45.618027] Iteration 63800, train loss = 0.137747, train accuracy = 0.992188\n",
      "[2018-07-16 19:40:51.247319] Iteration 63900, train loss = 0.132516, train accuracy = 1.000000\n",
      "[2018-07-16 19:40:56.893656] Iteration 64000, train loss = 0.131882, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:41:04.224475] Iteration 64100, train loss = 0.130188, train accuracy = 1.000000\n",
      "[2018-07-16 19:41:09.872175] Iteration 64200, train loss = 0.152309, train accuracy = 0.984375\n",
      "[2018-07-16 19:41:15.525944] Iteration 64300, train loss = 0.134397, train accuracy = 1.000000\n",
      "[2018-07-16 19:41:21.186784] Iteration 64400, train loss = 0.132908, train accuracy = 1.000000\n",
      "[2018-07-16 19:41:26.843161] Iteration 64500, train loss = 0.131228, train accuracy = 1.000000\n",
      "[2018-07-16 19:41:32.505605] Iteration 64600, train loss = 0.148950, train accuracy = 0.992188\n",
      "[2018-07-16 19:41:38.167929] Iteration 64700, train loss = 0.135271, train accuracy = 1.000000\n",
      "[2018-07-16 19:41:43.822634] Iteration 64800, train loss = 0.129807, train accuracy = 1.000000\n",
      "[2018-07-16 19:41:49.482538] Iteration 64900, train loss = 0.140993, train accuracy = 1.000000\n",
      "[2018-07-16 19:41:55.146635] Iteration 65000, train loss = 0.146885, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:42:02.497361] Iteration 65100, train loss = 0.141953, train accuracy = 0.992188\n",
      "[2018-07-16 19:42:08.161207] Iteration 65200, train loss = 0.142035, train accuracy = 0.992188\n",
      "[2018-07-16 19:42:13.825759] Iteration 65300, train loss = 0.139877, train accuracy = 1.000000\n",
      "[2018-07-16 19:42:19.487648] Iteration 65400, train loss = 0.137785, train accuracy = 1.000000\n",
      "[2018-07-16 19:42:25.143003] Iteration 65500, train loss = 0.133317, train accuracy = 1.000000\n",
      "[2018-07-16 19:42:30.802051] Iteration 65600, train loss = 0.143353, train accuracy = 1.000000\n",
      "[2018-07-16 19:42:36.452500] Iteration 65700, train loss = 0.130102, train accuracy = 1.000000\n",
      "[2018-07-16 19:42:42.111826] Iteration 65800, train loss = 0.138629, train accuracy = 1.000000\n",
      "[2018-07-16 19:42:47.764523] Iteration 65900, train loss = 0.145096, train accuracy = 0.984375\n",
      "[2018-07-16 19:42:53.425430] Iteration 66000, train loss = 0.132971, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 19:43:00.825677] Iteration 66100, train loss = 0.160842, train accuracy = 0.984375\n",
      "[2018-07-16 19:43:06.482425] Iteration 66200, train loss = 0.131719, train accuracy = 1.000000\n",
      "[2018-07-16 19:43:12.141001] Iteration 66300, train loss = 0.136066, train accuracy = 1.000000\n",
      "[2018-07-16 19:43:17.799779] Iteration 66400, train loss = 0.145409, train accuracy = 0.984375\n",
      "[2018-07-16 19:43:23.456062] Iteration 66500, train loss = 0.141732, train accuracy = 0.992188\n",
      "[2018-07-16 19:43:29.113989] Iteration 66600, train loss = 0.130384, train accuracy = 1.000000\n",
      "[2018-07-16 19:43:34.769170] Iteration 66700, train loss = 0.131072, train accuracy = 1.000000\n",
      "[2018-07-16 19:43:40.429611] Iteration 66800, train loss = 0.131972, train accuracy = 1.000000\n",
      "[2018-07-16 19:43:46.096234] Iteration 66900, train loss = 0.147093, train accuracy = 0.992188\n",
      "[2018-07-16 19:43:51.747831] Iteration 67000, train loss = 0.134190, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921400\n",
      "[2018-07-16 19:43:59.084712] Iteration 67100, train loss = 0.134702, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:04.736527] Iteration 67200, train loss = 0.134215, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:10.380854] Iteration 67300, train loss = 0.137709, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:16.045775] Iteration 67400, train loss = 0.132643, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:21.699438] Iteration 67500, train loss = 0.132528, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:27.357324] Iteration 67600, train loss = 0.139290, train accuracy = 0.992188\n",
      "[2018-07-16 19:44:33.014866] Iteration 67700, train loss = 0.131940, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:38.662553] Iteration 67800, train loss = 0.135238, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:44.312926] Iteration 67900, train loss = 0.138298, train accuracy = 1.000000\n",
      "[2018-07-16 19:44:49.978394] Iteration 68000, train loss = 0.133098, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921300\n",
      "[2018-07-16 19:44:57.316663] Iteration 68100, train loss = 0.135834, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:02.987220] Iteration 68200, train loss = 0.132883, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:08.657039] Iteration 68300, train loss = 0.133417, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:14.317158] Iteration 68400, train loss = 0.131534, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:19.974639] Iteration 68500, train loss = 0.133735, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:25.627616] Iteration 68600, train loss = 0.168235, train accuracy = 0.984375\n",
      "[2018-07-16 19:45:31.285720] Iteration 68700, train loss = 0.135542, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:36.937019] Iteration 68800, train loss = 0.132848, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:42.593917] Iteration 68900, train loss = 0.133410, train accuracy = 1.000000\n",
      "[2018-07-16 19:45:48.244358] Iteration 69000, train loss = 0.137551, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921300\n",
      "[2018-07-16 19:45:55.595576] Iteration 69100, train loss = 0.154609, train accuracy = 0.992188\n",
      "[2018-07-16 19:46:01.255307] Iteration 69200, train loss = 0.132487, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:06.907069] Iteration 69300, train loss = 0.139422, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:12.568085] Iteration 69400, train loss = 0.134234, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:18.224130] Iteration 69500, train loss = 0.135537, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:23.887402] Iteration 69600, train loss = 0.131912, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:29.545336] Iteration 69700, train loss = 0.132340, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:35.204048] Iteration 69800, train loss = 0.138621, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:40.867264] Iteration 69900, train loss = 0.130398, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:46.519279] Iteration 70000, train loss = 0.129707, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921500\n",
      "[2018-07-16 19:46:53.854005] Iteration 70100, train loss = 0.131843, train accuracy = 1.000000\n",
      "[2018-07-16 19:46:59.511687] Iteration 70200, train loss = 0.139581, train accuracy = 1.000000\n",
      "[2018-07-16 19:47:05.163728] Iteration 70300, train loss = 0.144587, train accuracy = 1.000000\n",
      "[2018-07-16 19:47:10.832390] Iteration 70400, train loss = 0.132296, train accuracy = 1.000000\n",
      "[2018-07-16 19:47:16.510570] Iteration 70500, train loss = 0.136179, train accuracy = 0.992188\n",
      "[2018-07-16 19:47:22.162061] Iteration 70600, train loss = 0.142782, train accuracy = 0.992188\n",
      "[2018-07-16 19:47:27.819050] Iteration 70700, train loss = 0.135386, train accuracy = 1.000000\n",
      "[2018-07-16 19:47:33.478546] Iteration 70800, train loss = 0.138670, train accuracy = 0.992188\n",
      "[2018-07-16 19:47:39.141518] Iteration 70900, train loss = 0.143402, train accuracy = 1.000000\n",
      "[2018-07-16 19:47:44.795210] Iteration 71000, train loss = 0.148944, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:47:52.126751] Iteration 71100, train loss = 0.136060, train accuracy = 1.000000\n",
      "[2018-07-16 19:47:57.778714] Iteration 71200, train loss = 0.131977, train accuracy = 1.000000\n",
      "[2018-07-16 19:48:03.467117] Iteration 71300, train loss = 0.133052, train accuracy = 1.000000\n",
      "[2018-07-16 19:48:09.126220] Iteration 71400, train loss = 0.132687, train accuracy = 1.000000\n",
      "[2018-07-16 19:48:14.776578] Iteration 71500, train loss = 0.137248, train accuracy = 1.000000\n",
      "[2018-07-16 19:48:20.440543] Iteration 71600, train loss = 0.131069, train accuracy = 1.000000\n",
      "[2018-07-16 19:48:26.095054] Iteration 71700, train loss = 0.143882, train accuracy = 0.992188\n",
      "[2018-07-16 19:48:31.749890] Iteration 71800, train loss = 0.144240, train accuracy = 1.000000\n",
      "[2018-07-16 19:48:37.398807] Iteration 71900, train loss = 0.143204, train accuracy = 0.992188\n",
      "[2018-07-16 19:48:43.059934] Iteration 72000, train loss = 0.131876, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921500\n",
      "[2018-07-16 19:48:50.395052] Iteration 72100, train loss = 0.134753, train accuracy = 1.000000\n",
      "[2018-07-16 19:48:56.053809] Iteration 72200, train loss = 0.143086, train accuracy = 1.000000\n",
      "[2018-07-16 19:49:01.715818] Iteration 72300, train loss = 0.133165, train accuracy = 1.000000\n",
      "[2018-07-16 19:49:07.378507] Iteration 72400, train loss = 0.133946, train accuracy = 1.000000\n",
      "[2018-07-16 19:49:13.046057] Iteration 72500, train loss = 0.141302, train accuracy = 0.992188\n",
      "[2018-07-16 19:49:18.694332] Iteration 72600, train loss = 0.135417, train accuracy = 1.000000\n",
      "[2018-07-16 19:49:24.360921] Iteration 72700, train loss = 0.138491, train accuracy = 1.000000\n",
      "[2018-07-16 19:49:30.025192] Iteration 72800, train loss = 0.131119, train accuracy = 1.000000\n",
      "[2018-07-16 19:49:35.697136] Iteration 72900, train loss = 0.130473, train accuracy = 1.000000\n",
      "[2018-07-16 19:49:41.359377] Iteration 73000, train loss = 0.129538, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922000\n",
      "[2018-07-16 19:49:48.686738] Iteration 73100, train loss = 0.151692, train accuracy = 0.992188\n",
      "[2018-07-16 19:49:54.353901] Iteration 73200, train loss = 0.139220, train accuracy = 0.992188\n",
      "[2018-07-16 19:50:00.006296] Iteration 73300, train loss = 0.136775, train accuracy = 1.000000\n",
      "[2018-07-16 19:50:05.660192] Iteration 73400, train loss = 0.132327, train accuracy = 1.000000\n",
      "[2018-07-16 19:50:11.317766] Iteration 73500, train loss = 0.132092, train accuracy = 1.000000\n",
      "[2018-07-16 19:50:16.994859] Iteration 73600, train loss = 0.131207, train accuracy = 1.000000\n",
      "[2018-07-16 19:50:22.655723] Iteration 73700, train loss = 0.146468, train accuracy = 0.992188\n",
      "[2018-07-16 19:50:28.325615] Iteration 73800, train loss = 0.132970, train accuracy = 1.000000\n",
      "[2018-07-16 19:50:33.985914] Iteration 73900, train loss = 0.134679, train accuracy = 1.000000\n",
      "[2018-07-16 19:50:39.651356] Iteration 74000, train loss = 0.135030, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 19:50:46.991419] Iteration 74100, train loss = 0.148458, train accuracy = 0.992188\n",
      "[2018-07-16 19:50:52.656311] Iteration 74200, train loss = 0.133626, train accuracy = 1.000000\n",
      "[2018-07-16 19:50:58.315686] Iteration 74300, train loss = 0.138024, train accuracy = 1.000000\n",
      "[2018-07-16 19:51:03.967098] Iteration 74400, train loss = 0.137348, train accuracy = 1.000000\n",
      "[2018-07-16 19:51:09.626447] Iteration 74500, train loss = 0.152108, train accuracy = 0.992188\n",
      "[2018-07-16 19:51:15.276896] Iteration 74600, train loss = 0.134265, train accuracy = 1.000000\n",
      "[2018-07-16 19:51:20.945308] Iteration 74700, train loss = 0.134289, train accuracy = 1.000000\n",
      "[2018-07-16 19:51:26.607223] Iteration 74800, train loss = 0.129776, train accuracy = 1.000000\n",
      "[2018-07-16 19:51:32.265235] Iteration 74900, train loss = 0.145957, train accuracy = 0.992188\n",
      "[2018-07-16 19:51:37.916752] Iteration 75000, train loss = 0.139835, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:51:45.234867] Iteration 75100, train loss = 0.140640, train accuracy = 1.000000\n",
      "[2018-07-16 19:51:50.891133] Iteration 75200, train loss = 0.138546, train accuracy = 1.000000\n",
      "[2018-07-16 19:51:56.555799] Iteration 75300, train loss = 0.137691, train accuracy = 1.000000\n",
      "[2018-07-16 19:52:02.213777] Iteration 75400, train loss = 0.134312, train accuracy = 1.000000\n",
      "[2018-07-16 19:52:07.879369] Iteration 75500, train loss = 0.143229, train accuracy = 0.992188\n",
      "[2018-07-16 19:52:13.543743] Iteration 75600, train loss = 0.143393, train accuracy = 0.992188\n",
      "[2018-07-16 19:52:19.204931] Iteration 75700, train loss = 0.135179, train accuracy = 1.000000\n",
      "[2018-07-16 19:52:24.848208] Iteration 75800, train loss = 0.134659, train accuracy = 1.000000\n",
      "[2018-07-16 19:52:30.495741] Iteration 75900, train loss = 0.142458, train accuracy = 0.992188\n",
      "[2018-07-16 19:52:36.159938] Iteration 76000, train loss = 0.139711, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:52:43.482111] Iteration 76100, train loss = 0.135950, train accuracy = 1.000000\n",
      "[2018-07-16 19:52:49.129747] Iteration 76200, train loss = 0.132211, train accuracy = 1.000000\n",
      "[2018-07-16 19:52:54.790508] Iteration 76300, train loss = 0.144343, train accuracy = 0.992188\n",
      "[2018-07-16 19:53:00.439910] Iteration 76400, train loss = 0.142244, train accuracy = 1.000000\n",
      "[2018-07-16 19:53:06.104639] Iteration 76500, train loss = 0.153161, train accuracy = 0.992188\n",
      "[2018-07-16 19:53:11.759129] Iteration 76600, train loss = 0.131108, train accuracy = 1.000000\n",
      "[2018-07-16 19:53:17.412070] Iteration 76700, train loss = 0.134016, train accuracy = 1.000000\n",
      "[2018-07-16 19:53:23.083143] Iteration 76800, train loss = 0.169311, train accuracy = 0.992188\n",
      "[2018-07-16 19:53:28.742329] Iteration 76900, train loss = 0.132251, train accuracy = 1.000000\n",
      "[2018-07-16 19:53:34.416907] Iteration 77000, train loss = 0.130540, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921800\n",
      "[2018-07-16 19:53:41.755897] Iteration 77100, train loss = 0.134687, train accuracy = 1.000000\n",
      "[2018-07-16 19:53:47.419197] Iteration 77200, train loss = 0.140131, train accuracy = 0.992188\n",
      "[2018-07-16 19:53:53.077467] Iteration 77300, train loss = 0.140987, train accuracy = 0.992188\n",
      "[2018-07-16 19:53:58.747578] Iteration 77400, train loss = 0.131222, train accuracy = 1.000000\n",
      "[2018-07-16 19:54:04.406747] Iteration 77500, train loss = 0.137537, train accuracy = 1.000000\n",
      "[2018-07-16 19:54:10.056813] Iteration 77600, train loss = 0.141987, train accuracy = 0.992188\n",
      "[2018-07-16 19:54:15.714737] Iteration 77700, train loss = 0.135557, train accuracy = 1.000000\n",
      "[2018-07-16 19:54:21.377532] Iteration 77800, train loss = 0.151082, train accuracy = 0.992188\n",
      "[2018-07-16 19:54:27.026877] Iteration 77900, train loss = 0.132593, train accuracy = 1.000000\n",
      "[2018-07-16 19:54:32.679025] Iteration 78000, train loss = 0.133038, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922300\n",
      "[2018-07-16 19:54:40.013212] Iteration 78100, train loss = 0.131975, train accuracy = 1.000000\n",
      "[2018-07-16 19:54:45.655998] Iteration 78200, train loss = 0.134782, train accuracy = 1.000000\n",
      "[2018-07-16 19:54:51.333106] Iteration 78300, train loss = 0.131340, train accuracy = 1.000000\n",
      "[2018-07-16 19:54:56.986420] Iteration 78400, train loss = 0.138395, train accuracy = 0.992188\n",
      "[2018-07-16 19:55:02.641758] Iteration 78500, train loss = 0.131930, train accuracy = 1.000000\n",
      "[2018-07-16 19:55:08.298315] Iteration 78600, train loss = 0.135228, train accuracy = 1.000000\n",
      "[2018-07-16 19:55:13.949776] Iteration 78700, train loss = 0.142854, train accuracy = 0.992188\n",
      "[2018-07-16 19:55:19.608069] Iteration 78800, train loss = 0.131000, train accuracy = 1.000000\n",
      "[2018-07-16 19:55:25.271129] Iteration 78900, train loss = 0.140043, train accuracy = 1.000000\n",
      "[2018-07-16 19:55:30.921394] Iteration 79000, train loss = 0.130597, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.921700\n",
      "[2018-07-16 19:55:38.303866] Iteration 79100, train loss = 0.136420, train accuracy = 0.992188\n",
      "[2018-07-16 19:55:43.956623] Iteration 79200, train loss = 0.131476, train accuracy = 1.000000\n",
      "[2018-07-16 19:55:49.603250] Iteration 79300, train loss = 0.168617, train accuracy = 0.984375\n",
      "[2018-07-16 19:55:55.258438] Iteration 79400, train loss = 0.141313, train accuracy = 0.992188\n",
      "[2018-07-16 19:56:00.924461] Iteration 79500, train loss = 0.135405, train accuracy = 1.000000\n",
      "[2018-07-16 19:56:06.570549] Iteration 79600, train loss = 0.136194, train accuracy = 1.000000\n",
      "[2018-07-16 19:56:12.222810] Iteration 79700, train loss = 0.147050, train accuracy = 0.984375\n",
      "[2018-07-16 19:56:17.875476] Iteration 79800, train loss = 0.138295, train accuracy = 1.000000\n",
      "[2018-07-16 19:56:23.527265] Iteration 79900, train loss = 0.136323, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四轮  量化  \n",
    "prune_rate = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.922200\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.03125    -0.0625      0.0361976   0.125       0.03125    -0.03125\n",
      "  0.01740384  0.03125     0.015625   -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,1)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-16 19:58:16.385923] Iteration 100, train loss = 0.186130, train accuracy = 0.984375\n",
      "[2018-07-16 19:58:21.138481] Iteration 200, train loss = 0.182097, train accuracy = 0.976562\n",
      "[2018-07-16 19:58:25.886719] Iteration 300, train loss = 0.199887, train accuracy = 0.968750\n",
      "[2018-07-16 19:58:30.639712] Iteration 400, train loss = 0.216577, train accuracy = 0.976562\n",
      "[2018-07-16 19:58:35.396355] Iteration 500, train loss = 0.183710, train accuracy = 0.976562\n",
      "[2018-07-16 19:58:40.164101] Iteration 600, train loss = 0.139521, train accuracy = 1.000000\n",
      "[2018-07-16 19:58:44.957159] Iteration 700, train loss = 0.200165, train accuracy = 0.984375\n",
      "[2018-07-16 19:58:49.706191] Iteration 800, train loss = 0.166233, train accuracy = 0.984375\n",
      "[2018-07-16 19:58:54.476525] Iteration 900, train loss = 0.193392, train accuracy = 0.976562\n",
      "[2018-07-16 19:58:59.240757] Iteration 1000, train loss = 0.182412, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 19:59:05.681839] Iteration 1100, train loss = 0.204663, train accuracy = 0.976562\n",
      "[2018-07-16 19:59:10.439712] Iteration 1200, train loss = 0.166037, train accuracy = 0.984375\n",
      "[2018-07-16 19:59:15.209506] Iteration 1300, train loss = 0.193147, train accuracy = 0.976562\n",
      "[2018-07-16 19:59:19.962182] Iteration 1400, train loss = 0.193526, train accuracy = 0.968750\n",
      "[2018-07-16 19:59:24.708340] Iteration 1500, train loss = 0.180036, train accuracy = 0.992188\n",
      "[2018-07-16 19:59:29.480373] Iteration 1600, train loss = 0.170452, train accuracy = 0.976562\n",
      "[2018-07-16 19:59:34.223543] Iteration 1700, train loss = 0.174613, train accuracy = 0.968750\n",
      "[2018-07-16 19:59:38.985972] Iteration 1800, train loss = 0.187131, train accuracy = 0.968750\n",
      "[2018-07-16 19:59:43.816203] Iteration 1900, train loss = 0.213689, train accuracy = 0.984375\n",
      "[2018-07-16 19:59:48.583376] Iteration 2000, train loss = 0.242957, train accuracy = 0.937500\n",
      "Evaluating...\n",
      "Test accuracy = 0.907700\n",
      "[2018-07-16 19:59:55.013075] Iteration 2100, train loss = 0.169601, train accuracy = 0.992188\n",
      "[2018-07-16 19:59:59.779109] Iteration 2200, train loss = 0.172947, train accuracy = 0.984375\n",
      "[2018-07-16 20:00:04.524386] Iteration 2300, train loss = 0.142250, train accuracy = 1.000000\n",
      "[2018-07-16 20:00:09.281804] Iteration 2400, train loss = 0.151081, train accuracy = 0.984375\n",
      "[2018-07-16 20:00:14.035355] Iteration 2500, train loss = 0.236185, train accuracy = 0.953125\n",
      "[2018-07-16 20:00:18.802162] Iteration 2600, train loss = 0.150797, train accuracy = 1.000000\n",
      "[2018-07-16 20:00:23.554101] Iteration 2700, train loss = 0.150369, train accuracy = 0.992188\n",
      "[2018-07-16 20:00:28.300468] Iteration 2800, train loss = 0.155911, train accuracy = 1.000000\n",
      "[2018-07-16 20:00:33.051188] Iteration 2900, train loss = 0.221052, train accuracy = 0.968750\n",
      "[2018-07-16 20:00:37.806528] Iteration 3000, train loss = 0.259747, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:00:44.268517] Iteration 3100, train loss = 0.155119, train accuracy = 0.992188\n",
      "[2018-07-16 20:00:49.019830] Iteration 3200, train loss = 0.164792, train accuracy = 0.984375\n",
      "[2018-07-16 20:00:53.775125] Iteration 3300, train loss = 0.174888, train accuracy = 0.976562\n",
      "[2018-07-16 20:00:58.523828] Iteration 3400, train loss = 0.172172, train accuracy = 0.976562\n",
      "[2018-07-16 20:01:03.294269] Iteration 3500, train loss = 0.161247, train accuracy = 0.992188\n",
      "[2018-07-16 20:01:08.041685] Iteration 3600, train loss = 0.240419, train accuracy = 0.968750\n",
      "[2018-07-16 20:01:12.790970] Iteration 3700, train loss = 0.156899, train accuracy = 0.992188\n",
      "[2018-07-16 20:01:17.541462] Iteration 3800, train loss = 0.180206, train accuracy = 0.976562\n",
      "[2018-07-16 20:01:22.288886] Iteration 3900, train loss = 0.150590, train accuracy = 1.000000\n",
      "[2018-07-16 20:01:27.034666] Iteration 4000, train loss = 0.244597, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.907200\n",
      "[2018-07-16 20:01:33.471473] Iteration 4100, train loss = 0.153999, train accuracy = 0.984375\n",
      "[2018-07-16 20:01:38.216801] Iteration 4200, train loss = 0.175375, train accuracy = 0.984375\n",
      "[2018-07-16 20:01:42.973373] Iteration 4300, train loss = 0.161134, train accuracy = 0.992188\n",
      "[2018-07-16 20:01:47.739378] Iteration 4400, train loss = 0.268925, train accuracy = 0.953125\n",
      "[2018-07-16 20:01:52.495693] Iteration 4500, train loss = 0.216037, train accuracy = 0.968750\n",
      "[2018-07-16 20:01:57.257250] Iteration 4600, train loss = 0.206049, train accuracy = 0.992188\n",
      "[2018-07-16 20:02:02.016518] Iteration 4700, train loss = 0.185563, train accuracy = 0.976562\n",
      "[2018-07-16 20:02:06.770589] Iteration 4800, train loss = 0.161906, train accuracy = 0.992188\n",
      "[2018-07-16 20:02:11.525019] Iteration 4900, train loss = 0.147913, train accuracy = 1.000000\n",
      "[2018-07-16 20:02:16.288224] Iteration 5000, train loss = 0.187219, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:02:22.714717] Iteration 5100, train loss = 0.201147, train accuracy = 0.960938\n",
      "[2018-07-16 20:02:27.477037] Iteration 5200, train loss = 0.236836, train accuracy = 0.953125\n",
      "[2018-07-16 20:02:32.236822] Iteration 5300, train loss = 0.158690, train accuracy = 0.992188\n",
      "[2018-07-16 20:02:36.995787] Iteration 5400, train loss = 0.193976, train accuracy = 0.976562\n",
      "[2018-07-16 20:02:41.744585] Iteration 5500, train loss = 0.221289, train accuracy = 0.968750\n",
      "[2018-07-16 20:02:46.513793] Iteration 5600, train loss = 0.212364, train accuracy = 0.976562\n",
      "[2018-07-16 20:02:51.286579] Iteration 5700, train loss = 0.153747, train accuracy = 0.992188\n",
      "[2018-07-16 20:02:56.043065] Iteration 5800, train loss = 0.219535, train accuracy = 0.960938\n",
      "[2018-07-16 20:03:00.799472] Iteration 5900, train loss = 0.165519, train accuracy = 0.984375\n",
      "[2018-07-16 20:03:05.556380] Iteration 6000, train loss = 0.170385, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:03:11.983679] Iteration 6100, train loss = 0.168716, train accuracy = 0.984375\n",
      "[2018-07-16 20:03:16.733737] Iteration 6200, train loss = 0.202223, train accuracy = 0.968750\n",
      "[2018-07-16 20:03:21.472928] Iteration 6300, train loss = 0.141017, train accuracy = 0.992188\n",
      "[2018-07-16 20:03:26.223556] Iteration 6400, train loss = 0.193751, train accuracy = 0.968750\n",
      "[2018-07-16 20:03:30.983928] Iteration 6500, train loss = 0.195679, train accuracy = 0.976562\n",
      "[2018-07-16 20:03:35.743065] Iteration 6600, train loss = 0.171283, train accuracy = 0.992188\n",
      "[2018-07-16 20:03:40.502937] Iteration 6700, train loss = 0.171132, train accuracy = 0.984375\n",
      "[2018-07-16 20:03:45.259494] Iteration 6800, train loss = 0.221808, train accuracy = 0.968750\n",
      "[2018-07-16 20:03:50.009469] Iteration 6900, train loss = 0.207940, train accuracy = 0.960938\n",
      "[2018-07-16 20:03:54.815173] Iteration 7000, train loss = 0.163861, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:04:01.257501] Iteration 7100, train loss = 0.152894, train accuracy = 0.984375\n",
      "[2018-07-16 20:04:06.007000] Iteration 7200, train loss = 0.167941, train accuracy = 0.976562\n",
      "[2018-07-16 20:04:10.755148] Iteration 7300, train loss = 0.178613, train accuracy = 0.984375\n",
      "[2018-07-16 20:04:15.502145] Iteration 7400, train loss = 0.145166, train accuracy = 0.992188\n",
      "[2018-07-16 20:04:20.263309] Iteration 7500, train loss = 0.189582, train accuracy = 0.976562\n",
      "[2018-07-16 20:04:25.020480] Iteration 7600, train loss = 0.141045, train accuracy = 1.000000\n",
      "[2018-07-16 20:04:29.769263] Iteration 7700, train loss = 0.190704, train accuracy = 0.968750\n",
      "[2018-07-16 20:04:34.519654] Iteration 7800, train loss = 0.161933, train accuracy = 0.984375\n",
      "[2018-07-16 20:04:39.272557] Iteration 7900, train loss = 0.162762, train accuracy = 0.984375\n",
      "[2018-07-16 20:04:44.023676] Iteration 8000, train loss = 0.175276, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:04:50.448349] Iteration 8100, train loss = 0.165734, train accuracy = 0.992188\n",
      "[2018-07-16 20:04:55.224628] Iteration 8200, train loss = 0.268404, train accuracy = 0.960938\n",
      "[2018-07-16 20:04:59.982490] Iteration 8300, train loss = 0.208914, train accuracy = 0.968750\n",
      "[2018-07-16 20:05:04.739160] Iteration 8400, train loss = 0.172178, train accuracy = 0.984375\n",
      "[2018-07-16 20:05:09.484623] Iteration 8500, train loss = 0.160575, train accuracy = 0.984375\n",
      "[2018-07-16 20:05:14.232758] Iteration 8600, train loss = 0.171381, train accuracy = 0.984375\n",
      "[2018-07-16 20:05:18.981586] Iteration 8700, train loss = 0.199834, train accuracy = 0.976562\n",
      "[2018-07-16 20:05:23.738701] Iteration 8800, train loss = 0.195496, train accuracy = 0.976562\n",
      "[2018-07-16 20:05:28.491792] Iteration 8900, train loss = 0.167564, train accuracy = 0.992188\n",
      "[2018-07-16 20:05:33.249405] Iteration 9000, train loss = 0.198371, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907200\n",
      "[2018-07-16 20:05:39.673100] Iteration 9100, train loss = 0.170144, train accuracy = 0.976562\n",
      "[2018-07-16 20:05:44.432630] Iteration 9200, train loss = 0.154600, train accuracy = 0.992188\n",
      "[2018-07-16 20:05:49.193029] Iteration 9300, train loss = 0.198382, train accuracy = 0.953125\n",
      "[2018-07-16 20:05:53.947126] Iteration 9400, train loss = 0.153551, train accuracy = 0.992188\n",
      "[2018-07-16 20:05:58.737568] Iteration 9500, train loss = 0.142623, train accuracy = 0.992188\n",
      "[2018-07-16 20:06:03.489991] Iteration 9600, train loss = 0.165040, train accuracy = 0.976562\n",
      "[2018-07-16 20:06:08.267607] Iteration 9700, train loss = 0.146959, train accuracy = 1.000000\n",
      "[2018-07-16 20:06:13.020331] Iteration 9800, train loss = 0.152430, train accuracy = 0.984375\n",
      "[2018-07-16 20:06:17.777324] Iteration 9900, train loss = 0.173011, train accuracy = 0.976562\n",
      "[2018-07-16 20:06:22.532606] Iteration 10000, train loss = 0.201285, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:06:28.965454] Iteration 10100, train loss = 0.182504, train accuracy = 0.984375\n",
      "[2018-07-16 20:06:33.717947] Iteration 10200, train loss = 0.240306, train accuracy = 0.968750\n",
      "[2018-07-16 20:06:38.467410] Iteration 10300, train loss = 0.245544, train accuracy = 0.937500\n",
      "[2018-07-16 20:06:43.212732] Iteration 10400, train loss = 0.176315, train accuracy = 0.976562\n",
      "[2018-07-16 20:06:47.968046] Iteration 10500, train loss = 0.162116, train accuracy = 0.984375\n",
      "[2018-07-16 20:06:52.719303] Iteration 10600, train loss = 0.153996, train accuracy = 0.992188\n",
      "[2018-07-16 20:06:57.470140] Iteration 10700, train loss = 0.176493, train accuracy = 0.976562\n",
      "[2018-07-16 20:07:02.261962] Iteration 10800, train loss = 0.191864, train accuracy = 0.960938\n",
      "[2018-07-16 20:07:07.012295] Iteration 10900, train loss = 0.171071, train accuracy = 0.984375\n",
      "[2018-07-16 20:07:11.768691] Iteration 11000, train loss = 0.162420, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:07:18.193471] Iteration 11100, train loss = 0.200122, train accuracy = 0.968750\n",
      "[2018-07-16 20:07:22.937145] Iteration 11200, train loss = 0.146261, train accuracy = 0.992188\n",
      "[2018-07-16 20:07:27.692814] Iteration 11300, train loss = 0.188893, train accuracy = 0.968750\n",
      "[2018-07-16 20:07:32.445541] Iteration 11400, train loss = 0.151886, train accuracy = 0.992188\n",
      "[2018-07-16 20:07:37.199748] Iteration 11500, train loss = 0.189377, train accuracy = 0.976562\n",
      "[2018-07-16 20:07:41.962746] Iteration 11600, train loss = 0.193777, train accuracy = 0.968750\n",
      "[2018-07-16 20:07:46.719482] Iteration 11700, train loss = 0.181816, train accuracy = 0.984375\n",
      "[2018-07-16 20:07:51.468748] Iteration 11800, train loss = 0.146098, train accuracy = 1.000000\n",
      "[2018-07-16 20:07:56.226033] Iteration 11900, train loss = 0.142966, train accuracy = 1.000000\n",
      "[2018-07-16 20:08:00.982182] Iteration 12000, train loss = 0.201174, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:08:07.471606] Iteration 12100, train loss = 0.166710, train accuracy = 0.992188\n",
      "[2018-07-16 20:08:12.232474] Iteration 12200, train loss = 0.161202, train accuracy = 0.992188\n",
      "[2018-07-16 20:08:16.981257] Iteration 12300, train loss = 0.221409, train accuracy = 0.976562\n",
      "[2018-07-16 20:08:21.728078] Iteration 12400, train loss = 0.214879, train accuracy = 0.960938\n",
      "[2018-07-16 20:08:26.483347] Iteration 12500, train loss = 0.228770, train accuracy = 0.968750\n",
      "[2018-07-16 20:08:31.239228] Iteration 12600, train loss = 0.195613, train accuracy = 0.976562\n",
      "[2018-07-16 20:08:35.989275] Iteration 12700, train loss = 0.170723, train accuracy = 0.976562\n",
      "[2018-07-16 20:08:40.748146] Iteration 12800, train loss = 0.136485, train accuracy = 1.000000\n",
      "[2018-07-16 20:08:45.508087] Iteration 12900, train loss = 0.168929, train accuracy = 0.984375\n",
      "[2018-07-16 20:08:50.277141] Iteration 13000, train loss = 0.217015, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907400\n",
      "[2018-07-16 20:08:56.700601] Iteration 13100, train loss = 0.179866, train accuracy = 0.976562\n",
      "[2018-07-16 20:09:01.443960] Iteration 13200, train loss = 0.175297, train accuracy = 0.968750\n",
      "[2018-07-16 20:09:06.191227] Iteration 13300, train loss = 0.171604, train accuracy = 0.992188\n",
      "[2018-07-16 20:09:10.982428] Iteration 13400, train loss = 0.154145, train accuracy = 0.992188\n",
      "[2018-07-16 20:09:15.730977] Iteration 13500, train loss = 0.149330, train accuracy = 0.992188\n",
      "[2018-07-16 20:09:20.489528] Iteration 13600, train loss = 0.140368, train accuracy = 1.000000\n",
      "[2018-07-16 20:09:25.238886] Iteration 13700, train loss = 0.190619, train accuracy = 0.976562\n",
      "[2018-07-16 20:09:29.991319] Iteration 13800, train loss = 0.172112, train accuracy = 0.984375\n",
      "[2018-07-16 20:09:34.749734] Iteration 13900, train loss = 0.248484, train accuracy = 0.953125\n",
      "[2018-07-16 20:09:39.490091] Iteration 14000, train loss = 0.177631, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907100\n",
      "[2018-07-16 20:09:45.925213] Iteration 14100, train loss = 0.177776, train accuracy = 0.992188\n",
      "[2018-07-16 20:09:50.680189] Iteration 14200, train loss = 0.168049, train accuracy = 0.984375\n",
      "[2018-07-16 20:09:55.420658] Iteration 14300, train loss = 0.152431, train accuracy = 0.984375\n",
      "[2018-07-16 20:10:00.178291] Iteration 14400, train loss = 0.215022, train accuracy = 0.960938\n",
      "[2018-07-16 20:10:04.941793] Iteration 14500, train loss = 0.146462, train accuracy = 0.992188\n",
      "[2018-07-16 20:10:09.709093] Iteration 14600, train loss = 0.155120, train accuracy = 0.992188\n",
      "[2018-07-16 20:10:14.480990] Iteration 14700, train loss = 0.237382, train accuracy = 0.953125\n",
      "[2018-07-16 20:10:19.231828] Iteration 14800, train loss = 0.205543, train accuracy = 0.984375\n",
      "[2018-07-16 20:10:23.980199] Iteration 14900, train loss = 0.170125, train accuracy = 0.992188\n",
      "[2018-07-16 20:10:28.740609] Iteration 15000, train loss = 0.159556, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:10:35.185828] Iteration 15100, train loss = 0.188381, train accuracy = 0.976562\n",
      "[2018-07-16 20:10:39.940749] Iteration 15200, train loss = 0.146112, train accuracy = 0.992188\n",
      "[2018-07-16 20:10:44.695845] Iteration 15300, train loss = 0.188181, train accuracy = 0.976562\n",
      "[2018-07-16 20:10:49.446535] Iteration 15400, train loss = 0.197586, train accuracy = 0.976562\n",
      "[2018-07-16 20:10:54.207232] Iteration 15500, train loss = 0.184969, train accuracy = 0.984375\n",
      "[2018-07-16 20:10:58.969922] Iteration 15600, train loss = 0.153192, train accuracy = 0.992188\n",
      "[2018-07-16 20:11:03.719684] Iteration 15700, train loss = 0.154349, train accuracy = 0.992188\n",
      "[2018-07-16 20:11:08.466828] Iteration 15800, train loss = 0.163915, train accuracy = 0.992188\n",
      "[2018-07-16 20:11:13.236167] Iteration 15900, train loss = 0.175997, train accuracy = 0.984375\n",
      "[2018-07-16 20:11:18.001591] Iteration 16000, train loss = 0.162619, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.906700\n",
      "[2018-07-16 20:11:24.425071] Iteration 16100, train loss = 0.154839, train accuracy = 0.984375\n",
      "[2018-07-16 20:11:29.188335] Iteration 16200, train loss = 0.200468, train accuracy = 0.968750\n",
      "[2018-07-16 20:11:33.938724] Iteration 16300, train loss = 0.167058, train accuracy = 0.984375\n",
      "[2018-07-16 20:11:38.696367] Iteration 16400, train loss = 0.151170, train accuracy = 0.992188\n",
      "[2018-07-16 20:11:43.445993] Iteration 16500, train loss = 0.160970, train accuracy = 0.992188\n",
      "[2018-07-16 20:11:48.197066] Iteration 16600, train loss = 0.175890, train accuracy = 0.984375\n",
      "[2018-07-16 20:11:52.956728] Iteration 16700, train loss = 0.164032, train accuracy = 0.984375\n",
      "[2018-07-16 20:11:57.722354] Iteration 16800, train loss = 0.142694, train accuracy = 1.000000\n",
      "[2018-07-16 20:12:02.487006] Iteration 16900, train loss = 0.171124, train accuracy = 0.992188\n",
      "[2018-07-16 20:12:07.240540] Iteration 17000, train loss = 0.163310, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:12:13.676565] Iteration 17100, train loss = 0.156574, train accuracy = 0.992188\n",
      "[2018-07-16 20:12:18.444747] Iteration 17200, train loss = 0.219078, train accuracy = 0.976562\n",
      "[2018-07-16 20:12:23.198387] Iteration 17300, train loss = 0.195216, train accuracy = 0.968750\n",
      "[2018-07-16 20:12:27.949158] Iteration 17400, train loss = 0.143389, train accuracy = 0.992188\n",
      "[2018-07-16 20:12:32.712442] Iteration 17500, train loss = 0.182881, train accuracy = 0.976562\n",
      "[2018-07-16 20:12:37.464896] Iteration 17600, train loss = 0.189572, train accuracy = 0.968750\n",
      "[2018-07-16 20:12:42.244691] Iteration 17700, train loss = 0.157670, train accuracy = 1.000000\n",
      "[2018-07-16 20:12:46.993085] Iteration 17800, train loss = 0.176948, train accuracy = 0.984375\n",
      "[2018-07-16 20:12:51.756696] Iteration 17900, train loss = 0.156953, train accuracy = 0.984375\n",
      "[2018-07-16 20:12:56.519702] Iteration 18000, train loss = 0.157983, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906700\n",
      "[2018-07-16 20:13:02.942239] Iteration 18100, train loss = 0.166659, train accuracy = 0.992188\n",
      "[2018-07-16 20:13:07.686226] Iteration 18200, train loss = 0.195836, train accuracy = 0.976562\n",
      "[2018-07-16 20:13:12.447168] Iteration 18300, train loss = 0.172027, train accuracy = 0.992188\n",
      "[2018-07-16 20:13:17.200456] Iteration 18400, train loss = 0.165014, train accuracy = 0.992188\n",
      "[2018-07-16 20:13:21.982521] Iteration 18500, train loss = 0.169646, train accuracy = 0.992188\n",
      "[2018-07-16 20:13:26.737309] Iteration 18600, train loss = 0.247463, train accuracy = 0.968750\n",
      "[2018-07-16 20:13:31.495845] Iteration 18700, train loss = 0.186318, train accuracy = 0.976562\n",
      "[2018-07-16 20:13:36.252603] Iteration 18800, train loss = 0.187573, train accuracy = 0.976562\n",
      "[2018-07-16 20:13:41.025614] Iteration 18900, train loss = 0.176227, train accuracy = 0.976562\n",
      "[2018-07-16 20:13:45.776538] Iteration 19000, train loss = 0.145985, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.907500\n",
      "[2018-07-16 20:13:52.198253] Iteration 19100, train loss = 0.177459, train accuracy = 0.984375\n",
      "[2018-07-16 20:13:56.949326] Iteration 19200, train loss = 0.184655, train accuracy = 0.984375\n",
      "[2018-07-16 20:14:01.705941] Iteration 19300, train loss = 0.214359, train accuracy = 0.960938\n",
      "[2018-07-16 20:14:06.457440] Iteration 19400, train loss = 0.184111, train accuracy = 0.984375\n",
      "[2018-07-16 20:14:11.210013] Iteration 19500, train loss = 0.195888, train accuracy = 0.984375\n",
      "[2018-07-16 20:14:15.973963] Iteration 19600, train loss = 0.163551, train accuracy = 0.976562\n",
      "[2018-07-16 20:14:20.727653] Iteration 19700, train loss = 0.216786, train accuracy = 0.984375\n",
      "[2018-07-16 20:14:25.508859] Iteration 19800, train loss = 0.153243, train accuracy = 0.984375\n",
      "[2018-07-16 20:14:30.269780] Iteration 19900, train loss = 0.189386, train accuracy = 0.976562\n",
      "[2018-07-16 20:14:35.027838] Iteration 20000, train loss = 0.197456, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.906900\n",
      "[2018-07-16 20:14:41.449901] Iteration 20100, train loss = 0.250590, train accuracy = 0.953125\n",
      "[2018-07-16 20:14:46.198746] Iteration 20200, train loss = 0.189039, train accuracy = 0.984375\n",
      "[2018-07-16 20:14:50.971574] Iteration 20300, train loss = 0.183242, train accuracy = 0.968750\n",
      "[2018-07-16 20:14:55.726493] Iteration 20400, train loss = 0.220132, train accuracy = 0.968750\n",
      "[2018-07-16 20:15:00.478800] Iteration 20500, train loss = 0.161241, train accuracy = 0.984375\n",
      "[2018-07-16 20:15:05.235869] Iteration 20600, train loss = 0.159756, train accuracy = 0.992188\n",
      "[2018-07-16 20:15:09.983979] Iteration 20700, train loss = 0.208051, train accuracy = 0.960938\n",
      "[2018-07-16 20:15:14.740203] Iteration 20800, train loss = 0.215159, train accuracy = 0.953125\n",
      "[2018-07-16 20:15:19.490062] Iteration 20900, train loss = 0.179118, train accuracy = 0.984375\n",
      "[2018-07-16 20:15:24.255903] Iteration 21000, train loss = 0.235232, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.907700\n",
      "[2018-07-16 20:15:30.758947] Iteration 21100, train loss = 0.150185, train accuracy = 1.000000\n",
      "[2018-07-16 20:15:35.515506] Iteration 21200, train loss = 0.146891, train accuracy = 0.992188\n",
      "[2018-07-16 20:15:40.270684] Iteration 21300, train loss = 0.146487, train accuracy = 1.000000\n",
      "[2018-07-16 20:15:45.034812] Iteration 21400, train loss = 0.153606, train accuracy = 0.992188\n",
      "[2018-07-16 20:15:49.789952] Iteration 21500, train loss = 0.155649, train accuracy = 1.000000\n",
      "[2018-07-16 20:15:54.533031] Iteration 21600, train loss = 0.158204, train accuracy = 0.992188\n",
      "[2018-07-16 20:15:59.278158] Iteration 21700, train loss = 0.212102, train accuracy = 0.992188\n",
      "[2018-07-16 20:16:04.039846] Iteration 21800, train loss = 0.188181, train accuracy = 0.968750\n",
      "[2018-07-16 20:16:08.806542] Iteration 21900, train loss = 0.213756, train accuracy = 0.968750\n",
      "[2018-07-16 20:16:13.562169] Iteration 22000, train loss = 0.184314, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:16:19.978118] Iteration 22100, train loss = 0.216800, train accuracy = 0.968750\n",
      "[2018-07-16 20:16:24.734165] Iteration 22200, train loss = 0.184258, train accuracy = 0.976562\n",
      "[2018-07-16 20:16:29.533516] Iteration 22300, train loss = 0.149380, train accuracy = 0.992188\n",
      "[2018-07-16 20:16:34.326759] Iteration 22400, train loss = 0.231627, train accuracy = 0.953125\n",
      "[2018-07-16 20:16:39.120355] Iteration 22500, train loss = 0.263821, train accuracy = 0.953125\n",
      "[2018-07-16 20:16:43.913465] Iteration 22600, train loss = 0.155740, train accuracy = 0.992188\n",
      "[2018-07-16 20:16:48.705854] Iteration 22700, train loss = 0.287708, train accuracy = 0.953125\n",
      "[2018-07-16 20:16:53.495978] Iteration 22800, train loss = 0.157608, train accuracy = 0.984375\n",
      "[2018-07-16 20:16:58.289081] Iteration 22900, train loss = 0.175729, train accuracy = 0.992188\n",
      "[2018-07-16 20:17:03.078509] Iteration 23000, train loss = 0.153973, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.906700\n",
      "[2018-07-16 20:17:09.530870] Iteration 23100, train loss = 0.145120, train accuracy = 0.992188\n",
      "[2018-07-16 20:17:14.317167] Iteration 23200, train loss = 0.156005, train accuracy = 0.992188\n",
      "[2018-07-16 20:17:19.085561] Iteration 23300, train loss = 0.177485, train accuracy = 0.984375\n",
      "[2018-07-16 20:17:23.869011] Iteration 23400, train loss = 0.166453, train accuracy = 0.984375\n",
      "[2018-07-16 20:17:28.656149] Iteration 23500, train loss = 0.135191, train accuracy = 1.000000\n",
      "[2018-07-16 20:17:33.443434] Iteration 23600, train loss = 0.175136, train accuracy = 0.976562\n",
      "[2018-07-16 20:17:38.239201] Iteration 23700, train loss = 0.187236, train accuracy = 0.968750\n",
      "[2018-07-16 20:17:43.026784] Iteration 23800, train loss = 0.157338, train accuracy = 0.992188\n",
      "[2018-07-16 20:17:47.812504] Iteration 23900, train loss = 0.180650, train accuracy = 0.992188\n",
      "[2018-07-16 20:17:52.607805] Iteration 24000, train loss = 0.194993, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:17:59.062539] Iteration 24100, train loss = 0.169977, train accuracy = 0.984375\n",
      "[2018-07-16 20:18:03.850207] Iteration 24200, train loss = 0.162703, train accuracy = 0.984375\n",
      "[2018-07-16 20:18:08.641727] Iteration 24300, train loss = 0.170567, train accuracy = 0.976562\n",
      "[2018-07-16 20:18:13.385241] Iteration 24400, train loss = 0.172085, train accuracy = 0.984375\n",
      "[2018-07-16 20:18:18.140185] Iteration 24500, train loss = 0.180683, train accuracy = 0.984375\n",
      "[2018-07-16 20:18:22.876551] Iteration 24600, train loss = 0.182613, train accuracy = 0.976562\n",
      "[2018-07-16 20:18:27.570964] Iteration 24700, train loss = 0.142902, train accuracy = 1.000000\n",
      "[2018-07-16 20:18:32.295249] Iteration 24800, train loss = 0.145794, train accuracy = 0.992188\n",
      "[2018-07-16 20:18:37.015843] Iteration 24900, train loss = 0.154597, train accuracy = 0.992188\n",
      "[2018-07-16 20:18:41.773971] Iteration 25000, train loss = 0.163600, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:18:48.236716] Iteration 25100, train loss = 0.151218, train accuracy = 0.992188\n",
      "[2018-07-16 20:18:53.029267] Iteration 25200, train loss = 0.173543, train accuracy = 0.976562\n",
      "[2018-07-16 20:18:57.809494] Iteration 25300, train loss = 0.173141, train accuracy = 0.976562\n",
      "[2018-07-16 20:19:02.620847] Iteration 25400, train loss = 0.201593, train accuracy = 0.984375\n",
      "[2018-07-16 20:19:07.404240] Iteration 25500, train loss = 0.170785, train accuracy = 0.992188\n",
      "[2018-07-16 20:19:12.171268] Iteration 25600, train loss = 0.155916, train accuracy = 0.992188\n",
      "[2018-07-16 20:19:16.959672] Iteration 25700, train loss = 0.189935, train accuracy = 0.968750\n",
      "[2018-07-16 20:19:21.726498] Iteration 25800, train loss = 0.212692, train accuracy = 0.984375\n",
      "[2018-07-16 20:19:26.499116] Iteration 25900, train loss = 0.133551, train accuracy = 1.000000\n",
      "[2018-07-16 20:19:31.265951] Iteration 26000, train loss = 0.213831, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907200\n",
      "[2018-07-16 20:19:37.725891] Iteration 26100, train loss = 0.198901, train accuracy = 0.968750\n",
      "[2018-07-16 20:19:42.485271] Iteration 26200, train loss = 0.136776, train accuracy = 1.000000\n",
      "[2018-07-16 20:19:47.262322] Iteration 26300, train loss = 0.137633, train accuracy = 0.992188\n",
      "[2018-07-16 20:19:52.032646] Iteration 26400, train loss = 0.208431, train accuracy = 0.968750\n",
      "[2018-07-16 20:19:56.823013] Iteration 26500, train loss = 0.184396, train accuracy = 0.984375\n",
      "[2018-07-16 20:20:01.590265] Iteration 26600, train loss = 0.199218, train accuracy = 0.976562\n",
      "[2018-07-16 20:20:06.352548] Iteration 26700, train loss = 0.220889, train accuracy = 0.976562\n",
      "[2018-07-16 20:20:11.124090] Iteration 26800, train loss = 0.152289, train accuracy = 1.000000\n",
      "[2018-07-16 20:20:15.894395] Iteration 26900, train loss = 0.193508, train accuracy = 0.984375\n",
      "[2018-07-16 20:20:20.664142] Iteration 27000, train loss = 0.187488, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907400\n",
      "[2018-07-16 20:20:27.113937] Iteration 27100, train loss = 0.137918, train accuracy = 0.992188\n",
      "[2018-07-16 20:20:31.892780] Iteration 27200, train loss = 0.153694, train accuracy = 0.992188\n",
      "[2018-07-16 20:20:36.666284] Iteration 27300, train loss = 0.285165, train accuracy = 0.945312\n",
      "[2018-07-16 20:20:41.431237] Iteration 27400, train loss = 0.178315, train accuracy = 0.984375\n",
      "[2018-07-16 20:20:46.207546] Iteration 27500, train loss = 0.182469, train accuracy = 0.984375\n",
      "[2018-07-16 20:20:50.973143] Iteration 27600, train loss = 0.270616, train accuracy = 0.945312\n",
      "[2018-07-16 20:20:55.729715] Iteration 27700, train loss = 0.160013, train accuracy = 0.984375\n",
      "[2018-07-16 20:21:00.499272] Iteration 27800, train loss = 0.156113, train accuracy = 0.992188\n",
      "[2018-07-16 20:21:05.258456] Iteration 27900, train loss = 0.192992, train accuracy = 0.976562\n",
      "[2018-07-16 20:21:10.015726] Iteration 28000, train loss = 0.201823, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907900\n",
      "[2018-07-16 20:21:16.462780] Iteration 28100, train loss = 0.203909, train accuracy = 0.976562\n",
      "[2018-07-16 20:21:21.225410] Iteration 28200, train loss = 0.218403, train accuracy = 0.960938\n",
      "[2018-07-16 20:21:25.996481] Iteration 28300, train loss = 0.189188, train accuracy = 0.984375\n",
      "[2018-07-16 20:21:30.783641] Iteration 28400, train loss = 0.176648, train accuracy = 0.984375\n",
      "[2018-07-16 20:21:35.551065] Iteration 28500, train loss = 0.181461, train accuracy = 0.976562\n",
      "[2018-07-16 20:21:40.358369] Iteration 28600, train loss = 0.170878, train accuracy = 0.976562\n",
      "[2018-07-16 20:21:45.111347] Iteration 28700, train loss = 0.255702, train accuracy = 0.953125\n",
      "[2018-07-16 20:21:49.867618] Iteration 28800, train loss = 0.206031, train accuracy = 0.968750\n",
      "[2018-07-16 20:21:54.632898] Iteration 28900, train loss = 0.197239, train accuracy = 0.984375\n",
      "[2018-07-16 20:21:59.398450] Iteration 29000, train loss = 0.178192, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:22:05.838378] Iteration 29100, train loss = 0.174446, train accuracy = 0.976562\n",
      "[2018-07-16 20:22:10.606496] Iteration 29200, train loss = 0.188017, train accuracy = 0.976562\n",
      "[2018-07-16 20:22:15.388619] Iteration 29300, train loss = 0.219582, train accuracy = 0.945312\n",
      "[2018-07-16 20:22:20.146703] Iteration 29400, train loss = 0.154816, train accuracy = 0.992188\n",
      "[2018-07-16 20:22:24.915154] Iteration 29500, train loss = 0.223323, train accuracy = 0.976562\n",
      "[2018-07-16 20:22:29.684410] Iteration 29600, train loss = 0.158154, train accuracy = 0.984375\n",
      "[2018-07-16 20:22:34.471704] Iteration 29700, train loss = 0.157229, train accuracy = 0.992188\n",
      "[2018-07-16 20:22:39.227730] Iteration 29800, train loss = 0.185875, train accuracy = 0.968750\n",
      "[2018-07-16 20:22:43.996078] Iteration 29900, train loss = 0.168983, train accuracy = 0.992188\n",
      "[2018-07-16 20:22:48.758381] Iteration 30000, train loss = 0.153763, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:22:55.224911] Iteration 30100, train loss = 0.205793, train accuracy = 0.984375\n",
      "[2018-07-16 20:22:59.995673] Iteration 30200, train loss = 0.143926, train accuracy = 1.000000\n",
      "[2018-07-16 20:23:04.767594] Iteration 30300, train loss = 0.190693, train accuracy = 0.976562\n",
      "[2018-07-16 20:23:09.536975] Iteration 30400, train loss = 0.201508, train accuracy = 0.968750\n",
      "[2018-07-16 20:23:14.294313] Iteration 30500, train loss = 0.205269, train accuracy = 0.968750\n",
      "[2018-07-16 20:23:19.057184] Iteration 30600, train loss = 0.161596, train accuracy = 0.984375\n",
      "[2018-07-16 20:23:23.809621] Iteration 30700, train loss = 0.135047, train accuracy = 1.000000\n",
      "[2018-07-16 20:23:28.597288] Iteration 30800, train loss = 0.178374, train accuracy = 0.992188\n",
      "[2018-07-16 20:23:33.358425] Iteration 30900, train loss = 0.214671, train accuracy = 0.960938\n",
      "[2018-07-16 20:23:38.131386] Iteration 31000, train loss = 0.232693, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.907400\n",
      "[2018-07-16 20:23:44.575182] Iteration 31100, train loss = 0.152808, train accuracy = 0.992188\n",
      "[2018-07-16 20:23:49.332949] Iteration 31200, train loss = 0.198131, train accuracy = 0.976562\n",
      "[2018-07-16 20:23:54.113035] Iteration 31300, train loss = 0.180036, train accuracy = 0.976562\n",
      "[2018-07-16 20:23:58.876035] Iteration 31400, train loss = 0.163900, train accuracy = 0.992188\n",
      "[2018-07-16 20:24:03.629037] Iteration 31500, train loss = 0.185049, train accuracy = 0.992188\n",
      "[2018-07-16 20:24:08.416659] Iteration 31600, train loss = 0.202961, train accuracy = 0.960938\n",
      "[2018-07-16 20:24:13.174718] Iteration 31700, train loss = 0.155235, train accuracy = 0.992188\n",
      "[2018-07-16 20:24:17.963836] Iteration 31800, train loss = 0.171251, train accuracy = 0.984375\n",
      "[2018-07-16 20:24:22.750532] Iteration 31900, train loss = 0.228464, train accuracy = 0.968750\n",
      "[2018-07-16 20:24:27.527811] Iteration 32000, train loss = 0.157357, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:24:33.971207] Iteration 32100, train loss = 0.218482, train accuracy = 0.984375\n",
      "[2018-07-16 20:24:38.729904] Iteration 32200, train loss = 0.155276, train accuracy = 0.992188\n",
      "[2018-07-16 20:24:43.494152] Iteration 32300, train loss = 0.192485, train accuracy = 0.968750\n",
      "[2018-07-16 20:24:48.252891] Iteration 32400, train loss = 0.160357, train accuracy = 0.984375\n",
      "[2018-07-16 20:24:53.019360] Iteration 32500, train loss = 0.190718, train accuracy = 0.960938\n",
      "[2018-07-16 20:24:57.772118] Iteration 32600, train loss = 0.164990, train accuracy = 0.984375\n",
      "[2018-07-16 20:25:02.540638] Iteration 32700, train loss = 0.160960, train accuracy = 0.984375\n",
      "[2018-07-16 20:25:07.301140] Iteration 32800, train loss = 0.209949, train accuracy = 0.953125\n",
      "[2018-07-16 20:25:12.097468] Iteration 32900, train loss = 0.173983, train accuracy = 0.976562\n",
      "[2018-07-16 20:25:16.889279] Iteration 33000, train loss = 0.152840, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907100\n",
      "[2018-07-16 20:25:23.345158] Iteration 33100, train loss = 0.144010, train accuracy = 0.992188\n",
      "[2018-07-16 20:25:28.121548] Iteration 33200, train loss = 0.212785, train accuracy = 0.968750\n",
      "[2018-07-16 20:25:32.885184] Iteration 33300, train loss = 0.155600, train accuracy = 0.992188\n",
      "[2018-07-16 20:25:37.674078] Iteration 33400, train loss = 0.156807, train accuracy = 0.984375\n",
      "[2018-07-16 20:25:42.439885] Iteration 33500, train loss = 0.153840, train accuracy = 0.984375\n",
      "[2018-07-16 20:25:47.212104] Iteration 33600, train loss = 0.198871, train accuracy = 0.976562\n",
      "[2018-07-16 20:25:51.978785] Iteration 33700, train loss = 0.217441, train accuracy = 0.968750\n",
      "[2018-07-16 20:25:56.744958] Iteration 33800, train loss = 0.168054, train accuracy = 0.992188\n",
      "[2018-07-16 20:26:01.508736] Iteration 33900, train loss = 0.164166, train accuracy = 0.984375\n",
      "[2018-07-16 20:26:06.324019] Iteration 34000, train loss = 0.172598, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:26:12.772898] Iteration 34100, train loss = 0.161879, train accuracy = 0.984375\n",
      "[2018-07-16 20:26:17.536426] Iteration 34200, train loss = 0.155072, train accuracy = 0.984375\n",
      "[2018-07-16 20:26:22.306821] Iteration 34300, train loss = 0.165191, train accuracy = 0.976562\n",
      "[2018-07-16 20:26:27.068096] Iteration 34400, train loss = 0.157615, train accuracy = 0.992188\n",
      "[2018-07-16 20:26:31.833291] Iteration 34500, train loss = 0.167813, train accuracy = 0.976562\n",
      "[2018-07-16 20:26:36.589926] Iteration 34600, train loss = 0.145651, train accuracy = 0.992188\n",
      "[2018-07-16 20:26:41.356157] Iteration 34700, train loss = 0.188607, train accuracy = 0.968750\n",
      "[2018-07-16 20:26:46.112534] Iteration 34800, train loss = 0.157338, train accuracy = 0.992188\n",
      "[2018-07-16 20:26:50.876965] Iteration 34900, train loss = 0.201238, train accuracy = 0.976562\n",
      "[2018-07-16 20:26:55.639443] Iteration 35000, train loss = 0.181239, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907400\n",
      "[2018-07-16 20:27:02.147731] Iteration 35100, train loss = 0.149210, train accuracy = 0.992188\n",
      "[2018-07-16 20:27:06.912599] Iteration 35200, train loss = 0.175202, train accuracy = 0.984375\n",
      "[2018-07-16 20:27:11.681850] Iteration 35300, train loss = 0.202434, train accuracy = 0.968750\n",
      "[2018-07-16 20:27:16.452012] Iteration 35400, train loss = 0.162101, train accuracy = 0.976562\n",
      "[2018-07-16 20:27:21.216157] Iteration 35500, train loss = 0.155577, train accuracy = 0.992188\n",
      "[2018-07-16 20:27:25.989982] Iteration 35600, train loss = 0.196372, train accuracy = 0.968750\n",
      "[2018-07-16 20:27:30.762655] Iteration 35700, train loss = 0.206308, train accuracy = 0.968750\n",
      "[2018-07-16 20:27:35.528001] Iteration 35800, train loss = 0.145021, train accuracy = 1.000000\n",
      "[2018-07-16 20:27:40.299014] Iteration 35900, train loss = 0.173997, train accuracy = 0.984375\n",
      "[2018-07-16 20:27:45.066695] Iteration 36000, train loss = 0.149950, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:27:51.524003] Iteration 36100, train loss = 0.149816, train accuracy = 1.000000\n",
      "[2018-07-16 20:27:56.306906] Iteration 36200, train loss = 0.158609, train accuracy = 0.992188\n",
      "[2018-07-16 20:28:01.069667] Iteration 36300, train loss = 0.187348, train accuracy = 0.984375\n",
      "[2018-07-16 20:28:05.829458] Iteration 36400, train loss = 0.156125, train accuracy = 0.992188\n",
      "[2018-07-16 20:28:10.600456] Iteration 36500, train loss = 0.151932, train accuracy = 0.992188\n",
      "[2018-07-16 20:28:15.360962] Iteration 36600, train loss = 0.201760, train accuracy = 0.976562\n",
      "[2018-07-16 20:28:20.117069] Iteration 36700, train loss = 0.214232, train accuracy = 0.960938\n",
      "[2018-07-16 20:28:24.901170] Iteration 36800, train loss = 0.184215, train accuracy = 0.984375\n",
      "[2018-07-16 20:28:29.669765] Iteration 36900, train loss = 0.219410, train accuracy = 0.976562\n",
      "[2018-07-16 20:28:34.428022] Iteration 37000, train loss = 0.244271, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:28:40.883678] Iteration 37100, train loss = 0.174675, train accuracy = 0.976562\n",
      "[2018-07-16 20:28:45.704650] Iteration 37200, train loss = 0.152842, train accuracy = 0.992188\n",
      "[2018-07-16 20:28:50.467463] Iteration 37300, train loss = 0.156643, train accuracy = 1.000000\n",
      "[2018-07-16 20:28:55.238144] Iteration 37400, train loss = 0.147342, train accuracy = 0.992188\n",
      "[2018-07-16 20:29:00.007108] Iteration 37500, train loss = 0.142340, train accuracy = 1.000000\n",
      "[2018-07-16 20:29:04.786407] Iteration 37600, train loss = 0.175459, train accuracy = 0.976562\n",
      "[2018-07-16 20:29:09.542192] Iteration 37700, train loss = 0.176693, train accuracy = 0.976562\n",
      "[2018-07-16 20:29:14.309808] Iteration 37800, train loss = 0.160312, train accuracy = 0.984375\n",
      "[2018-07-16 20:29:19.067848] Iteration 37900, train loss = 0.146758, train accuracy = 1.000000\n",
      "[2018-07-16 20:29:23.828163] Iteration 38000, train loss = 0.150506, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907400\n",
      "[2018-07-16 20:29:30.265968] Iteration 38100, train loss = 0.166059, train accuracy = 0.984375\n",
      "[2018-07-16 20:29:35.041907] Iteration 38200, train loss = 0.206913, train accuracy = 0.968750\n",
      "[2018-07-16 20:29:39.830799] Iteration 38300, train loss = 0.150555, train accuracy = 1.000000\n",
      "[2018-07-16 20:29:44.591616] Iteration 38400, train loss = 0.161636, train accuracy = 0.984375\n",
      "[2018-07-16 20:29:49.362474] Iteration 38500, train loss = 0.208165, train accuracy = 0.968750\n",
      "[2018-07-16 20:29:54.123182] Iteration 38600, train loss = 0.146662, train accuracy = 1.000000\n",
      "[2018-07-16 20:29:58.882548] Iteration 38700, train loss = 0.197664, train accuracy = 0.968750\n",
      "[2018-07-16 20:30:03.646923] Iteration 38800, train loss = 0.149816, train accuracy = 0.992188\n",
      "[2018-07-16 20:30:08.418425] Iteration 38900, train loss = 0.207088, train accuracy = 0.976562\n",
      "[2018-07-16 20:30:13.175432] Iteration 39000, train loss = 0.190565, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906900\n",
      "[2018-07-16 20:30:19.624858] Iteration 39100, train loss = 0.181483, train accuracy = 0.968750\n",
      "[2018-07-16 20:30:24.398906] Iteration 39200, train loss = 0.187392, train accuracy = 0.984375\n",
      "[2018-07-16 20:30:29.160079] Iteration 39300, train loss = 0.241394, train accuracy = 0.968750\n",
      "[2018-07-16 20:30:33.964243] Iteration 39400, train loss = 0.197159, train accuracy = 0.968750\n",
      "[2018-07-16 20:30:38.735813] Iteration 39500, train loss = 0.149436, train accuracy = 0.992188\n",
      "[2018-07-16 20:30:43.520077] Iteration 39600, train loss = 0.174537, train accuracy = 0.984375\n",
      "[2018-07-16 20:30:48.288045] Iteration 39700, train loss = 0.218714, train accuracy = 0.976562\n",
      "[2018-07-16 20:30:53.062713] Iteration 39800, train loss = 0.177845, train accuracy = 0.984375\n",
      "[2018-07-16 20:30:57.820472] Iteration 39900, train loss = 0.244923, train accuracy = 0.968750\n",
      "[2018-07-16 20:31:02.582060] Iteration 40000, train loss = 0.152584, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907500\n",
      "[2018-07-16 20:31:09.019473] Iteration 40100, train loss = 0.156208, train accuracy = 0.984375\n",
      "[2018-07-16 20:31:13.776336] Iteration 40200, train loss = 0.186315, train accuracy = 0.992188\n",
      "[2018-07-16 20:31:18.541464] Iteration 40300, train loss = 0.199782, train accuracy = 0.968750\n",
      "[2018-07-16 20:31:23.309796] Iteration 40400, train loss = 0.192387, train accuracy = 0.968750\n",
      "[2018-07-16 20:31:28.117628] Iteration 40500, train loss = 0.165703, train accuracy = 0.984375\n",
      "[2018-07-16 20:31:32.875867] Iteration 40600, train loss = 0.199125, train accuracy = 0.976562\n",
      "[2018-07-16 20:31:37.644284] Iteration 40700, train loss = 0.170409, train accuracy = 0.984375\n",
      "[2018-07-16 20:31:42.418464] Iteration 40800, train loss = 0.182531, train accuracy = 0.984375\n",
      "[2018-07-16 20:31:47.187375] Iteration 40900, train loss = 0.222220, train accuracy = 0.976562\n",
      "[2018-07-16 20:31:51.951370] Iteration 41000, train loss = 0.183667, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.906900\n",
      "[2018-07-16 20:31:58.387266] Iteration 41100, train loss = 0.182481, train accuracy = 0.984375\n",
      "[2018-07-16 20:32:03.163477] Iteration 41200, train loss = 0.154855, train accuracy = 0.992188\n",
      "[2018-07-16 20:32:07.946875] Iteration 41300, train loss = 0.174381, train accuracy = 0.976562\n",
      "[2018-07-16 20:32:12.709592] Iteration 41400, train loss = 0.143374, train accuracy = 0.992188\n",
      "[2018-07-16 20:32:17.499565] Iteration 41500, train loss = 0.178135, train accuracy = 0.984375\n",
      "[2018-07-16 20:32:22.261001] Iteration 41600, train loss = 0.136135, train accuracy = 1.000000\n",
      "[2018-07-16 20:32:27.029489] Iteration 41700, train loss = 0.143041, train accuracy = 0.992188\n",
      "[2018-07-16 20:32:31.790340] Iteration 41800, train loss = 0.229305, train accuracy = 0.960938\n",
      "[2018-07-16 20:32:36.577431] Iteration 41900, train loss = 0.156661, train accuracy = 0.992188\n",
      "[2018-07-16 20:32:41.351582] Iteration 42000, train loss = 0.257495, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:32:47.809034] Iteration 42100, train loss = 0.159985, train accuracy = 0.992188\n",
      "[2018-07-16 20:32:52.582714] Iteration 42200, train loss = 0.169937, train accuracy = 0.992188\n",
      "[2018-07-16 20:32:57.346332] Iteration 42300, train loss = 0.144412, train accuracy = 0.992188\n",
      "[2018-07-16 20:33:02.102647] Iteration 42400, train loss = 0.141818, train accuracy = 1.000000\n",
      "[2018-07-16 20:33:06.859131] Iteration 42500, train loss = 0.159014, train accuracy = 0.984375\n",
      "[2018-07-16 20:33:11.665281] Iteration 42600, train loss = 0.150062, train accuracy = 1.000000\n",
      "[2018-07-16 20:33:16.436585] Iteration 42700, train loss = 0.159983, train accuracy = 0.976562\n",
      "[2018-07-16 20:33:21.195140] Iteration 42800, train loss = 0.248784, train accuracy = 0.968750\n",
      "[2018-07-16 20:33:25.964374] Iteration 42900, train loss = 0.187194, train accuracy = 0.976562\n",
      "[2018-07-16 20:33:30.717403] Iteration 43000, train loss = 0.175154, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906900\n",
      "[2018-07-16 20:33:37.149519] Iteration 43100, train loss = 0.164281, train accuracy = 0.984375\n",
      "[2018-07-16 20:33:41.912996] Iteration 43200, train loss = 0.185390, train accuracy = 0.976562\n",
      "[2018-07-16 20:33:46.676309] Iteration 43300, train loss = 0.177857, train accuracy = 0.976562\n",
      "[2018-07-16 20:33:51.448016] Iteration 43400, train loss = 0.253475, train accuracy = 0.953125\n",
      "[2018-07-16 20:33:56.212005] Iteration 43500, train loss = 0.303001, train accuracy = 0.953125\n",
      "[2018-07-16 20:34:00.978131] Iteration 43600, train loss = 0.187199, train accuracy = 0.976562\n",
      "[2018-07-16 20:34:05.773982] Iteration 43700, train loss = 0.188376, train accuracy = 0.968750\n",
      "[2018-07-16 20:34:10.542063] Iteration 43800, train loss = 0.149589, train accuracy = 0.992188\n",
      "[2018-07-16 20:34:15.309062] Iteration 43900, train loss = 0.227917, train accuracy = 0.968750\n",
      "[2018-07-16 20:34:20.063954] Iteration 44000, train loss = 0.171364, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907500\n",
      "[2018-07-16 20:34:26.491298] Iteration 44100, train loss = 0.167147, train accuracy = 0.984375\n",
      "[2018-07-16 20:34:31.252316] Iteration 44200, train loss = 0.203165, train accuracy = 0.984375\n",
      "[2018-07-16 20:34:36.009910] Iteration 44300, train loss = 0.162054, train accuracy = 0.992188\n",
      "[2018-07-16 20:34:40.773877] Iteration 44400, train loss = 0.175693, train accuracy = 0.984375\n",
      "[2018-07-16 20:34:45.535659] Iteration 44500, train loss = 0.149596, train accuracy = 1.000000\n",
      "[2018-07-16 20:34:50.304440] Iteration 44600, train loss = 0.222839, train accuracy = 0.960938\n",
      "[2018-07-16 20:34:55.077239] Iteration 44700, train loss = 0.194178, train accuracy = 0.976562\n",
      "[2018-07-16 20:34:59.866644] Iteration 44800, train loss = 0.208209, train accuracy = 0.976562\n",
      "[2018-07-16 20:35:04.636422] Iteration 44900, train loss = 0.183079, train accuracy = 0.976562\n",
      "[2018-07-16 20:35:09.411627] Iteration 45000, train loss = 0.161378, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907600\n",
      "[2018-07-16 20:35:15.857621] Iteration 45100, train loss = 0.176619, train accuracy = 0.992188\n",
      "[2018-07-16 20:35:20.619408] Iteration 45200, train loss = 0.178149, train accuracy = 0.984375\n",
      "[2018-07-16 20:35:25.375262] Iteration 45300, train loss = 0.169620, train accuracy = 0.984375\n",
      "[2018-07-16 20:35:30.138544] Iteration 45400, train loss = 0.144338, train accuracy = 1.000000\n",
      "[2018-07-16 20:35:34.899502] Iteration 45500, train loss = 0.144577, train accuracy = 0.992188\n",
      "[2018-07-16 20:35:39.662552] Iteration 45600, train loss = 0.165696, train accuracy = 0.992188\n",
      "[2018-07-16 20:35:44.424438] Iteration 45700, train loss = 0.193723, train accuracy = 0.968750\n",
      "[2018-07-16 20:35:49.196644] Iteration 45800, train loss = 0.208657, train accuracy = 0.984375\n",
      "[2018-07-16 20:35:54.000970] Iteration 45900, train loss = 0.177863, train accuracy = 0.984375\n",
      "[2018-07-16 20:35:58.769578] Iteration 46000, train loss = 0.158436, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:36:05.214879] Iteration 46100, train loss = 0.233780, train accuracy = 0.960938\n",
      "[2018-07-16 20:36:09.979333] Iteration 46200, train loss = 0.180111, train accuracy = 0.992188\n",
      "[2018-07-16 20:36:14.752997] Iteration 46300, train loss = 0.196300, train accuracy = 0.968750\n",
      "[2018-07-16 20:36:19.510751] Iteration 46400, train loss = 0.202885, train accuracy = 0.968750\n",
      "[2018-07-16 20:36:24.271814] Iteration 46500, train loss = 0.134854, train accuracy = 1.000000\n",
      "[2018-07-16 20:36:29.035120] Iteration 46600, train loss = 0.140276, train accuracy = 1.000000\n",
      "[2018-07-16 20:36:33.803258] Iteration 46700, train loss = 0.236997, train accuracy = 0.968750\n",
      "[2018-07-16 20:36:38.559829] Iteration 46800, train loss = 0.186989, train accuracy = 0.984375\n",
      "[2018-07-16 20:36:43.316683] Iteration 46900, train loss = 0.168879, train accuracy = 0.976562\n",
      "[2018-07-16 20:36:48.104169] Iteration 47000, train loss = 0.173211, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:36:54.559447] Iteration 47100, train loss = 0.185686, train accuracy = 0.976562\n",
      "[2018-07-16 20:36:59.324251] Iteration 47200, train loss = 0.164518, train accuracy = 0.992188\n",
      "[2018-07-16 20:37:04.081826] Iteration 47300, train loss = 0.227463, train accuracy = 0.953125\n",
      "[2018-07-16 20:37:08.837056] Iteration 47400, train loss = 0.163580, train accuracy = 1.000000\n",
      "[2018-07-16 20:37:13.592992] Iteration 47500, train loss = 0.180969, train accuracy = 0.984375\n",
      "[2018-07-16 20:37:18.355382] Iteration 47600, train loss = 0.223432, train accuracy = 0.945312\n",
      "[2018-07-16 20:37:23.127228] Iteration 47700, train loss = 0.143259, train accuracy = 1.000000\n",
      "[2018-07-16 20:37:27.894511] Iteration 47800, train loss = 0.195028, train accuracy = 0.960938\n",
      "[2018-07-16 20:37:32.661221] Iteration 47900, train loss = 0.191317, train accuracy = 0.976562\n",
      "[2018-07-16 20:37:37.460752] Iteration 48000, train loss = 0.192644, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.906500\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-16 20:37:43.943089] Iteration 48100, train loss = 0.158093, train accuracy = 0.984375\n",
      "[2018-07-16 20:37:48.713341] Iteration 48200, train loss = 0.189147, train accuracy = 0.968750\n",
      "[2018-07-16 20:37:53.480898] Iteration 48300, train loss = 0.197103, train accuracy = 0.976562\n",
      "[2018-07-16 20:37:58.241227] Iteration 48400, train loss = 0.220588, train accuracy = 0.968750\n",
      "[2018-07-16 20:38:03.001632] Iteration 48500, train loss = 0.138031, train accuracy = 1.000000\n",
      "[2018-07-16 20:38:07.767535] Iteration 48600, train loss = 0.169205, train accuracy = 0.984375\n",
      "[2018-07-16 20:38:12.523935] Iteration 48700, train loss = 0.201779, train accuracy = 0.960938\n",
      "[2018-07-16 20:38:17.279566] Iteration 48800, train loss = 0.156174, train accuracy = 0.984375\n",
      "[2018-07-16 20:38:22.056819] Iteration 48900, train loss = 0.206264, train accuracy = 0.968750\n",
      "[2018-07-16 20:38:26.816795] Iteration 49000, train loss = 0.145095, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.906500\n",
      "[2018-07-16 20:38:33.271830] Iteration 49100, train loss = 0.237408, train accuracy = 0.984375\n",
      "[2018-07-16 20:38:38.033394] Iteration 49200, train loss = 0.206552, train accuracy = 0.953125\n",
      "[2018-07-16 20:38:42.790493] Iteration 49300, train loss = 0.168400, train accuracy = 0.984375\n",
      "[2018-07-16 20:38:47.550111] Iteration 49400, train loss = 0.199826, train accuracy = 0.984375\n",
      "[2018-07-16 20:38:52.316344] Iteration 49500, train loss = 0.193552, train accuracy = 0.984375\n",
      "[2018-07-16 20:38:57.077467] Iteration 49600, train loss = 0.228232, train accuracy = 0.968750\n",
      "[2018-07-16 20:39:01.828063] Iteration 49700, train loss = 0.224406, train accuracy = 0.960938\n",
      "[2018-07-16 20:39:06.587952] Iteration 49800, train loss = 0.211026, train accuracy = 0.960938\n",
      "[2018-07-16 20:39:11.353555] Iteration 49900, train loss = 0.140356, train accuracy = 1.000000\n",
      "[2018-07-16 20:39:16.117116] Iteration 50000, train loss = 0.166891, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907200\n",
      "[2018-07-16 20:39:22.563374] Iteration 50100, train loss = 0.193933, train accuracy = 0.976562\n",
      "[2018-07-16 20:39:27.345369] Iteration 50200, train loss = 0.171937, train accuracy = 0.992188\n",
      "[2018-07-16 20:39:32.112305] Iteration 50300, train loss = 0.160836, train accuracy = 0.984375\n",
      "[2018-07-16 20:39:36.875470] Iteration 50400, train loss = 0.205059, train accuracy = 0.968750\n",
      "[2018-07-16 20:39:41.652102] Iteration 50500, train loss = 0.204619, train accuracy = 0.976562\n",
      "[2018-07-16 20:39:46.424420] Iteration 50600, train loss = 0.161026, train accuracy = 0.992188\n",
      "[2018-07-16 20:39:51.189525] Iteration 50700, train loss = 0.242309, train accuracy = 0.968750\n",
      "[2018-07-16 20:39:55.968065] Iteration 50800, train loss = 0.168788, train accuracy = 0.992188\n",
      "[2018-07-16 20:40:00.738693] Iteration 50900, train loss = 0.193200, train accuracy = 0.976562\n",
      "[2018-07-16 20:40:05.502338] Iteration 51000, train loss = 0.269607, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:40:11.952275] Iteration 51100, train loss = 0.195439, train accuracy = 0.976562\n",
      "[2018-07-16 20:40:16.723234] Iteration 51200, train loss = 0.169357, train accuracy = 0.992188\n",
      "[2018-07-16 20:40:21.508808] Iteration 51300, train loss = 0.242115, train accuracy = 0.976562\n",
      "[2018-07-16 20:40:26.270824] Iteration 51400, train loss = 0.230568, train accuracy = 0.960938\n",
      "[2018-07-16 20:40:31.026475] Iteration 51500, train loss = 0.177615, train accuracy = 0.976562\n",
      "[2018-07-16 20:40:35.783216] Iteration 51600, train loss = 0.170073, train accuracy = 0.984375\n",
      "[2018-07-16 20:40:40.552280] Iteration 51700, train loss = 0.158463, train accuracy = 0.992188\n",
      "[2018-07-16 20:40:45.309831] Iteration 51800, train loss = 0.255947, train accuracy = 0.968750\n",
      "[2018-07-16 20:40:50.084827] Iteration 51900, train loss = 0.203087, train accuracy = 0.968750\n",
      "[2018-07-16 20:40:54.848650] Iteration 52000, train loss = 0.171004, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:41:01.294860] Iteration 52100, train loss = 0.146515, train accuracy = 0.992188\n",
      "[2018-07-16 20:41:06.070401] Iteration 52200, train loss = 0.139055, train accuracy = 1.000000\n",
      "[2018-07-16 20:41:10.854509] Iteration 52300, train loss = 0.207293, train accuracy = 0.960938\n",
      "[2018-07-16 20:41:15.622249] Iteration 52400, train loss = 0.157329, train accuracy = 0.992188\n",
      "[2018-07-16 20:41:20.400800] Iteration 52500, train loss = 0.277123, train accuracy = 0.953125\n",
      "[2018-07-16 20:41:25.166748] Iteration 52600, train loss = 0.200201, train accuracy = 0.968750\n",
      "[2018-07-16 20:41:29.921832] Iteration 52700, train loss = 0.157127, train accuracy = 0.992188\n",
      "[2018-07-16 20:41:34.688266] Iteration 52800, train loss = 0.168256, train accuracy = 0.984375\n",
      "[2018-07-16 20:41:39.456869] Iteration 52900, train loss = 0.187468, train accuracy = 0.968750\n",
      "[2018-07-16 20:41:44.203985] Iteration 53000, train loss = 0.171201, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907400\n",
      "[2018-07-16 20:41:50.655193] Iteration 53100, train loss = 0.178575, train accuracy = 0.976562\n",
      "[2018-07-16 20:41:55.421266] Iteration 53200, train loss = 0.137811, train accuracy = 1.000000\n",
      "[2018-07-16 20:42:00.169980] Iteration 53300, train loss = 0.180971, train accuracy = 0.976562\n",
      "[2018-07-16 20:42:04.968550] Iteration 53400, train loss = 0.224147, train accuracy = 0.968750\n",
      "[2018-07-16 20:42:09.747093] Iteration 53500, train loss = 0.178884, train accuracy = 0.984375\n",
      "[2018-07-16 20:42:14.517153] Iteration 53600, train loss = 0.196189, train accuracy = 0.968750\n",
      "[2018-07-16 20:42:19.290161] Iteration 53700, train loss = 0.135284, train accuracy = 1.000000\n",
      "[2018-07-16 20:42:24.061845] Iteration 53800, train loss = 0.145596, train accuracy = 1.000000\n",
      "[2018-07-16 20:42:28.809592] Iteration 53900, train loss = 0.181235, train accuracy = 0.976562\n",
      "[2018-07-16 20:42:33.582065] Iteration 54000, train loss = 0.182767, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:42:40.031842] Iteration 54100, train loss = 0.183530, train accuracy = 0.976562\n",
      "[2018-07-16 20:42:44.805497] Iteration 54200, train loss = 0.188381, train accuracy = 0.976562\n",
      "[2018-07-16 20:42:49.568509] Iteration 54300, train loss = 0.151405, train accuracy = 0.992188\n",
      "[2018-07-16 20:42:54.354460] Iteration 54400, train loss = 0.141597, train accuracy = 1.000000\n",
      "[2018-07-16 20:42:59.161311] Iteration 54500, train loss = 0.258539, train accuracy = 0.960938\n",
      "[2018-07-16 20:43:03.925029] Iteration 54600, train loss = 0.169449, train accuracy = 0.984375\n",
      "[2018-07-16 20:43:08.688191] Iteration 54700, train loss = 0.148871, train accuracy = 1.000000\n",
      "[2018-07-16 20:43:13.451950] Iteration 54800, train loss = 0.142392, train accuracy = 1.000000\n",
      "[2018-07-16 20:43:18.212201] Iteration 54900, train loss = 0.143051, train accuracy = 1.000000\n",
      "[2018-07-16 20:43:22.972774] Iteration 55000, train loss = 0.193426, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907200\n",
      "[2018-07-16 20:43:29.416300] Iteration 55100, train loss = 0.154354, train accuracy = 0.992188\n",
      "[2018-07-16 20:43:34.181804] Iteration 55200, train loss = 0.170146, train accuracy = 0.992188\n",
      "[2018-07-16 20:43:38.947989] Iteration 55300, train loss = 0.202824, train accuracy = 0.976562\n",
      "[2018-07-16 20:43:43.707500] Iteration 55400, train loss = 0.205044, train accuracy = 0.976562\n",
      "[2018-07-16 20:43:48.473491] Iteration 55500, train loss = 0.263370, train accuracy = 0.960938\n",
      "[2018-07-16 20:43:53.259189] Iteration 55600, train loss = 0.249121, train accuracy = 0.968750\n",
      "[2018-07-16 20:43:58.023739] Iteration 55700, train loss = 0.149541, train accuracy = 1.000000\n",
      "[2018-07-16 20:44:02.793397] Iteration 55800, train loss = 0.149158, train accuracy = 0.992188\n",
      "[2018-07-16 20:44:07.566298] Iteration 55900, train loss = 0.191440, train accuracy = 0.976562\n",
      "[2018-07-16 20:44:12.325180] Iteration 56000, train loss = 0.210044, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.906900\n",
      "[2018-07-16 20:44:18.763793] Iteration 56100, train loss = 0.211780, train accuracy = 0.960938\n",
      "[2018-07-16 20:44:23.526241] Iteration 56200, train loss = 0.192103, train accuracy = 0.968750\n",
      "[2018-07-16 20:44:28.291763] Iteration 56300, train loss = 0.158131, train accuracy = 0.984375\n",
      "[2018-07-16 20:44:33.061073] Iteration 56400, train loss = 0.182891, train accuracy = 0.984375\n",
      "[2018-07-16 20:44:37.819869] Iteration 56500, train loss = 0.163068, train accuracy = 0.992188\n",
      "[2018-07-16 20:44:42.596066] Iteration 56600, train loss = 0.259324, train accuracy = 0.968750\n",
      "[2018-07-16 20:44:47.384135] Iteration 56700, train loss = 0.175649, train accuracy = 0.984375\n",
      "[2018-07-16 20:44:52.147989] Iteration 56800, train loss = 0.177745, train accuracy = 0.976562\n",
      "[2018-07-16 20:44:56.925962] Iteration 56900, train loss = 0.179891, train accuracy = 0.984375\n",
      "[2018-07-16 20:45:01.677459] Iteration 57000, train loss = 0.228573, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:45:08.116260] Iteration 57100, train loss = 0.205164, train accuracy = 0.968750\n",
      "[2018-07-16 20:45:12.883150] Iteration 57200, train loss = 0.199277, train accuracy = 0.984375\n",
      "[2018-07-16 20:45:17.642053] Iteration 57300, train loss = 0.183582, train accuracy = 0.976562\n",
      "[2018-07-16 20:45:22.409828] Iteration 57400, train loss = 0.145018, train accuracy = 0.992188\n",
      "[2018-07-16 20:45:27.184991] Iteration 57500, train loss = 0.163752, train accuracy = 0.976562\n",
      "[2018-07-16 20:45:31.953837] Iteration 57600, train loss = 0.201130, train accuracy = 0.984375\n",
      "[2018-07-16 20:45:36.733707] Iteration 57700, train loss = 0.228549, train accuracy = 0.968750\n",
      "[2018-07-16 20:45:41.523664] Iteration 57800, train loss = 0.206739, train accuracy = 0.984375\n",
      "[2018-07-16 20:45:46.296841] Iteration 57900, train loss = 0.172664, train accuracy = 0.976562\n",
      "[2018-07-16 20:45:51.063109] Iteration 58000, train loss = 0.159480, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:45:57.526603] Iteration 58100, train loss = 0.192541, train accuracy = 0.992188\n",
      "[2018-07-16 20:46:02.305942] Iteration 58200, train loss = 0.203320, train accuracy = 0.984375\n",
      "[2018-07-16 20:46:07.078461] Iteration 58300, train loss = 0.207593, train accuracy = 0.968750\n",
      "[2018-07-16 20:46:11.833994] Iteration 58400, train loss = 0.163478, train accuracy = 0.984375\n",
      "[2018-07-16 20:46:16.589794] Iteration 58500, train loss = 0.154747, train accuracy = 0.992188\n",
      "[2018-07-16 20:46:21.355093] Iteration 58600, train loss = 0.159887, train accuracy = 0.992188\n",
      "[2018-07-16 20:46:26.130230] Iteration 58700, train loss = 0.205700, train accuracy = 0.976562\n",
      "[2018-07-16 20:46:30.937288] Iteration 58800, train loss = 0.166560, train accuracy = 0.992188\n",
      "[2018-07-16 20:46:35.692097] Iteration 58900, train loss = 0.202546, train accuracy = 0.968750\n",
      "[2018-07-16 20:46:40.455820] Iteration 59000, train loss = 0.216753, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907200\n",
      "[2018-07-16 20:46:46.903013] Iteration 59100, train loss = 0.175713, train accuracy = 0.984375\n",
      "[2018-07-16 20:46:51.663006] Iteration 59200, train loss = 0.215320, train accuracy = 0.968750\n",
      "[2018-07-16 20:46:56.443550] Iteration 59300, train loss = 0.151229, train accuracy = 0.992188\n",
      "[2018-07-16 20:47:01.227291] Iteration 59400, train loss = 0.215295, train accuracy = 0.968750\n",
      "[2018-07-16 20:47:05.985943] Iteration 59500, train loss = 0.249480, train accuracy = 0.976562\n",
      "[2018-07-16 20:47:10.753373] Iteration 59600, train loss = 0.173415, train accuracy = 0.984375\n",
      "[2018-07-16 20:47:15.523751] Iteration 59700, train loss = 0.200484, train accuracy = 0.968750\n",
      "[2018-07-16 20:47:20.290930] Iteration 59800, train loss = 0.170231, train accuracy = 0.992188\n",
      "[2018-07-16 20:47:25.088894] Iteration 59900, train loss = 0.191535, train accuracy = 0.968750\n",
      "[2018-07-16 20:47:29.861774] Iteration 60000, train loss = 0.181692, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:47:36.312766] Iteration 60100, train loss = 0.170412, train accuracy = 0.976562\n",
      "[2018-07-16 20:47:41.081674] Iteration 60200, train loss = 0.246071, train accuracy = 0.937500\n",
      "[2018-07-16 20:47:45.847529] Iteration 60300, train loss = 0.211208, train accuracy = 0.960938\n",
      "[2018-07-16 20:47:50.618407] Iteration 60400, train loss = 0.146753, train accuracy = 1.000000\n",
      "[2018-07-16 20:47:55.385574] Iteration 60500, train loss = 0.166200, train accuracy = 0.976562\n",
      "[2018-07-16 20:48:00.165750] Iteration 60600, train loss = 0.175760, train accuracy = 0.968750\n",
      "[2018-07-16 20:48:04.920947] Iteration 60700, train loss = 0.176768, train accuracy = 0.984375\n",
      "[2018-07-16 20:48:09.690779] Iteration 60800, train loss = 0.170376, train accuracy = 0.984375\n",
      "[2018-07-16 20:48:14.474865] Iteration 60900, train loss = 0.143856, train accuracy = 0.992188\n",
      "[2018-07-16 20:48:19.262470] Iteration 61000, train loss = 0.163642, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907200\n",
      "[2018-07-16 20:48:25.704410] Iteration 61100, train loss = 0.175865, train accuracy = 0.976562\n",
      "[2018-07-16 20:48:30.459786] Iteration 61200, train loss = 0.168957, train accuracy = 0.984375\n",
      "[2018-07-16 20:48:35.226783] Iteration 61300, train loss = 0.173047, train accuracy = 0.992188\n",
      "[2018-07-16 20:48:39.997634] Iteration 61400, train loss = 0.209482, train accuracy = 0.960938\n",
      "[2018-07-16 20:48:44.753439] Iteration 61500, train loss = 0.195302, train accuracy = 0.984375\n",
      "[2018-07-16 20:48:49.522049] Iteration 61600, train loss = 0.231102, train accuracy = 0.968750\n",
      "[2018-07-16 20:48:54.290230] Iteration 61700, train loss = 0.171391, train accuracy = 0.984375\n",
      "[2018-07-16 20:48:59.060258] Iteration 61800, train loss = 0.149312, train accuracy = 0.992188\n",
      "[2018-07-16 20:49:03.821201] Iteration 61900, train loss = 0.189898, train accuracy = 0.984375\n",
      "[2018-07-16 20:49:08.577841] Iteration 62000, train loss = 0.208177, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.906600\n",
      "[2018-07-16 20:49:15.132718] Iteration 62100, train loss = 0.271407, train accuracy = 0.960938\n",
      "[2018-07-16 20:49:19.903240] Iteration 62200, train loss = 0.171861, train accuracy = 0.976562\n",
      "[2018-07-16 20:49:24.658294] Iteration 62300, train loss = 0.173402, train accuracy = 0.984375\n",
      "[2018-07-16 20:49:29.415817] Iteration 62400, train loss = 0.250913, train accuracy = 0.960938\n",
      "[2018-07-16 20:49:34.179545] Iteration 62500, train loss = 0.261651, train accuracy = 0.984375\n",
      "[2018-07-16 20:49:38.945929] Iteration 62600, train loss = 0.150837, train accuracy = 0.992188\n",
      "[2018-07-16 20:49:43.713595] Iteration 62700, train loss = 0.136958, train accuracy = 1.000000\n",
      "[2018-07-16 20:49:48.490074] Iteration 62800, train loss = 0.169676, train accuracy = 0.976562\n",
      "[2018-07-16 20:49:53.250470] Iteration 62900, train loss = 0.151016, train accuracy = 0.984375\n",
      "[2018-07-16 20:49:58.018980] Iteration 63000, train loss = 0.165501, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.906500\n",
      "[2018-07-16 20:50:04.488077] Iteration 63100, train loss = 0.218377, train accuracy = 0.960938\n",
      "[2018-07-16 20:50:09.261516] Iteration 63200, train loss = 0.170663, train accuracy = 0.976562\n",
      "[2018-07-16 20:50:14.031167] Iteration 63300, train loss = 0.184903, train accuracy = 0.976562\n",
      "[2018-07-16 20:50:18.797672] Iteration 63400, train loss = 0.158386, train accuracy = 0.984375\n",
      "[2018-07-16 20:50:23.560709] Iteration 63500, train loss = 0.195147, train accuracy = 0.976562\n",
      "[2018-07-16 20:50:28.334661] Iteration 63600, train loss = 0.156668, train accuracy = 0.984375\n",
      "[2018-07-16 20:50:33.090906] Iteration 63700, train loss = 0.142650, train accuracy = 1.000000\n",
      "[2018-07-16 20:50:37.861743] Iteration 63800, train loss = 0.187880, train accuracy = 0.976562\n",
      "[2018-07-16 20:50:42.623478] Iteration 63900, train loss = 0.260502, train accuracy = 0.976562\n",
      "[2018-07-16 20:50:47.397050] Iteration 64000, train loss = 0.169971, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:50:53.840747] Iteration 64100, train loss = 0.166047, train accuracy = 0.984375\n",
      "[2018-07-16 20:50:58.621540] Iteration 64200, train loss = 0.195371, train accuracy = 0.984375\n",
      "[2018-07-16 20:51:03.384996] Iteration 64300, train loss = 0.146692, train accuracy = 0.992188\n",
      "[2018-07-16 20:51:08.143561] Iteration 64400, train loss = 0.166968, train accuracy = 0.992188\n",
      "[2018-07-16 20:51:12.914874] Iteration 64500, train loss = 0.146235, train accuracy = 0.992188\n",
      "[2018-07-16 20:51:17.676219] Iteration 64600, train loss = 0.200110, train accuracy = 0.984375\n",
      "[2018-07-16 20:51:22.436153] Iteration 64700, train loss = 0.153032, train accuracy = 1.000000\n",
      "[2018-07-16 20:51:27.212966] Iteration 64800, train loss = 0.265549, train accuracy = 0.960938\n",
      "[2018-07-16 20:51:31.988313] Iteration 64900, train loss = 0.171422, train accuracy = 0.976562\n",
      "[2018-07-16 20:51:36.757248] Iteration 65000, train loss = 0.194047, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.907100\n",
      "[2018-07-16 20:51:43.210796] Iteration 65100, train loss = 0.221517, train accuracy = 0.960938\n",
      "[2018-07-16 20:51:47.976877] Iteration 65200, train loss = 0.237337, train accuracy = 0.968750\n",
      "[2018-07-16 20:51:52.768117] Iteration 65300, train loss = 0.167412, train accuracy = 0.976562\n",
      "[2018-07-16 20:51:57.530861] Iteration 65400, train loss = 0.163766, train accuracy = 0.984375\n",
      "[2018-07-16 20:52:02.292498] Iteration 65500, train loss = 0.202984, train accuracy = 0.976562\n",
      "[2018-07-16 20:52:07.052944] Iteration 65600, train loss = 0.237217, train accuracy = 0.953125\n",
      "[2018-07-16 20:52:11.820169] Iteration 65700, train loss = 0.139932, train accuracy = 1.000000\n",
      "[2018-07-16 20:52:16.588518] Iteration 65800, train loss = 0.139781, train accuracy = 1.000000\n",
      "[2018-07-16 20:52:21.354933] Iteration 65900, train loss = 0.246792, train accuracy = 0.945312\n",
      "[2018-07-16 20:52:26.124482] Iteration 66000, train loss = 0.157404, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907100\n",
      "[2018-07-16 20:52:32.567323] Iteration 66100, train loss = 0.152466, train accuracy = 0.992188\n",
      "[2018-07-16 20:52:37.335512] Iteration 66200, train loss = 0.162457, train accuracy = 0.992188\n",
      "[2018-07-16 20:52:42.118911] Iteration 66300, train loss = 0.213871, train accuracy = 0.968750\n",
      "[2018-07-16 20:52:46.886617] Iteration 66400, train loss = 0.209354, train accuracy = 0.976562\n",
      "[2018-07-16 20:52:51.660207] Iteration 66500, train loss = 0.200441, train accuracy = 0.960938\n",
      "[2018-07-16 20:52:56.428071] Iteration 66600, train loss = 0.154442, train accuracy = 0.992188\n",
      "[2018-07-16 20:53:01.192130] Iteration 66700, train loss = 0.206630, train accuracy = 0.976562\n",
      "[2018-07-16 20:53:05.951227] Iteration 66800, train loss = 0.177745, train accuracy = 0.984375\n",
      "[2018-07-16 20:53:10.723092] Iteration 66900, train loss = 0.149528, train accuracy = 0.992188\n",
      "[2018-07-16 20:53:15.488190] Iteration 67000, train loss = 0.242005, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:53:21.930605] Iteration 67100, train loss = 0.192457, train accuracy = 0.984375\n",
      "[2018-07-16 20:53:26.710506] Iteration 67200, train loss = 0.193122, train accuracy = 0.968750\n",
      "[2018-07-16 20:53:31.470722] Iteration 67300, train loss = 0.151830, train accuracy = 0.992188\n",
      "[2018-07-16 20:53:36.261414] Iteration 67400, train loss = 0.149631, train accuracy = 0.992188\n",
      "[2018-07-16 20:53:41.029206] Iteration 67500, train loss = 0.158971, train accuracy = 0.984375\n",
      "[2018-07-16 20:53:45.794929] Iteration 67600, train loss = 0.220736, train accuracy = 0.968750\n",
      "[2018-07-16 20:53:50.548391] Iteration 67700, train loss = 0.170896, train accuracy = 0.984375\n",
      "[2018-07-16 20:53:55.319754] Iteration 67800, train loss = 0.179338, train accuracy = 0.984375\n",
      "[2018-07-16 20:54:00.078829] Iteration 67900, train loss = 0.223270, train accuracy = 0.968750\n",
      "[2018-07-16 20:54:04.843080] Iteration 68000, train loss = 0.170734, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.906700\n",
      "[2018-07-16 20:54:11.267883] Iteration 68100, train loss = 0.172022, train accuracy = 0.992188\n",
      "[2018-07-16 20:54:16.022204] Iteration 68200, train loss = 0.164245, train accuracy = 0.976562\n",
      "[2018-07-16 20:54:20.780210] Iteration 68300, train loss = 0.213585, train accuracy = 0.953125\n",
      "[2018-07-16 20:54:25.541523] Iteration 68400, train loss = 0.219674, train accuracy = 0.960938\n",
      "[2018-07-16 20:54:30.377030] Iteration 68500, train loss = 0.143101, train accuracy = 0.992188\n",
      "[2018-07-16 20:54:35.135827] Iteration 68600, train loss = 0.220725, train accuracy = 0.968750\n",
      "[2018-07-16 20:54:39.890770] Iteration 68700, train loss = 0.185311, train accuracy = 0.984375\n",
      "[2018-07-16 20:54:44.659431] Iteration 68800, train loss = 0.152854, train accuracy = 0.992188\n",
      "[2018-07-16 20:54:49.422046] Iteration 68900, train loss = 0.187975, train accuracy = 0.976562\n",
      "[2018-07-16 20:54:54.194706] Iteration 69000, train loss = 0.192479, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:55:00.650466] Iteration 69100, train loss = 0.140879, train accuracy = 1.000000\n",
      "[2018-07-16 20:55:05.408796] Iteration 69200, train loss = 0.157727, train accuracy = 0.992188\n",
      "[2018-07-16 20:55:10.174912] Iteration 69300, train loss = 0.190763, train accuracy = 0.960938\n",
      "[2018-07-16 20:55:14.942900] Iteration 69400, train loss = 0.155431, train accuracy = 0.984375\n",
      "[2018-07-16 20:55:19.713809] Iteration 69500, train loss = 0.194852, train accuracy = 0.976562\n",
      "[2018-07-16 20:55:24.500706] Iteration 69600, train loss = 0.148706, train accuracy = 0.992188\n",
      "[2018-07-16 20:55:29.255842] Iteration 69700, train loss = 0.178279, train accuracy = 0.976562\n",
      "[2018-07-16 20:55:34.019962] Iteration 69800, train loss = 0.175423, train accuracy = 0.984375\n",
      "[2018-07-16 20:55:38.780218] Iteration 69900, train loss = 0.183698, train accuracy = 0.992188\n",
      "[2018-07-16 20:55:43.542164] Iteration 70000, train loss = 0.164670, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:55:49.988737] Iteration 70100, train loss = 0.214269, train accuracy = 0.960938\n",
      "[2018-07-16 20:55:54.760376] Iteration 70200, train loss = 0.212768, train accuracy = 0.968750\n",
      "[2018-07-16 20:55:59.529648] Iteration 70300, train loss = 0.215086, train accuracy = 0.960938\n",
      "[2018-07-16 20:56:04.295923] Iteration 70400, train loss = 0.150631, train accuracy = 0.992188\n",
      "[2018-07-16 20:56:09.061829] Iteration 70500, train loss = 0.185119, train accuracy = 0.992188\n",
      "[2018-07-16 20:56:13.821004] Iteration 70600, train loss = 0.187021, train accuracy = 0.984375\n",
      "[2018-07-16 20:56:18.616583] Iteration 70700, train loss = 0.141160, train accuracy = 1.000000\n",
      "[2018-07-16 20:56:23.377362] Iteration 70800, train loss = 0.227347, train accuracy = 0.960938\n",
      "[2018-07-16 20:56:28.154927] Iteration 70900, train loss = 0.156007, train accuracy = 0.992188\n",
      "[2018-07-16 20:56:32.917880] Iteration 71000, train loss = 0.153289, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.906800\n",
      "[2018-07-16 20:56:39.377371] Iteration 71100, train loss = 0.154042, train accuracy = 1.000000\n",
      "[2018-07-16 20:56:44.141613] Iteration 71200, train loss = 0.159820, train accuracy = 0.976562\n",
      "[2018-07-16 20:56:48.892504] Iteration 71300, train loss = 0.151845, train accuracy = 1.000000\n",
      "[2018-07-16 20:56:53.662147] Iteration 71400, train loss = 0.141346, train accuracy = 1.000000\n",
      "[2018-07-16 20:56:58.413073] Iteration 71500, train loss = 0.196973, train accuracy = 0.968750\n",
      "[2018-07-16 20:57:03.199229] Iteration 71600, train loss = 0.132687, train accuracy = 1.000000\n",
      "[2018-07-16 20:57:07.998789] Iteration 71700, train loss = 0.220802, train accuracy = 0.976562\n",
      "[2018-07-16 20:57:12.776351] Iteration 71800, train loss = 0.193735, train accuracy = 0.976562\n",
      "[2018-07-16 20:57:17.536758] Iteration 71900, train loss = 0.175764, train accuracy = 0.984375\n",
      "[2018-07-16 20:57:22.303253] Iteration 72000, train loss = 0.217053, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907100\n",
      "[2018-07-16 20:57:28.752555] Iteration 72100, train loss = 0.175895, train accuracy = 0.976562\n",
      "[2018-07-16 20:57:33.519758] Iteration 72200, train loss = 0.253934, train accuracy = 0.960938\n",
      "[2018-07-16 20:57:38.280929] Iteration 72300, train loss = 0.188944, train accuracy = 0.976562\n",
      "[2018-07-16 20:57:43.040726] Iteration 72400, train loss = 0.163501, train accuracy = 0.984375\n",
      "[2018-07-16 20:57:47.799409] Iteration 72500, train loss = 0.187491, train accuracy = 0.968750\n",
      "[2018-07-16 20:57:52.565611] Iteration 72600, train loss = 0.145304, train accuracy = 0.992188\n",
      "[2018-07-16 20:57:57.338817] Iteration 72700, train loss = 0.196929, train accuracy = 0.992188\n",
      "[2018-07-16 20:58:02.153704] Iteration 72800, train loss = 0.169184, train accuracy = 0.992188\n",
      "[2018-07-16 20:58:06.914306] Iteration 72900, train loss = 0.161749, train accuracy = 0.992188\n",
      "[2018-07-16 20:58:11.684308] Iteration 73000, train loss = 0.190778, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 20:58:18.153214] Iteration 73100, train loss = 0.185034, train accuracy = 0.976562\n",
      "[2018-07-16 20:58:22.919645] Iteration 73200, train loss = 0.178851, train accuracy = 0.984375\n",
      "[2018-07-16 20:58:27.679394] Iteration 73300, train loss = 0.255600, train accuracy = 0.968750\n",
      "[2018-07-16 20:58:32.440167] Iteration 73400, train loss = 0.177668, train accuracy = 0.976562\n",
      "[2018-07-16 20:58:37.209947] Iteration 73500, train loss = 0.229744, train accuracy = 0.992188\n",
      "[2018-07-16 20:58:41.968613] Iteration 73600, train loss = 0.178991, train accuracy = 0.976562\n",
      "[2018-07-16 20:58:46.742770] Iteration 73700, train loss = 0.164680, train accuracy = 0.984375\n",
      "[2018-07-16 20:58:51.509750] Iteration 73800, train loss = 0.165860, train accuracy = 0.976562\n",
      "[2018-07-16 20:58:56.277791] Iteration 73900, train loss = 0.169858, train accuracy = 0.984375\n",
      "[2018-07-16 20:59:01.040503] Iteration 74000, train loss = 0.137388, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.907100\n",
      "[2018-07-16 20:59:07.478978] Iteration 74100, train loss = 0.141703, train accuracy = 1.000000\n",
      "[2018-07-16 20:59:12.247272] Iteration 74200, train loss = 0.146113, train accuracy = 0.992188\n",
      "[2018-07-16 20:59:17.014811] Iteration 74300, train loss = 0.208520, train accuracy = 0.968750\n",
      "[2018-07-16 20:59:21.777799] Iteration 74400, train loss = 0.217968, train accuracy = 0.976562\n",
      "[2018-07-16 20:59:26.545405] Iteration 74500, train loss = 0.203456, train accuracy = 0.968750\n",
      "[2018-07-16 20:59:31.309473] Iteration 74600, train loss = 0.134141, train accuracy = 1.000000\n",
      "[2018-07-16 20:59:36.061917] Iteration 74700, train loss = 0.154914, train accuracy = 0.984375\n",
      "[2018-07-16 20:59:40.815249] Iteration 74800, train loss = 0.186685, train accuracy = 0.968750\n",
      "[2018-07-16 20:59:45.584964] Iteration 74900, train loss = 0.207924, train accuracy = 0.968750\n",
      "[2018-07-16 20:59:50.395937] Iteration 75000, train loss = 0.174892, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 20:59:56.833082] Iteration 75100, train loss = 0.178268, train accuracy = 0.968750\n",
      "[2018-07-16 21:00:01.598506] Iteration 75200, train loss = 0.186732, train accuracy = 0.960938\n",
      "[2018-07-16 21:00:06.359727] Iteration 75300, train loss = 0.163725, train accuracy = 0.984375\n",
      "[2018-07-16 21:00:11.128825] Iteration 75400, train loss = 0.250915, train accuracy = 0.945312\n",
      "[2018-07-16 21:00:15.907906] Iteration 75500, train loss = 0.154422, train accuracy = 1.000000\n",
      "[2018-07-16 21:00:20.668581] Iteration 75600, train loss = 0.215950, train accuracy = 0.960938\n",
      "[2018-07-16 21:00:25.432202] Iteration 75700, train loss = 0.164099, train accuracy = 0.984375\n",
      "[2018-07-16 21:00:30.196427] Iteration 75800, train loss = 0.200437, train accuracy = 0.984375\n",
      "[2018-07-16 21:00:34.973025] Iteration 75900, train loss = 0.208202, train accuracy = 0.960938\n",
      "[2018-07-16 21:00:39.730787] Iteration 76000, train loss = 0.167923, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.907700\n",
      "[2018-07-16 21:00:46.215410] Iteration 76100, train loss = 0.134041, train accuracy = 1.000000\n",
      "[2018-07-16 21:00:50.987324] Iteration 76200, train loss = 0.172269, train accuracy = 0.992188\n",
      "[2018-07-16 21:00:55.745884] Iteration 76300, train loss = 0.203927, train accuracy = 0.984375\n",
      "[2018-07-16 21:01:00.506721] Iteration 76400, train loss = 0.143542, train accuracy = 1.000000\n",
      "[2018-07-16 21:01:05.275211] Iteration 76500, train loss = 0.273007, train accuracy = 0.953125\n",
      "[2018-07-16 21:01:10.037620] Iteration 76600, train loss = 0.227633, train accuracy = 0.976562\n",
      "[2018-07-16 21:01:14.800164] Iteration 76700, train loss = 0.146305, train accuracy = 0.992188\n",
      "[2018-07-16 21:01:19.569815] Iteration 76800, train loss = 0.144392, train accuracy = 1.000000\n",
      "[2018-07-16 21:01:24.348143] Iteration 76900, train loss = 0.172859, train accuracy = 0.984375\n",
      "[2018-07-16 21:01:29.114446] Iteration 77000, train loss = 0.145525, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.907100\n",
      "[2018-07-16 21:01:35.601567] Iteration 77100, train loss = 0.177389, train accuracy = 0.976562\n",
      "[2018-07-16 21:01:40.359004] Iteration 77200, train loss = 0.151950, train accuracy = 0.992188\n",
      "[2018-07-16 21:01:45.142557] Iteration 77300, train loss = 0.210066, train accuracy = 0.968750\n",
      "[2018-07-16 21:01:49.902469] Iteration 77400, train loss = 0.158280, train accuracy = 0.992188\n",
      "[2018-07-16 21:01:54.657508] Iteration 77500, train loss = 0.178900, train accuracy = 0.984375\n",
      "[2018-07-16 21:01:59.421910] Iteration 77600, train loss = 0.147168, train accuracy = 1.000000\n",
      "[2018-07-16 21:02:04.185124] Iteration 77700, train loss = 0.199329, train accuracy = 0.960938\n",
      "[2018-07-16 21:02:08.944745] Iteration 77800, train loss = 0.168613, train accuracy = 0.984375\n",
      "[2018-07-16 21:02:13.716149] Iteration 77900, train loss = 0.155729, train accuracy = 0.984375\n",
      "[2018-07-16 21:02:18.485826] Iteration 78000, train loss = 0.187498, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.907300\n",
      "[2018-07-16 21:02:24.943124] Iteration 78100, train loss = 0.189942, train accuracy = 0.984375\n",
      "[2018-07-16 21:02:29.741183] Iteration 78200, train loss = 0.175210, train accuracy = 0.976562\n",
      "[2018-07-16 21:02:34.510013] Iteration 78300, train loss = 0.168228, train accuracy = 0.984375\n",
      "[2018-07-16 21:02:39.279446] Iteration 78400, train loss = 0.152371, train accuracy = 0.992188\n",
      "[2018-07-16 21:02:44.048740] Iteration 78500, train loss = 0.148573, train accuracy = 1.000000\n",
      "[2018-07-16 21:02:48.811685] Iteration 78600, train loss = 0.162558, train accuracy = 0.992188\n",
      "[2018-07-16 21:02:53.568787] Iteration 78700, train loss = 0.226719, train accuracy = 0.968750\n",
      "[2018-07-16 21:02:58.333857] Iteration 78800, train loss = 0.217266, train accuracy = 0.976562\n",
      "[2018-07-16 21:03:03.103482] Iteration 78900, train loss = 0.156132, train accuracy = 0.984375\n",
      "[2018-07-16 21:03:07.866362] Iteration 79000, train loss = 0.143184, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.907000\n",
      "[2018-07-16 21:03:14.309510] Iteration 79100, train loss = 0.151276, train accuracy = 0.992188\n",
      "[2018-07-16 21:03:19.068118] Iteration 79200, train loss = 0.176458, train accuracy = 0.984375\n",
      "[2018-07-16 21:03:23.886561] Iteration 79300, train loss = 0.191578, train accuracy = 0.984375\n",
      "[2018-07-16 21:03:28.656800] Iteration 79400, train loss = 0.184790, train accuracy = 0.968750\n",
      "[2018-07-16 21:03:33.429164] Iteration 79500, train loss = 0.169110, train accuracy = 0.984375\n",
      "[2018-07-16 21:03:38.195407] Iteration 79600, train loss = 0.175908, train accuracy = 0.984375\n",
      "[2018-07-16 21:03:42.959502] Iteration 79700, train loss = 0.139194, train accuracy = 1.000000\n",
      "[2018-07-16 21:03:47.728627] Iteration 79800, train loss = 0.276187, train accuracy = 0.960938\n",
      "[2018-07-16 21:03:52.491037] Iteration 79900, train loss = 0.175117, train accuracy = 0.984375\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune后的准确率\n",
      "Test accuracy = 0.906900\n"
     ]
    }
   ],
   "source": [
    "print('prune后的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.03125  -0.0625    0.03125   0.125     0.03125  -0.03125   0.015625\n",
      "  0.03125   0.015625 -0.125   ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
