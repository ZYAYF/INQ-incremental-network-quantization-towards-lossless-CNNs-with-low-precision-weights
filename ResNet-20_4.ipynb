{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "# import ipdb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('residual_net_n', 3, '')\n",
    "tf.app.flags.DEFINE_string('train_tf_path', '/home/s1/raochuan/code/data/train.tf', '')\n",
    "tf.app.flags.DEFINE_string('val_tf_path', './data/test.tf', '')\n",
    "tf.app.flags.DEFINE_integer('train_batch_size', 128, '')\n",
    "tf.app.flags.DEFINE_integer('val_batch_size', 100, '')\n",
    "tf.app.flags.DEFINE_float('weight_decay', 0.0005, 'Weight decay')\n",
    "tf.app.flags.DEFINE_integer('summary_interval', 100, 'Interval for summary.')\n",
    "tf.app.flags.DEFINE_integer('val_interval', 1000, 'Interval for evaluation.')\n",
    "tf.app.flags.DEFINE_integer('max_steps', 80000, 'Maximum number of iterations.')\n",
    "tf.app.flags.DEFINE_integer('save_interval', 5000, '')\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')######zhen ni ma  gou shi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_embedding(label, n_classes):\n",
    "  \"\"\"\n",
    "  One-hot embedding\n",
    "  Args:\n",
    "    label: int32 tensor [B]\n",
    "    n_classes: int32, number of classes\n",
    "  Return:\n",
    "    embedding: tensor [B x n_classes]\n",
    "  \"\"\"\n",
    "  embedding_params = np.eye(n_classes, dtype=np.float32)\n",
    "  with tf.device('/cpu:0'):\n",
    "    params = tf.constant(embedding_params)\n",
    "    embedding = tf.gather(params, label)\n",
    "  return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, n_in, n_out, k, s, p='SAME', bias=False, scope='conv'):\n",
    "  with tf.variable_scope(scope):\n",
    "    kernel = tf.Variable(\n",
    "      tf.truncated_normal([k, k, n_in, n_out],\n",
    "        stddev=math.sqrt(2/(k*k*n_in))),\n",
    "      name='weight')\n",
    "    tf.add_to_collection('weights', kernel)\n",
    "    conv = tf.nn.conv2d(x, kernel, [1,s,s,1], padding=p)\n",
    "    if bias:\n",
    "      bias = tf.get_variable('bias', [n_out], initializer=tf.constant_initializer(0.0))\n",
    "      tf.add_to_collection('biases', bias)\n",
    "      conv = tf.nn.bias_add(conv, bias)\n",
    "  return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, scope='bn', affine=True):\n",
    "  \"\"\"\n",
    "  Batch normalization on convolutional maps.\n",
    "  Args:\n",
    "    x: Tensor, 4D BHWD input maps\n",
    "    n_out: integer, depth of input maps\n",
    "    phase_train: boolean tf.Variable, true indicates training phase\n",
    "    scope: string, variable scope\n",
    "    affine: whether to affine-transform outputs\n",
    "  Return:\n",
    "    normed: batch-normalized maps\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope):\n",
    "    beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "      name='beta', trainable=True)\n",
    "    gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "      name='gamma', trainable=affine)\n",
    "    tf.add_to_collection('biases', beta)\n",
    "    tf.add_to_collection('weights', gamma)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "\n",
    "    def mean_var_with_update():\n",
    "      ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "      with tf.control_dependencies([ema_apply_op]):\n",
    "        return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "      mean_var_with_update,\n",
    "      lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var, \n",
    "      beta, gamma, 1e-3, affine)\n",
    "  return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, n_in, n_out, subsample, phase_train, scope='res_block'):\n",
    "  with tf.variable_scope(scope):\n",
    "    if subsample:\n",
    "      y = conv2d(x, n_in, n_out, 3, 2, 'SAME', False, scope='conv_1')\n",
    "      shortcut = conv2d(x, n_in, n_out, 3, 2, 'SAME',\n",
    "                False, scope='shortcut')\n",
    "    else:\n",
    "      y = conv2d(x, n_in, n_out, 3, 1, 'SAME', False, scope='conv_1')\n",
    "      shortcut = tf.identity(x, name='shortcut')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_1')\n",
    "    y = tf.nn.relu(y, name='relu_1')\n",
    "    y = conv2d(y, n_out, n_out, 3, 1, 'SAME', True, scope='conv_2')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_2')\n",
    "    y = y + shortcut\n",
    "    y = tf.nn.relu(y, name='relu_2')\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_group(x, n_in, n_out, n, first_subsample, phase_train, scope='res_group'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = residual_block(x, n_in, n_out, first_subsample, phase_train, scope='block_1')\n",
    "    for i in range(n - 1):\n",
    "      y = residual_block(y, n_out, n_out, False, phase_train, scope='block_%d' % (i + 2))\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_net(x, n, n_classes, phase_train, scope='res_net'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = conv2d(x, 3, 16, 3, 1, 'SAME', False, scope='conv_init')\n",
    "    y = batch_norm(y, 16, phase_train, scope='bn_init')\n",
    "    y = tf.nn.relu(y, name='relu_init')\n",
    "    y = residual_group(y, 16, 16, n, False, phase_train, scope='group_1')\n",
    "    y = residual_group(y, 16, 32, n, True, phase_train, scope='group_2')\n",
    "    y = residual_group(y, 32, 64, n, True, phase_train, scope='group_3')\n",
    "#     y = conv2d(y, 64, n_classes, 1, 1, 'SAME', True, scope='conv_last')\n",
    "    y = tf.nn.avg_pool(y, [1, 8, 8, 1], [1, 1, 1, 1], 'VALID', name='avg_pool')\n",
    "    y = tf.reshape(y, [-1, 64])\n",
    "    w = tf.get_variable(name='weight_fc', shape=[64, n_classes], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    tf.add_to_collection('weights', w)\n",
    "    b = tf.get_variable(name='weight_biase', shape=[n_classes], initializer=tf.constant_initializer(0))\n",
    "    tf.add_to_collection('last_biases', b)\n",
    "    y = tf.matmul(y, w) + b\n",
    "#     y = tf.squeeze(y, squeeze_dims=[1, 2])\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _loss(logits, labels, scope='loss'):\n",
    "  with tf.variable_scope(scope):\n",
    "    # entropy loss\n",
    "    targets = one_hot_embedding(labels, 10)\n",
    "    entropy_loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),\n",
    "      name='entropy_loss')\n",
    "    tf.add_to_collection('losses', entropy_loss)\n",
    "    # weight l2 decay loss\n",
    "    weight_l2_losses = [tf.nn.l2_loss(o) for o in tf.get_collection('weights')]\n",
    "    weight_decay_loss = FLAGS.weight_decay*tf.add_n(weight_l2_losses)\n",
    "    tf.add_to_collection('losses', weight_decay_loss)\n",
    "  # for var in tf.get_collection('losses'):\n",
    "    # tf.scalar_summary('losses/' + var.op.name, var)\n",
    "  # total loss\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _accuracy(logits, gt_label, scope='accuracy'):\n",
    "  with tf.variable_scope(scope):\n",
    "    pred_label = tf.argmax(logits, 1)\n",
    "    acc = 1.0 - tf.nn.zero_fraction(\n",
    "      tf.cast(tf.equal(pred_label, gt_label), tf.int32))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_op(loss, global_step, learning_rate):\n",
    "  params = tf.trainable_variables()\n",
    "  gradients = tf.gradients(loss, params, name='gradients')\n",
    "  optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "  update = optim.apply_gradients(zip(gradients, params))\n",
    "  with tf.control_dependencies([update]):\n",
    "    train_op = tf.no_op(name='train_op')\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar10_input_stream(records_path):\n",
    "  reader = tf.TFRecordReader()\n",
    "  filename_queue = tf.train.string_input_producer([records_path], None)\n",
    "  _, record_value = reader.read(filename_queue)\n",
    "  features = tf.parse_single_example(record_value,\n",
    "    {\n",
    "      'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "  image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "  image = tf.reshape(image, [32,32,3])\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  label = tf.cast(features['label'], tf.int64)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "  # meanstd = joblib.load(FLAGS.mean_std_path)\n",
    "  # mean, std = meanstd['mean'], meanstd['std']\n",
    "  mean = [ 125.30690002,122.95014954,113.86599731]\n",
    "  std = [ 62.9932518,62.08860397,66.70500946]\n",
    "  normed_image = (image - mean) / std\n",
    "  return normed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_distort_image(image):\n",
    "  distorted_image = image\n",
    "  distorted_image = tf.image.pad_to_bounding_box(\n",
    "    image, 4, 4, 40, 40)  # pad 4 pixels to each side\n",
    "  distorted_image = tf.random_crop(distorted_image, [32, 32, 3])\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "  return distorted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_batch(train_records_path, batch_size):\n",
    "  with tf.variable_scope('train_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      train_image, train_label = cifar10_input_stream(train_records_path)\n",
    "      train_image = normalize_image(train_image)\n",
    "      train_image = random_distort_image(train_image)\n",
    "      train_image_batch, train_label_batch = tf.train.shuffle_batch(\n",
    "        [train_image, train_label], batch_size=batch_size, num_threads=4,\n",
    "        capacity=50000,\n",
    "        min_after_dequeue=1000)\n",
    "  return train_image_batch, train_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_validation_batch(test_records_path, batch_size):\n",
    "  with tf.variable_scope('evaluate_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      test_image, test_label = cifar10_input_stream(test_records_path)\n",
    "      test_image = normalize_image(test_image)\n",
    "      test_image_batch, test_label_batch = tf.train.batch(\n",
    "        [test_image, test_label], batch_size=batch_size, num_threads=1,\n",
    "        capacity=10000)\n",
    "  return test_image_batch, test_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5533cdbb8cb6>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "train_image_batch, train_label_batch = make_train_batch(FLAGS.train_tf_path, FLAGS.train_batch_size)\n",
    "val_image_batch, val_label_batch = make_validation_batch(FLAGS.val_tf_path, FLAGS.val_batch_size)\n",
    "\n",
    "image_batch, label_batch = control_flow_ops.cond(phase_train,lambda: (train_image_batch, train_label_batch),lambda: (val_image_batch, val_label_batch))\n",
    "\n",
    "\n",
    "logits = residual_net(image_batch, FLAGS.residual_net_n, 10, phase_train)\n",
    "\n",
    "\n",
    "loss = _loss(logits, label_batch)\n",
    "accuracy = _accuracy(logits, label_batch)\n",
    "\n",
    "# train one step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "INFO:tensorflow:Restoring parameters from ./full_precision/res20/model/res.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-train_batch/input_producer-train_batch/input_producer/input_producer_EnqueueMany, started daemon 139664191112960)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 139664199505664)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 139664207898368)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 139664216291072)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 139664182720256)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/input_producer-evaluate_batch/input_producer/input_producer_EnqueueMany, started daemon 139664174327552)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/batch/fifo_queue-evaluate_batch/batch/fifo_queue_enqueue, started daemon 139664165934848)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "print('Initializing...')\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'./full_precision/res20/model/res.ckpt')\n",
    "\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Test accuracy = 0.921200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# validation\n",
    "\n",
    "print('Evaluating...')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "  fetches = [logits, label_batch, loss]\n",
    "  session_outputs = sess.run(\n",
    "    fetches, {phase_train.name: False})\n",
    "  val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "  val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "  val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(\n",
    "  pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_prune_on_grads(grads_and_vars, dict_nzidx):\n",
    "    for key, nzidx in dict_nzidx.items():\n",
    "        count = 0\n",
    "        for grad, var in grads_and_vars:\n",
    "            if var.name == key:\n",
    "                nzidx_obj = tf.cast(tf.constant(sess.run(dict_nzidx[key])), tf.float32)\n",
    "                grads_and_vars[count] = (tf.multiply(nzidx_obj, grad), var)\n",
    "            count += 1\n",
    "    return grads_and_vars\n",
    "\n",
    "def apply_inq(weights, inq_dict, var_name, prune_rate):  \n",
    "    for target in var_name:\n",
    "        wl = target\n",
    "        bit = 16\n",
    "\n",
    "        weight_obj = weights[wl]\n",
    "        weight_arr = sess.run(weight_obj)\n",
    "\n",
    "        weight_rest = np.reshape(weight_arr, [-1])\n",
    "        dic_tem = np.reshape(sess.run(inq_dict[wl]), [-1])\n",
    "        idx_rest = np.flip(np.argsort(abs(np.reshape(weight_rest, [-1]))), 0)\n",
    "        num_prune = int(len(weight_rest) * prune_rate)\n",
    "        weight_toINQ = weight_rest[idx_rest[:num_prune]]\n",
    "\n",
    "        n1 = (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        n2 = n1 + 1 - bit / 4\n",
    "        upper_bound = 2 ** (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        lower_bound = 2 ** (n1 + 1 - bit / 4)\n",
    "\n",
    "        weight_toINQ[abs(weight_toINQ) < lower_bound] = 0\n",
    "        weight_toINQ[weight_toINQ != 0] = 2 ** (np.floor(np.log2(abs(weight_toINQ[weight_toINQ != 0] * 4 / 3)))) * np.sign(weight_toINQ[weight_toINQ != 0])\n",
    "\n",
    "        weight_rest[idx_rest[:num_prune]] = weight_toINQ\n",
    "        weight_arr = np.reshape(weight_rest, np.shape(weight_arr))\n",
    "        dic_tem[idx_rest[:num_prune]] = np.zeros_like(dic_tem[idx_rest[:num_prune]])\n",
    "        inq_dict[wl] = tf.cast(np.reshape(dic_tem, np.shape(sess.run(inq_dict[wl]))), tf.float32)\n",
    "        sess.run(weights[wl].assign(weight_arr))\n",
    "    return inq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一轮  量化\n",
    "prune_rate =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.921200\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.06590594 -0.06288774  0.03332484  0.15145954  0.02605803 -0.04664146\n",
      "  0.02131429 -0.0513982  -0.00593484 -0.13121311]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.5)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-16 12:11:43.423288] Iteration 100, train loss = 0.269466, train accuracy = 0.953125\n",
      "[2018-07-16 12:11:46.992298] Iteration 200, train loss = 0.212816, train accuracy = 0.984375\n",
      "[2018-07-16 12:11:50.802189] Iteration 300, train loss = 0.218252, train accuracy = 0.984375\n",
      "[2018-07-16 12:11:54.537171] Iteration 400, train loss = 0.214541, train accuracy = 0.992188\n",
      "[2018-07-16 12:11:58.239849] Iteration 500, train loss = 0.239161, train accuracy = 0.960938\n",
      "[2018-07-16 12:12:01.966858] Iteration 600, train loss = 0.235033, train accuracy = 0.953125\n",
      "[2018-07-16 12:12:05.639119] Iteration 700, train loss = 0.222858, train accuracy = 0.968750\n",
      "[2018-07-16 12:12:09.333059] Iteration 800, train loss = 0.210325, train accuracy = 0.976562\n",
      "[2018-07-16 12:12:12.981976] Iteration 900, train loss = 0.206980, train accuracy = 0.984375\n",
      "[2018-07-16 12:12:16.672970] Iteration 1000, train loss = 0.203243, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.913000\n",
      "[2018-07-16 12:12:21.356386] Iteration 1100, train loss = 0.201947, train accuracy = 1.000000\n",
      "[2018-07-16 12:12:24.936309] Iteration 1200, train loss = 0.186443, train accuracy = 0.992188\n",
      "[2018-07-16 12:12:28.581821] Iteration 1300, train loss = 0.176741, train accuracy = 0.992188\n",
      "[2018-07-16 12:12:32.194698] Iteration 1400, train loss = 0.224859, train accuracy = 0.984375\n",
      "[2018-07-16 12:12:35.845532] Iteration 1500, train loss = 0.178510, train accuracy = 1.000000\n",
      "[2018-07-16 12:12:39.486249] Iteration 1600, train loss = 0.305987, train accuracy = 0.945312\n",
      "[2018-07-16 12:12:43.206215] Iteration 1700, train loss = 0.178983, train accuracy = 0.984375\n",
      "[2018-07-16 12:12:46.969768] Iteration 1800, train loss = 0.195324, train accuracy = 0.984375\n",
      "[2018-07-16 12:12:50.631775] Iteration 1900, train loss = 0.186893, train accuracy = 0.992188\n",
      "[2018-07-16 12:12:54.261777] Iteration 2000, train loss = 0.170997, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916800\n",
      "[2018-07-16 12:12:58.976256] Iteration 2100, train loss = 0.176186, train accuracy = 1.000000\n",
      "[2018-07-16 12:13:02.967588] Iteration 2200, train loss = 0.179611, train accuracy = 1.000000\n",
      "[2018-07-16 12:13:07.148160] Iteration 2300, train loss = 0.219832, train accuracy = 0.976562\n",
      "[2018-07-16 12:13:11.062769] Iteration 2400, train loss = 0.200266, train accuracy = 0.976562\n",
      "[2018-07-16 12:13:14.986711] Iteration 2500, train loss = 0.167453, train accuracy = 1.000000\n",
      "[2018-07-16 12:13:18.832623] Iteration 2600, train loss = 0.200692, train accuracy = 0.992188\n",
      "[2018-07-16 12:13:22.551015] Iteration 2700, train loss = 0.183437, train accuracy = 1.000000\n",
      "[2018-07-16 12:13:26.252759] Iteration 2800, train loss = 0.190519, train accuracy = 0.992188\n",
      "[2018-07-16 12:13:30.219502] Iteration 2900, train loss = 0.201545, train accuracy = 0.984375\n",
      "[2018-07-16 12:13:34.098711] Iteration 3000, train loss = 0.213072, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-07-16 12:13:39.376968] Iteration 3100, train loss = 0.162418, train accuracy = 1.000000\n",
      "[2018-07-16 12:13:43.371130] Iteration 3200, train loss = 0.204570, train accuracy = 0.976562\n",
      "[2018-07-16 12:13:47.237883] Iteration 3300, train loss = 0.174694, train accuracy = 0.992188\n",
      "[2018-07-16 12:13:50.930260] Iteration 3400, train loss = 0.235021, train accuracy = 0.945312\n",
      "[2018-07-16 12:13:54.641281] Iteration 3500, train loss = 0.182674, train accuracy = 0.992188\n",
      "[2018-07-16 12:13:58.378529] Iteration 3600, train loss = 0.212723, train accuracy = 0.976562\n",
      "[2018-07-16 12:14:02.072185] Iteration 3700, train loss = 0.181889, train accuracy = 0.992188\n",
      "[2018-07-16 12:14:05.762218] Iteration 3800, train loss = 0.182307, train accuracy = 0.992188\n",
      "[2018-07-16 12:14:09.476295] Iteration 3900, train loss = 0.171631, train accuracy = 1.000000\n",
      "[2018-07-16 12:14:13.222303] Iteration 4000, train loss = 0.203918, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.916600\n",
      "[2018-07-16 12:14:18.164507] Iteration 4100, train loss = 0.174363, train accuracy = 1.000000\n",
      "[2018-07-16 12:14:21.930305] Iteration 4200, train loss = 0.217203, train accuracy = 0.984375\n",
      "[2018-07-16 12:14:25.724689] Iteration 4300, train loss = 0.213205, train accuracy = 0.984375\n",
      "[2018-07-16 12:14:29.506030] Iteration 4400, train loss = 0.170155, train accuracy = 0.992188\n",
      "[2018-07-16 12:14:33.311142] Iteration 4500, train loss = 0.193500, train accuracy = 0.992188\n",
      "[2018-07-16 12:14:37.202807] Iteration 4600, train loss = 0.162319, train accuracy = 0.992188\n",
      "[2018-07-16 12:14:40.998768] Iteration 4700, train loss = 0.177271, train accuracy = 0.992188\n",
      "[2018-07-16 12:14:44.798871] Iteration 4800, train loss = 0.168868, train accuracy = 0.992188\n",
      "[2018-07-16 12:14:48.629250] Iteration 4900, train loss = 0.176317, train accuracy = 0.984375\n",
      "[2018-07-16 12:14:52.430860] Iteration 5000, train loss = 0.191636, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.916100\n",
      "[2018-07-16 12:14:57.421315] Iteration 5100, train loss = 0.207897, train accuracy = 0.984375\n",
      "[2018-07-16 12:15:01.318214] Iteration 5200, train loss = 0.177325, train accuracy = 1.000000\n",
      "[2018-07-16 12:15:05.157010] Iteration 5300, train loss = 0.202752, train accuracy = 0.960938\n",
      "[2018-07-16 12:15:09.033842] Iteration 5400, train loss = 0.185443, train accuracy = 0.992188\n",
      "[2018-07-16 12:15:12.940461] Iteration 5500, train loss = 0.197072, train accuracy = 0.976562\n",
      "[2018-07-16 12:15:16.849539] Iteration 5600, train loss = 0.191647, train accuracy = 0.984375\n",
      "[2018-07-16 12:15:20.767243] Iteration 5700, train loss = 0.156544, train accuracy = 1.000000\n",
      "[2018-07-16 12:15:24.652633] Iteration 5800, train loss = 0.236642, train accuracy = 0.960938\n",
      "[2018-07-16 12:15:28.574988] Iteration 5900, train loss = 0.187802, train accuracy = 0.992188\n",
      "[2018-07-16 12:15:32.440482] Iteration 6000, train loss = 0.204995, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.916200\n",
      "[2018-07-16 12:15:37.548981] Iteration 6100, train loss = 0.189604, train accuracy = 0.976562\n",
      "[2018-07-16 12:15:41.473319] Iteration 6200, train loss = 0.184679, train accuracy = 0.984375\n",
      "[2018-07-16 12:15:45.346599] Iteration 6300, train loss = 0.192718, train accuracy = 0.992188\n",
      "[2018-07-16 12:15:49.126290] Iteration 6400, train loss = 0.174107, train accuracy = 1.000000\n",
      "[2018-07-16 12:15:53.175278] Iteration 6500, train loss = 0.191460, train accuracy = 0.976562\n",
      "[2018-07-16 12:15:57.090934] Iteration 6600, train loss = 0.173714, train accuracy = 0.992188\n",
      "[2018-07-16 12:16:01.037404] Iteration 6700, train loss = 0.183720, train accuracy = 0.992188\n",
      "[2018-07-16 12:16:05.038414] Iteration 6800, train loss = 0.186337, train accuracy = 0.984375\n",
      "[2018-07-16 12:16:09.051849] Iteration 6900, train loss = 0.243462, train accuracy = 0.960938\n",
      "[2018-07-16 12:16:13.023425] Iteration 7000, train loss = 0.164650, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916500\n",
      "[2018-07-16 12:16:18.306184] Iteration 7100, train loss = 0.198366, train accuracy = 0.984375\n",
      "[2018-07-16 12:16:22.316398] Iteration 7200, train loss = 0.164660, train accuracy = 1.000000\n",
      "[2018-07-16 12:16:26.310697] Iteration 7300, train loss = 0.193190, train accuracy = 0.984375\n",
      "[2018-07-16 12:16:30.357393] Iteration 7400, train loss = 0.186420, train accuracy = 0.984375\n",
      "[2018-07-16 12:16:34.395839] Iteration 7500, train loss = 0.182505, train accuracy = 0.984375\n",
      "[2018-07-16 12:16:38.451205] Iteration 7600, train loss = 0.196169, train accuracy = 0.984375\n",
      "[2018-07-16 12:16:42.476515] Iteration 7700, train loss = 0.226479, train accuracy = 0.976562\n",
      "[2018-07-16 12:16:46.487522] Iteration 7800, train loss = 0.154632, train accuracy = 1.000000\n",
      "[2018-07-16 12:16:50.468533] Iteration 7900, train loss = 0.172167, train accuracy = 1.000000\n",
      "[2018-07-16 12:16:54.361178] Iteration 8000, train loss = 0.177748, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.916600\n",
      "[2018-07-16 12:16:59.305790] Iteration 8100, train loss = 0.174494, train accuracy = 0.992188\n",
      "[2018-07-16 12:17:03.220570] Iteration 8200, train loss = 0.193703, train accuracy = 0.984375\n",
      "[2018-07-16 12:17:07.199581] Iteration 8300, train loss = 0.176824, train accuracy = 1.000000\n",
      "[2018-07-16 12:17:11.133529] Iteration 8400, train loss = 0.170165, train accuracy = 0.992188\n",
      "[2018-07-16 12:17:15.023295] Iteration 8500, train loss = 0.179815, train accuracy = 0.992188\n",
      "[2018-07-16 12:17:18.983295] Iteration 8600, train loss = 0.174873, train accuracy = 0.992188\n",
      "[2018-07-16 12:17:23.050968] Iteration 8700, train loss = 0.189521, train accuracy = 0.984375\n",
      "[2018-07-16 12:17:27.127127] Iteration 8800, train loss = 0.191097, train accuracy = 0.976562\n",
      "[2018-07-16 12:17:31.194974] Iteration 8900, train loss = 0.158755, train accuracy = 0.992188\n",
      "[2018-07-16 12:17:35.298428] Iteration 9000, train loss = 0.175503, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.916600\n",
      "[2018-07-16 12:17:40.651549] Iteration 9100, train loss = 0.230559, train accuracy = 0.984375\n",
      "[2018-07-16 12:17:44.757422] Iteration 9200, train loss = 0.197094, train accuracy = 0.984375\n",
      "[2018-07-16 12:17:48.850151] Iteration 9300, train loss = 0.162519, train accuracy = 0.984375\n",
      "[2018-07-16 12:17:52.941311] Iteration 9400, train loss = 0.170108, train accuracy = 0.992188\n",
      "[2018-07-16 12:17:56.999027] Iteration 9500, train loss = 0.165797, train accuracy = 1.000000\n",
      "[2018-07-16 12:18:01.048962] Iteration 9600, train loss = 0.184476, train accuracy = 0.984375\n",
      "[2018-07-16 12:18:05.102448] Iteration 9700, train loss = 0.183962, train accuracy = 0.992188\n",
      "[2018-07-16 12:18:09.160138] Iteration 9800, train loss = 0.194348, train accuracy = 0.976562\n",
      "[2018-07-16 12:18:13.223365] Iteration 9900, train loss = 0.185354, train accuracy = 0.984375\n",
      "[2018-07-16 12:18:17.318452] Iteration 10000, train loss = 0.166317, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-07-16 12:18:22.712395] Iteration 10100, train loss = 0.170435, train accuracy = 0.992188\n",
      "[2018-07-16 12:18:26.826606] Iteration 10200, train loss = 0.197635, train accuracy = 0.976562\n",
      "[2018-07-16 12:18:30.913304] Iteration 10300, train loss = 0.185553, train accuracy = 0.976562\n",
      "[2018-07-16 12:18:35.006657] Iteration 10400, train loss = 0.164531, train accuracy = 1.000000\n",
      "[2018-07-16 12:18:39.113876] Iteration 10500, train loss = 0.189233, train accuracy = 0.992188\n",
      "[2018-07-16 12:18:43.181936] Iteration 10600, train loss = 0.186918, train accuracy = 0.976562\n",
      "[2018-07-16 12:18:47.240436] Iteration 10700, train loss = 0.162120, train accuracy = 0.992188\n",
      "[2018-07-16 12:18:51.301025] Iteration 10800, train loss = 0.166491, train accuracy = 1.000000\n",
      "[2018-07-16 12:18:55.364721] Iteration 10900, train loss = 0.164416, train accuracy = 1.000000\n",
      "[2018-07-16 12:18:59.434607] Iteration 11000, train loss = 0.176532, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-07-16 12:19:04.929812] Iteration 11100, train loss = 0.170244, train accuracy = 0.992188\n",
      "[2018-07-16 12:19:08.996149] Iteration 11200, train loss = 0.160370, train accuracy = 1.000000\n",
      "[2018-07-16 12:19:13.084770] Iteration 11300, train loss = 0.172846, train accuracy = 0.992188\n",
      "[2018-07-16 12:19:17.175802] Iteration 11400, train loss = 0.151296, train accuracy = 1.000000\n",
      "[2018-07-16 12:19:21.248088] Iteration 11500, train loss = 0.162512, train accuracy = 1.000000\n",
      "[2018-07-16 12:19:25.343319] Iteration 11600, train loss = 0.162637, train accuracy = 1.000000\n",
      "[2018-07-16 12:19:29.429311] Iteration 11700, train loss = 0.160975, train accuracy = 0.992188\n",
      "[2018-07-16 12:19:33.482340] Iteration 11800, train loss = 0.176891, train accuracy = 0.984375\n",
      "[2018-07-16 12:19:37.560792] Iteration 11900, train loss = 0.180555, train accuracy = 0.992188\n",
      "[2018-07-16 12:19:41.633630] Iteration 12000, train loss = 0.185414, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-07-16 12:19:46.955944] Iteration 12100, train loss = 0.162377, train accuracy = 1.000000\n",
      "[2018-07-16 12:19:51.034989] Iteration 12200, train loss = 0.184691, train accuracy = 0.992188\n",
      "[2018-07-16 12:19:55.113559] Iteration 12300, train loss = 0.183834, train accuracy = 0.984375\n",
      "[2018-07-16 12:19:59.210483] Iteration 12400, train loss = 0.155907, train accuracy = 1.000000\n",
      "[2018-07-16 12:20:03.289393] Iteration 12500, train loss = 0.180715, train accuracy = 0.992188\n",
      "[2018-07-16 12:20:07.372487] Iteration 12600, train loss = 0.176637, train accuracy = 0.992188\n",
      "[2018-07-16 12:20:11.485352] Iteration 12700, train loss = 0.175029, train accuracy = 1.000000\n",
      "[2018-07-16 12:20:15.618101] Iteration 12800, train loss = 0.160175, train accuracy = 0.992188\n",
      "[2018-07-16 12:20:19.713254] Iteration 12900, train loss = 0.169652, train accuracy = 1.000000\n",
      "[2018-07-16 12:20:23.780274] Iteration 13000, train loss = 0.161069, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915500\n",
      "[2018-07-16 12:20:29.094332] Iteration 13100, train loss = 0.172195, train accuracy = 0.992188\n",
      "[2018-07-16 12:20:33.150199] Iteration 13200, train loss = 0.185498, train accuracy = 0.976562\n",
      "[2018-07-16 12:20:37.221403] Iteration 13300, train loss = 0.192195, train accuracy = 0.976562\n",
      "[2018-07-16 12:20:41.318609] Iteration 13400, train loss = 0.164603, train accuracy = 0.992188\n",
      "[2018-07-16 12:20:45.386007] Iteration 13500, train loss = 0.160972, train accuracy = 0.992188\n",
      "[2018-07-16 12:20:49.472937] Iteration 13600, train loss = 0.157057, train accuracy = 1.000000\n",
      "[2018-07-16 12:20:53.587342] Iteration 13700, train loss = 0.192462, train accuracy = 0.984375\n",
      "[2018-07-16 12:20:57.668615] Iteration 13800, train loss = 0.176518, train accuracy = 0.976562\n",
      "[2018-07-16 12:21:01.763705] Iteration 13900, train loss = 0.166387, train accuracy = 0.992188\n",
      "[2018-07-16 12:21:05.835174] Iteration 14000, train loss = 0.191365, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.915800\n",
      "[2018-07-16 12:21:11.145386] Iteration 14100, train loss = 0.158615, train accuracy = 1.000000\n",
      "[2018-07-16 12:21:15.199029] Iteration 14200, train loss = 0.162223, train accuracy = 1.000000\n",
      "[2018-07-16 12:21:19.255508] Iteration 14300, train loss = 0.192830, train accuracy = 0.984375\n",
      "[2018-07-16 12:21:23.325215] Iteration 14400, train loss = 0.172286, train accuracy = 0.984375\n",
      "[2018-07-16 12:21:27.389632] Iteration 14500, train loss = 0.186626, train accuracy = 0.976562\n",
      "[2018-07-16 12:21:31.540538] Iteration 14600, train loss = 0.209104, train accuracy = 0.976562\n",
      "[2018-07-16 12:21:35.629166] Iteration 14700, train loss = 0.172834, train accuracy = 0.984375\n",
      "[2018-07-16 12:21:39.708055] Iteration 14800, train loss = 0.151113, train accuracy = 1.000000\n",
      "[2018-07-16 12:21:43.796201] Iteration 14900, train loss = 0.155669, train accuracy = 1.000000\n",
      "[2018-07-16 12:21:47.888914] Iteration 15000, train loss = 0.196163, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-07-16 12:21:53.250762] Iteration 15100, train loss = 0.166656, train accuracy = 0.992188\n",
      "[2018-07-16 12:21:57.327011] Iteration 15200, train loss = 0.182432, train accuracy = 0.984375\n",
      "[2018-07-16 12:22:01.393152] Iteration 15300, train loss = 0.175198, train accuracy = 0.992188\n",
      "[2018-07-16 12:22:05.452441] Iteration 15400, train loss = 0.163335, train accuracy = 0.992188\n",
      "[2018-07-16 12:22:09.551148] Iteration 15500, train loss = 0.174195, train accuracy = 0.984375\n",
      "[2018-07-16 12:22:13.632552] Iteration 15600, train loss = 0.171793, train accuracy = 0.992188\n",
      "[2018-07-16 12:22:17.718935] Iteration 15700, train loss = 0.167436, train accuracy = 0.992188\n",
      "[2018-07-16 12:22:21.787146] Iteration 15800, train loss = 0.206783, train accuracy = 0.968750\n",
      "[2018-07-16 12:22:25.879625] Iteration 15900, train loss = 0.175091, train accuracy = 0.984375\n",
      "[2018-07-16 12:22:29.973494] Iteration 16000, train loss = 0.177226, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916300\n",
      "[2018-07-16 12:22:35.329641] Iteration 16100, train loss = 0.162941, train accuracy = 1.000000\n",
      "[2018-07-16 12:22:39.398592] Iteration 16200, train loss = 0.150369, train accuracy = 1.000000\n",
      "[2018-07-16 12:22:43.470912] Iteration 16300, train loss = 0.153665, train accuracy = 1.000000\n",
      "[2018-07-16 12:22:47.594605] Iteration 16400, train loss = 0.197444, train accuracy = 0.984375\n",
      "[2018-07-16 12:22:51.659320] Iteration 16500, train loss = 0.170391, train accuracy = 0.992188\n",
      "[2018-07-16 12:22:55.713764] Iteration 16600, train loss = 0.189620, train accuracy = 0.984375\n",
      "[2018-07-16 12:22:59.780138] Iteration 16700, train loss = 0.165604, train accuracy = 0.992188\n",
      "[2018-07-16 12:23:03.849617] Iteration 16800, train loss = 0.192689, train accuracy = 0.976562\n",
      "[2018-07-16 12:23:07.949927] Iteration 16900, train loss = 0.171275, train accuracy = 0.984375\n",
      "[2018-07-16 12:23:12.054911] Iteration 17000, train loss = 0.164585, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-07-16 12:23:17.402349] Iteration 17100, train loss = 0.190042, train accuracy = 0.976562\n",
      "[2018-07-16 12:23:21.478233] Iteration 17200, train loss = 0.204300, train accuracy = 0.968750\n",
      "[2018-07-16 12:23:25.616340] Iteration 17300, train loss = 0.150425, train accuracy = 1.000000\n",
      "[2018-07-16 12:23:29.701032] Iteration 17400, train loss = 0.165777, train accuracy = 0.992188\n",
      "[2018-07-16 12:23:33.758765] Iteration 17500, train loss = 0.169904, train accuracy = 0.992188\n",
      "[2018-07-16 12:23:37.817276] Iteration 17600, train loss = 0.173174, train accuracy = 0.992188\n",
      "[2018-07-16 12:23:41.865148] Iteration 17700, train loss = 0.153395, train accuracy = 1.000000\n",
      "[2018-07-16 12:23:45.918209] Iteration 17800, train loss = 0.160077, train accuracy = 1.000000\n",
      "[2018-07-16 12:23:50.015475] Iteration 17900, train loss = 0.185614, train accuracy = 0.984375\n",
      "[2018-07-16 12:23:54.090431] Iteration 18000, train loss = 0.171675, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-07-16 12:23:59.467289] Iteration 18100, train loss = 0.155574, train accuracy = 0.992188\n",
      "[2018-07-16 12:24:03.589864] Iteration 18200, train loss = 0.166714, train accuracy = 1.000000\n",
      "[2018-07-16 12:24:07.681533] Iteration 18300, train loss = 0.184036, train accuracy = 0.992188\n",
      "[2018-07-16 12:24:11.774005] Iteration 18400, train loss = 0.166371, train accuracy = 0.992188\n",
      "[2018-07-16 12:24:15.855553] Iteration 18500, train loss = 0.156468, train accuracy = 1.000000\n",
      "[2018-07-16 12:24:19.926661] Iteration 18600, train loss = 0.182216, train accuracy = 0.976562\n",
      "[2018-07-16 12:24:23.978570] Iteration 18700, train loss = 0.168570, train accuracy = 0.992188\n",
      "[2018-07-16 12:24:28.045216] Iteration 18800, train loss = 0.234716, train accuracy = 0.984375\n",
      "[2018-07-16 12:24:32.100776] Iteration 18900, train loss = 0.170678, train accuracy = 0.984375\n",
      "[2018-07-16 12:24:36.184363] Iteration 19000, train loss = 0.175559, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-07-16 12:24:41.603985] Iteration 19100, train loss = 0.204669, train accuracy = 0.968750\n",
      "[2018-07-16 12:24:45.681229] Iteration 19200, train loss = 0.189761, train accuracy = 0.984375\n",
      "[2018-07-16 12:24:49.768703] Iteration 19300, train loss = 0.182357, train accuracy = 0.992188\n",
      "[2018-07-16 12:24:53.847028] Iteration 19400, train loss = 0.193429, train accuracy = 0.984375\n",
      "[2018-07-16 12:24:57.930152] Iteration 19500, train loss = 0.171507, train accuracy = 0.992188\n",
      "[2018-07-16 12:25:02.041497] Iteration 19600, train loss = 0.165019, train accuracy = 0.992188\n",
      "[2018-07-16 12:25:06.117003] Iteration 19700, train loss = 0.173332, train accuracy = 0.992188\n",
      "[2018-07-16 12:25:10.168098] Iteration 19800, train loss = 0.205076, train accuracy = 0.976562\n",
      "[2018-07-16 12:25:14.228655] Iteration 19900, train loss = 0.162036, train accuracy = 0.992188\n",
      "[2018-07-16 12:25:18.338268] Iteration 20000, train loss = 0.150604, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-07-16 12:25:23.667476] Iteration 20100, train loss = 0.176435, train accuracy = 0.992188\n",
      "[2018-07-16 12:25:27.737411] Iteration 20200, train loss = 0.158660, train accuracy = 1.000000\n",
      "[2018-07-16 12:25:31.827400] Iteration 20300, train loss = 0.182759, train accuracy = 0.984375\n",
      "[2018-07-16 12:25:35.923635] Iteration 20400, train loss = 0.160558, train accuracy = 1.000000\n",
      "[2018-07-16 12:25:40.004842] Iteration 20500, train loss = 0.160895, train accuracy = 1.000000\n",
      "[2018-07-16 12:25:44.116818] Iteration 20600, train loss = 0.148818, train accuracy = 1.000000\n",
      "[2018-07-16 12:25:48.188761] Iteration 20700, train loss = 0.208535, train accuracy = 0.960938\n",
      "[2018-07-16 12:25:52.264120] Iteration 20800, train loss = 0.176966, train accuracy = 0.976562\n",
      "[2018-07-16 12:25:56.388852] Iteration 20900, train loss = 0.160049, train accuracy = 0.992188\n",
      "[2018-07-16 12:26:00.451548] Iteration 21000, train loss = 0.178303, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 12:26:05.764657] Iteration 21100, train loss = 0.203473, train accuracy = 0.984375\n",
      "[2018-07-16 12:26:09.829215] Iteration 21200, train loss = 0.153180, train accuracy = 1.000000\n",
      "[2018-07-16 12:26:13.915443] Iteration 21300, train loss = 0.185351, train accuracy = 0.984375\n",
      "[2018-07-16 12:26:17.995904] Iteration 21400, train loss = 0.178044, train accuracy = 0.992188\n",
      "[2018-07-16 12:26:22.086287] Iteration 21500, train loss = 0.161747, train accuracy = 0.984375\n",
      "[2018-07-16 12:26:26.182083] Iteration 21600, train loss = 0.170414, train accuracy = 0.984375\n",
      "[2018-07-16 12:26:30.259634] Iteration 21700, train loss = 0.158342, train accuracy = 1.000000\n",
      "[2018-07-16 12:26:34.398115] Iteration 21800, train loss = 0.174298, train accuracy = 1.000000\n",
      "[2018-07-16 12:26:38.500535] Iteration 21900, train loss = 0.181852, train accuracy = 0.984375\n",
      "[2018-07-16 12:26:42.581570] Iteration 22000, train loss = 0.167831, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.917100\n",
      "[2018-07-16 12:26:47.893166] Iteration 22100, train loss = 0.149699, train accuracy = 1.000000\n",
      "[2018-07-16 12:26:51.944024] Iteration 22200, train loss = 0.155871, train accuracy = 1.000000\n",
      "[2018-07-16 12:26:56.016366] Iteration 22300, train loss = 0.154386, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:00.084951] Iteration 22400, train loss = 0.152277, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:04.151654] Iteration 22500, train loss = 0.163772, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:08.244722] Iteration 22600, train loss = 0.150842, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:12.356094] Iteration 22700, train loss = 0.166652, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:16.453024] Iteration 22800, train loss = 0.146579, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:20.544032] Iteration 22900, train loss = 0.161234, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:24.615917] Iteration 23000, train loss = 0.191421, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916800\n",
      "[2018-07-16 12:27:29.959937] Iteration 23100, train loss = 0.168220, train accuracy = 0.984375\n",
      "[2018-07-16 12:27:34.010260] Iteration 23200, train loss = 0.164581, train accuracy = 0.992188\n",
      "[2018-07-16 12:27:38.077925] Iteration 23300, train loss = 0.190558, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:42.123726] Iteration 23400, train loss = 0.156092, train accuracy = 1.000000\n",
      "[2018-07-16 12:27:46.173441] Iteration 23500, train loss = 0.166155, train accuracy = 0.992188\n",
      "[2018-07-16 12:27:50.310678] Iteration 23600, train loss = 0.177913, train accuracy = 0.992188\n",
      "[2018-07-16 12:27:54.399655] Iteration 23700, train loss = 0.182929, train accuracy = 0.992188\n",
      "[2018-07-16 12:27:58.481719] Iteration 23800, train loss = 0.159267, train accuracy = 1.000000\n",
      "[2018-07-16 12:28:02.572870] Iteration 23900, train loss = 0.163166, train accuracy = 0.992188\n",
      "[2018-07-16 12:28:06.659662] Iteration 24000, train loss = 0.161360, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-07-16 12:28:12.035598] Iteration 24100, train loss = 0.168438, train accuracy = 0.992188\n",
      "[2018-07-16 12:28:16.104015] Iteration 24200, train loss = 0.164961, train accuracy = 0.992188\n",
      "[2018-07-16 12:28:20.169567] Iteration 24300, train loss = 0.152603, train accuracy = 1.000000\n",
      "[2018-07-16 12:28:24.221274] Iteration 24400, train loss = 0.148551, train accuracy = 1.000000\n",
      "[2018-07-16 12:28:28.330002] Iteration 24500, train loss = 0.182537, train accuracy = 0.984375\n",
      "[2018-07-16 12:28:32.388312] Iteration 24600, train loss = 0.183099, train accuracy = 0.976562\n",
      "[2018-07-16 12:28:36.451343] Iteration 24700, train loss = 0.163278, train accuracy = 0.992188\n",
      "[2018-07-16 12:28:40.534225] Iteration 24800, train loss = 0.172221, train accuracy = 0.992188\n",
      "[2018-07-16 12:28:44.621550] Iteration 24900, train loss = 0.169360, train accuracy = 1.000000\n",
      "[2018-07-16 12:28:48.701103] Iteration 25000, train loss = 0.152944, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.917100\n",
      "[2018-07-16 12:28:54.081212] Iteration 25100, train loss = 0.166212, train accuracy = 0.992188\n",
      "[2018-07-16 12:28:58.167296] Iteration 25200, train loss = 0.167144, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:02.283207] Iteration 25300, train loss = 0.165730, train accuracy = 1.000000\n",
      "[2018-07-16 12:29:06.400499] Iteration 25400, train loss = 0.166291, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:10.463748] Iteration 25500, train loss = 0.164821, train accuracy = 1.000000\n",
      "[2018-07-16 12:29:14.519270] Iteration 25600, train loss = 0.161876, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:18.572137] Iteration 25700, train loss = 0.162910, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:22.636940] Iteration 25800, train loss = 0.157442, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:26.727531] Iteration 25900, train loss = 0.166779, train accuracy = 1.000000\n",
      "[2018-07-16 12:29:30.804663] Iteration 26000, train loss = 0.162388, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-07-16 12:29:36.172047] Iteration 26100, train loss = 0.170563, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:40.302568] Iteration 26200, train loss = 0.163546, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:44.436287] Iteration 26300, train loss = 0.190779, train accuracy = 0.976562\n",
      "[2018-07-16 12:29:48.513755] Iteration 26400, train loss = 0.161348, train accuracy = 0.992188\n",
      "[2018-07-16 12:29:52.601811] Iteration 26500, train loss = 0.154151, train accuracy = 1.000000\n",
      "[2018-07-16 12:29:56.669247] Iteration 26600, train loss = 0.164232, train accuracy = 1.000000\n",
      "[2018-07-16 12:30:00.722780] Iteration 26700, train loss = 0.185766, train accuracy = 0.984375\n",
      "[2018-07-16 12:30:04.784737] Iteration 26800, train loss = 0.155382, train accuracy = 1.000000\n",
      "[2018-07-16 12:30:08.855405] Iteration 26900, train loss = 0.153574, train accuracy = 1.000000\n",
      "[2018-07-16 12:30:12.924662] Iteration 27000, train loss = 0.175461, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 12:30:18.339337] Iteration 27100, train loss = 0.156937, train accuracy = 0.992188\n",
      "[2018-07-16 12:30:22.445524] Iteration 27200, train loss = 0.149785, train accuracy = 1.000000\n",
      "[2018-07-16 12:30:26.531640] Iteration 27300, train loss = 0.148878, train accuracy = 1.000000\n",
      "[2018-07-16 12:30:30.603312] Iteration 27400, train loss = 0.168546, train accuracy = 0.992188\n",
      "[2018-07-16 12:30:34.712387] Iteration 27500, train loss = 0.167643, train accuracy = 0.984375\n",
      "[2018-07-16 12:30:38.796439] Iteration 27600, train loss = 0.167885, train accuracy = 0.992188\n",
      "[2018-07-16 12:30:42.870974] Iteration 27700, train loss = 0.188161, train accuracy = 0.992188\n",
      "[2018-07-16 12:30:46.938247] Iteration 27800, train loss = 0.165799, train accuracy = 0.984375\n",
      "[2018-07-16 12:30:50.992405] Iteration 27900, train loss = 0.180711, train accuracy = 0.992188\n",
      "[2018-07-16 12:30:55.053867] Iteration 28000, train loss = 0.181053, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 12:31:00.530436] Iteration 28100, train loss = 0.193097, train accuracy = 0.984375\n",
      "[2018-07-16 12:31:04.608143] Iteration 28200, train loss = 0.163739, train accuracy = 0.992188\n",
      "[2018-07-16 12:31:08.694017] Iteration 28300, train loss = 0.160938, train accuracy = 1.000000\n",
      "[2018-07-16 12:31:12.770409] Iteration 28400, train loss = 0.197697, train accuracy = 0.976562\n",
      "[2018-07-16 12:31:16.867054] Iteration 28500, train loss = 0.172295, train accuracy = 0.992188\n",
      "[2018-07-16 12:31:20.946845] Iteration 28600, train loss = 0.164757, train accuracy = 0.992188\n",
      "[2018-07-16 12:31:25.015017] Iteration 28700, train loss = 0.176371, train accuracy = 0.992188\n",
      "[2018-07-16 12:31:29.102060] Iteration 28800, train loss = 0.157966, train accuracy = 1.000000\n",
      "[2018-07-16 12:31:33.171025] Iteration 28900, train loss = 0.162131, train accuracy = 1.000000\n",
      "[2018-07-16 12:31:37.254884] Iteration 29000, train loss = 0.164623, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915300\n",
      "[2018-07-16 12:31:42.567058] Iteration 29100, train loss = 0.155033, train accuracy = 1.000000\n",
      "[2018-07-16 12:31:46.616643] Iteration 29200, train loss = 0.193849, train accuracy = 0.984375\n",
      "[2018-07-16 12:31:50.697383] Iteration 29300, train loss = 0.168278, train accuracy = 0.984375\n",
      "[2018-07-16 12:31:54.769249] Iteration 29400, train loss = 0.180896, train accuracy = 0.984375\n",
      "[2018-07-16 12:31:58.857090] Iteration 29500, train loss = 0.189506, train accuracy = 0.976562\n",
      "[2018-07-16 12:32:02.949471] Iteration 29600, train loss = 0.165782, train accuracy = 1.000000\n",
      "[2018-07-16 12:32:07.033871] Iteration 29700, train loss = 0.168820, train accuracy = 0.992188\n",
      "[2018-07-16 12:32:11.141280] Iteration 29800, train loss = 0.156972, train accuracy = 1.000000\n",
      "[2018-07-16 12:32:15.240511] Iteration 29900, train loss = 0.161676, train accuracy = 0.992188\n",
      "[2018-07-16 12:32:19.316185] Iteration 30000, train loss = 0.179898, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 12:32:24.617329] Iteration 30100, train loss = 0.164139, train accuracy = 1.000000\n",
      "[2018-07-16 12:32:28.678226] Iteration 30200, train loss = 0.190267, train accuracy = 0.976562\n",
      "[2018-07-16 12:32:32.734828] Iteration 30300, train loss = 0.174476, train accuracy = 0.992188\n",
      "[2018-07-16 12:32:36.799859] Iteration 30400, train loss = 0.184354, train accuracy = 0.984375\n",
      "[2018-07-16 12:32:40.888641] Iteration 30500, train loss = 0.167703, train accuracy = 1.000000\n",
      "[2018-07-16 12:32:44.977471] Iteration 30600, train loss = 0.153892, train accuracy = 1.000000\n",
      "[2018-07-16 12:32:49.092119] Iteration 30700, train loss = 0.169693, train accuracy = 0.992188\n",
      "[2018-07-16 12:32:53.226627] Iteration 30800, train loss = 0.157740, train accuracy = 0.992188\n",
      "[2018-07-16 12:32:57.310669] Iteration 30900, train loss = 0.164976, train accuracy = 0.984375\n",
      "[2018-07-16 12:33:01.392226] Iteration 31000, train loss = 0.168658, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-07-16 12:33:06.716279] Iteration 31100, train loss = 0.163480, train accuracy = 0.992188\n",
      "[2018-07-16 12:33:10.770000] Iteration 31200, train loss = 0.180515, train accuracy = 0.992188\n",
      "[2018-07-16 12:33:14.837263] Iteration 31300, train loss = 0.177681, train accuracy = 0.984375\n",
      "[2018-07-16 12:33:18.898879] Iteration 31400, train loss = 0.151009, train accuracy = 1.000000\n",
      "[2018-07-16 12:33:22.967740] Iteration 31500, train loss = 0.154070, train accuracy = 1.000000\n",
      "[2018-07-16 12:33:27.106682] Iteration 31600, train loss = 0.160070, train accuracy = 1.000000\n",
      "[2018-07-16 12:33:31.189285] Iteration 31700, train loss = 0.145532, train accuracy = 1.000000\n",
      "[2018-07-16 12:33:35.288121] Iteration 31800, train loss = 0.152966, train accuracy = 1.000000\n",
      "[2018-07-16 12:33:39.369985] Iteration 31900, train loss = 0.154907, train accuracy = 1.000000\n",
      "[2018-07-16 12:33:43.466220] Iteration 32000, train loss = 0.168480, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-07-16 12:33:48.813783] Iteration 32100, train loss = 0.161639, train accuracy = 1.000000\n",
      "[2018-07-16 12:33:52.907361] Iteration 32200, train loss = 0.184777, train accuracy = 0.976562\n",
      "[2018-07-16 12:33:56.972791] Iteration 32300, train loss = 0.179619, train accuracy = 0.984375\n",
      "[2018-07-16 12:34:01.022644] Iteration 32400, train loss = 0.163268, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:05.122136] Iteration 32500, train loss = 0.170398, train accuracy = 0.992188\n",
      "[2018-07-16 12:34:09.185574] Iteration 32600, train loss = 0.173893, train accuracy = 0.992188\n",
      "[2018-07-16 12:34:13.259741] Iteration 32700, train loss = 0.146675, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:17.354152] Iteration 32800, train loss = 0.156105, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:21.430612] Iteration 32900, train loss = 0.166139, train accuracy = 0.992188\n",
      "[2018-07-16 12:34:25.510744] Iteration 33000, train loss = 0.176298, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916600\n",
      "[2018-07-16 12:34:30.843863] Iteration 33100, train loss = 0.156805, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:34.945307] Iteration 33200, train loss = 0.155078, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:39.026675] Iteration 33300, train loss = 0.156592, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:43.152927] Iteration 33400, train loss = 0.175614, train accuracy = 0.984375\n",
      "[2018-07-16 12:34:47.203478] Iteration 33500, train loss = 0.152216, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:51.264424] Iteration 33600, train loss = 0.157718, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:55.323432] Iteration 33700, train loss = 0.152104, train accuracy = 1.000000\n",
      "[2018-07-16 12:34:59.404694] Iteration 33800, train loss = 0.155427, train accuracy = 0.992188\n",
      "[2018-07-16 12:35:03.490661] Iteration 33900, train loss = 0.167125, train accuracy = 0.992188\n",
      "[2018-07-16 12:35:07.587779] Iteration 34000, train loss = 0.167052, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915600\n",
      "[2018-07-16 12:35:12.926338] Iteration 34100, train loss = 0.151823, train accuracy = 1.000000\n",
      "[2018-07-16 12:35:17.029357] Iteration 34200, train loss = 0.198630, train accuracy = 0.984375\n",
      "[2018-07-16 12:35:21.143301] Iteration 34300, train loss = 0.146745, train accuracy = 1.000000\n",
      "[2018-07-16 12:35:25.211692] Iteration 34400, train loss = 0.152384, train accuracy = 0.992188\n",
      "[2018-07-16 12:35:29.302009] Iteration 34500, train loss = 0.164762, train accuracy = 0.992188\n",
      "[2018-07-16 12:35:33.350375] Iteration 34600, train loss = 0.152106, train accuracy = 1.000000\n",
      "[2018-07-16 12:35:37.406854] Iteration 34700, train loss = 0.160055, train accuracy = 0.984375\n",
      "[2018-07-16 12:35:41.457862] Iteration 34800, train loss = 0.161339, train accuracy = 1.000000\n",
      "[2018-07-16 12:35:45.511243] Iteration 34900, train loss = 0.161137, train accuracy = 1.000000\n",
      "[2018-07-16 12:35:49.587778] Iteration 35000, train loss = 0.149109, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915300\n",
      "[2018-07-16 12:35:54.918468] Iteration 35100, train loss = 0.156759, train accuracy = 1.000000\n",
      "[2018-07-16 12:35:59.078612] Iteration 35200, train loss = 0.151651, train accuracy = 1.000000\n",
      "[2018-07-16 12:36:03.163134] Iteration 35300, train loss = 0.157233, train accuracy = 0.992188\n",
      "[2018-07-16 12:36:07.239822] Iteration 35400, train loss = 0.160824, train accuracy = 1.000000\n",
      "[2018-07-16 12:36:11.349738] Iteration 35500, train loss = 0.181036, train accuracy = 0.984375\n",
      "[2018-07-16 12:36:15.418082] Iteration 35600, train loss = 0.184696, train accuracy = 0.976562\n",
      "[2018-07-16 12:36:19.479074] Iteration 35700, train loss = 0.181563, train accuracy = 0.984375\n",
      "[2018-07-16 12:36:23.541735] Iteration 35800, train loss = 0.154363, train accuracy = 1.000000\n",
      "[2018-07-16 12:36:27.599586] Iteration 35900, train loss = 0.155886, train accuracy = 1.000000\n",
      "[2018-07-16 12:36:31.657365] Iteration 36000, train loss = 0.150951, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-07-16 12:36:37.030425] Iteration 36100, train loss = 0.173471, train accuracy = 0.984375\n",
      "[2018-07-16 12:36:41.134666] Iteration 36200, train loss = 0.154766, train accuracy = 1.000000\n",
      "[2018-07-16 12:36:45.212637] Iteration 36300, train loss = 0.186979, train accuracy = 0.976562\n",
      "[2018-07-16 12:36:49.302428] Iteration 36400, train loss = 0.156963, train accuracy = 1.000000\n",
      "[2018-07-16 12:36:53.407342] Iteration 36500, train loss = 0.156986, train accuracy = 1.000000\n",
      "[2018-07-16 12:36:57.503956] Iteration 36600, train loss = 0.159153, train accuracy = 0.992188\n",
      "[2018-07-16 12:37:01.587421] Iteration 36700, train loss = 0.160424, train accuracy = 0.992188\n",
      "[2018-07-16 12:37:05.670908] Iteration 36800, train loss = 0.193761, train accuracy = 0.984375\n",
      "[2018-07-16 12:37:09.726186] Iteration 36900, train loss = 0.159353, train accuracy = 0.992188\n",
      "[2018-07-16 12:37:13.824921] Iteration 37000, train loss = 0.173931, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 12:37:19.129495] Iteration 37100, train loss = 0.182823, train accuracy = 0.976562\n",
      "[2018-07-16 12:37:23.191412] Iteration 37200, train loss = 0.175325, train accuracy = 1.000000\n",
      "[2018-07-16 12:37:27.268199] Iteration 37300, train loss = 0.174815, train accuracy = 0.992188\n",
      "[2018-07-16 12:37:31.366254] Iteration 37400, train loss = 0.175871, train accuracy = 0.984375\n",
      "[2018-07-16 12:37:35.455874] Iteration 37500, train loss = 0.157747, train accuracy = 1.000000\n",
      "[2018-07-16 12:37:39.540229] Iteration 37600, train loss = 0.155745, train accuracy = 1.000000\n",
      "[2018-07-16 12:37:43.629293] Iteration 37700, train loss = 0.195911, train accuracy = 0.976562\n",
      "[2018-07-16 12:37:47.716831] Iteration 37800, train loss = 0.149393, train accuracy = 1.000000\n",
      "[2018-07-16 12:37:51.792113] Iteration 37900, train loss = 0.171510, train accuracy = 0.992188\n",
      "[2018-07-16 12:37:55.794768] Iteration 38000, train loss = 0.157056, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916200\n",
      "[2018-07-16 12:38:01.126838] Iteration 38100, train loss = 0.161893, train accuracy = 1.000000\n",
      "[2018-07-16 12:38:05.184545] Iteration 38200, train loss = 0.160151, train accuracy = 0.992188\n",
      "[2018-07-16 12:38:09.273857] Iteration 38300, train loss = 0.149826, train accuracy = 1.000000\n",
      "[2018-07-16 12:38:13.344288] Iteration 38400, train loss = 0.167333, train accuracy = 0.992188\n",
      "[2018-07-16 12:38:17.434784] Iteration 38500, train loss = 0.167936, train accuracy = 0.992188\n",
      "[2018-07-16 12:38:21.530647] Iteration 38600, train loss = 0.169824, train accuracy = 0.984375\n",
      "[2018-07-16 12:38:25.613563] Iteration 38700, train loss = 0.171998, train accuracy = 0.992188\n",
      "[2018-07-16 12:38:29.766900] Iteration 38800, train loss = 0.152789, train accuracy = 1.000000\n",
      "[2018-07-16 12:38:33.826548] Iteration 38900, train loss = 0.159246, train accuracy = 1.000000\n",
      "[2018-07-16 12:38:37.882147] Iteration 39000, train loss = 0.185203, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.913000\n",
      "[2018-07-16 12:38:43.143344] Iteration 39100, train loss = 0.191417, train accuracy = 0.984375\n",
      "[2018-07-16 12:38:47.209342] Iteration 39200, train loss = 0.157294, train accuracy = 1.000000\n",
      "[2018-07-16 12:38:51.258847] Iteration 39300, train loss = 0.153126, train accuracy = 1.000000\n",
      "[2018-07-16 12:38:55.302426] Iteration 39400, train loss = 0.163709, train accuracy = 1.000000\n",
      "[2018-07-16 12:38:59.376898] Iteration 39500, train loss = 0.176613, train accuracy = 0.992188\n",
      "[2018-07-16 12:39:03.444610] Iteration 39600, train loss = 0.186543, train accuracy = 0.992188\n",
      "[2018-07-16 12:39:07.525556] Iteration 39700, train loss = 0.161961, train accuracy = 1.000000\n",
      "[2018-07-16 12:39:11.622920] Iteration 39800, train loss = 0.157438, train accuracy = 0.992188\n",
      "[2018-07-16 12:39:15.695732] Iteration 39900, train loss = 0.154573, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "curr_lr = 0\n",
    "for step in range(40000):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二轮 量化\n",
    "prune_rate = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.916900\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.04016392  0.125       0.07315639 -0.02169925\n",
      "  0.02299175 -0.0625      0.02231506 -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.75)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-16 12:39:47.281933] Iteration 100, train loss = 0.241169, train accuracy = 0.968750\n",
      "[2018-07-16 12:39:50.913144] Iteration 200, train loss = 0.182785, train accuracy = 1.000000\n",
      "[2018-07-16 12:39:54.617665] Iteration 300, train loss = 0.239107, train accuracy = 0.968750\n",
      "[2018-07-16 12:39:58.350335] Iteration 400, train loss = 0.191382, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:02.075357] Iteration 500, train loss = 0.182772, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:05.917771] Iteration 600, train loss = 0.192294, train accuracy = 0.968750\n",
      "[2018-07-16 12:40:09.682349] Iteration 700, train loss = 0.176096, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:13.588936] Iteration 800, train loss = 0.175947, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:17.606930] Iteration 900, train loss = 0.225114, train accuracy = 0.976562\n",
      "[2018-07-16 12:40:21.658410] Iteration 1000, train loss = 0.178778, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.909000\n",
      "[2018-07-16 12:40:26.980256] Iteration 1100, train loss = 0.184336, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:31.028525] Iteration 1200, train loss = 0.216952, train accuracy = 0.976562\n",
      "[2018-07-16 12:40:35.089319] Iteration 1300, train loss = 0.163052, train accuracy = 1.000000\n",
      "[2018-07-16 12:40:39.170770] Iteration 1400, train loss = 0.183922, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:43.294642] Iteration 1500, train loss = 0.160247, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:47.425773] Iteration 1600, train loss = 0.196758, train accuracy = 0.984375\n",
      "[2018-07-16 12:40:51.486994] Iteration 1700, train loss = 0.155881, train accuracy = 1.000000\n",
      "[2018-07-16 12:40:55.575587] Iteration 1800, train loss = 0.171358, train accuracy = 0.992188\n",
      "[2018-07-16 12:40:59.660900] Iteration 1900, train loss = 0.177046, train accuracy = 0.976562\n",
      "[2018-07-16 12:41:03.722683] Iteration 2000, train loss = 0.165924, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-16 12:41:09.084653] Iteration 2100, train loss = 0.181750, train accuracy = 0.976562\n",
      "[2018-07-16 12:41:13.134396] Iteration 2200, train loss = 0.177140, train accuracy = 0.992188\n",
      "[2018-07-16 12:41:17.188822] Iteration 2300, train loss = 0.161692, train accuracy = 0.992188\n",
      "[2018-07-16 12:41:21.289472] Iteration 2400, train loss = 0.186034, train accuracy = 0.984375\n",
      "[2018-07-16 12:41:25.351124] Iteration 2500, train loss = 0.249983, train accuracy = 0.945312\n",
      "[2018-07-16 12:41:29.434686] Iteration 2600, train loss = 0.154068, train accuracy = 1.000000\n",
      "[2018-07-16 12:41:33.499330] Iteration 2700, train loss = 0.175161, train accuracy = 0.992188\n",
      "[2018-07-16 12:41:37.578371] Iteration 2800, train loss = 0.174561, train accuracy = 0.984375\n",
      "[2018-07-16 12:41:41.665748] Iteration 2900, train loss = 0.166123, train accuracy = 0.992188\n",
      "[2018-07-16 12:41:45.733219] Iteration 3000, train loss = 0.161255, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-07-16 12:41:51.053937] Iteration 3100, train loss = 0.201812, train accuracy = 0.984375\n",
      "[2018-07-16 12:41:55.123753] Iteration 3200, train loss = 0.194662, train accuracy = 1.000000\n",
      "[2018-07-16 12:41:59.223027] Iteration 3300, train loss = 0.181189, train accuracy = 0.992188\n",
      "[2018-07-16 12:42:03.281075] Iteration 3400, train loss = 0.188506, train accuracy = 0.976562\n",
      "[2018-07-16 12:42:07.329092] Iteration 3500, train loss = 0.223001, train accuracy = 0.960938\n",
      "[2018-07-16 12:42:11.385750] Iteration 3600, train loss = 0.191067, train accuracy = 0.984375\n",
      "[2018-07-16 12:42:15.468198] Iteration 3700, train loss = 0.155039, train accuracy = 1.000000\n",
      "[2018-07-16 12:42:19.565116] Iteration 3800, train loss = 0.170789, train accuracy = 0.992188\n",
      "[2018-07-16 12:42:23.644841] Iteration 3900, train loss = 0.193490, train accuracy = 0.992188\n",
      "[2018-07-16 12:42:27.713704] Iteration 4000, train loss = 0.209770, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911800\n",
      "[2018-07-16 12:42:33.058251] Iteration 4100, train loss = 0.181268, train accuracy = 0.992188\n",
      "[2018-07-16 12:42:37.186009] Iteration 4200, train loss = 0.148689, train accuracy = 1.000000\n",
      "[2018-07-16 12:42:41.271026] Iteration 4300, train loss = 0.168937, train accuracy = 0.992188\n",
      "[2018-07-16 12:42:45.321142] Iteration 4400, train loss = 0.199558, train accuracy = 0.976562\n",
      "[2018-07-16 12:42:49.373704] Iteration 4500, train loss = 0.166011, train accuracy = 0.992188\n",
      "[2018-07-16 12:42:53.423711] Iteration 4600, train loss = 0.183277, train accuracy = 0.992188\n",
      "[2018-07-16 12:42:57.467184] Iteration 4700, train loss = 0.184677, train accuracy = 0.984375\n",
      "[2018-07-16 12:43:01.541541] Iteration 4800, train loss = 0.203086, train accuracy = 0.976562\n",
      "[2018-07-16 12:43:05.618859] Iteration 4900, train loss = 0.248984, train accuracy = 0.968750\n",
      "[2018-07-16 12:43:09.680203] Iteration 5000, train loss = 0.200979, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.912600\n",
      "[2018-07-16 12:43:15.068903] Iteration 5100, train loss = 0.155173, train accuracy = 1.000000\n",
      "[2018-07-16 12:43:19.133879] Iteration 5200, train loss = 0.166596, train accuracy = 0.992188\n",
      "[2018-07-16 12:43:23.223707] Iteration 5300, train loss = 0.178455, train accuracy = 0.992188\n",
      "[2018-07-16 12:43:27.288431] Iteration 5400, train loss = 0.176188, train accuracy = 1.000000\n",
      "[2018-07-16 12:43:31.368601] Iteration 5500, train loss = 0.206294, train accuracy = 0.984375\n",
      "[2018-07-16 12:43:35.435583] Iteration 5600, train loss = 0.177952, train accuracy = 0.976562\n",
      "[2018-07-16 12:43:39.483061] Iteration 5700, train loss = 0.192345, train accuracy = 0.968750\n",
      "[2018-07-16 12:43:43.535469] Iteration 5800, train loss = 0.174258, train accuracy = 0.992188\n",
      "[2018-07-16 12:43:47.591885] Iteration 5900, train loss = 0.162742, train accuracy = 0.992188\n",
      "[2018-07-16 12:43:51.709347] Iteration 6000, train loss = 0.256497, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.912000\n",
      "[2018-07-16 12:43:57.057401] Iteration 6100, train loss = 0.191013, train accuracy = 0.976562\n",
      "[2018-07-16 12:44:01.131159] Iteration 6200, train loss = 0.191625, train accuracy = 0.984375\n",
      "[2018-07-16 12:44:05.218098] Iteration 6300, train loss = 0.175778, train accuracy = 0.984375\n",
      "[2018-07-16 12:44:09.287122] Iteration 6400, train loss = 0.167794, train accuracy = 0.992188\n",
      "[2018-07-16 12:44:13.368448] Iteration 6500, train loss = 0.171353, train accuracy = 0.984375\n",
      "[2018-07-16 12:44:17.448155] Iteration 6600, train loss = 0.170355, train accuracy = 0.984375\n",
      "[2018-07-16 12:44:21.500575] Iteration 6700, train loss = 0.158323, train accuracy = 1.000000\n",
      "[2018-07-16 12:44:25.549875] Iteration 6800, train loss = 0.200615, train accuracy = 0.976562\n",
      "[2018-07-16 12:44:29.663796] Iteration 6900, train loss = 0.169157, train accuracy = 0.992188\n",
      "[2018-07-16 12:44:33.707155] Iteration 7000, train loss = 0.157073, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 12:44:39.044766] Iteration 7100, train loss = 0.149332, train accuracy = 1.000000\n",
      "[2018-07-16 12:44:43.112756] Iteration 7200, train loss = 0.179947, train accuracy = 0.984375\n",
      "[2018-07-16 12:44:47.187465] Iteration 7300, train loss = 0.155405, train accuracy = 1.000000\n",
      "[2018-07-16 12:44:51.262942] Iteration 7400, train loss = 0.150368, train accuracy = 1.000000\n",
      "[2018-07-16 12:44:55.341517] Iteration 7500, train loss = 0.168920, train accuracy = 0.992188\n",
      "[2018-07-16 12:44:59.424127] Iteration 7600, train loss = 0.169882, train accuracy = 1.000000\n",
      "[2018-07-16 12:45:03.493157] Iteration 7700, train loss = 0.196195, train accuracy = 0.984375\n",
      "[2018-07-16 12:45:07.623905] Iteration 7800, train loss = 0.181144, train accuracy = 0.984375\n",
      "[2018-07-16 12:45:11.666211] Iteration 7900, train loss = 0.162102, train accuracy = 1.000000\n",
      "[2018-07-16 12:45:15.710718] Iteration 8000, train loss = 0.169934, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 12:45:21.042264] Iteration 8100, train loss = 0.187185, train accuracy = 0.984375\n",
      "[2018-07-16 12:45:25.110085] Iteration 8200, train loss = 0.166676, train accuracy = 1.000000\n",
      "[2018-07-16 12:45:29.201340] Iteration 8300, train loss = 0.171174, train accuracy = 0.992188\n",
      "[2018-07-16 12:45:33.273040] Iteration 8400, train loss = 0.187174, train accuracy = 0.984375\n",
      "[2018-07-16 12:45:37.354181] Iteration 8500, train loss = 0.171787, train accuracy = 0.992188\n",
      "[2018-07-16 12:45:41.443455] Iteration 8600, train loss = 0.162452, train accuracy = 0.992188\n",
      "[2018-07-16 12:45:45.488844] Iteration 8700, train loss = 0.153719, train accuracy = 1.000000\n",
      "[2018-07-16 12:45:49.536609] Iteration 8800, train loss = 0.189443, train accuracy = 0.992188\n",
      "[2018-07-16 12:45:53.615097] Iteration 8900, train loss = 0.164763, train accuracy = 0.984375\n",
      "[2018-07-16 12:45:57.659136] Iteration 9000, train loss = 0.167742, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 12:46:02.965864] Iteration 9100, train loss = 0.155497, train accuracy = 0.992188\n",
      "[2018-07-16 12:46:07.003254] Iteration 9200, train loss = 0.209155, train accuracy = 0.968750\n",
      "[2018-07-16 12:46:11.056964] Iteration 9300, train loss = 0.220086, train accuracy = 0.968750\n",
      "[2018-07-16 12:46:15.127386] Iteration 9400, train loss = 0.182642, train accuracy = 0.992188\n",
      "[2018-07-16 12:46:19.194049] Iteration 9500, train loss = 0.177991, train accuracy = 0.976562\n",
      "[2018-07-16 12:46:23.368236] Iteration 9600, train loss = 0.163666, train accuracy = 1.000000\n",
      "[2018-07-16 12:46:27.431851] Iteration 9700, train loss = 0.151902, train accuracy = 1.000000\n",
      "[2018-07-16 12:46:31.510887] Iteration 9800, train loss = 0.153696, train accuracy = 1.000000\n",
      "[2018-07-16 12:46:35.598259] Iteration 9900, train loss = 0.172411, train accuracy = 1.000000\n",
      "[2018-07-16 12:46:39.659420] Iteration 10000, train loss = 0.162501, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 12:46:44.983701] Iteration 10100, train loss = 0.152358, train accuracy = 1.000000\n",
      "[2018-07-16 12:46:49.039839] Iteration 10200, train loss = 0.219081, train accuracy = 0.960938\n",
      "[2018-07-16 12:46:53.093662] Iteration 10300, train loss = 0.167418, train accuracy = 0.992188\n",
      "[2018-07-16 12:46:57.144864] Iteration 10400, train loss = 0.212659, train accuracy = 0.984375\n",
      "[2018-07-16 12:47:01.256557] Iteration 10500, train loss = 0.165117, train accuracy = 0.992188\n",
      "[2018-07-16 12:47:05.345260] Iteration 10600, train loss = 0.154547, train accuracy = 1.000000\n",
      "[2018-07-16 12:47:09.413541] Iteration 10700, train loss = 0.156033, train accuracy = 1.000000\n",
      "[2018-07-16 12:47:13.499956] Iteration 10800, train loss = 0.166620, train accuracy = 0.992188\n",
      "[2018-07-16 12:47:17.593410] Iteration 10900, train loss = 0.200665, train accuracy = 0.960938\n",
      "[2018-07-16 12:47:21.650986] Iteration 11000, train loss = 0.161958, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-07-16 12:47:27.006607] Iteration 11100, train loss = 0.202357, train accuracy = 0.960938\n",
      "[2018-07-16 12:47:31.078391] Iteration 11200, train loss = 0.161048, train accuracy = 0.992188\n",
      "[2018-07-16 12:47:35.125720] Iteration 11300, train loss = 0.183672, train accuracy = 0.992188\n",
      "[2018-07-16 12:47:39.242547] Iteration 11400, train loss = 0.163210, train accuracy = 1.000000\n",
      "[2018-07-16 12:47:43.295509] Iteration 11500, train loss = 0.189404, train accuracy = 0.976562\n",
      "[2018-07-16 12:47:47.352043] Iteration 11600, train loss = 0.186497, train accuracy = 0.976562\n",
      "[2018-07-16 12:47:51.426819] Iteration 11700, train loss = 0.157407, train accuracy = 0.992188\n",
      "[2018-07-16 12:47:55.521480] Iteration 11800, train loss = 0.152062, train accuracy = 1.000000\n",
      "[2018-07-16 12:47:59.600110] Iteration 11900, train loss = 0.166445, train accuracy = 0.992188\n",
      "[2018-07-16 12:48:03.667355] Iteration 12000, train loss = 0.197200, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-07-16 12:48:09.012582] Iteration 12100, train loss = 0.201635, train accuracy = 0.960938\n",
      "[2018-07-16 12:48:13.092330] Iteration 12200, train loss = 0.170488, train accuracy = 0.992188\n",
      "[2018-07-16 12:48:17.229049] Iteration 12300, train loss = 0.177635, train accuracy = 0.992188\n",
      "[2018-07-16 12:48:21.281723] Iteration 12400, train loss = 0.162649, train accuracy = 0.992188\n",
      "[2018-07-16 12:48:25.329999] Iteration 12500, train loss = 0.184281, train accuracy = 0.992188\n",
      "[2018-07-16 12:48:29.376113] Iteration 12600, train loss = 0.156155, train accuracy = 1.000000\n",
      "[2018-07-16 12:48:33.419785] Iteration 12700, train loss = 0.180358, train accuracy = 0.984375\n",
      "[2018-07-16 12:48:37.494869] Iteration 12800, train loss = 0.166533, train accuracy = 1.000000\n",
      "[2018-07-16 12:48:41.570655] Iteration 12900, train loss = 0.166658, train accuracy = 0.992188\n",
      "[2018-07-16 12:48:45.645347] Iteration 13000, train loss = 0.184553, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 12:48:50.988867] Iteration 13100, train loss = 0.174085, train accuracy = 1.000000\n",
      "[2018-07-16 12:48:55.073579] Iteration 13200, train loss = 0.168969, train accuracy = 1.000000\n",
      "[2018-07-16 12:48:59.189252] Iteration 13300, train loss = 0.210214, train accuracy = 0.984375\n",
      "[2018-07-16 12:49:03.281182] Iteration 13400, train loss = 0.179060, train accuracy = 0.992188\n",
      "[2018-07-16 12:49:07.346263] Iteration 13500, train loss = 0.146549, train accuracy = 1.000000\n",
      "[2018-07-16 12:49:11.394440] Iteration 13600, train loss = 0.186756, train accuracy = 0.984375\n",
      "[2018-07-16 12:49:15.450954] Iteration 13700, train loss = 0.161412, train accuracy = 1.000000\n",
      "[2018-07-16 12:49:19.504991] Iteration 13800, train loss = 0.179378, train accuracy = 0.992188\n",
      "[2018-07-16 12:49:23.572402] Iteration 13900, train loss = 0.158622, train accuracy = 1.000000\n",
      "[2018-07-16 12:49:27.637344] Iteration 14000, train loss = 0.182594, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 12:49:33.104015] Iteration 14100, train loss = 0.153825, train accuracy = 1.000000\n",
      "[2018-07-16 12:49:37.189470] Iteration 14200, train loss = 0.150826, train accuracy = 1.000000\n",
      "[2018-07-16 12:49:41.304651] Iteration 14300, train loss = 0.154511, train accuracy = 1.000000\n",
      "[2018-07-16 12:49:45.363147] Iteration 14400, train loss = 0.158222, train accuracy = 0.992188\n",
      "[2018-07-16 12:49:49.455071] Iteration 14500, train loss = 0.156106, train accuracy = 1.000000\n",
      "[2018-07-16 12:49:53.526620] Iteration 14600, train loss = 0.181549, train accuracy = 0.976562\n",
      "[2018-07-16 12:49:57.572138] Iteration 14700, train loss = 0.174684, train accuracy = 0.984375\n",
      "[2018-07-16 12:50:01.635362] Iteration 14800, train loss = 0.158086, train accuracy = 1.000000\n",
      "[2018-07-16 12:50:05.697170] Iteration 14900, train loss = 0.169126, train accuracy = 1.000000\n",
      "[2018-07-16 12:50:09.784997] Iteration 15000, train loss = 0.181392, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912600\n",
      "[2018-07-16 12:50:15.156128] Iteration 15100, train loss = 0.149511, train accuracy = 1.000000\n",
      "[2018-07-16 12:50:19.236777] Iteration 15200, train loss = 0.154508, train accuracy = 1.000000\n",
      "[2018-07-16 12:50:23.320455] Iteration 15300, train loss = 0.165737, train accuracy = 0.992188\n",
      "[2018-07-16 12:50:27.389635] Iteration 15400, train loss = 0.164759, train accuracy = 0.992188\n",
      "[2018-07-16 12:50:31.473862] Iteration 15500, train loss = 0.169337, train accuracy = 0.992188\n",
      "[2018-07-16 12:50:35.551135] Iteration 15600, train loss = 0.148043, train accuracy = 1.000000\n",
      "[2018-07-16 12:50:39.620147] Iteration 15700, train loss = 0.159591, train accuracy = 1.000000\n",
      "[2018-07-16 12:50:43.708373] Iteration 15800, train loss = 0.229663, train accuracy = 0.968750\n",
      "[2018-07-16 12:50:47.784100] Iteration 15900, train loss = 0.164292, train accuracy = 1.000000\n",
      "[2018-07-16 12:50:51.840289] Iteration 16000, train loss = 0.148291, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-16 12:50:57.150478] Iteration 16100, train loss = 0.171564, train accuracy = 0.992188\n",
      "[2018-07-16 12:51:01.214704] Iteration 16200, train loss = 0.152479, train accuracy = 1.000000\n",
      "[2018-07-16 12:51:05.320523] Iteration 16300, train loss = 0.153006, train accuracy = 1.000000\n",
      "[2018-07-16 12:51:09.388004] Iteration 16400, train loss = 0.172528, train accuracy = 0.992188\n",
      "[2018-07-16 12:51:13.478208] Iteration 16500, train loss = 0.158304, train accuracy = 1.000000\n",
      "[2018-07-16 12:51:17.563862] Iteration 16600, train loss = 0.172969, train accuracy = 0.984375\n",
      "[2018-07-16 12:51:21.677023] Iteration 16700, train loss = 0.157076, train accuracy = 1.000000\n",
      "[2018-07-16 12:51:25.685022] Iteration 16800, train loss = 0.167408, train accuracy = 0.976562\n",
      "[2018-07-16 12:51:29.753135] Iteration 16900, train loss = 0.174293, train accuracy = 0.984375\n",
      "[2018-07-16 12:51:33.800761] Iteration 17000, train loss = 0.162402, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912900\n",
      "[2018-07-16 12:51:39.107735] Iteration 17100, train loss = 0.152138, train accuracy = 1.000000\n",
      "[2018-07-16 12:51:43.161937] Iteration 17200, train loss = 0.211583, train accuracy = 0.976562\n",
      "[2018-07-16 12:51:47.228597] Iteration 17300, train loss = 0.172187, train accuracy = 0.992188\n",
      "[2018-07-16 12:51:51.309727] Iteration 17400, train loss = 0.168876, train accuracy = 1.000000\n",
      "[2018-07-16 12:51:55.401554] Iteration 17500, train loss = 0.169131, train accuracy = 0.992188\n",
      "[2018-07-16 12:51:59.535193] Iteration 17600, train loss = 0.182110, train accuracy = 0.976562\n",
      "[2018-07-16 12:52:03.597488] Iteration 17700, train loss = 0.163014, train accuracy = 0.992188\n",
      "[2018-07-16 12:52:07.677085] Iteration 17800, train loss = 0.150781, train accuracy = 1.000000\n",
      "[2018-07-16 12:52:11.761797] Iteration 17900, train loss = 0.178294, train accuracy = 1.000000\n",
      "[2018-07-16 12:52:15.835989] Iteration 18000, train loss = 0.174658, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "[2018-07-16 12:52:21.177281] Iteration 18100, train loss = 0.149265, train accuracy = 1.000000\n",
      "[2018-07-16 12:52:25.225920] Iteration 18200, train loss = 0.179013, train accuracy = 0.992188\n",
      "[2018-07-16 12:52:29.283563] Iteration 18300, train loss = 0.180735, train accuracy = 0.984375\n",
      "[2018-07-16 12:52:33.325048] Iteration 18400, train loss = 0.175277, train accuracy = 0.984375\n",
      "[2018-07-16 12:52:37.439112] Iteration 18500, train loss = 0.161506, train accuracy = 1.000000\n",
      "[2018-07-16 12:52:41.521115] Iteration 18600, train loss = 0.187271, train accuracy = 0.976562\n",
      "[2018-07-16 12:52:45.583392] Iteration 18700, train loss = 0.151073, train accuracy = 1.000000\n",
      "[2018-07-16 12:52:49.670612] Iteration 18800, train loss = 0.158266, train accuracy = 1.000000\n",
      "[2018-07-16 12:52:53.744743] Iteration 18900, train loss = 0.149779, train accuracy = 1.000000\n",
      "[2018-07-16 12:52:57.816388] Iteration 19000, train loss = 0.189576, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913400\n",
      "[2018-07-16 12:53:03.162339] Iteration 19100, train loss = 0.163171, train accuracy = 0.992188\n",
      "[2018-07-16 12:53:07.219157] Iteration 19200, train loss = 0.178931, train accuracy = 1.000000\n",
      "[2018-07-16 12:53:11.275482] Iteration 19300, train loss = 0.170199, train accuracy = 0.992188\n",
      "[2018-07-16 12:53:15.366390] Iteration 19400, train loss = 0.154317, train accuracy = 1.000000\n",
      "[2018-07-16 12:53:19.423575] Iteration 19500, train loss = 0.162834, train accuracy = 0.992188\n",
      "[2018-07-16 12:53:23.492617] Iteration 19600, train loss = 0.170676, train accuracy = 0.992188\n",
      "[2018-07-16 12:53:27.562791] Iteration 19700, train loss = 0.157790, train accuracy = 1.000000\n",
      "[2018-07-16 12:53:31.648850] Iteration 19800, train loss = 0.158787, train accuracy = 1.000000\n",
      "[2018-07-16 12:53:35.736287] Iteration 19900, train loss = 0.150900, train accuracy = 1.000000\n",
      "[2018-07-16 12:53:39.815258] Iteration 20000, train loss = 0.164550, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913300\n",
      "[2018-07-16 12:53:45.164312] Iteration 20100, train loss = 0.162874, train accuracy = 1.000000\n",
      "[2018-07-16 12:53:49.224628] Iteration 20200, train loss = 0.180276, train accuracy = 0.976562\n",
      "[2018-07-16 12:53:53.358923] Iteration 20300, train loss = 0.212006, train accuracy = 0.976562\n",
      "[2018-07-16 12:53:57.407992] Iteration 20400, train loss = 0.155094, train accuracy = 1.000000\n",
      "[2018-07-16 12:54:01.450752] Iteration 20500, train loss = 0.159101, train accuracy = 1.000000\n",
      "[2018-07-16 12:54:05.509074] Iteration 20600, train loss = 0.177470, train accuracy = 0.992188\n",
      "[2018-07-16 12:54:09.561111] Iteration 20700, train loss = 0.196714, train accuracy = 0.976562\n",
      "[2018-07-16 12:54:13.638923] Iteration 20800, train loss = 0.171051, train accuracy = 0.992188\n",
      "[2018-07-16 12:54:17.719769] Iteration 20900, train loss = 0.159619, train accuracy = 1.000000\n",
      "[2018-07-16 12:54:21.812739] Iteration 21000, train loss = 0.182707, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913100\n",
      "[2018-07-16 12:54:27.173352] Iteration 21100, train loss = 0.170601, train accuracy = 1.000000\n",
      "[2018-07-16 12:54:31.300738] Iteration 21200, train loss = 0.171423, train accuracy = 1.000000\n",
      "[2018-07-16 12:54:35.407076] Iteration 21300, train loss = 0.176057, train accuracy = 0.984375\n",
      "[2018-07-16 12:54:39.478329] Iteration 21400, train loss = 0.176786, train accuracy = 0.984375\n",
      "[2018-07-16 12:54:43.540519] Iteration 21500, train loss = 0.158226, train accuracy = 0.992188\n",
      "[2018-07-16 12:54:47.594828] Iteration 21600, train loss = 0.164528, train accuracy = 0.992188\n",
      "[2018-07-16 12:54:51.641055] Iteration 21700, train loss = 0.151806, train accuracy = 1.000000\n",
      "[2018-07-16 12:54:55.712408] Iteration 21800, train loss = 0.169552, train accuracy = 0.992188\n",
      "[2018-07-16 12:54:59.777830] Iteration 21900, train loss = 0.163225, train accuracy = 1.000000\n",
      "[2018-07-16 12:55:03.840433] Iteration 22000, train loss = 0.162336, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 12:55:09.236025] Iteration 22100, train loss = 0.170025, train accuracy = 0.992188\n",
      "[2018-07-16 12:55:13.305616] Iteration 22200, train loss = 0.173393, train accuracy = 0.992188\n",
      "[2018-07-16 12:55:17.409303] Iteration 22300, train loss = 0.164041, train accuracy = 0.992188\n",
      "[2018-07-16 12:55:21.495777] Iteration 22400, train loss = 0.194979, train accuracy = 0.976562\n",
      "[2018-07-16 12:55:25.573390] Iteration 22500, train loss = 0.160112, train accuracy = 0.992188\n",
      "[2018-07-16 12:55:29.654496] Iteration 22600, train loss = 0.195418, train accuracy = 0.984375\n",
      "[2018-07-16 12:55:33.700963] Iteration 22700, train loss = 0.161767, train accuracy = 0.984375\n",
      "[2018-07-16 12:55:37.753599] Iteration 22800, train loss = 0.162441, train accuracy = 0.984375\n",
      "[2018-07-16 12:55:41.801570] Iteration 22900, train loss = 0.167735, train accuracy = 0.992188\n",
      "[2018-07-16 12:55:45.883026] Iteration 23000, train loss = 0.171442, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 12:55:51.229390] Iteration 23100, train loss = 0.162305, train accuracy = 1.000000\n",
      "[2018-07-16 12:55:55.293204] Iteration 23200, train loss = 0.202483, train accuracy = 0.976562\n",
      "[2018-07-16 12:55:59.376085] Iteration 23300, train loss = 0.160293, train accuracy = 1.000000\n",
      "[2018-07-16 12:56:03.459032] Iteration 23400, train loss = 0.199609, train accuracy = 0.984375\n",
      "[2018-07-16 12:56:07.538009] Iteration 23500, train loss = 0.163512, train accuracy = 0.992188\n",
      "[2018-07-16 12:56:11.628957] Iteration 23600, train loss = 0.173001, train accuracy = 0.992188\n",
      "[2018-07-16 12:56:15.691684] Iteration 23700, train loss = 0.160905, train accuracy = 0.992188\n",
      "[2018-07-16 12:56:19.757481] Iteration 23800, train loss = 0.153974, train accuracy = 1.000000\n",
      "[2018-07-16 12:56:23.869577] Iteration 23900, train loss = 0.177911, train accuracy = 0.984375\n",
      "[2018-07-16 12:56:27.921798] Iteration 24000, train loss = 0.166757, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-07-16 12:56:33.226871] Iteration 24100, train loss = 0.162032, train accuracy = 0.992188\n",
      "[2018-07-16 12:56:37.294117] Iteration 24200, train loss = 0.185115, train accuracy = 0.968750\n",
      "[2018-07-16 12:56:41.381487] Iteration 24300, train loss = 0.157243, train accuracy = 1.000000\n",
      "[2018-07-16 12:56:45.443921] Iteration 24400, train loss = 0.163530, train accuracy = 1.000000\n",
      "[2018-07-16 12:56:49.535214] Iteration 24500, train loss = 0.171975, train accuracy = 0.992188\n",
      "[2018-07-16 12:56:53.626197] Iteration 24600, train loss = 0.183914, train accuracy = 0.992188\n",
      "[2018-07-16 12:56:57.695544] Iteration 24700, train loss = 0.167114, train accuracy = 1.000000\n",
      "[2018-07-16 12:57:01.855711] Iteration 24800, train loss = 0.177599, train accuracy = 0.984375\n",
      "[2018-07-16 12:57:05.915513] Iteration 24900, train loss = 0.157574, train accuracy = 1.000000\n",
      "[2018-07-16 12:57:09.966238] Iteration 25000, train loss = 0.195399, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.912400\n",
      "[2018-07-16 12:57:15.295405] Iteration 25100, train loss = 0.149317, train accuracy = 1.000000\n",
      "[2018-07-16 12:57:19.342428] Iteration 25200, train loss = 0.157495, train accuracy = 1.000000\n",
      "[2018-07-16 12:57:23.405440] Iteration 25300, train loss = 0.178603, train accuracy = 0.984375\n",
      "[2018-07-16 12:57:27.474979] Iteration 25400, train loss = 0.149528, train accuracy = 1.000000\n",
      "[2018-07-16 12:57:31.553619] Iteration 25500, train loss = 0.176262, train accuracy = 0.992188\n",
      "[2018-07-16 12:57:35.633256] Iteration 25600, train loss = 0.173347, train accuracy = 0.992188\n",
      "[2018-07-16 12:57:39.750592] Iteration 25700, train loss = 0.174637, train accuracy = 0.984375\n",
      "[2018-07-16 12:57:43.849008] Iteration 25800, train loss = 0.158318, train accuracy = 0.992188\n",
      "[2018-07-16 12:57:47.929068] Iteration 25900, train loss = 0.154504, train accuracy = 1.000000\n",
      "[2018-07-16 12:57:51.993360] Iteration 26000, train loss = 0.159160, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913000\n",
      "[2018-07-16 12:57:57.313758] Iteration 26100, train loss = 0.161100, train accuracy = 0.992188\n",
      "[2018-07-16 12:58:01.369306] Iteration 26200, train loss = 0.159279, train accuracy = 0.992188\n",
      "[2018-07-16 12:58:05.424624] Iteration 26300, train loss = 0.173634, train accuracy = 0.984375\n",
      "[2018-07-16 12:58:09.469010] Iteration 26400, train loss = 0.189430, train accuracy = 0.976562\n",
      "[2018-07-16 12:58:13.543453] Iteration 26500, train loss = 0.164327, train accuracy = 0.992188\n",
      "[2018-07-16 12:58:17.699981] Iteration 26600, train loss = 0.203156, train accuracy = 0.976562\n",
      "[2018-07-16 12:58:21.763368] Iteration 26700, train loss = 0.146892, train accuracy = 1.000000\n",
      "[2018-07-16 12:58:25.843499] Iteration 26800, train loss = 0.163330, train accuracy = 1.000000\n",
      "[2018-07-16 12:58:29.925201] Iteration 26900, train loss = 0.170759, train accuracy = 0.992188\n",
      "[2018-07-16 12:58:33.994976] Iteration 27000, train loss = 0.160708, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912000\n",
      "[2018-07-16 12:58:39.358095] Iteration 27100, train loss = 0.152758, train accuracy = 1.000000\n",
      "[2018-07-16 12:58:43.438055] Iteration 27200, train loss = 0.151673, train accuracy = 1.000000\n",
      "[2018-07-16 12:58:47.494677] Iteration 27300, train loss = 0.190885, train accuracy = 0.992188\n",
      "[2018-07-16 12:58:51.536015] Iteration 27400, train loss = 0.189642, train accuracy = 0.984375\n",
      "[2018-07-16 12:58:55.630531] Iteration 27500, train loss = 0.161023, train accuracy = 1.000000\n",
      "[2018-07-16 12:58:59.703539] Iteration 27600, train loss = 0.173255, train accuracy = 0.992188\n",
      "[2018-07-16 12:59:03.784521] Iteration 27700, train loss = 0.167991, train accuracy = 0.992188\n",
      "[2018-07-16 12:59:07.880329] Iteration 27800, train loss = 0.151907, train accuracy = 1.000000\n",
      "[2018-07-16 12:59:11.957996] Iteration 27900, train loss = 0.167144, train accuracy = 0.992188\n",
      "[2018-07-16 12:59:16.027273] Iteration 28000, train loss = 0.153050, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911000\n",
      "[2018-07-16 12:59:21.400366] Iteration 28100, train loss = 0.186639, train accuracy = 0.984375\n",
      "[2018-07-16 12:59:25.487765] Iteration 28200, train loss = 0.159881, train accuracy = 0.992188\n",
      "[2018-07-16 12:59:29.587656] Iteration 28300, train loss = 0.180777, train accuracy = 0.984375\n",
      "[2018-07-16 12:59:33.677670] Iteration 28400, train loss = 0.194321, train accuracy = 0.984375\n",
      "[2018-07-16 12:59:37.734729] Iteration 28500, train loss = 0.159548, train accuracy = 0.992188\n",
      "[2018-07-16 12:59:41.783610] Iteration 28600, train loss = 0.172886, train accuracy = 0.992188\n",
      "[2018-07-16 12:59:45.834153] Iteration 28700, train loss = 0.160286, train accuracy = 1.000000\n",
      "[2018-07-16 12:59:49.910180] Iteration 28800, train loss = 0.180152, train accuracy = 0.984375\n",
      "[2018-07-16 12:59:53.969866] Iteration 28900, train loss = 0.173932, train accuracy = 0.992188\n",
      "[2018-07-16 12:59:58.040628] Iteration 29000, train loss = 0.149404, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913000\n",
      "[2018-07-16 13:00:03.402282] Iteration 29100, train loss = 0.151273, train accuracy = 1.000000\n",
      "[2018-07-16 13:00:07.525533] Iteration 29200, train loss = 0.166288, train accuracy = 0.992188\n",
      "[2018-07-16 13:00:11.618773] Iteration 29300, train loss = 0.172993, train accuracy = 0.992188\n",
      "[2018-07-16 13:00:15.690581] Iteration 29400, train loss = 0.179383, train accuracy = 0.992188\n",
      "[2018-07-16 13:00:19.753936] Iteration 29500, train loss = 0.160551, train accuracy = 0.992188\n",
      "[2018-07-16 13:00:23.796020] Iteration 29600, train loss = 0.156023, train accuracy = 1.000000\n",
      "[2018-07-16 13:00:27.846613] Iteration 29700, train loss = 0.162219, train accuracy = 0.992188\n",
      "[2018-07-16 13:00:31.901582] Iteration 29800, train loss = 0.166734, train accuracy = 0.992188\n",
      "[2018-07-16 13:00:35.976436] Iteration 29900, train loss = 0.185851, train accuracy = 0.984375\n",
      "[2018-07-16 13:00:40.061640] Iteration 30000, train loss = 0.160084, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912000\n",
      "[2018-07-16 13:00:45.485488] Iteration 30100, train loss = 0.164815, train accuracy = 0.992188\n",
      "[2018-07-16 13:00:49.582243] Iteration 30200, train loss = 0.163239, train accuracy = 1.000000\n",
      "[2018-07-16 13:00:53.654065] Iteration 30300, train loss = 0.157824, train accuracy = 1.000000\n",
      "[2018-07-16 13:00:57.723841] Iteration 30400, train loss = 0.155395, train accuracy = 1.000000\n",
      "[2018-07-16 13:01:01.821057] Iteration 30500, train loss = 0.153788, train accuracy = 1.000000\n",
      "[2018-07-16 13:01:05.894947] Iteration 30600, train loss = 0.160583, train accuracy = 1.000000\n",
      "[2018-07-16 13:01:09.949528] Iteration 30700, train loss = 0.148047, train accuracy = 1.000000\n",
      "[2018-07-16 13:01:14.013193] Iteration 30800, train loss = 0.157949, train accuracy = 1.000000\n",
      "[2018-07-16 13:01:18.069880] Iteration 30900, train loss = 0.160133, train accuracy = 0.992188\n",
      "[2018-07-16 13:01:22.132316] Iteration 31000, train loss = 0.151292, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913000\n",
      "[2018-07-16 13:01:27.572063] Iteration 31100, train loss = 0.175899, train accuracy = 0.984375\n",
      "[2018-07-16 13:01:31.662002] Iteration 31200, train loss = 0.185068, train accuracy = 0.984375\n",
      "[2018-07-16 13:01:35.750013] Iteration 31300, train loss = 0.156687, train accuracy = 1.000000\n",
      "[2018-07-16 13:01:39.814927] Iteration 31400, train loss = 0.155437, train accuracy = 1.000000\n",
      "[2018-07-16 13:01:43.907689] Iteration 31500, train loss = 0.174020, train accuracy = 0.976562\n",
      "[2018-07-16 13:01:47.968876] Iteration 31600, train loss = 0.164452, train accuracy = 0.992188\n",
      "[2018-07-16 13:01:52.031417] Iteration 31700, train loss = 0.198534, train accuracy = 0.968750\n",
      "[2018-07-16 13:01:56.096305] Iteration 31800, train loss = 0.163681, train accuracy = 0.992188\n",
      "[2018-07-16 13:02:00.172434] Iteration 31900, train loss = 0.164501, train accuracy = 0.992188\n",
      "[2018-07-16 13:02:04.242957] Iteration 32000, train loss = 0.197978, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-16 13:02:09.560595] Iteration 32100, train loss = 0.152302, train accuracy = 1.000000\n",
      "[2018-07-16 13:02:13.622251] Iteration 32200, train loss = 0.197086, train accuracy = 0.984375\n",
      "[2018-07-16 13:02:17.712188] Iteration 32300, train loss = 0.168141, train accuracy = 0.984375\n",
      "[2018-07-16 13:02:21.781092] Iteration 32400, train loss = 0.187133, train accuracy = 0.984375\n",
      "[2018-07-16 13:02:25.882291] Iteration 32500, train loss = 0.165785, train accuracy = 0.992188\n",
      "[2018-07-16 13:02:29.952043] Iteration 32600, train loss = 0.153754, train accuracy = 1.000000\n",
      "[2018-07-16 13:02:34.019148] Iteration 32700, train loss = 0.164981, train accuracy = 0.992188\n",
      "[2018-07-16 13:02:38.145126] Iteration 32800, train loss = 0.152494, train accuracy = 1.000000\n",
      "[2018-07-16 13:02:42.214742] Iteration 32900, train loss = 0.162036, train accuracy = 1.000000\n",
      "[2018-07-16 13:02:46.262996] Iteration 33000, train loss = 0.166602, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 13:02:51.569111] Iteration 33100, train loss = 0.179731, train accuracy = 0.976562\n",
      "[2018-07-16 13:02:55.631800] Iteration 33200, train loss = 0.160507, train accuracy = 0.992188\n",
      "[2018-07-16 13:02:59.696877] Iteration 33300, train loss = 0.189863, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:03.762197] Iteration 33400, train loss = 0.171092, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:07.842143] Iteration 33500, train loss = 0.162415, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:11.926653] Iteration 33600, train loss = 0.165829, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:16.052570] Iteration 33700, train loss = 0.199341, train accuracy = 0.984375\n",
      "[2018-07-16 13:03:20.151503] Iteration 33800, train loss = 0.146545, train accuracy = 1.000000\n",
      "[2018-07-16 13:03:24.222014] Iteration 33900, train loss = 0.174539, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:28.302282] Iteration 34000, train loss = 0.178507, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 13:03:33.600214] Iteration 34100, train loss = 0.158902, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:37.668580] Iteration 34200, train loss = 0.168069, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:41.721456] Iteration 34300, train loss = 0.167188, train accuracy = 0.992188\n",
      "[2018-07-16 13:03:45.769915] Iteration 34400, train loss = 0.161164, train accuracy = 1.000000\n",
      "[2018-07-16 13:03:49.862436] Iteration 34500, train loss = 0.198509, train accuracy = 0.976562\n",
      "[2018-07-16 13:03:53.995778] Iteration 34600, train loss = 0.206416, train accuracy = 0.976562\n",
      "[2018-07-16 13:03:58.034599] Iteration 34700, train loss = 0.166869, train accuracy = 0.992188\n",
      "[2018-07-16 13:04:02.126477] Iteration 34800, train loss = 0.157250, train accuracy = 1.000000\n",
      "[2018-07-16 13:04:06.205091] Iteration 34900, train loss = 0.168663, train accuracy = 0.992188\n",
      "[2018-07-16 13:04:10.288175] Iteration 35000, train loss = 0.187224, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.912200\n",
      "[2018-07-16 13:04:15.641315] Iteration 35100, train loss = 0.162782, train accuracy = 0.984375\n",
      "[2018-07-16 13:04:19.704371] Iteration 35200, train loss = 0.154601, train accuracy = 1.000000\n",
      "[2018-07-16 13:04:23.749262] Iteration 35300, train loss = 0.211695, train accuracy = 0.976562\n",
      "[2018-07-16 13:04:27.801372] Iteration 35400, train loss = 0.145816, train accuracy = 1.000000\n",
      "[2018-07-16 13:04:31.886807] Iteration 35500, train loss = 0.165792, train accuracy = 1.000000\n",
      "[2018-07-16 13:04:35.949255] Iteration 35600, train loss = 0.159347, train accuracy = 0.992188\n",
      "[2018-07-16 13:04:40.021735] Iteration 35700, train loss = 0.186244, train accuracy = 0.976562\n",
      "[2018-07-16 13:04:44.119367] Iteration 35800, train loss = 0.159475, train accuracy = 1.000000\n",
      "[2018-07-16 13:04:48.192051] Iteration 35900, train loss = 0.155252, train accuracy = 1.000000\n",
      "[2018-07-16 13:04:52.263382] Iteration 36000, train loss = 0.173956, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.912400\n",
      "[2018-07-16 13:04:57.597506] Iteration 36100, train loss = 0.176734, train accuracy = 0.984375\n",
      "[2018-07-16 13:05:01.687585] Iteration 36200, train loss = 0.155407, train accuracy = 1.000000\n",
      "[2018-07-16 13:05:05.781002] Iteration 36300, train loss = 0.153690, train accuracy = 1.000000\n",
      "[2018-07-16 13:05:09.882071] Iteration 36400, train loss = 0.170129, train accuracy = 0.984375\n",
      "[2018-07-16 13:05:13.933769] Iteration 36500, train loss = 0.173351, train accuracy = 0.992188\n",
      "[2018-07-16 13:05:17.972610] Iteration 36600, train loss = 0.167894, train accuracy = 0.992188\n",
      "[2018-07-16 13:05:22.021273] Iteration 36700, train loss = 0.148643, train accuracy = 1.000000\n",
      "[2018-07-16 13:05:26.118544] Iteration 36800, train loss = 0.155300, train accuracy = 1.000000\n",
      "[2018-07-16 13:05:30.191708] Iteration 36900, train loss = 0.155519, train accuracy = 1.000000\n",
      "[2018-07-16 13:05:34.249092] Iteration 37000, train loss = 0.191920, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.912400\n",
      "[2018-07-16 13:05:39.604252] Iteration 37100, train loss = 0.176904, train accuracy = 0.992188\n",
      "[2018-07-16 13:05:43.683221] Iteration 37200, train loss = 0.152849, train accuracy = 1.000000\n",
      "[2018-07-16 13:05:47.820790] Iteration 37300, train loss = 0.164688, train accuracy = 0.992188\n",
      "[2018-07-16 13:05:51.891732] Iteration 37400, train loss = 0.148793, train accuracy = 1.000000\n",
      "[2018-07-16 13:05:55.967076] Iteration 37500, train loss = 0.165200, train accuracy = 1.000000\n",
      "[2018-07-16 13:06:00.022970] Iteration 37600, train loss = 0.203595, train accuracy = 0.968750\n",
      "[2018-07-16 13:06:04.067754] Iteration 37700, train loss = 0.169472, train accuracy = 1.000000\n",
      "[2018-07-16 13:06:08.118592] Iteration 37800, train loss = 0.174673, train accuracy = 0.992188\n",
      "[2018-07-16 13:06:12.198988] Iteration 37900, train loss = 0.160619, train accuracy = 1.000000\n",
      "[2018-07-16 13:06:16.273296] Iteration 38000, train loss = 0.155447, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912300\n",
      "[2018-07-16 13:06:21.615428] Iteration 38100, train loss = 0.166687, train accuracy = 0.992188\n",
      "[2018-07-16 13:06:25.742394] Iteration 38200, train loss = 0.160939, train accuracy = 1.000000\n",
      "[2018-07-16 13:06:29.823081] Iteration 38300, train loss = 0.173419, train accuracy = 0.992188\n",
      "[2018-07-16 13:06:33.894828] Iteration 38400, train loss = 0.169110, train accuracy = 0.992188\n",
      "[2018-07-16 13:06:37.985300] Iteration 38500, train loss = 0.163341, train accuracy = 0.992188\n",
      "[2018-07-16 13:06:42.056283] Iteration 38600, train loss = 0.173853, train accuracy = 0.984375\n",
      "[2018-07-16 13:06:46.098165] Iteration 38700, train loss = 0.153516, train accuracy = 1.000000\n",
      "[2018-07-16 13:06:50.147545] Iteration 38800, train loss = 0.151163, train accuracy = 1.000000\n",
      "[2018-07-16 13:06:54.191020] Iteration 38900, train loss = 0.151746, train accuracy = 1.000000\n",
      "[2018-07-16 13:06:58.248789] Iteration 39000, train loss = 0.157113, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912500\n",
      "[2018-07-16 13:07:03.638190] Iteration 39100, train loss = 0.193118, train accuracy = 0.992188\n",
      "[2018-07-16 13:07:07.731757] Iteration 39200, train loss = 0.149628, train accuracy = 1.000000\n",
      "[2018-07-16 13:07:11.815705] Iteration 39300, train loss = 0.156472, train accuracy = 0.992188\n",
      "[2018-07-16 13:07:15.881413] Iteration 39400, train loss = 0.175335, train accuracy = 0.992188\n",
      "[2018-07-16 13:07:19.977857] Iteration 39500, train loss = 0.157439, train accuracy = 1.000000\n",
      "[2018-07-16 13:07:24.057295] Iteration 39600, train loss = 0.155207, train accuracy = 1.000000\n",
      "[2018-07-16 13:07:28.126228] Iteration 39700, train loss = 0.161186, train accuracy = 0.992188\n",
      "[2018-07-16 13:07:32.199421] Iteration 39800, train loss = 0.172913, train accuracy = 0.984375\n",
      "[2018-07-16 13:07:36.259362] Iteration 39900, train loss = 0.155068, train accuracy = 1.000000\n",
      "[2018-07-16 13:07:40.294388] Iteration 40000, train loss = 0.177867, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913500\n",
      "[2018-07-16 13:07:45.553440] Iteration 40100, train loss = 0.154007, train accuracy = 1.000000\n",
      "[2018-07-16 13:07:49.630393] Iteration 40200, train loss = 0.152177, train accuracy = 1.000000\n",
      "[2018-07-16 13:07:53.722588] Iteration 40300, train loss = 0.160704, train accuracy = 0.992188\n",
      "[2018-07-16 13:07:57.790128] Iteration 40400, train loss = 0.170672, train accuracy = 0.992188\n",
      "[2018-07-16 13:08:01.881074] Iteration 40500, train loss = 0.174218, train accuracy = 0.992188\n",
      "[2018-07-16 13:08:05.955538] Iteration 40600, train loss = 0.163434, train accuracy = 1.000000\n",
      "[2018-07-16 13:08:10.014067] Iteration 40700, train loss = 0.168535, train accuracy = 0.984375\n",
      "[2018-07-16 13:08:14.098998] Iteration 40800, train loss = 0.161735, train accuracy = 1.000000\n",
      "[2018-07-16 13:08:18.225665] Iteration 40900, train loss = 0.152548, train accuracy = 1.000000\n",
      "[2018-07-16 13:08:22.278006] Iteration 41000, train loss = 0.163564, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913300\n",
      "[2018-07-16 13:08:27.583151] Iteration 41100, train loss = 0.156199, train accuracy = 1.000000\n",
      "[2018-07-16 13:08:31.645431] Iteration 41200, train loss = 0.157761, train accuracy = 0.992188\n",
      "[2018-07-16 13:08:35.707515] Iteration 41300, train loss = 0.155008, train accuracy = 1.000000\n",
      "[2018-07-16 13:08:39.780117] Iteration 41400, train loss = 0.171323, train accuracy = 0.992188\n",
      "[2018-07-16 13:08:43.871474] Iteration 41500, train loss = 0.175008, train accuracy = 0.992188\n",
      "[2018-07-16 13:08:47.944638] Iteration 41600, train loss = 0.160673, train accuracy = 1.000000\n",
      "[2018-07-16 13:08:52.027072] Iteration 41700, train loss = 0.148492, train accuracy = 1.000000\n",
      "[2018-07-16 13:08:56.173286] Iteration 41800, train loss = 0.181184, train accuracy = 0.984375\n",
      "[2018-07-16 13:09:00.243256] Iteration 41900, train loss = 0.156901, train accuracy = 1.000000\n",
      "[2018-07-16 13:09:04.320748] Iteration 42000, train loss = 0.172977, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912800\n",
      "[2018-07-16 13:09:09.649139] Iteration 42100, train loss = 0.166648, train accuracy = 1.000000\n",
      "[2018-07-16 13:09:13.702828] Iteration 42200, train loss = 0.186731, train accuracy = 0.984375\n",
      "[2018-07-16 13:09:17.753780] Iteration 42300, train loss = 0.171327, train accuracy = 0.984375\n",
      "[2018-07-16 13:09:21.797324] Iteration 42400, train loss = 0.162768, train accuracy = 0.984375\n",
      "[2018-07-16 13:09:25.891466] Iteration 42500, train loss = 0.153657, train accuracy = 1.000000\n",
      "[2018-07-16 13:09:29.966247] Iteration 42600, train loss = 0.150861, train accuracy = 1.000000\n",
      "[2018-07-16 13:09:34.093477] Iteration 42700, train loss = 0.159061, train accuracy = 1.000000\n",
      "[2018-07-16 13:09:38.187041] Iteration 42800, train loss = 0.173026, train accuracy = 0.992188\n",
      "[2018-07-16 13:09:42.256862] Iteration 42900, train loss = 0.148355, train accuracy = 1.000000\n",
      "[2018-07-16 13:09:46.334073] Iteration 43000, train loss = 0.162596, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912800\n",
      "[2018-07-16 13:09:51.669769] Iteration 43100, train loss = 0.182432, train accuracy = 0.984375\n",
      "[2018-07-16 13:09:55.737487] Iteration 43200, train loss = 0.161031, train accuracy = 0.984375\n",
      "[2018-07-16 13:09:59.789459] Iteration 43300, train loss = 0.193919, train accuracy = 0.976562\n",
      "[2018-07-16 13:10:03.849582] Iteration 43400, train loss = 0.166597, train accuracy = 0.992188\n",
      "[2018-07-16 13:10:07.903738] Iteration 43500, train loss = 0.155108, train accuracy = 1.000000\n",
      "[2018-07-16 13:10:12.012055] Iteration 43600, train loss = 0.153577, train accuracy = 1.000000\n",
      "[2018-07-16 13:10:16.077919] Iteration 43700, train loss = 0.159205, train accuracy = 0.992188\n",
      "[2018-07-16 13:10:20.166515] Iteration 43800, train loss = 0.161994, train accuracy = 1.000000\n",
      "[2018-07-16 13:10:24.253734] Iteration 43900, train loss = 0.161250, train accuracy = 1.000000\n",
      "[2018-07-16 13:10:28.324299] Iteration 44000, train loss = 0.181178, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-07-16 13:10:33.673030] Iteration 44100, train loss = 0.156247, train accuracy = 0.992188\n",
      "[2018-07-16 13:10:37.768138] Iteration 44200, train loss = 0.172288, train accuracy = 1.000000\n",
      "[2018-07-16 13:10:41.822598] Iteration 44300, train loss = 0.205850, train accuracy = 0.984375\n",
      "[2018-07-16 13:10:45.874195] Iteration 44400, train loss = 0.149070, train accuracy = 1.000000\n",
      "[2018-07-16 13:10:49.996574] Iteration 44500, train loss = 0.165473, train accuracy = 0.992188\n",
      "[2018-07-16 13:10:54.045286] Iteration 44600, train loss = 0.193695, train accuracy = 0.984375\n",
      "[2018-07-16 13:10:58.103625] Iteration 44700, train loss = 0.167550, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:02.189586] Iteration 44800, train loss = 0.158731, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:06.256791] Iteration 44900, train loss = 0.185299, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:10.331833] Iteration 45000, train loss = 0.153044, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912700\n",
      "[2018-07-16 13:11:15.680224] Iteration 45100, train loss = 0.184556, train accuracy = 0.984375\n",
      "[2018-07-16 13:11:19.764543] Iteration 45200, train loss = 0.181721, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:23.862160] Iteration 45300, train loss = 0.166856, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:27.953593] Iteration 45400, train loss = 0.159808, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:32.041242] Iteration 45500, train loss = 0.165004, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:36.097517] Iteration 45600, train loss = 0.178108, train accuracy = 0.984375\n",
      "[2018-07-16 13:11:40.146790] Iteration 45700, train loss = 0.161954, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:44.194417] Iteration 45800, train loss = 0.164495, train accuracy = 0.992188\n",
      "[2018-07-16 13:11:48.255298] Iteration 45900, train loss = 0.162160, train accuracy = 1.000000\n",
      "[2018-07-16 13:11:52.330391] Iteration 46000, train loss = 0.181583, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 13:11:57.665174] Iteration 46100, train loss = 0.169192, train accuracy = 0.984375\n",
      "[2018-07-16 13:12:01.786354] Iteration 46200, train loss = 0.152452, train accuracy = 1.000000\n",
      "[2018-07-16 13:12:05.863172] Iteration 46300, train loss = 0.155377, train accuracy = 1.000000\n",
      "[2018-07-16 13:12:09.926434] Iteration 46400, train loss = 0.174768, train accuracy = 0.992188\n",
      "[2018-07-16 13:12:14.012163] Iteration 46500, train loss = 0.153511, train accuracy = 0.992188\n",
      "[2018-07-16 13:12:18.076987] Iteration 46600, train loss = 0.148260, train accuracy = 1.000000\n",
      "[2018-07-16 13:12:22.129023] Iteration 46700, train loss = 0.182850, train accuracy = 0.992188\n",
      "[2018-07-16 13:12:26.185792] Iteration 46800, train loss = 0.165171, train accuracy = 0.992188\n",
      "[2018-07-16 13:12:30.230848] Iteration 46900, train loss = 0.168810, train accuracy = 0.992188\n",
      "[2018-07-16 13:12:34.285191] Iteration 47000, train loss = 0.151850, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 13:12:39.721920] Iteration 47100, train loss = 0.173204, train accuracy = 0.992188\n",
      "[2018-07-16 13:12:43.816599] Iteration 47200, train loss = 0.195530, train accuracy = 0.976562\n",
      "[2018-07-16 13:12:47.916218] Iteration 47300, train loss = 0.154847, train accuracy = 1.000000\n",
      "[2018-07-16 13:12:52.000311] Iteration 47400, train loss = 0.158677, train accuracy = 0.992188\n",
      "[2018-07-16 13:12:56.092434] Iteration 47500, train loss = 0.159667, train accuracy = 0.992188\n",
      "[2018-07-16 13:13:00.169762] Iteration 47600, train loss = 0.150024, train accuracy = 1.000000\n",
      "[2018-07-16 13:13:04.234007] Iteration 47700, train loss = 0.164957, train accuracy = 1.000000\n",
      "[2018-07-16 13:13:08.311295] Iteration 47800, train loss = 0.164224, train accuracy = 0.992188\n",
      "[2018-07-16 13:13:12.356587] Iteration 47900, train loss = 0.160832, train accuracy = 0.992188\n",
      "[2018-07-16 13:13:16.426782] Iteration 48000, train loss = 0.155985, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912400\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-16 13:13:21.860638] Iteration 48100, train loss = 0.150796, train accuracy = 1.000000\n",
      "[2018-07-16 13:13:25.928513] Iteration 48200, train loss = 0.149814, train accuracy = 1.000000\n",
      "[2018-07-16 13:13:30.013128] Iteration 48300, train loss = 0.164903, train accuracy = 0.992188\n",
      "[2018-07-16 13:13:34.104413] Iteration 48400, train loss = 0.159739, train accuracy = 1.000000\n",
      "[2018-07-16 13:13:38.195178] Iteration 48500, train loss = 0.190864, train accuracy = 0.984375\n",
      "[2018-07-16 13:13:42.283890] Iteration 48600, train loss = 0.172533, train accuracy = 0.992188\n",
      "[2018-07-16 13:13:46.365462] Iteration 48700, train loss = 0.163592, train accuracy = 0.984375\n",
      "[2018-07-16 13:13:50.452206] Iteration 48800, train loss = 0.167007, train accuracy = 0.992188\n",
      "[2018-07-16 13:13:54.559449] Iteration 48900, train loss = 0.163389, train accuracy = 0.992188\n",
      "[2018-07-16 13:13:58.636792] Iteration 49000, train loss = 0.168826, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 13:14:03.953681] Iteration 49100, train loss = 0.155777, train accuracy = 0.992188\n",
      "[2018-07-16 13:14:08.012670] Iteration 49200, train loss = 0.215533, train accuracy = 0.968750\n",
      "[2018-07-16 13:14:12.063614] Iteration 49300, train loss = 0.164484, train accuracy = 1.000000\n",
      "[2018-07-16 13:14:16.135200] Iteration 49400, train loss = 0.176911, train accuracy = 0.984375\n",
      "[2018-07-16 13:14:20.225914] Iteration 49500, train loss = 0.172885, train accuracy = 0.984375\n",
      "[2018-07-16 13:14:24.314919] Iteration 49600, train loss = 0.208651, train accuracy = 0.968750\n",
      "[2018-07-16 13:14:28.401122] Iteration 49700, train loss = 0.149640, train accuracy = 1.000000\n",
      "[2018-07-16 13:14:32.537584] Iteration 49800, train loss = 0.200467, train accuracy = 0.984375\n",
      "[2018-07-16 13:14:36.499678] Iteration 49900, train loss = 0.157721, train accuracy = 1.000000\n",
      "[2018-07-16 13:14:40.580307] Iteration 50000, train loss = 0.157227, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 13:14:45.891967] Iteration 50100, train loss = 0.177453, train accuracy = 0.984375\n",
      "[2018-07-16 13:14:49.950606] Iteration 50200, train loss = 0.161767, train accuracy = 0.992188\n",
      "[2018-07-16 13:14:54.008823] Iteration 50300, train loss = 0.171313, train accuracy = 0.992188\n",
      "[2018-07-16 13:14:58.057735] Iteration 50400, train loss = 0.160840, train accuracy = 0.992188\n",
      "[2018-07-16 13:15:02.144708] Iteration 50500, train loss = 0.169748, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:06.230242] Iteration 50600, train loss = 0.155087, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:10.355136] Iteration 50700, train loss = 0.183519, train accuracy = 0.976562\n",
      "[2018-07-16 13:15:14.457464] Iteration 50800, train loss = 0.153717, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:18.523059] Iteration 50900, train loss = 0.153349, train accuracy = 0.992188\n",
      "[2018-07-16 13:15:22.605732] Iteration 51000, train loss = 0.157659, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 13:15:27.920279] Iteration 51100, train loss = 0.173634, train accuracy = 0.992188\n",
      "[2018-07-16 13:15:31.993210] Iteration 51200, train loss = 0.155691, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:36.042183] Iteration 51300, train loss = 0.159784, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:40.094230] Iteration 51400, train loss = 0.157748, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:44.144962] Iteration 51500, train loss = 0.154482, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:48.247944] Iteration 51600, train loss = 0.155056, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:52.322122] Iteration 51700, train loss = 0.158249, train accuracy = 1.000000\n",
      "[2018-07-16 13:15:56.422636] Iteration 51800, train loss = 0.177209, train accuracy = 0.984375\n",
      "[2018-07-16 13:16:00.502473] Iteration 51900, train loss = 0.162452, train accuracy = 1.000000\n",
      "[2018-07-16 13:16:04.578972] Iteration 52000, train loss = 0.169969, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 13:16:09.909141] Iteration 52100, train loss = 0.152932, train accuracy = 1.000000\n",
      "[2018-07-16 13:16:13.999230] Iteration 52200, train loss = 0.171908, train accuracy = 0.992188\n",
      "[2018-07-16 13:16:18.072223] Iteration 52300, train loss = 0.153080, train accuracy = 1.000000\n",
      "[2018-07-16 13:16:22.121213] Iteration 52400, train loss = 0.191915, train accuracy = 0.992188\n",
      "[2018-07-16 13:16:26.230726] Iteration 52500, train loss = 0.152333, train accuracy = 1.000000\n",
      "[2018-07-16 13:16:30.288294] Iteration 52600, train loss = 0.158894, train accuracy = 1.000000\n",
      "[2018-07-16 13:16:34.339414] Iteration 52700, train loss = 0.178513, train accuracy = 0.992188\n",
      "[2018-07-16 13:16:38.442532] Iteration 52800, train loss = 0.167126, train accuracy = 0.992188\n",
      "[2018-07-16 13:16:42.534203] Iteration 52900, train loss = 0.158410, train accuracy = 1.000000\n",
      "[2018-07-16 13:16:46.613385] Iteration 53000, train loss = 0.178171, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 13:16:51.951363] Iteration 53100, train loss = 0.165999, train accuracy = 0.992188\n",
      "[2018-07-16 13:16:56.043851] Iteration 53200, train loss = 0.143771, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:00.119995] Iteration 53300, train loss = 0.177753, train accuracy = 0.984375\n",
      "[2018-07-16 13:17:04.254791] Iteration 53400, train loss = 0.149882, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:08.318679] Iteration 53500, train loss = 0.152780, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:12.370037] Iteration 53600, train loss = 0.156996, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:16.413207] Iteration 53700, train loss = 0.158555, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:20.464910] Iteration 53800, train loss = 0.161668, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:24.527030] Iteration 53900, train loss = 0.158993, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:28.607354] Iteration 54000, train loss = 0.157165, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 13:17:33.942036] Iteration 54100, train loss = 0.153673, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:38.042425] Iteration 54200, train loss = 0.164364, train accuracy = 0.992188\n",
      "[2018-07-16 13:17:42.158080] Iteration 54300, train loss = 0.160997, train accuracy = 0.992188\n",
      "[2018-07-16 13:17:46.250104] Iteration 54400, train loss = 0.182076, train accuracy = 0.984375\n",
      "[2018-07-16 13:17:50.352303] Iteration 54500, train loss = 0.150488, train accuracy = 1.000000\n",
      "[2018-07-16 13:17:54.418747] Iteration 54600, train loss = 0.172883, train accuracy = 0.992188\n",
      "[2018-07-16 13:17:58.473022] Iteration 54700, train loss = 0.147810, train accuracy = 1.000000\n",
      "[2018-07-16 13:18:02.525653] Iteration 54800, train loss = 0.207088, train accuracy = 0.984375\n",
      "[2018-07-16 13:18:06.568369] Iteration 54900, train loss = 0.145930, train accuracy = 1.000000\n",
      "[2018-07-16 13:18:10.619570] Iteration 55000, train loss = 0.174652, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 13:18:15.976240] Iteration 55100, train loss = 0.175958, train accuracy = 0.992188\n",
      "[2018-07-16 13:18:20.095800] Iteration 55200, train loss = 0.163486, train accuracy = 1.000000\n",
      "[2018-07-16 13:18:24.169301] Iteration 55300, train loss = 0.179933, train accuracy = 0.984375\n",
      "[2018-07-16 13:18:28.246051] Iteration 55400, train loss = 0.154462, train accuracy = 1.000000\n",
      "[2018-07-16 13:18:32.332846] Iteration 55500, train loss = 0.166097, train accuracy = 0.992188\n",
      "[2018-07-16 13:18:36.411056] Iteration 55600, train loss = 0.162688, train accuracy = 0.992188\n",
      "[2018-07-16 13:18:40.491259] Iteration 55700, train loss = 0.152393, train accuracy = 1.000000\n",
      "[2018-07-16 13:18:44.554554] Iteration 55800, train loss = 0.165563, train accuracy = 0.984375\n",
      "[2018-07-16 13:18:48.598961] Iteration 55900, train loss = 0.176081, train accuracy = 0.984375\n",
      "[2018-07-16 13:18:52.646783] Iteration 56000, train loss = 0.171446, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 13:18:57.981508] Iteration 56100, train loss = 0.182794, train accuracy = 0.984375\n",
      "[2018-07-16 13:19:02.068220] Iteration 56200, train loss = 0.155915, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:06.132059] Iteration 56300, train loss = 0.148646, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:10.205924] Iteration 56400, train loss = 0.149688, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:14.287556] Iteration 56500, train loss = 0.160685, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:18.361510] Iteration 56600, train loss = 0.161994, train accuracy = 0.992188\n",
      "[2018-07-16 13:19:22.440927] Iteration 56700, train loss = 0.152910, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:26.545953] Iteration 56800, train loss = 0.177632, train accuracy = 0.984375\n",
      "[2018-07-16 13:19:30.614648] Iteration 56900, train loss = 0.155985, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:34.715880] Iteration 57000, train loss = 0.155127, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 13:19:40.023686] Iteration 57100, train loss = 0.145204, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:44.081056] Iteration 57200, train loss = 0.182404, train accuracy = 0.976562\n",
      "[2018-07-16 13:19:48.149949] Iteration 57300, train loss = 0.188742, train accuracy = 0.984375\n",
      "[2018-07-16 13:19:52.222252] Iteration 57400, train loss = 0.152417, train accuracy = 1.000000\n",
      "[2018-07-16 13:19:56.313542] Iteration 57500, train loss = 0.185528, train accuracy = 0.992188\n",
      "[2018-07-16 13:20:00.393448] Iteration 57600, train loss = 0.159143, train accuracy = 1.000000\n",
      "[2018-07-16 13:20:04.476754] Iteration 57700, train loss = 0.180985, train accuracy = 0.992188\n",
      "[2018-07-16 13:20:08.559634] Iteration 57800, train loss = 0.164558, train accuracy = 1.000000\n",
      "[2018-07-16 13:20:12.676204] Iteration 57900, train loss = 0.152774, train accuracy = 0.992188\n",
      "[2018-07-16 13:20:16.760581] Iteration 58000, train loss = 0.178054, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913300\n",
      "[2018-07-16 13:20:22.069920] Iteration 58100, train loss = 0.178627, train accuracy = 0.992188\n",
      "[2018-07-16 13:20:26.127489] Iteration 58200, train loss = 0.173859, train accuracy = 0.984375\n",
      "[2018-07-16 13:20:30.174761] Iteration 58300, train loss = 0.172884, train accuracy = 0.992188\n",
      "[2018-07-16 13:20:34.222335] Iteration 58400, train loss = 0.183759, train accuracy = 0.992188\n",
      "[2018-07-16 13:20:38.300447] Iteration 58500, train loss = 0.154375, train accuracy = 1.000000\n",
      "[2018-07-16 13:20:42.365986] Iteration 58600, train loss = 0.152611, train accuracy = 1.000000\n",
      "[2018-07-16 13:20:46.447188] Iteration 58700, train loss = 0.175925, train accuracy = 0.984375\n",
      "[2018-07-16 13:20:50.574450] Iteration 58800, train loss = 0.155546, train accuracy = 1.000000\n",
      "[2018-07-16 13:20:54.671030] Iteration 58900, train loss = 0.155448, train accuracy = 1.000000\n",
      "[2018-07-16 13:20:58.751459] Iteration 59000, train loss = 0.153264, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913100\n",
      "[2018-07-16 13:21:04.082157] Iteration 59100, train loss = 0.166166, train accuracy = 0.992188\n",
      "[2018-07-16 13:21:08.150261] Iteration 59200, train loss = 0.176461, train accuracy = 0.984375\n",
      "[2018-07-16 13:21:12.196532] Iteration 59300, train loss = 0.152221, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:16.236001] Iteration 59400, train loss = 0.154830, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:20.289279] Iteration 59500, train loss = 0.154212, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:24.354595] Iteration 59600, train loss = 0.195253, train accuracy = 0.976562\n",
      "[2018-07-16 13:21:28.478036] Iteration 59700, train loss = 0.152792, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:32.577051] Iteration 59800, train loss = 0.147170, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:36.664349] Iteration 59900, train loss = 0.151324, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:40.735577] Iteration 60000, train loss = 0.174543, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913300\n",
      "[2018-07-16 13:21:46.073572] Iteration 60100, train loss = 0.152371, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:50.158743] Iteration 60200, train loss = 0.155116, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:54.228557] Iteration 60300, train loss = 0.163504, train accuracy = 1.000000\n",
      "[2018-07-16 13:21:58.277325] Iteration 60400, train loss = 0.205198, train accuracy = 0.968750\n",
      "[2018-07-16 13:22:02.324799] Iteration 60500, train loss = 0.157023, train accuracy = 1.000000\n",
      "[2018-07-16 13:22:06.420828] Iteration 60600, train loss = 0.168886, train accuracy = 0.992188\n",
      "[2018-07-16 13:22:10.472586] Iteration 60700, train loss = 0.157271, train accuracy = 1.000000\n",
      "[2018-07-16 13:22:14.562485] Iteration 60800, train loss = 0.165775, train accuracy = 1.000000\n",
      "[2018-07-16 13:22:18.624610] Iteration 60900, train loss = 0.166533, train accuracy = 0.992188\n",
      "[2018-07-16 13:22:22.706136] Iteration 61000, train loss = 0.154273, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 13:22:28.042127] Iteration 61100, train loss = 0.150847, train accuracy = 0.992188\n",
      "[2018-07-16 13:22:32.119415] Iteration 61200, train loss = 0.159423, train accuracy = 0.992188\n",
      "[2018-07-16 13:22:36.193585] Iteration 61300, train loss = 0.156860, train accuracy = 1.000000\n",
      "[2018-07-16 13:22:40.267722] Iteration 61400, train loss = 0.152735, train accuracy = 1.000000\n",
      "[2018-07-16 13:22:44.368960] Iteration 61500, train loss = 0.164773, train accuracy = 0.992188\n",
      "[2018-07-16 13:22:48.422988] Iteration 61600, train loss = 0.150296, train accuracy = 1.000000\n",
      "[2018-07-16 13:22:52.474226] Iteration 61700, train loss = 0.155934, train accuracy = 1.000000\n",
      "[2018-07-16 13:22:56.524277] Iteration 61800, train loss = 0.151399, train accuracy = 1.000000\n",
      "[2018-07-16 13:23:00.584626] Iteration 61900, train loss = 0.223140, train accuracy = 0.968750\n",
      "[2018-07-16 13:23:04.654315] Iteration 62000, train loss = 0.161525, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913400\n",
      "[2018-07-16 13:23:09.985854] Iteration 62100, train loss = 0.164877, train accuracy = 0.992188\n",
      "[2018-07-16 13:23:14.075437] Iteration 62200, train loss = 0.161531, train accuracy = 0.992188\n",
      "[2018-07-16 13:23:18.150780] Iteration 62300, train loss = 0.150519, train accuracy = 1.000000\n",
      "[2018-07-16 13:23:22.285620] Iteration 62400, train loss = 0.149510, train accuracy = 1.000000\n",
      "[2018-07-16 13:23:26.377515] Iteration 62500, train loss = 0.150409, train accuracy = 1.000000\n",
      "[2018-07-16 13:23:30.433457] Iteration 62600, train loss = 0.172028, train accuracy = 0.976562\n",
      "[2018-07-16 13:23:34.488475] Iteration 62700, train loss = 0.169204, train accuracy = 0.984375\n",
      "[2018-07-16 13:23:38.545847] Iteration 62800, train loss = 0.160498, train accuracy = 0.992188\n",
      "[2018-07-16 13:23:42.603955] Iteration 62900, train loss = 0.154946, train accuracy = 1.000000\n",
      "[2018-07-16 13:23:46.653237] Iteration 63000, train loss = 0.149331, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 13:23:51.988862] Iteration 63100, train loss = 0.164424, train accuracy = 0.992188\n",
      "[2018-07-16 13:23:56.084149] Iteration 63200, train loss = 0.155772, train accuracy = 1.000000\n",
      "[2018-07-16 13:24:00.210679] Iteration 63300, train loss = 0.146199, train accuracy = 1.000000\n",
      "[2018-07-16 13:24:04.275085] Iteration 63400, train loss = 0.162375, train accuracy = 1.000000\n",
      "[2018-07-16 13:24:08.359961] Iteration 63500, train loss = 0.151790, train accuracy = 1.000000\n",
      "[2018-07-16 13:24:12.430092] Iteration 63600, train loss = 0.190498, train accuracy = 0.976562\n",
      "[2018-07-16 13:24:16.519735] Iteration 63700, train loss = 0.159890, train accuracy = 0.992188\n",
      "[2018-07-16 13:24:20.578334] Iteration 63800, train loss = 0.152568, train accuracy = 1.000000\n",
      "[2018-07-16 13:24:24.626367] Iteration 63900, train loss = 0.167160, train accuracy = 0.992188\n",
      "[2018-07-16 13:24:28.677049] Iteration 64000, train loss = 0.163709, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-07-16 13:24:34.036269] Iteration 64100, train loss = 0.163105, train accuracy = 0.992188\n",
      "[2018-07-16 13:24:38.106533] Iteration 64200, train loss = 0.154943, train accuracy = 1.000000\n",
      "[2018-07-16 13:24:42.191785] Iteration 64300, train loss = 0.158242, train accuracy = 0.992188\n",
      "[2018-07-16 13:24:46.254517] Iteration 64400, train loss = 0.164138, train accuracy = 0.992188\n",
      "[2018-07-16 13:24:50.357985] Iteration 64500, train loss = 0.166958, train accuracy = 0.992188\n",
      "[2018-07-16 13:24:54.426970] Iteration 64600, train loss = 0.169170, train accuracy = 0.992188\n",
      "[2018-07-16 13:24:58.521487] Iteration 64700, train loss = 0.153264, train accuracy = 0.992188\n",
      "[2018-07-16 13:25:02.609294] Iteration 64800, train loss = 0.187510, train accuracy = 0.968750\n",
      "[2018-07-16 13:25:06.669808] Iteration 64900, train loss = 0.168113, train accuracy = 1.000000\n",
      "[2018-07-16 13:25:10.736733] Iteration 65000, train loss = 0.158917, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913200\n",
      "[2018-07-16 13:25:16.153200] Iteration 65100, train loss = 0.177056, train accuracy = 0.984375\n",
      "[2018-07-16 13:25:20.201756] Iteration 65200, train loss = 0.161453, train accuracy = 1.000000\n",
      "[2018-07-16 13:25:24.282709] Iteration 65300, train loss = 0.186456, train accuracy = 0.984375\n",
      "[2018-07-16 13:25:28.356044] Iteration 65400, train loss = 0.156283, train accuracy = 0.992188\n",
      "[2018-07-16 13:25:32.446421] Iteration 65500, train loss = 0.150293, train accuracy = 1.000000\n",
      "[2018-07-16 13:25:36.523667] Iteration 65600, train loss = 0.151086, train accuracy = 1.000000\n",
      "[2018-07-16 13:25:40.601721] Iteration 65700, train loss = 0.148280, train accuracy = 1.000000\n",
      "[2018-07-16 13:25:44.691165] Iteration 65800, train loss = 0.162035, train accuracy = 1.000000\n",
      "[2018-07-16 13:25:48.785975] Iteration 65900, train loss = 0.159719, train accuracy = 0.992188\n",
      "[2018-07-16 13:25:52.934587] Iteration 66000, train loss = 0.186190, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 13:25:58.240837] Iteration 66100, train loss = 0.161262, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:02.298525] Iteration 66200, train loss = 0.173924, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:06.350887] Iteration 66300, train loss = 0.170778, train accuracy = 0.992188\n",
      "[2018-07-16 13:26:10.393266] Iteration 66400, train loss = 0.161211, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:14.477620] Iteration 66500, train loss = 0.158347, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:18.553313] Iteration 66600, train loss = 0.155434, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:22.634174] Iteration 66700, train loss = 0.167249, train accuracy = 0.984375\n",
      "[2018-07-16 13:26:26.731407] Iteration 66800, train loss = 0.162067, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:30.889925] Iteration 66900, train loss = 0.159115, train accuracy = 0.992188\n",
      "[2018-07-16 13:26:34.978588] Iteration 67000, train loss = 0.163701, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-07-16 13:26:40.301115] Iteration 67100, train loss = 0.178361, train accuracy = 0.992188\n",
      "[2018-07-16 13:26:44.369310] Iteration 67200, train loss = 0.151149, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:48.412671] Iteration 67300, train loss = 0.144393, train accuracy = 1.000000\n",
      "[2018-07-16 13:26:52.458755] Iteration 67400, train loss = 0.193773, train accuracy = 0.976562\n",
      "[2018-07-16 13:26:56.507277] Iteration 67500, train loss = 0.182649, train accuracy = 0.992188\n",
      "[2018-07-16 13:27:00.570162] Iteration 67600, train loss = 0.170419, train accuracy = 0.992188\n",
      "[2018-07-16 13:27:04.690682] Iteration 67700, train loss = 0.160112, train accuracy = 0.992188\n",
      "[2018-07-16 13:27:08.809306] Iteration 67800, train loss = 0.152430, train accuracy = 1.000000\n",
      "[2018-07-16 13:27:12.882259] Iteration 67900, train loss = 0.157955, train accuracy = 0.992188\n",
      "[2018-07-16 13:27:16.979913] Iteration 68000, train loss = 0.170132, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 13:27:22.302580] Iteration 68100, train loss = 0.169590, train accuracy = 0.984375\n",
      "[2018-07-16 13:27:26.397829] Iteration 68200, train loss = 0.169692, train accuracy = 0.992188\n",
      "[2018-07-16 13:27:30.457844] Iteration 68300, train loss = 0.152564, train accuracy = 1.000000\n",
      "[2018-07-16 13:27:34.506881] Iteration 68400, train loss = 0.168571, train accuracy = 0.984375\n",
      "[2018-07-16 13:27:38.558522] Iteration 68500, train loss = 0.197672, train accuracy = 0.976562\n",
      "[2018-07-16 13:27:42.628645] Iteration 68600, train loss = 0.181694, train accuracy = 0.992188\n",
      "[2018-07-16 13:27:46.702981] Iteration 68700, train loss = 0.152486, train accuracy = 1.000000\n",
      "[2018-07-16 13:27:50.792977] Iteration 68800, train loss = 0.154173, train accuracy = 0.992188\n",
      "[2018-07-16 13:27:54.860706] Iteration 68900, train loss = 0.155861, train accuracy = 1.000000\n",
      "[2018-07-16 13:27:58.958294] Iteration 69000, train loss = 0.156114, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-07-16 13:28:04.301323] Iteration 69100, train loss = 0.195577, train accuracy = 0.976562\n",
      "[2018-07-16 13:28:08.397313] Iteration 69200, train loss = 0.165534, train accuracy = 0.992188\n",
      "[2018-07-16 13:28:12.470236] Iteration 69300, train loss = 0.171536, train accuracy = 0.984375\n",
      "[2018-07-16 13:28:16.542865] Iteration 69400, train loss = 0.160503, train accuracy = 1.000000\n",
      "[2018-07-16 13:28:20.651082] Iteration 69500, train loss = 0.157749, train accuracy = 1.000000\n",
      "[2018-07-16 13:28:24.718944] Iteration 69600, train loss = 0.186387, train accuracy = 0.992188\n",
      "[2018-07-16 13:28:28.781549] Iteration 69700, train loss = 0.148760, train accuracy = 1.000000\n",
      "[2018-07-16 13:28:32.828540] Iteration 69800, train loss = 0.158728, train accuracy = 1.000000\n",
      "[2018-07-16 13:28:36.889659] Iteration 69900, train loss = 0.155603, train accuracy = 1.000000\n",
      "[2018-07-16 13:28:40.974887] Iteration 70000, train loss = 0.185146, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.913500\n",
      "[2018-07-16 13:28:46.311283] Iteration 70100, train loss = 0.165937, train accuracy = 0.992188\n",
      "[2018-07-16 13:28:50.410417] Iteration 70200, train loss = 0.155649, train accuracy = 1.000000\n",
      "[2018-07-16 13:28:54.465897] Iteration 70300, train loss = 0.152984, train accuracy = 1.000000\n",
      "[2018-07-16 13:28:58.580609] Iteration 70400, train loss = 0.150019, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:02.646693] Iteration 70500, train loss = 0.150737, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:06.698655] Iteration 70600, train loss = 0.156607, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:10.739930] Iteration 70700, train loss = 0.158394, train accuracy = 0.992188\n",
      "[2018-07-16 13:29:14.759224] Iteration 70800, train loss = 0.155350, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:18.791354] Iteration 70900, train loss = 0.167590, train accuracy = 0.992188\n",
      "[2018-07-16 13:29:22.829169] Iteration 71000, train loss = 0.151954, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 13:29:28.107408] Iteration 71100, train loss = 0.163944, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:32.190839] Iteration 71200, train loss = 0.163752, train accuracy = 0.992188\n",
      "[2018-07-16 13:29:36.257126] Iteration 71300, train loss = 0.157606, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:40.326007] Iteration 71400, train loss = 0.191699, train accuracy = 0.984375\n",
      "[2018-07-16 13:29:44.422969] Iteration 71500, train loss = 0.157263, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:48.503688] Iteration 71600, train loss = 0.150935, train accuracy = 1.000000\n",
      "[2018-07-16 13:29:52.584140] Iteration 71700, train loss = 0.163886, train accuracy = 0.984375\n",
      "[2018-07-16 13:29:56.654911] Iteration 71800, train loss = 0.186015, train accuracy = 0.976562\n",
      "[2018-07-16 13:30:00.701166] Iteration 71900, train loss = 0.171292, train accuracy = 0.984375\n",
      "[2018-07-16 13:30:04.756346] Iteration 72000, train loss = 0.185487, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 13:30:10.110485] Iteration 72100, train loss = 0.176233, train accuracy = 0.984375\n",
      "[2018-07-16 13:30:14.199488] Iteration 72200, train loss = 0.158304, train accuracy = 1.000000\n",
      "[2018-07-16 13:30:18.281683] Iteration 72300, train loss = 0.149902, train accuracy = 1.000000\n",
      "[2018-07-16 13:30:22.347258] Iteration 72400, train loss = 0.156213, train accuracy = 1.000000\n",
      "[2018-07-16 13:30:26.438925] Iteration 72500, train loss = 0.179575, train accuracy = 0.992188\n",
      "[2018-07-16 13:30:30.511046] Iteration 72600, train loss = 0.165607, train accuracy = 0.992188\n",
      "[2018-07-16 13:30:34.613200] Iteration 72700, train loss = 0.181169, train accuracy = 0.984375\n",
      "[2018-07-16 13:30:38.697273] Iteration 72800, train loss = 0.181390, train accuracy = 0.992188\n",
      "[2018-07-16 13:30:42.762689] Iteration 72900, train loss = 0.177285, train accuracy = 0.984375\n",
      "[2018-07-16 13:30:46.875327] Iteration 73000, train loss = 0.189599, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 13:30:52.207153] Iteration 73100, train loss = 0.178750, train accuracy = 0.976562\n",
      "[2018-07-16 13:30:56.251184] Iteration 73200, train loss = 0.153572, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:00.309742] Iteration 73300, train loss = 0.150574, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:04.386987] Iteration 73400, train loss = 0.149105, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:08.482088] Iteration 73500, train loss = 0.161322, train accuracy = 0.992188\n",
      "[2018-07-16 13:31:12.547651] Iteration 73600, train loss = 0.194625, train accuracy = 0.984375\n",
      "[2018-07-16 13:31:16.629127] Iteration 73700, train loss = 0.163086, train accuracy = 0.992188\n",
      "[2018-07-16 13:31:20.722057] Iteration 73800, train loss = 0.166136, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:24.827917] Iteration 73900, train loss = 0.154427, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:28.930883] Iteration 74000, train loss = 0.158938, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912400\n",
      "[2018-07-16 13:31:34.235563] Iteration 74100, train loss = 0.154679, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:38.289680] Iteration 74200, train loss = 0.155116, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:42.344943] Iteration 74300, train loss = 0.152136, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:46.396235] Iteration 74400, train loss = 0.169341, train accuracy = 0.992188\n",
      "[2018-07-16 13:31:50.493411] Iteration 74500, train loss = 0.146048, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:54.563985] Iteration 74600, train loss = 0.154611, train accuracy = 1.000000\n",
      "[2018-07-16 13:31:58.651168] Iteration 74700, train loss = 0.165130, train accuracy = 0.992188\n",
      "[2018-07-16 13:32:02.779835] Iteration 74800, train loss = 0.154319, train accuracy = 1.000000\n",
      "[2018-07-16 13:32:06.851542] Iteration 74900, train loss = 0.182065, train accuracy = 0.984375\n",
      "[2018-07-16 13:32:10.931910] Iteration 75000, train loss = 0.167884, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913100\n",
      "[2018-07-16 13:32:16.254822] Iteration 75100, train loss = 0.158252, train accuracy = 0.992188\n",
      "[2018-07-16 13:32:20.313350] Iteration 75200, train loss = 0.164578, train accuracy = 0.992188\n",
      "[2018-07-16 13:32:24.368605] Iteration 75300, train loss = 0.166739, train accuracy = 0.984375\n",
      "[2018-07-16 13:32:28.419975] Iteration 75400, train loss = 0.157957, train accuracy = 1.000000\n",
      "[2018-07-16 13:32:32.470594] Iteration 75500, train loss = 0.167444, train accuracy = 1.000000\n",
      "[2018-07-16 13:32:36.527468] Iteration 75600, train loss = 0.172258, train accuracy = 0.984375\n",
      "[2018-07-16 13:32:40.655737] Iteration 75700, train loss = 0.154792, train accuracy = 1.000000\n",
      "[2018-07-16 13:32:44.746099] Iteration 75800, train loss = 0.152145, train accuracy = 1.000000\n",
      "[2018-07-16 13:32:48.828383] Iteration 75900, train loss = 0.159199, train accuracy = 0.992188\n",
      "[2018-07-16 13:32:52.910453] Iteration 76000, train loss = 0.188729, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.912700\n",
      "[2018-07-16 13:32:58.245132] Iteration 76100, train loss = 0.172638, train accuracy = 0.992188\n",
      "[2018-07-16 13:33:02.348877] Iteration 76200, train loss = 0.170360, train accuracy = 0.984375\n",
      "[2018-07-16 13:33:06.416220] Iteration 76300, train loss = 0.207120, train accuracy = 0.976562\n",
      "[2018-07-16 13:33:10.460311] Iteration 76400, train loss = 0.179292, train accuracy = 0.984375\n",
      "[2018-07-16 13:33:14.516131] Iteration 76500, train loss = 0.176252, train accuracy = 0.992188\n",
      "[2018-07-16 13:33:18.617889] Iteration 76600, train loss = 0.166229, train accuracy = 0.992188\n",
      "[2018-07-16 13:33:22.669433] Iteration 76700, train loss = 0.180448, train accuracy = 0.976562\n",
      "[2018-07-16 13:33:26.750411] Iteration 76800, train loss = 0.166589, train accuracy = 0.984375\n",
      "[2018-07-16 13:33:30.829431] Iteration 76900, train loss = 0.161364, train accuracy = 1.000000\n",
      "[2018-07-16 13:33:34.922730] Iteration 77000, train loss = 0.153337, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 13:33:40.223705] Iteration 77100, train loss = 0.161712, train accuracy = 1.000000\n",
      "[2018-07-16 13:33:44.321473] Iteration 77200, train loss = 0.151265, train accuracy = 1.000000\n",
      "[2018-07-16 13:33:48.399508] Iteration 77300, train loss = 0.163379, train accuracy = 0.992188\n",
      "[2018-07-16 13:33:52.505781] Iteration 77400, train loss = 0.172120, train accuracy = 1.000000\n",
      "[2018-07-16 13:33:56.599579] Iteration 77500, train loss = 0.166415, train accuracy = 0.992188\n",
      "[2018-07-16 13:34:00.646520] Iteration 77600, train loss = 0.158635, train accuracy = 1.000000\n",
      "[2018-07-16 13:34:04.704284] Iteration 77700, train loss = 0.171977, train accuracy = 0.992188\n",
      "[2018-07-16 13:34:08.768039] Iteration 77800, train loss = 0.170396, train accuracy = 0.992188\n",
      "[2018-07-16 13:34:12.837832] Iteration 77900, train loss = 0.159519, train accuracy = 0.992188\n",
      "[2018-07-16 13:34:16.925107] Iteration 78000, train loss = 0.197030, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.912800\n",
      "[2018-07-16 13:34:22.277506] Iteration 78100, train loss = 0.168683, train accuracy = 0.984375\n",
      "[2018-07-16 13:34:26.386736] Iteration 78200, train loss = 0.153366, train accuracy = 0.992188\n",
      "[2018-07-16 13:34:30.488164] Iteration 78300, train loss = 0.152591, train accuracy = 1.000000\n",
      "[2018-07-16 13:34:34.599672] Iteration 78400, train loss = 0.157703, train accuracy = 1.000000\n",
      "[2018-07-16 13:34:38.675616] Iteration 78500, train loss = 0.157853, train accuracy = 1.000000\n",
      "[2018-07-16 13:34:42.731416] Iteration 78600, train loss = 0.155463, train accuracy = 1.000000\n",
      "[2018-07-16 13:34:46.789218] Iteration 78700, train loss = 0.157348, train accuracy = 1.000000\n",
      "[2018-07-16 13:34:50.843147] Iteration 78800, train loss = 0.156983, train accuracy = 1.000000\n",
      "[2018-07-16 13:34:54.896704] Iteration 78900, train loss = 0.179988, train accuracy = 0.984375\n",
      "[2018-07-16 13:34:58.957718] Iteration 79000, train loss = 0.181766, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913400\n",
      "[2018-07-16 13:35:04.282229] Iteration 79100, train loss = 0.162492, train accuracy = 0.992188\n",
      "[2018-07-16 13:35:08.398915] Iteration 79200, train loss = 0.150559, train accuracy = 1.000000\n",
      "[2018-07-16 13:35:12.493957] Iteration 79300, train loss = 0.159011, train accuracy = 1.000000\n",
      "[2018-07-16 13:35:16.565224] Iteration 79400, train loss = 0.188225, train accuracy = 0.984375\n",
      "[2018-07-16 13:35:20.655420] Iteration 79500, train loss = 0.145680, train accuracy = 1.000000\n",
      "[2018-07-16 13:35:24.744466] Iteration 79600, train loss = 0.205361, train accuracy = 0.984375\n",
      "[2018-07-16 13:35:28.828327] Iteration 79700, train loss = 0.166577, train accuracy = 1.000000\n",
      "[2018-07-16 13:35:32.883002] Iteration 79800, train loss = 0.154188, train accuracy = 1.000000\n",
      "[2018-07-16 13:35:36.941291] Iteration 79900, train loss = 0.155779, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三轮  量化\n",
    "prune_rate = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.913700\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.03125     0.125       0.0625     -0.03571235\n",
      "  0.01374359 -0.0625      0.04389446 -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.85)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-16 13:36:17.840958] Iteration 100, train loss = 0.203773, train accuracy = 0.984375\n",
      "[2018-07-16 13:36:21.641637] Iteration 200, train loss = 0.204744, train accuracy = 0.976562\n",
      "[2018-07-16 13:36:25.654726] Iteration 300, train loss = 0.162857, train accuracy = 0.992188\n",
      "[2018-07-16 13:36:29.664889] Iteration 400, train loss = 0.188047, train accuracy = 0.984375\n",
      "[2018-07-16 13:36:33.464161] Iteration 500, train loss = 0.170623, train accuracy = 0.984375\n",
      "[2018-07-16 13:36:37.285299] Iteration 600, train loss = 0.156860, train accuracy = 1.000000\n",
      "[2018-07-16 13:36:41.307244] Iteration 700, train loss = 0.171856, train accuracy = 0.992188\n",
      "[2018-07-16 13:36:45.281307] Iteration 800, train loss = 0.173089, train accuracy = 0.992188\n",
      "[2018-07-16 13:36:49.191815] Iteration 900, train loss = 0.154663, train accuracy = 1.000000\n",
      "[2018-07-16 13:36:53.050491] Iteration 1000, train loss = 0.198795, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911800\n",
      "[2018-07-16 13:36:58.276999] Iteration 1100, train loss = 0.180456, train accuracy = 0.976562\n",
      "[2018-07-16 13:37:02.436546] Iteration 1200, train loss = 0.183344, train accuracy = 0.992188\n",
      "[2018-07-16 13:37:06.501699] Iteration 1300, train loss = 0.241904, train accuracy = 0.960938\n",
      "[2018-07-16 13:37:10.553559] Iteration 1400, train loss = 0.174186, train accuracy = 0.984375\n",
      "[2018-07-16 13:37:14.603287] Iteration 1500, train loss = 0.183511, train accuracy = 0.984375\n",
      "[2018-07-16 13:37:18.652080] Iteration 1600, train loss = 0.169155, train accuracy = 0.992188\n",
      "[2018-07-16 13:37:22.703836] Iteration 1700, train loss = 0.182071, train accuracy = 0.976562\n",
      "[2018-07-16 13:37:26.792924] Iteration 1800, train loss = 0.203113, train accuracy = 0.976562\n",
      "[2018-07-16 13:37:30.880264] Iteration 1900, train loss = 0.159205, train accuracy = 1.000000\n",
      "[2018-07-16 13:37:34.982728] Iteration 2000, train loss = 0.161962, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 13:37:40.357133] Iteration 2100, train loss = 0.161044, train accuracy = 0.992188\n",
      "[2018-07-16 13:37:44.456527] Iteration 2200, train loss = 0.200523, train accuracy = 0.984375\n",
      "[2018-07-16 13:37:48.530536] Iteration 2300, train loss = 0.193719, train accuracy = 0.984375\n",
      "[2018-07-16 13:37:52.625219] Iteration 2400, train loss = 0.162180, train accuracy = 1.000000\n",
      "[2018-07-16 13:37:56.689656] Iteration 2500, train loss = 0.166932, train accuracy = 1.000000\n",
      "[2018-07-16 13:38:00.745440] Iteration 2600, train loss = 0.195888, train accuracy = 0.968750\n",
      "[2018-07-16 13:38:04.804710] Iteration 2700, train loss = 0.162011, train accuracy = 0.992188\n",
      "[2018-07-16 13:38:08.861375] Iteration 2800, train loss = 0.169350, train accuracy = 0.992188\n",
      "[2018-07-16 13:38:12.930106] Iteration 2900, train loss = 0.155986, train accuracy = 1.000000\n",
      "[2018-07-16 13:38:17.072195] Iteration 3000, train loss = 0.251318, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-07-16 13:38:22.402352] Iteration 3100, train loss = 0.190094, train accuracy = 0.992188\n",
      "[2018-07-16 13:38:26.508293] Iteration 3200, train loss = 0.193092, train accuracy = 0.984375\n",
      "[2018-07-16 13:38:30.579190] Iteration 3300, train loss = 0.186677, train accuracy = 0.984375\n",
      "[2018-07-16 13:38:34.672516] Iteration 3400, train loss = 0.172350, train accuracy = 0.992188\n",
      "[2018-07-16 13:38:38.764397] Iteration 3500, train loss = 0.181944, train accuracy = 0.976562\n",
      "[2018-07-16 13:38:42.831019] Iteration 3600, train loss = 0.172373, train accuracy = 0.992188\n",
      "[2018-07-16 13:38:46.895482] Iteration 3700, train loss = 0.159338, train accuracy = 1.000000\n",
      "[2018-07-16 13:38:50.934491] Iteration 3800, train loss = 0.190091, train accuracy = 0.984375\n",
      "[2018-07-16 13:38:55.033806] Iteration 3900, train loss = 0.179920, train accuracy = 0.992188\n",
      "[2018-07-16 13:38:59.094132] Iteration 4000, train loss = 0.169617, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913200\n",
      "[2018-07-16 13:39:04.404021] Iteration 4100, train loss = 0.161855, train accuracy = 1.000000\n",
      "[2018-07-16 13:39:08.498357] Iteration 4200, train loss = 0.164378, train accuracy = 1.000000\n",
      "[2018-07-16 13:39:12.553455] Iteration 4300, train loss = 0.207565, train accuracy = 0.968750\n",
      "[2018-07-16 13:39:16.629825] Iteration 4400, train loss = 0.163049, train accuracy = 1.000000\n",
      "[2018-07-16 13:39:20.718581] Iteration 4500, train loss = 0.152294, train accuracy = 1.000000\n",
      "[2018-07-16 13:39:24.787051] Iteration 4600, train loss = 0.168455, train accuracy = 0.992188\n",
      "[2018-07-16 13:39:28.878392] Iteration 4700, train loss = 0.159931, train accuracy = 0.992188\n",
      "[2018-07-16 13:39:32.977218] Iteration 4800, train loss = 0.165042, train accuracy = 0.992188\n",
      "[2018-07-16 13:39:37.031173] Iteration 4900, train loss = 0.149816, train accuracy = 1.000000\n",
      "[2018-07-16 13:39:41.090912] Iteration 5000, train loss = 0.162295, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 13:39:46.401853] Iteration 5100, train loss = 0.167438, train accuracy = 0.992188\n",
      "[2018-07-16 13:39:50.495296] Iteration 5200, train loss = 0.154355, train accuracy = 0.992188\n",
      "[2018-07-16 13:39:54.561401] Iteration 5300, train loss = 0.187841, train accuracy = 0.968750\n",
      "[2018-07-16 13:39:58.640818] Iteration 5400, train loss = 0.184318, train accuracy = 0.984375\n",
      "[2018-07-16 13:40:02.722911] Iteration 5500, train loss = 0.181975, train accuracy = 0.992188\n",
      "[2018-07-16 13:40:06.794086] Iteration 5600, train loss = 0.166155, train accuracy = 0.992188\n",
      "[2018-07-16 13:40:10.896721] Iteration 5700, train loss = 0.193836, train accuracy = 0.976562\n",
      "[2018-07-16 13:40:14.958687] Iteration 5800, train loss = 0.190737, train accuracy = 0.992188\n",
      "[2018-07-16 13:40:19.016813] Iteration 5900, train loss = 0.159651, train accuracy = 1.000000\n",
      "[2018-07-16 13:40:23.062321] Iteration 6000, train loss = 0.177365, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-07-16 13:40:28.357232] Iteration 6100, train loss = 0.157121, train accuracy = 1.000000\n",
      "[2018-07-16 13:40:32.404307] Iteration 6200, train loss = 0.178904, train accuracy = 0.992188\n",
      "[2018-07-16 13:40:36.463640] Iteration 6300, train loss = 0.161342, train accuracy = 0.992188\n",
      "[2018-07-16 13:40:40.546369] Iteration 6400, train loss = 0.155651, train accuracy = 1.000000\n",
      "[2018-07-16 13:40:44.629804] Iteration 6500, train loss = 0.167832, train accuracy = 1.000000\n",
      "[2018-07-16 13:40:48.719046] Iteration 6600, train loss = 0.188365, train accuracy = 0.976562\n",
      "[2018-07-16 13:40:52.784917] Iteration 6700, train loss = 0.160880, train accuracy = 0.992188\n",
      "[2018-07-16 13:40:56.881174] Iteration 6800, train loss = 0.158300, train accuracy = 0.992188\n",
      "[2018-07-16 13:41:00.950533] Iteration 6900, train loss = 0.159270, train accuracy = 0.992188\n",
      "[2018-07-16 13:41:05.042415] Iteration 7000, train loss = 0.148186, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-07-16 13:41:10.339257] Iteration 7100, train loss = 0.178230, train accuracy = 0.992188\n",
      "[2018-07-16 13:41:14.395476] Iteration 7200, train loss = 0.186136, train accuracy = 0.976562\n",
      "[2018-07-16 13:41:18.450708] Iteration 7300, train loss = 0.183641, train accuracy = 0.984375\n",
      "[2018-07-16 13:41:22.505894] Iteration 7400, train loss = 0.154540, train accuracy = 1.000000\n",
      "[2018-07-16 13:41:26.636717] Iteration 7500, train loss = 0.166653, train accuracy = 1.000000\n",
      "[2018-07-16 13:41:30.728266] Iteration 7600, train loss = 0.185008, train accuracy = 0.984375\n",
      "[2018-07-16 13:41:34.810791] Iteration 7700, train loss = 0.205037, train accuracy = 0.984375\n",
      "[2018-07-16 13:41:38.894362] Iteration 7800, train loss = 0.178598, train accuracy = 0.992188\n",
      "[2018-07-16 13:41:42.959396] Iteration 7900, train loss = 0.168937, train accuracy = 0.992188\n",
      "[2018-07-16 13:41:47.048580] Iteration 8000, train loss = 0.164452, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-07-16 13:41:52.407669] Iteration 8100, train loss = 0.163022, train accuracy = 1.000000\n",
      "[2018-07-16 13:41:56.477020] Iteration 8200, train loss = 0.169989, train accuracy = 0.992188\n",
      "[2018-07-16 13:42:00.521961] Iteration 8300, train loss = 0.193796, train accuracy = 0.976562\n",
      "[2018-07-16 13:42:04.623687] Iteration 8400, train loss = 0.165328, train accuracy = 0.992188\n",
      "[2018-07-16 13:42:08.687612] Iteration 8500, train loss = 0.198176, train accuracy = 0.984375\n",
      "[2018-07-16 13:42:12.752892] Iteration 8600, train loss = 0.166508, train accuracy = 0.992188\n",
      "[2018-07-16 13:42:16.840545] Iteration 8700, train loss = 0.183491, train accuracy = 0.976562\n",
      "[2018-07-16 13:42:20.925697] Iteration 8800, train loss = 0.166540, train accuracy = 1.000000\n",
      "[2018-07-16 13:42:24.997227] Iteration 8900, train loss = 0.189758, train accuracy = 0.976562\n",
      "[2018-07-16 13:42:29.079602] Iteration 9000, train loss = 0.165078, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-07-16 13:42:34.406259] Iteration 9100, train loss = 0.158530, train accuracy = 0.992188\n",
      "[2018-07-16 13:42:38.501984] Iteration 9200, train loss = 0.165736, train accuracy = 0.992188\n",
      "[2018-07-16 13:42:42.630750] Iteration 9300, train loss = 0.149716, train accuracy = 1.000000\n",
      "[2018-07-16 13:42:46.684376] Iteration 9400, train loss = 0.160098, train accuracy = 0.992188\n",
      "[2018-07-16 13:42:50.735829] Iteration 9500, train loss = 0.162664, train accuracy = 0.992188\n",
      "[2018-07-16 13:42:54.797129] Iteration 9600, train loss = 0.190145, train accuracy = 0.976562\n",
      "[2018-07-16 13:42:58.860884] Iteration 9700, train loss = 0.165322, train accuracy = 1.000000\n",
      "[2018-07-16 13:43:02.946498] Iteration 9800, train loss = 0.179561, train accuracy = 0.976562\n",
      "[2018-07-16 13:43:07.019345] Iteration 9900, train loss = 0.198202, train accuracy = 0.984375\n",
      "[2018-07-16 13:43:11.101699] Iteration 10000, train loss = 0.217049, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 13:43:16.450315] Iteration 10100, train loss = 0.168907, train accuracy = 0.992188\n",
      "[2018-07-16 13:43:20.600229] Iteration 10200, train loss = 0.192468, train accuracy = 0.976562\n",
      "[2018-07-16 13:43:24.668675] Iteration 10300, train loss = 0.155700, train accuracy = 1.000000\n",
      "[2018-07-16 13:43:28.740287] Iteration 10400, train loss = 0.154346, train accuracy = 0.992188\n",
      "[2018-07-16 13:43:32.798261] Iteration 10500, train loss = 0.183912, train accuracy = 0.992188\n",
      "[2018-07-16 13:43:36.849339] Iteration 10600, train loss = 0.175938, train accuracy = 0.992188\n",
      "[2018-07-16 13:43:40.898920] Iteration 10700, train loss = 0.163937, train accuracy = 0.992188\n",
      "[2018-07-16 13:43:44.955436] Iteration 10800, train loss = 0.158459, train accuracy = 0.992188\n",
      "[2018-07-16 13:43:49.022545] Iteration 10900, train loss = 0.161426, train accuracy = 0.992188\n",
      "[2018-07-16 13:43:53.116795] Iteration 11000, train loss = 0.155641, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-07-16 13:43:58.538286] Iteration 11100, train loss = 0.158083, train accuracy = 0.992188\n",
      "[2018-07-16 13:44:02.627248] Iteration 11200, train loss = 0.165221, train accuracy = 0.992188\n",
      "[2018-07-16 13:44:06.694981] Iteration 11300, train loss = 0.158900, train accuracy = 1.000000\n",
      "[2018-07-16 13:44:10.772802] Iteration 11400, train loss = 0.151483, train accuracy = 1.000000\n",
      "[2018-07-16 13:44:14.852951] Iteration 11500, train loss = 0.160037, train accuracy = 0.992188\n",
      "[2018-07-16 13:44:18.919451] Iteration 11600, train loss = 0.156524, train accuracy = 1.000000\n",
      "[2018-07-16 13:44:22.968611] Iteration 11700, train loss = 0.150406, train accuracy = 1.000000\n",
      "[2018-07-16 13:44:27.018454] Iteration 11800, train loss = 0.174977, train accuracy = 0.984375\n",
      "[2018-07-16 13:44:31.061770] Iteration 11900, train loss = 0.175787, train accuracy = 0.984375\n",
      "[2018-07-16 13:44:35.158586] Iteration 12000, train loss = 0.167620, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 13:44:40.506571] Iteration 12100, train loss = 0.172032, train accuracy = 0.992188\n",
      "[2018-07-16 13:44:44.593675] Iteration 12200, train loss = 0.152384, train accuracy = 1.000000\n",
      "[2018-07-16 13:44:48.658221] Iteration 12300, train loss = 0.150330, train accuracy = 1.000000\n",
      "[2018-07-16 13:44:52.746933] Iteration 12400, train loss = 0.186278, train accuracy = 0.984375\n",
      "[2018-07-16 13:44:56.843620] Iteration 12500, train loss = 0.158009, train accuracy = 0.992188\n",
      "[2018-07-16 13:45:00.915398] Iteration 12600, train loss = 0.159498, train accuracy = 1.000000\n",
      "[2018-07-16 13:45:05.002811] Iteration 12700, train loss = 0.170885, train accuracy = 0.992188\n",
      "[2018-07-16 13:45:09.049664] Iteration 12800, train loss = 0.169758, train accuracy = 0.992188\n",
      "[2018-07-16 13:45:13.150055] Iteration 12900, train loss = 0.168257, train accuracy = 0.992188\n",
      "[2018-07-16 13:45:17.205232] Iteration 13000, train loss = 0.176848, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915500\n",
      "[2018-07-16 13:45:22.512868] Iteration 13100, train loss = 0.197288, train accuracy = 0.984375\n",
      "[2018-07-16 13:45:26.602570] Iteration 13200, train loss = 0.192527, train accuracy = 0.976562\n",
      "[2018-07-16 13:45:30.682606] Iteration 13300, train loss = 0.182250, train accuracy = 0.992188\n",
      "[2018-07-16 13:45:34.754313] Iteration 13400, train loss = 0.160716, train accuracy = 1.000000\n",
      "[2018-07-16 13:45:38.829200] Iteration 13500, train loss = 0.174727, train accuracy = 0.984375\n",
      "[2018-07-16 13:45:42.897631] Iteration 13600, train loss = 0.165085, train accuracy = 0.992188\n",
      "[2018-07-16 13:45:46.994153] Iteration 13700, train loss = 0.166596, train accuracy = 1.000000\n",
      "[2018-07-16 13:45:51.119437] Iteration 13800, train loss = 0.157309, train accuracy = 1.000000\n",
      "[2018-07-16 13:45:55.188033] Iteration 13900, train loss = 0.189095, train accuracy = 0.992188\n",
      "[2018-07-16 13:45:59.246766] Iteration 14000, train loss = 0.162590, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.917300\n",
      "[2018-07-16 13:46:04.544626] Iteration 14100, train loss = 0.151757, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:08.593591] Iteration 14200, train loss = 0.157985, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:12.656884] Iteration 14300, train loss = 0.163843, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:16.743940] Iteration 14400, train loss = 0.155558, train accuracy = 0.992188\n",
      "[2018-07-16 13:46:20.842881] Iteration 14500, train loss = 0.175388, train accuracy = 0.984375\n",
      "[2018-07-16 13:46:24.914064] Iteration 14600, train loss = 0.161960, train accuracy = 0.992188\n",
      "[2018-07-16 13:46:28.936257] Iteration 14700, train loss = 0.153991, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:32.876783] Iteration 14800, train loss = 0.149255, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:36.789064] Iteration 14900, train loss = 0.155779, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:40.707662] Iteration 15000, train loss = 0.162010, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-07-16 13:46:45.986308] Iteration 15100, train loss = 0.154293, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:50.046890] Iteration 15200, train loss = 0.154529, train accuracy = 1.000000\n",
      "[2018-07-16 13:46:54.085382] Iteration 15300, train loss = 0.191088, train accuracy = 0.984375\n",
      "[2018-07-16 13:46:58.129315] Iteration 15400, train loss = 0.163763, train accuracy = 1.000000\n",
      "[2018-07-16 13:47:02.205576] Iteration 15500, train loss = 0.167447, train accuracy = 0.992188\n",
      "[2018-07-16 13:47:06.351178] Iteration 15600, train loss = 0.184947, train accuracy = 0.984375\n",
      "[2018-07-16 13:47:10.430605] Iteration 15700, train loss = 0.170022, train accuracy = 0.984375\n",
      "[2018-07-16 13:47:14.520138] Iteration 15800, train loss = 0.169335, train accuracy = 0.984375\n",
      "[2018-07-16 13:47:18.583258] Iteration 15900, train loss = 0.161048, train accuracy = 0.992188\n",
      "[2018-07-16 13:47:22.674774] Iteration 16000, train loss = 0.164396, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 13:47:28.011349] Iteration 16100, train loss = 0.190421, train accuracy = 0.976562\n",
      "[2018-07-16 13:47:32.076671] Iteration 16200, train loss = 0.190715, train accuracy = 0.992188\n",
      "[2018-07-16 13:47:36.131641] Iteration 16300, train loss = 0.178491, train accuracy = 0.976562\n",
      "[2018-07-16 13:47:40.182809] Iteration 16400, train loss = 0.157215, train accuracy = 1.000000\n",
      "[2018-07-16 13:47:44.309174] Iteration 16500, train loss = 0.166407, train accuracy = 0.992188\n",
      "[2018-07-16 13:47:48.372768] Iteration 16600, train loss = 0.185538, train accuracy = 0.984375\n",
      "[2018-07-16 13:47:52.439254] Iteration 16700, train loss = 0.153847, train accuracy = 1.000000\n",
      "[2018-07-16 13:47:56.547103] Iteration 16800, train loss = 0.156986, train accuracy = 1.000000\n",
      "[2018-07-16 13:48:00.619373] Iteration 16900, train loss = 0.171017, train accuracy = 0.984375\n",
      "[2018-07-16 13:48:04.688631] Iteration 17000, train loss = 0.156602, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-07-16 13:48:10.028213] Iteration 17100, train loss = 0.193886, train accuracy = 0.984375\n",
      "[2018-07-16 13:48:14.128454] Iteration 17200, train loss = 0.149146, train accuracy = 1.000000\n",
      "[2018-07-16 13:48:18.197987] Iteration 17300, train loss = 0.157177, train accuracy = 1.000000\n",
      "[2018-07-16 13:48:22.286240] Iteration 17400, train loss = 0.145901, train accuracy = 1.000000\n",
      "[2018-07-16 13:48:26.347663] Iteration 17500, train loss = 0.159703, train accuracy = 0.992188\n",
      "[2018-07-16 13:48:30.408214] Iteration 17600, train loss = 0.172104, train accuracy = 0.992188\n",
      "[2018-07-16 13:48:34.466153] Iteration 17700, train loss = 0.164486, train accuracy = 0.992188\n",
      "[2018-07-16 13:48:38.566669] Iteration 17800, train loss = 0.156895, train accuracy = 1.000000\n",
      "[2018-07-16 13:48:42.636117] Iteration 17900, train loss = 0.150008, train accuracy = 1.000000\n",
      "[2018-07-16 13:48:46.706969] Iteration 18000, train loss = 0.155036, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913500\n",
      "[2018-07-16 13:48:52.044231] Iteration 18100, train loss = 0.186126, train accuracy = 0.984375\n",
      "[2018-07-16 13:48:56.121758] Iteration 18200, train loss = 0.166560, train accuracy = 0.992188\n",
      "[2018-07-16 13:49:00.256938] Iteration 18300, train loss = 0.147564, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:04.310915] Iteration 18400, train loss = 0.153573, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:08.379587] Iteration 18500, train loss = 0.167560, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:12.435759] Iteration 18600, train loss = 0.173090, train accuracy = 0.984375\n",
      "[2018-07-16 13:49:16.484788] Iteration 18700, train loss = 0.170945, train accuracy = 0.992188\n",
      "[2018-07-16 13:49:20.546393] Iteration 18800, train loss = 0.160172, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:24.610770] Iteration 18900, train loss = 0.166003, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:28.701251] Iteration 19000, train loss = 0.164339, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-07-16 13:49:34.034860] Iteration 19100, train loss = 0.153496, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:38.161731] Iteration 19200, train loss = 0.148829, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:42.231369] Iteration 19300, train loss = 0.151064, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:46.309110] Iteration 19400, train loss = 0.162032, train accuracy = 1.000000\n",
      "[2018-07-16 13:49:50.412611] Iteration 19500, train loss = 0.183910, train accuracy = 0.984375\n",
      "[2018-07-16 13:49:54.478212] Iteration 19600, train loss = 0.158868, train accuracy = 0.992188\n",
      "[2018-07-16 13:49:58.527271] Iteration 19700, train loss = 0.170725, train accuracy = 0.992188\n",
      "[2018-07-16 13:50:02.566568] Iteration 19800, train loss = 0.177311, train accuracy = 0.984375\n",
      "[2018-07-16 13:50:06.608063] Iteration 19900, train loss = 0.152215, train accuracy = 1.000000\n",
      "[2018-07-16 13:50:10.660242] Iteration 20000, train loss = 0.157941, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 13:50:16.118701] Iteration 20100, train loss = 0.153114, train accuracy = 1.000000\n",
      "[2018-07-16 13:50:20.215840] Iteration 20200, train loss = 0.161809, train accuracy = 0.992188\n",
      "[2018-07-16 13:50:24.289931] Iteration 20300, train loss = 0.158537, train accuracy = 1.000000\n",
      "[2018-07-16 13:50:28.369965] Iteration 20400, train loss = 0.164958, train accuracy = 1.000000\n",
      "[2018-07-16 13:50:32.462422] Iteration 20500, train loss = 0.172705, train accuracy = 0.992188\n",
      "[2018-07-16 13:50:36.526798] Iteration 20600, train loss = 0.175864, train accuracy = 0.992188\n",
      "[2018-07-16 13:50:40.608084] Iteration 20700, train loss = 0.183099, train accuracy = 0.976562\n",
      "[2018-07-16 13:50:44.656127] Iteration 20800, train loss = 0.173180, train accuracy = 0.984375\n",
      "[2018-07-16 13:50:48.708799] Iteration 20900, train loss = 0.152652, train accuracy = 1.000000\n",
      "[2018-07-16 13:50:52.809567] Iteration 21000, train loss = 0.191594, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-07-16 13:50:58.117156] Iteration 21100, train loss = 0.172759, train accuracy = 0.984375\n",
      "[2018-07-16 13:51:02.194361] Iteration 21200, train loss = 0.156965, train accuracy = 0.992188\n",
      "[2018-07-16 13:51:06.267906] Iteration 21300, train loss = 0.153406, train accuracy = 1.000000\n",
      "[2018-07-16 13:51:10.353993] Iteration 21400, train loss = 0.161634, train accuracy = 0.992188\n",
      "[2018-07-16 13:51:14.458980] Iteration 21500, train loss = 0.191075, train accuracy = 0.976562\n",
      "[2018-07-16 13:51:18.535689] Iteration 21600, train loss = 0.173907, train accuracy = 0.992188\n",
      "[2018-07-16 13:51:22.599589] Iteration 21700, train loss = 0.162647, train accuracy = 1.000000\n",
      "[2018-07-16 13:51:26.701053] Iteration 21800, train loss = 0.175433, train accuracy = 0.992188\n",
      "[2018-07-16 13:51:30.821468] Iteration 21900, train loss = 0.152823, train accuracy = 1.000000\n",
      "[2018-07-16 13:51:34.875188] Iteration 22000, train loss = 0.169333, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 13:51:40.196671] Iteration 22100, train loss = 0.188699, train accuracy = 0.976562\n",
      "[2018-07-16 13:51:44.259565] Iteration 22200, train loss = 0.158282, train accuracy = 0.992188\n",
      "[2018-07-16 13:51:48.321863] Iteration 22300, train loss = 0.207305, train accuracy = 0.968750\n",
      "[2018-07-16 13:51:52.398775] Iteration 22400, train loss = 0.167482, train accuracy = 0.992188\n",
      "[2018-07-16 13:51:56.488993] Iteration 22500, train loss = 0.159828, train accuracy = 1.000000\n",
      "[2018-07-16 13:52:00.564617] Iteration 22600, train loss = 0.177210, train accuracy = 0.984375\n",
      "[2018-07-16 13:52:04.656480] Iteration 22700, train loss = 0.201754, train accuracy = 0.984375\n",
      "[2018-07-16 13:52:08.771046] Iteration 22800, train loss = 0.162543, train accuracy = 1.000000\n",
      "[2018-07-16 13:52:12.842264] Iteration 22900, train loss = 0.155025, train accuracy = 1.000000\n",
      "[2018-07-16 13:52:16.941988] Iteration 23000, train loss = 0.155649, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-07-16 13:52:22.219701] Iteration 23100, train loss = 0.177361, train accuracy = 0.992188\n",
      "[2018-07-16 13:52:26.273175] Iteration 23200, train loss = 0.148097, train accuracy = 1.000000\n",
      "[2018-07-16 13:52:30.331748] Iteration 23300, train loss = 0.159598, train accuracy = 1.000000\n",
      "[2018-07-16 13:52:34.378035] Iteration 23400, train loss = 0.166237, train accuracy = 0.992188\n",
      "[2018-07-16 13:52:38.470464] Iteration 23500, train loss = 0.166989, train accuracy = 1.000000\n",
      "[2018-07-16 13:52:42.570345] Iteration 23600, train loss = 0.153626, train accuracy = 1.000000\n",
      "[2018-07-16 13:52:46.683294] Iteration 23700, train loss = 0.165531, train accuracy = 0.992188\n",
      "[2018-07-16 13:52:50.773832] Iteration 23800, train loss = 0.178605, train accuracy = 0.984375\n",
      "[2018-07-16 13:52:54.863932] Iteration 23900, train loss = 0.181896, train accuracy = 0.976562\n",
      "[2018-07-16 13:52:58.947606] Iteration 24000, train loss = 0.170340, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-07-16 13:53:04.265004] Iteration 24100, train loss = 0.165992, train accuracy = 0.992188\n",
      "[2018-07-16 13:53:08.333781] Iteration 24200, train loss = 0.165918, train accuracy = 1.000000\n",
      "[2018-07-16 13:53:12.382042] Iteration 24300, train loss = 0.169902, train accuracy = 0.992188\n",
      "[2018-07-16 13:53:16.435794] Iteration 24400, train loss = 0.167152, train accuracy = 0.992188\n",
      "[2018-07-16 13:53:20.522135] Iteration 24500, train loss = 0.182968, train accuracy = 0.984375\n",
      "[2018-07-16 13:53:24.590803] Iteration 24600, train loss = 0.155429, train accuracy = 1.000000\n",
      "[2018-07-16 13:53:28.683409] Iteration 24700, train loss = 0.194878, train accuracy = 0.992188\n",
      "[2018-07-16 13:53:32.771118] Iteration 24800, train loss = 0.172669, train accuracy = 0.984375\n",
      "[2018-07-16 13:53:36.848214] Iteration 24900, train loss = 0.176915, train accuracy = 0.992188\n",
      "[2018-07-16 13:53:40.937574] Iteration 25000, train loss = 0.170789, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913500\n",
      "[2018-07-16 13:53:46.268865] Iteration 25100, train loss = 0.200547, train accuracy = 0.984375\n",
      "[2018-07-16 13:53:50.368472] Iteration 25200, train loss = 0.166315, train accuracy = 0.984375\n",
      "[2018-07-16 13:53:54.440052] Iteration 25300, train loss = 0.177754, train accuracy = 0.992188\n",
      "[2018-07-16 13:53:58.551314] Iteration 25400, train loss = 0.156178, train accuracy = 0.992188\n",
      "[2018-07-16 13:54:02.611961] Iteration 25500, train loss = 0.180217, train accuracy = 0.992188\n",
      "[2018-07-16 13:54:06.664311] Iteration 25600, train loss = 0.163558, train accuracy = 1.000000\n",
      "[2018-07-16 13:54:10.716063] Iteration 25700, train loss = 0.186637, train accuracy = 0.984375\n",
      "[2018-07-16 13:54:14.803007] Iteration 25800, train loss = 0.191168, train accuracy = 0.984375\n",
      "[2018-07-16 13:54:18.873684] Iteration 25900, train loss = 0.170089, train accuracy = 0.984375\n",
      "[2018-07-16 13:54:22.942322] Iteration 26000, train loss = 0.153760, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 13:54:28.290784] Iteration 26100, train loss = 0.154135, train accuracy = 1.000000\n",
      "[2018-07-16 13:54:32.382182] Iteration 26200, train loss = 0.175497, train accuracy = 0.984375\n",
      "[2018-07-16 13:54:36.526404] Iteration 26300, train loss = 0.154172, train accuracy = 0.992188\n",
      "[2018-07-16 13:54:40.617428] Iteration 26400, train loss = 0.166130, train accuracy = 0.992188\n",
      "[2018-07-16 13:54:44.677712] Iteration 26500, train loss = 0.153670, train accuracy = 1.000000\n",
      "[2018-07-16 13:54:48.735476] Iteration 26600, train loss = 0.154743, train accuracy = 1.000000\n",
      "[2018-07-16 13:54:52.797417] Iteration 26700, train loss = 0.160918, train accuracy = 1.000000\n",
      "[2018-07-16 13:54:56.845137] Iteration 26800, train loss = 0.162600, train accuracy = 0.992188\n",
      "[2018-07-16 13:55:00.914531] Iteration 26900, train loss = 0.179683, train accuracy = 0.984375\n",
      "[2018-07-16 13:55:05.001937] Iteration 27000, train loss = 0.182670, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 13:55:10.334214] Iteration 27100, train loss = 0.158333, train accuracy = 1.000000\n",
      "[2018-07-16 13:55:14.508827] Iteration 27200, train loss = 0.154700, train accuracy = 1.000000\n",
      "[2018-07-16 13:55:18.590203] Iteration 27300, train loss = 0.151388, train accuracy = 1.000000\n",
      "[2018-07-16 13:55:22.675080] Iteration 27400, train loss = 0.153647, train accuracy = 0.992188\n",
      "[2018-07-16 13:55:26.756317] Iteration 27500, train loss = 0.149167, train accuracy = 1.000000\n",
      "[2018-07-16 13:55:30.812318] Iteration 27600, train loss = 0.188474, train accuracy = 0.976562\n",
      "[2018-07-16 13:55:34.870958] Iteration 27700, train loss = 0.160344, train accuracy = 1.000000\n",
      "[2018-07-16 13:55:38.920594] Iteration 27800, train loss = 0.166777, train accuracy = 1.000000\n",
      "[2018-07-16 13:55:42.977317] Iteration 27900, train loss = 0.154096, train accuracy = 1.000000\n",
      "[2018-07-16 13:55:47.032843] Iteration 28000, train loss = 0.153305, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 13:55:52.444694] Iteration 28100, train loss = 0.161008, train accuracy = 0.992188\n",
      "[2018-07-16 13:55:56.529004] Iteration 28200, train loss = 0.165367, train accuracy = 0.984375\n",
      "[2018-07-16 13:56:00.592062] Iteration 28300, train loss = 0.184340, train accuracy = 0.976562\n",
      "[2018-07-16 13:56:04.671702] Iteration 28400, train loss = 0.153508, train accuracy = 1.000000\n",
      "[2018-07-16 13:56:08.757485] Iteration 28500, train loss = 0.146257, train accuracy = 1.000000\n",
      "[2018-07-16 13:56:12.829554] Iteration 28600, train loss = 0.163924, train accuracy = 0.992188\n",
      "[2018-07-16 13:56:16.931817] Iteration 28700, train loss = 0.183062, train accuracy = 0.984375\n",
      "[2018-07-16 13:56:20.978115] Iteration 28800, train loss = 0.152674, train accuracy = 1.000000\n",
      "[2018-07-16 13:56:25.027468] Iteration 28900, train loss = 0.174067, train accuracy = 0.992188\n",
      "[2018-07-16 13:56:29.125456] Iteration 29000, train loss = 0.181697, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913100\n",
      "[2018-07-16 13:56:34.456231] Iteration 29100, train loss = 0.161113, train accuracy = 1.000000\n",
      "[2018-07-16 13:56:38.554476] Iteration 29200, train loss = 0.165086, train accuracy = 1.000000\n",
      "[2018-07-16 13:56:42.627494] Iteration 29300, train loss = 0.187438, train accuracy = 0.976562\n",
      "[2018-07-16 13:56:46.718693] Iteration 29400, train loss = 0.167154, train accuracy = 1.000000\n",
      "[2018-07-16 13:56:50.827676] Iteration 29500, train loss = 0.157578, train accuracy = 1.000000\n",
      "[2018-07-16 13:56:54.899068] Iteration 29600, train loss = 0.165474, train accuracy = 0.984375\n",
      "[2018-07-16 13:56:58.989508] Iteration 29700, train loss = 0.147247, train accuracy = 1.000000\n",
      "[2018-07-16 13:57:03.067048] Iteration 29800, train loss = 0.183901, train accuracy = 0.992188\n",
      "[2018-07-16 13:57:07.180130] Iteration 29900, train loss = 0.153539, train accuracy = 1.000000\n",
      "[2018-07-16 13:57:11.238351] Iteration 30000, train loss = 0.165660, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912500\n",
      "[2018-07-16 13:57:16.539842] Iteration 30100, train loss = 0.163394, train accuracy = 0.992188\n",
      "[2018-07-16 13:57:20.604319] Iteration 30200, train loss = 0.155039, train accuracy = 1.000000\n",
      "[2018-07-16 13:57:24.658285] Iteration 30300, train loss = 0.208572, train accuracy = 0.976562\n",
      "[2018-07-16 13:57:28.736291] Iteration 30400, train loss = 0.173187, train accuracy = 0.984375\n",
      "[2018-07-16 13:57:32.822401] Iteration 30500, train loss = 0.165455, train accuracy = 1.000000\n",
      "[2018-07-16 13:57:36.903940] Iteration 30600, train loss = 0.168384, train accuracy = 0.992188\n",
      "[2018-07-16 13:57:41.009625] Iteration 30700, train loss = 0.161566, train accuracy = 1.000000\n",
      "[2018-07-16 13:57:45.119326] Iteration 30800, train loss = 0.163345, train accuracy = 0.984375\n",
      "[2018-07-16 13:57:49.168640] Iteration 30900, train loss = 0.155469, train accuracy = 1.000000\n",
      "[2018-07-16 13:57:53.257111] Iteration 31000, train loss = 0.184447, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-07-16 13:57:58.581593] Iteration 31100, train loss = 0.157136, train accuracy = 1.000000\n",
      "[2018-07-16 13:58:02.649259] Iteration 31200, train loss = 0.163196, train accuracy = 1.000000\n",
      "[2018-07-16 13:58:06.714671] Iteration 31300, train loss = 0.159576, train accuracy = 0.992188\n",
      "[2018-07-16 13:58:10.763103] Iteration 31400, train loss = 0.161073, train accuracy = 1.000000\n",
      "[2018-07-16 13:58:14.847515] Iteration 31500, train loss = 0.166425, train accuracy = 0.992188\n",
      "[2018-07-16 13:58:18.913442] Iteration 31600, train loss = 0.179860, train accuracy = 0.984375\n",
      "[2018-07-16 13:58:23.096675] Iteration 31700, train loss = 0.155190, train accuracy = 1.000000\n",
      "[2018-07-16 13:58:27.173039] Iteration 31800, train loss = 0.182199, train accuracy = 0.984375\n",
      "[2018-07-16 13:58:31.250621] Iteration 31900, train loss = 0.156421, train accuracy = 1.000000\n",
      "[2018-07-16 13:58:35.334995] Iteration 32000, train loss = 0.172255, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913100\n",
      "[2018-07-16 13:58:40.683316] Iteration 32100, train loss = 0.177670, train accuracy = 0.984375\n",
      "[2018-07-16 13:58:44.736119] Iteration 32200, train loss = 0.175918, train accuracy = 0.984375\n",
      "[2018-07-16 13:58:48.792652] Iteration 32300, train loss = 0.191138, train accuracy = 0.976562\n",
      "[2018-07-16 13:58:52.841532] Iteration 32400, train loss = 0.164677, train accuracy = 1.000000\n",
      "[2018-07-16 13:58:56.897554] Iteration 32500, train loss = 0.163647, train accuracy = 0.992188\n",
      "[2018-07-16 13:59:01.012916] Iteration 32600, train loss = 0.157168, train accuracy = 1.000000\n",
      "[2018-07-16 13:59:05.099887] Iteration 32700, train loss = 0.167212, train accuracy = 0.992188\n",
      "[2018-07-16 13:59:09.181614] Iteration 32800, train loss = 0.172153, train accuracy = 0.984375\n",
      "[2018-07-16 13:59:13.262079] Iteration 32900, train loss = 0.169161, train accuracy = 0.992188\n",
      "[2018-07-16 13:59:17.368114] Iteration 33000, train loss = 0.177545, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.912700\n",
      "[2018-07-16 13:59:22.721218] Iteration 33100, train loss = 0.175400, train accuracy = 1.000000\n",
      "[2018-07-16 13:59:26.809727] Iteration 33200, train loss = 0.172874, train accuracy = 0.984375\n",
      "[2018-07-16 13:59:30.883132] Iteration 33300, train loss = 0.172178, train accuracy = 0.984375\n",
      "[2018-07-16 13:59:34.931981] Iteration 33400, train loss = 0.149457, train accuracy = 1.000000\n",
      "[2018-07-16 13:59:39.035876] Iteration 33500, train loss = 0.152874, train accuracy = 1.000000\n",
      "[2018-07-16 13:59:43.090662] Iteration 33600, train loss = 0.200162, train accuracy = 0.984375\n",
      "[2018-07-16 13:59:47.165370] Iteration 33700, train loss = 0.159608, train accuracy = 1.000000\n",
      "[2018-07-16 13:59:51.236597] Iteration 33800, train loss = 0.152912, train accuracy = 1.000000\n",
      "[2018-07-16 13:59:55.299296] Iteration 33900, train loss = 0.177138, train accuracy = 0.984375\n",
      "[2018-07-16 13:59:59.389279] Iteration 34000, train loss = 0.159349, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 14:00:04.742988] Iteration 34100, train loss = 0.155515, train accuracy = 1.000000\n",
      "[2018-07-16 14:00:08.829472] Iteration 34200, train loss = 0.156680, train accuracy = 0.992188\n",
      "[2018-07-16 14:00:12.893592] Iteration 34300, train loss = 0.159364, train accuracy = 1.000000\n",
      "[2018-07-16 14:00:17.029097] Iteration 34400, train loss = 0.149603, train accuracy = 1.000000\n",
      "[2018-07-16 14:00:21.081654] Iteration 34500, train loss = 0.168535, train accuracy = 0.992188\n",
      "[2018-07-16 14:00:25.134252] Iteration 34600, train loss = 0.155096, train accuracy = 1.000000\n",
      "[2018-07-16 14:00:29.186647] Iteration 34700, train loss = 0.180244, train accuracy = 0.992188\n",
      "[2018-07-16 14:00:33.234336] Iteration 34800, train loss = 0.160541, train accuracy = 0.992188\n",
      "[2018-07-16 14:00:37.302577] Iteration 34900, train loss = 0.153038, train accuracy = 1.000000\n",
      "[2018-07-16 14:00:41.394423] Iteration 35000, train loss = 0.160305, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-07-16 14:00:46.733872] Iteration 35100, train loss = 0.153348, train accuracy = 0.992188\n",
      "[2018-07-16 14:00:50.808025] Iteration 35200, train loss = 0.157487, train accuracy = 1.000000\n",
      "[2018-07-16 14:00:54.934393] Iteration 35300, train loss = 0.149521, train accuracy = 1.000000\n",
      "[2018-07-16 14:00:59.054484] Iteration 35400, train loss = 0.164475, train accuracy = 0.992188\n",
      "[2018-07-16 14:01:03.140301] Iteration 35500, train loss = 0.158396, train accuracy = 1.000000\n",
      "[2018-07-16 14:01:07.203285] Iteration 35600, train loss = 0.181594, train accuracy = 0.984375\n",
      "[2018-07-16 14:01:11.261228] Iteration 35700, train loss = 0.170232, train accuracy = 0.992188\n",
      "[2018-07-16 14:01:15.305141] Iteration 35800, train loss = 0.157561, train accuracy = 1.000000\n",
      "[2018-07-16 14:01:19.362922] Iteration 35900, train loss = 0.166639, train accuracy = 0.992188\n",
      "[2018-07-16 14:01:23.430019] Iteration 36000, train loss = 0.163157, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912900\n",
      "[2018-07-16 14:01:28.784210] Iteration 36100, train loss = 0.167053, train accuracy = 0.992188\n",
      "[2018-07-16 14:01:32.917427] Iteration 36200, train loss = 0.155171, train accuracy = 1.000000\n",
      "[2018-07-16 14:01:36.990924] Iteration 36300, train loss = 0.176429, train accuracy = 0.984375\n",
      "[2018-07-16 14:01:41.083778] Iteration 36400, train loss = 0.167506, train accuracy = 0.992188\n",
      "[2018-07-16 14:01:45.155463] Iteration 36500, train loss = 0.170957, train accuracy = 0.984375\n",
      "[2018-07-16 14:01:49.220414] Iteration 36600, train loss = 0.169071, train accuracy = 0.992188\n",
      "[2018-07-16 14:01:53.308834] Iteration 36700, train loss = 0.177527, train accuracy = 0.984375\n",
      "[2018-07-16 14:01:57.354625] Iteration 36800, train loss = 0.159074, train accuracy = 1.000000\n",
      "[2018-07-16 14:02:01.407141] Iteration 36900, train loss = 0.179872, train accuracy = 0.992188\n",
      "[2018-07-16 14:02:05.458422] Iteration 37000, train loss = 0.168337, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913200\n",
      "[2018-07-16 14:02:10.833312] Iteration 37100, train loss = 0.174190, train accuracy = 0.984375\n",
      "[2018-07-16 14:02:14.917191] Iteration 37200, train loss = 0.156619, train accuracy = 1.000000\n",
      "[2018-07-16 14:02:19.002136] Iteration 37300, train loss = 0.154250, train accuracy = 1.000000\n",
      "[2018-07-16 14:02:23.085752] Iteration 37400, train loss = 0.154179, train accuracy = 0.992188\n",
      "[2018-07-16 14:02:27.168787] Iteration 37500, train loss = 0.146850, train accuracy = 1.000000\n",
      "[2018-07-16 14:02:31.240382] Iteration 37600, train loss = 0.170891, train accuracy = 0.992188\n",
      "[2018-07-16 14:02:35.335154] Iteration 37700, train loss = 0.175175, train accuracy = 0.984375\n",
      "[2018-07-16 14:02:39.405135] Iteration 37800, train loss = 0.146097, train accuracy = 1.000000\n",
      "[2018-07-16 14:02:43.464836] Iteration 37900, train loss = 0.178996, train accuracy = 0.992188\n",
      "[2018-07-16 14:02:47.545659] Iteration 38000, train loss = 0.152239, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912900\n",
      "[2018-07-16 14:02:52.851174] Iteration 38100, train loss = 0.153435, train accuracy = 0.992188\n",
      "[2018-07-16 14:02:56.904067] Iteration 38200, train loss = 0.160843, train accuracy = 0.992188\n",
      "[2018-07-16 14:03:00.962398] Iteration 38300, train loss = 0.153625, train accuracy = 1.000000\n",
      "[2018-07-16 14:03:05.051929] Iteration 38400, train loss = 0.160017, train accuracy = 0.992188\n",
      "[2018-07-16 14:03:09.125213] Iteration 38500, train loss = 0.156069, train accuracy = 1.000000\n",
      "[2018-07-16 14:03:13.191762] Iteration 38600, train loss = 0.157151, train accuracy = 1.000000\n",
      "[2018-07-16 14:03:17.287706] Iteration 38700, train loss = 0.154174, train accuracy = 1.000000\n",
      "[2018-07-16 14:03:21.367499] Iteration 38800, train loss = 0.166553, train accuracy = 1.000000\n",
      "[2018-07-16 14:03:25.489355] Iteration 38900, train loss = 0.157552, train accuracy = 0.992188\n",
      "[2018-07-16 14:03:29.577828] Iteration 39000, train loss = 0.160696, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "[2018-07-16 14:03:34.892969] Iteration 39100, train loss = 0.162991, train accuracy = 0.992188\n",
      "[2018-07-16 14:03:38.956914] Iteration 39200, train loss = 0.155342, train accuracy = 1.000000\n",
      "[2018-07-16 14:03:43.000737] Iteration 39300, train loss = 0.165308, train accuracy = 0.992188\n",
      "[2018-07-16 14:03:47.068971] Iteration 39400, train loss = 0.157482, train accuracy = 0.992188\n",
      "[2018-07-16 14:03:51.142997] Iteration 39500, train loss = 0.169164, train accuracy = 0.984375\n",
      "[2018-07-16 14:03:55.215428] Iteration 39600, train loss = 0.175208, train accuracy = 0.992188\n",
      "[2018-07-16 14:03:59.310390] Iteration 39700, train loss = 0.169299, train accuracy = 0.992188\n",
      "[2018-07-16 14:04:03.427122] Iteration 39800, train loss = 0.145610, train accuracy = 1.000000\n",
      "[2018-07-16 14:04:07.506204] Iteration 39900, train loss = 0.174079, train accuracy = 0.984375\n",
      "[2018-07-16 14:04:11.598648] Iteration 40000, train loss = 0.161712, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912900\n",
      "[2018-07-16 14:04:16.922431] Iteration 40100, train loss = 0.185580, train accuracy = 0.976562\n",
      "[2018-07-16 14:04:20.971662] Iteration 40200, train loss = 0.156293, train accuracy = 0.992188\n",
      "[2018-07-16 14:04:25.016720] Iteration 40300, train loss = 0.148199, train accuracy = 1.000000\n",
      "[2018-07-16 14:04:29.079734] Iteration 40400, train loss = 0.156235, train accuracy = 1.000000\n",
      "[2018-07-16 14:04:33.119599] Iteration 40500, train loss = 0.149383, train accuracy = 1.000000\n",
      "[2018-07-16 14:04:37.178744] Iteration 40600, train loss = 0.175904, train accuracy = 1.000000\n",
      "[2018-07-16 14:04:41.309023] Iteration 40700, train loss = 0.159968, train accuracy = 1.000000\n",
      "[2018-07-16 14:04:45.376156] Iteration 40800, train loss = 0.165663, train accuracy = 0.984375\n",
      "[2018-07-16 14:04:49.450826] Iteration 40900, train loss = 0.167741, train accuracy = 0.992188\n",
      "[2018-07-16 14:04:53.560495] Iteration 41000, train loss = 0.167875, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 14:04:58.884230] Iteration 41100, train loss = 0.148074, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:02.981674] Iteration 41200, train loss = 0.158564, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:07.058700] Iteration 41300, train loss = 0.154970, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:11.116693] Iteration 41400, train loss = 0.165244, train accuracy = 0.992188\n",
      "[2018-07-16 14:05:15.166793] Iteration 41500, train loss = 0.147657, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:19.273496] Iteration 41600, train loss = 0.160122, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:23.335621] Iteration 41700, train loss = 0.163207, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:27.416268] Iteration 41800, train loss = 0.174962, train accuracy = 0.984375\n",
      "[2018-07-16 14:05:31.505494] Iteration 41900, train loss = 0.162511, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:35.608938] Iteration 42000, train loss = 0.184728, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-07-16 14:05:40.933123] Iteration 42100, train loss = 0.180208, train accuracy = 0.984375\n",
      "[2018-07-16 14:05:45.016496] Iteration 42200, train loss = 0.175026, train accuracy = 0.984375\n",
      "[2018-07-16 14:05:49.091729] Iteration 42300, train loss = 0.156707, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:53.173691] Iteration 42400, train loss = 0.152825, train accuracy = 1.000000\n",
      "[2018-07-16 14:05:57.263163] Iteration 42500, train loss = 0.163617, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:01.309793] Iteration 42600, train loss = 0.149772, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:05.357400] Iteration 42700, train loss = 0.155694, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:09.408785] Iteration 42800, train loss = 0.201928, train accuracy = 0.960938\n",
      "[2018-07-16 14:06:13.467566] Iteration 42900, train loss = 0.152507, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:17.572718] Iteration 43000, train loss = 0.182934, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 14:06:22.900487] Iteration 43100, train loss = 0.150522, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:26.986951] Iteration 43200, train loss = 0.177602, train accuracy = 0.992188\n",
      "[2018-07-16 14:06:31.064996] Iteration 43300, train loss = 0.151632, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:35.206753] Iteration 43400, train loss = 0.147119, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:39.293712] Iteration 43500, train loss = 0.170064, train accuracy = 0.992188\n",
      "[2018-07-16 14:06:43.353048] Iteration 43600, train loss = 0.217831, train accuracy = 0.968750\n",
      "[2018-07-16 14:06:47.405232] Iteration 43700, train loss = 0.160549, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:51.449476] Iteration 43800, train loss = 0.152803, train accuracy = 1.000000\n",
      "[2018-07-16 14:06:55.492899] Iteration 43900, train loss = 0.161461, train accuracy = 0.992188\n",
      "[2018-07-16 14:06:59.563156] Iteration 44000, train loss = 0.156674, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913400\n",
      "[2018-07-16 14:07:04.907354] Iteration 44100, train loss = 0.170535, train accuracy = 0.992188\n",
      "[2018-07-16 14:07:09.001801] Iteration 44200, train loss = 0.153437, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:13.108600] Iteration 44300, train loss = 0.145793, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:17.206379] Iteration 44400, train loss = 0.151441, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:21.285346] Iteration 44500, train loss = 0.154125, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:25.350920] Iteration 44600, train loss = 0.153437, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:29.440691] Iteration 44700, train loss = 0.160031, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:33.487437] Iteration 44800, train loss = 0.172950, train accuracy = 0.992188\n",
      "[2018-07-16 14:07:37.534101] Iteration 44900, train loss = 0.175589, train accuracy = 0.984375\n",
      "[2018-07-16 14:07:41.597847] Iteration 45000, train loss = 0.154658, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-07-16 14:07:46.938253] Iteration 45100, train loss = 0.153287, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:51.051613] Iteration 45200, train loss = 0.155038, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:55.157338] Iteration 45300, train loss = 0.153057, train accuracy = 1.000000\n",
      "[2018-07-16 14:07:59.249328] Iteration 45400, train loss = 0.148252, train accuracy = 1.000000\n",
      "[2018-07-16 14:08:03.316066] Iteration 45500, train loss = 0.183251, train accuracy = 0.984375\n",
      "[2018-07-16 14:08:07.385296] Iteration 45600, train loss = 0.172722, train accuracy = 0.992188\n",
      "[2018-07-16 14:08:11.483126] Iteration 45700, train loss = 0.166902, train accuracy = 0.992188\n",
      "[2018-07-16 14:08:15.545515] Iteration 45800, train loss = 0.171326, train accuracy = 0.992188\n",
      "[2018-07-16 14:08:19.610278] Iteration 45900, train loss = 0.157656, train accuracy = 1.000000\n",
      "[2018-07-16 14:08:23.676697] Iteration 46000, train loss = 0.168906, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 14:08:29.085362] Iteration 46100, train loss = 0.172735, train accuracy = 0.992188\n",
      "[2018-07-16 14:08:33.133110] Iteration 46200, train loss = 0.170025, train accuracy = 0.984375\n",
      "[2018-07-16 14:08:37.215356] Iteration 46300, train loss = 0.183575, train accuracy = 0.992188\n",
      "[2018-07-16 14:08:41.301491] Iteration 46400, train loss = 0.154873, train accuracy = 1.000000\n",
      "[2018-07-16 14:08:45.388538] Iteration 46500, train loss = 0.172433, train accuracy = 0.992188\n",
      "[2018-07-16 14:08:49.450479] Iteration 46600, train loss = 0.179289, train accuracy = 0.984375\n",
      "[2018-07-16 14:08:53.542696] Iteration 46700, train loss = 0.164247, train accuracy = 0.992188\n",
      "[2018-07-16 14:08:57.608646] Iteration 46800, train loss = 0.165144, train accuracy = 0.992188\n",
      "[2018-07-16 14:09:01.710226] Iteration 46900, train loss = 0.169813, train accuracy = 0.992188\n",
      "[2018-07-16 14:09:05.875479] Iteration 47000, train loss = 0.166318, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912500\n",
      "[2018-07-16 14:09:11.193911] Iteration 47100, train loss = 0.167249, train accuracy = 0.984375\n",
      "[2018-07-16 14:09:15.245272] Iteration 47200, train loss = 0.157302, train accuracy = 0.992188\n",
      "[2018-07-16 14:09:19.285798] Iteration 47300, train loss = 0.150669, train accuracy = 1.000000\n",
      "[2018-07-16 14:09:23.355774] Iteration 47400, train loss = 0.159737, train accuracy = 1.000000\n",
      "[2018-07-16 14:09:27.427535] Iteration 47500, train loss = 0.169104, train accuracy = 1.000000\n",
      "[2018-07-16 14:09:31.506014] Iteration 47600, train loss = 0.155352, train accuracy = 1.000000\n",
      "[2018-07-16 14:09:35.593969] Iteration 47700, train loss = 0.165224, train accuracy = 0.992188\n",
      "[2018-07-16 14:09:39.670785] Iteration 47800, train loss = 0.169088, train accuracy = 0.992188\n",
      "[2018-07-16 14:09:43.776581] Iteration 47900, train loss = 0.186421, train accuracy = 0.984375\n",
      "[2018-07-16 14:09:47.858172] Iteration 48000, train loss = 0.155802, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912800\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-16 14:09:53.210211] Iteration 48100, train loss = 0.149789, train accuracy = 1.000000\n",
      "[2018-07-16 14:09:57.252249] Iteration 48200, train loss = 0.159811, train accuracy = 0.992188\n",
      "[2018-07-16 14:10:01.312584] Iteration 48300, train loss = 0.159371, train accuracy = 0.992188\n",
      "[2018-07-16 14:10:05.365880] Iteration 48400, train loss = 0.151724, train accuracy = 1.000000\n",
      "[2018-07-16 14:10:09.412282] Iteration 48500, train loss = 0.174834, train accuracy = 0.984375\n",
      "[2018-07-16 14:10:13.475506] Iteration 48600, train loss = 0.165997, train accuracy = 0.992188\n",
      "[2018-07-16 14:10:17.589045] Iteration 48700, train loss = 0.152272, train accuracy = 0.992188\n",
      "[2018-07-16 14:10:21.684949] Iteration 48800, train loss = 0.173193, train accuracy = 0.992188\n",
      "[2018-07-16 14:10:25.765888] Iteration 48900, train loss = 0.152709, train accuracy = 1.000000\n",
      "[2018-07-16 14:10:29.867732] Iteration 49000, train loss = 0.176198, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-07-16 14:10:35.224294] Iteration 49100, train loss = 0.154966, train accuracy = 0.992188\n",
      "[2018-07-16 14:10:39.292031] Iteration 49200, train loss = 0.161132, train accuracy = 0.984375\n",
      "[2018-07-16 14:10:43.363163] Iteration 49300, train loss = 0.156322, train accuracy = 1.000000\n",
      "[2018-07-16 14:10:47.422856] Iteration 49400, train loss = 0.161630, train accuracy = 0.992188\n",
      "[2018-07-16 14:10:51.467294] Iteration 49500, train loss = 0.174663, train accuracy = 0.984375\n",
      "[2018-07-16 14:10:55.550453] Iteration 49600, train loss = 0.145682, train accuracy = 1.000000\n",
      "[2018-07-16 14:10:59.644729] Iteration 49700, train loss = 0.174362, train accuracy = 0.992188\n",
      "[2018-07-16 14:11:03.722446] Iteration 49800, train loss = 0.155072, train accuracy = 1.000000\n",
      "[2018-07-16 14:11:07.806822] Iteration 49900, train loss = 0.164609, train accuracy = 0.992188\n",
      "[2018-07-16 14:11:11.886758] Iteration 50000, train loss = 0.154849, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 14:11:17.228157] Iteration 50100, train loss = 0.160217, train accuracy = 0.992188\n",
      "[2018-07-16 14:11:21.304631] Iteration 50200, train loss = 0.170045, train accuracy = 0.984375\n",
      "[2018-07-16 14:11:25.364254] Iteration 50300, train loss = 0.172086, train accuracy = 0.984375\n",
      "[2018-07-16 14:11:29.448327] Iteration 50400, train loss = 0.190988, train accuracy = 0.984375\n",
      "[2018-07-16 14:11:33.527641] Iteration 50500, train loss = 0.157531, train accuracy = 1.000000\n",
      "[2018-07-16 14:11:37.596640] Iteration 50600, train loss = 0.180557, train accuracy = 0.984375\n",
      "[2018-07-16 14:11:41.652438] Iteration 50700, train loss = 0.150077, train accuracy = 1.000000\n",
      "[2018-07-16 14:11:45.696633] Iteration 50800, train loss = 0.148243, train accuracy = 1.000000\n",
      "[2018-07-16 14:11:49.762217] Iteration 50900, train loss = 0.162691, train accuracy = 0.992188\n",
      "[2018-07-16 14:11:53.847028] Iteration 51000, train loss = 0.182581, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 14:11:59.186425] Iteration 51100, train loss = 0.148616, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:03.264604] Iteration 51200, train loss = 0.167525, train accuracy = 0.992188\n",
      "[2018-07-16 14:12:07.334126] Iteration 51300, train loss = 0.172744, train accuracy = 0.984375\n",
      "[2018-07-16 14:12:11.461010] Iteration 51400, train loss = 0.167268, train accuracy = 0.992188\n",
      "[2018-07-16 14:12:15.532846] Iteration 51500, train loss = 0.164789, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:19.590672] Iteration 51600, train loss = 0.161037, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:23.649020] Iteration 51700, train loss = 0.153372, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:27.700550] Iteration 51800, train loss = 0.156866, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:31.760759] Iteration 51900, train loss = 0.150113, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:35.833168] Iteration 52000, train loss = 0.165292, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913300\n",
      "[2018-07-16 14:12:41.179302] Iteration 52100, train loss = 0.188196, train accuracy = 0.984375\n",
      "[2018-07-16 14:12:45.266629] Iteration 52200, train loss = 0.172119, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:49.398106] Iteration 52300, train loss = 0.173622, train accuracy = 0.992188\n",
      "[2018-07-16 14:12:53.495380] Iteration 52400, train loss = 0.162400, train accuracy = 1.000000\n",
      "[2018-07-16 14:12:57.572083] Iteration 52500, train loss = 0.147621, train accuracy = 1.000000\n",
      "[2018-07-16 14:13:01.655005] Iteration 52600, train loss = 0.173412, train accuracy = 0.984375\n",
      "[2018-07-16 14:13:05.737189] Iteration 52700, train loss = 0.149850, train accuracy = 1.000000\n",
      "[2018-07-16 14:13:09.786307] Iteration 52800, train loss = 0.155254, train accuracy = 1.000000\n",
      "[2018-07-16 14:13:13.835898] Iteration 52900, train loss = 0.169214, train accuracy = 0.992188\n",
      "[2018-07-16 14:13:17.894927] Iteration 53000, train loss = 0.173535, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913300\n",
      "[2018-07-16 14:13:23.238491] Iteration 53100, train loss = 0.178104, train accuracy = 0.992188\n",
      "[2018-07-16 14:13:27.357902] Iteration 53200, train loss = 0.152658, train accuracy = 1.000000\n",
      "[2018-07-16 14:13:31.445120] Iteration 53300, train loss = 0.171310, train accuracy = 0.992188\n",
      "[2018-07-16 14:13:35.535895] Iteration 53400, train loss = 0.173630, train accuracy = 0.992188\n",
      "[2018-07-16 14:13:39.617758] Iteration 53500, train loss = 0.161310, train accuracy = 0.992188\n",
      "[2018-07-16 14:13:43.701508] Iteration 53600, train loss = 0.165160, train accuracy = 0.992188\n",
      "[2018-07-16 14:13:47.791260] Iteration 53700, train loss = 0.173300, train accuracy = 0.984375\n",
      "[2018-07-16 14:13:51.867034] Iteration 53800, train loss = 0.199919, train accuracy = 0.984375\n",
      "[2018-07-16 14:13:55.934549] Iteration 53900, train loss = 0.157501, train accuracy = 1.000000\n",
      "[2018-07-16 14:13:59.990592] Iteration 54000, train loss = 0.161861, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 14:14:05.361154] Iteration 54100, train loss = 0.157898, train accuracy = 1.000000\n",
      "[2018-07-16 14:14:09.406321] Iteration 54200, train loss = 0.157326, train accuracy = 1.000000\n",
      "[2018-07-16 14:14:13.473543] Iteration 54300, train loss = 0.172422, train accuracy = 0.992188\n",
      "[2018-07-16 14:14:17.580062] Iteration 54400, train loss = 0.149125, train accuracy = 1.000000\n",
      "[2018-07-16 14:14:21.649133] Iteration 54500, train loss = 0.183325, train accuracy = 0.984375\n",
      "[2018-07-16 14:14:25.724440] Iteration 54600, train loss = 0.184348, train accuracy = 0.976562\n",
      "[2018-07-16 14:14:29.814143] Iteration 54700, train loss = 0.159805, train accuracy = 0.992188\n",
      "[2018-07-16 14:14:33.889957] Iteration 54800, train loss = 0.163167, train accuracy = 0.992188\n",
      "[2018-07-16 14:14:37.985356] Iteration 54900, train loss = 0.149408, train accuracy = 1.000000\n",
      "[2018-07-16 14:14:42.092041] Iteration 55000, train loss = 0.160227, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 14:14:47.414251] Iteration 55100, train loss = 0.174358, train accuracy = 0.992188\n",
      "[2018-07-16 14:14:51.464154] Iteration 55200, train loss = 0.167866, train accuracy = 0.992188\n",
      "[2018-07-16 14:14:55.513813] Iteration 55300, train loss = 0.162746, train accuracy = 0.992188\n",
      "[2018-07-16 14:14:59.568720] Iteration 55400, train loss = 0.172526, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:03.640479] Iteration 55500, train loss = 0.158674, train accuracy = 1.000000\n",
      "[2018-07-16 14:15:07.726577] Iteration 55600, train loss = 0.169021, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:11.820642] Iteration 55700, train loss = 0.192286, train accuracy = 0.976562\n",
      "[2018-07-16 14:15:15.885072] Iteration 55800, train loss = 0.149182, train accuracy = 1.000000\n",
      "[2018-07-16 14:15:20.045331] Iteration 55900, train loss = 0.176596, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:24.128391] Iteration 56000, train loss = 0.162537, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913400\n",
      "[2018-07-16 14:15:29.478233] Iteration 56100, train loss = 0.169317, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:33.519803] Iteration 56200, train loss = 0.158816, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:37.584860] Iteration 56300, train loss = 0.185198, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:41.632372] Iteration 56400, train loss = 0.159075, train accuracy = 1.000000\n",
      "[2018-07-16 14:15:45.687137] Iteration 56500, train loss = 0.166922, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:49.751199] Iteration 56600, train loss = 0.200861, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:53.840710] Iteration 56700, train loss = 0.172827, train accuracy = 0.992188\n",
      "[2018-07-16 14:15:57.916345] Iteration 56800, train loss = 0.191412, train accuracy = 0.976562\n",
      "[2018-07-16 14:16:01.941974] Iteration 56900, train loss = 0.155296, train accuracy = 0.992188\n",
      "[2018-07-16 14:16:06.039147] Iteration 57000, train loss = 0.158126, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 14:16:11.387969] Iteration 57100, train loss = 0.159673, train accuracy = 1.000000\n",
      "[2018-07-16 14:16:15.463659] Iteration 57200, train loss = 0.165051, train accuracy = 1.000000\n",
      "[2018-07-16 14:16:19.523242] Iteration 57300, train loss = 0.172401, train accuracy = 0.992188\n",
      "[2018-07-16 14:16:23.581337] Iteration 57400, train loss = 0.169004, train accuracy = 0.992188\n",
      "[2018-07-16 14:16:27.630579] Iteration 57500, train loss = 0.159338, train accuracy = 1.000000\n",
      "[2018-07-16 14:16:31.685667] Iteration 57600, train loss = 0.159252, train accuracy = 1.000000\n",
      "[2018-07-16 14:16:35.784922] Iteration 57700, train loss = 0.157909, train accuracy = 1.000000\n",
      "[2018-07-16 14:16:39.867850] Iteration 57800, train loss = 0.157074, train accuracy = 0.992188\n",
      "[2018-07-16 14:16:43.954006] Iteration 57900, train loss = 0.152685, train accuracy = 1.000000\n",
      "[2018-07-16 14:16:48.049816] Iteration 58000, train loss = 0.159169, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-07-16 14:16:53.409479] Iteration 58100, train loss = 0.162295, train accuracy = 0.992188\n",
      "[2018-07-16 14:16:57.481139] Iteration 58200, train loss = 0.152960, train accuracy = 1.000000\n",
      "[2018-07-16 14:17:01.556315] Iteration 58300, train loss = 0.150677, train accuracy = 0.992188\n",
      "[2018-07-16 14:17:05.632854] Iteration 58400, train loss = 0.156964, train accuracy = 1.000000\n",
      "[2018-07-16 14:17:09.688914] Iteration 58500, train loss = 0.166493, train accuracy = 0.992188\n",
      "[2018-07-16 14:17:13.795972] Iteration 58600, train loss = 0.200733, train accuracy = 0.984375\n",
      "[2018-07-16 14:17:17.842389] Iteration 58700, train loss = 0.166193, train accuracy = 1.000000\n",
      "[2018-07-16 14:17:21.886839] Iteration 58800, train loss = 0.163760, train accuracy = 1.000000\n",
      "[2018-07-16 14:17:25.967078] Iteration 58900, train loss = 0.160065, train accuracy = 1.000000\n",
      "[2018-07-16 14:17:30.049191] Iteration 59000, train loss = 0.153266, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 14:17:35.433453] Iteration 59100, train loss = 0.168881, train accuracy = 0.984375\n",
      "[2018-07-16 14:17:39.524431] Iteration 59200, train loss = 0.171179, train accuracy = 0.992188\n",
      "[2018-07-16 14:17:43.600269] Iteration 59300, train loss = 0.193026, train accuracy = 0.992188\n",
      "[2018-07-16 14:17:47.682295] Iteration 59400, train loss = 0.165495, train accuracy = 0.992188\n",
      "[2018-07-16 14:17:51.807537] Iteration 59500, train loss = 0.170058, train accuracy = 0.984375\n",
      "[2018-07-16 14:17:55.878305] Iteration 59600, train loss = 0.177632, train accuracy = 0.984375\n",
      "[2018-07-16 14:17:59.931163] Iteration 59700, train loss = 0.159278, train accuracy = 0.992188\n",
      "[2018-07-16 14:18:03.976326] Iteration 59800, train loss = 0.159159, train accuracy = 1.000000\n",
      "[2018-07-16 14:18:08.031891] Iteration 59900, train loss = 0.163908, train accuracy = 0.992188\n",
      "[2018-07-16 14:18:12.098639] Iteration 60000, train loss = 0.150659, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 14:18:17.458091] Iteration 60100, train loss = 0.154073, train accuracy = 1.000000\n",
      "[2018-07-16 14:18:21.548302] Iteration 60200, train loss = 0.146978, train accuracy = 1.000000\n",
      "[2018-07-16 14:18:25.627045] Iteration 60300, train loss = 0.168617, train accuracy = 0.984375\n",
      "[2018-07-16 14:18:29.776960] Iteration 60400, train loss = 0.175484, train accuracy = 0.984375\n",
      "[2018-07-16 14:18:33.849253] Iteration 60500, train loss = 0.143612, train accuracy = 1.000000\n",
      "[2018-07-16 14:18:37.925004] Iteration 60600, train loss = 0.177386, train accuracy = 0.984375\n",
      "[2018-07-16 14:18:41.991424] Iteration 60700, train loss = 0.166982, train accuracy = 0.992188\n",
      "[2018-07-16 14:18:46.039706] Iteration 60800, train loss = 0.149589, train accuracy = 1.000000\n",
      "[2018-07-16 14:18:50.103163] Iteration 60900, train loss = 0.165894, train accuracy = 0.992188\n",
      "[2018-07-16 14:18:54.169048] Iteration 61000, train loss = 0.145771, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 14:18:59.502329] Iteration 61100, train loss = 0.167801, train accuracy = 0.992188\n",
      "[2018-07-16 14:19:03.571726] Iteration 61200, train loss = 0.148940, train accuracy = 1.000000\n",
      "[2018-07-16 14:19:07.689631] Iteration 61300, train loss = 0.150107, train accuracy = 1.000000\n",
      "[2018-07-16 14:19:11.777433] Iteration 61400, train loss = 0.166487, train accuracy = 0.992188\n",
      "[2018-07-16 14:19:15.844540] Iteration 61500, train loss = 0.174842, train accuracy = 0.992188\n",
      "[2018-07-16 14:19:19.930295] Iteration 61600, train loss = 0.149427, train accuracy = 1.000000\n",
      "[2018-07-16 14:19:24.025246] Iteration 61700, train loss = 0.169538, train accuracy = 0.992188\n",
      "[2018-07-16 14:19:28.091399] Iteration 61800, train loss = 0.166563, train accuracy = 1.000000\n",
      "[2018-07-16 14:19:32.158504] Iteration 61900, train loss = 0.183193, train accuracy = 0.992188\n",
      "[2018-07-16 14:19:36.218338] Iteration 62000, train loss = 0.147194, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-07-16 14:19:41.522901] Iteration 62100, train loss = 0.171031, train accuracy = 0.992188\n",
      "[2018-07-16 14:19:45.622318] Iteration 62200, train loss = 0.173264, train accuracy = 0.984375\n",
      "[2018-07-16 14:19:49.678746] Iteration 62300, train loss = 0.159820, train accuracy = 0.992188\n",
      "[2018-07-16 14:19:53.741343] Iteration 62400, train loss = 0.174012, train accuracy = 0.984375\n",
      "[2018-07-16 14:19:57.793683] Iteration 62500, train loss = 0.170029, train accuracy = 0.984375\n",
      "[2018-07-16 14:20:01.858749] Iteration 62600, train loss = 0.163526, train accuracy = 1.000000\n",
      "[2018-07-16 14:20:05.929460] Iteration 62700, train loss = 0.165077, train accuracy = 0.992188\n",
      "[2018-07-16 14:20:09.981611] Iteration 62800, train loss = 0.146332, train accuracy = 1.000000\n",
      "[2018-07-16 14:20:14.055391] Iteration 62900, train loss = 0.160251, train accuracy = 0.992188\n",
      "[2018-07-16 14:20:18.105883] Iteration 63000, train loss = 0.173896, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 14:20:23.360437] Iteration 63100, train loss = 0.171230, train accuracy = 0.984375\n",
      "[2018-07-16 14:20:27.417968] Iteration 63200, train loss = 0.166592, train accuracy = 0.992188\n",
      "[2018-07-16 14:20:31.472608] Iteration 63300, train loss = 0.184237, train accuracy = 0.976562\n",
      "[2018-07-16 14:20:35.552475] Iteration 63400, train loss = 0.157703, train accuracy = 1.000000\n",
      "[2018-07-16 14:20:39.651072] Iteration 63500, train loss = 0.155393, train accuracy = 0.992188\n",
      "[2018-07-16 14:20:43.745530] Iteration 63600, train loss = 0.168459, train accuracy = 0.992188\n",
      "[2018-07-16 14:20:47.856703] Iteration 63700, train loss = 0.147746, train accuracy = 1.000000\n",
      "[2018-07-16 14:20:51.949930] Iteration 63800, train loss = 0.190458, train accuracy = 0.992188\n",
      "[2018-07-16 14:20:56.097661] Iteration 63900, train loss = 0.156773, train accuracy = 0.992188\n",
      "[2018-07-16 14:21:00.200708] Iteration 64000, train loss = 0.163306, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-07-16 14:21:05.588400] Iteration 64100, train loss = 0.182980, train accuracy = 0.976562\n",
      "[2018-07-16 14:21:09.661145] Iteration 64200, train loss = 0.150107, train accuracy = 1.000000\n",
      "[2018-07-16 14:21:13.723260] Iteration 64300, train loss = 0.151134, train accuracy = 1.000000\n",
      "[2018-07-16 14:21:17.811607] Iteration 64400, train loss = 0.148258, train accuracy = 1.000000\n",
      "[2018-07-16 14:21:21.871695] Iteration 64500, train loss = 0.156047, train accuracy = 0.992188\n",
      "[2018-07-16 14:21:25.971851] Iteration 64600, train loss = 0.172212, train accuracy = 1.000000\n",
      "[2018-07-16 14:21:30.117167] Iteration 64700, train loss = 0.154303, train accuracy = 1.000000\n",
      "[2018-07-16 14:21:34.194455] Iteration 64800, train loss = 0.174132, train accuracy = 0.992188\n",
      "[2018-07-16 14:21:38.302261] Iteration 64900, train loss = 0.177073, train accuracy = 0.984375\n",
      "[2018-07-16 14:21:42.392368] Iteration 65000, train loss = 0.163367, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 14:21:47.726471] Iteration 65100, train loss = 0.155059, train accuracy = 1.000000\n",
      "[2018-07-16 14:21:51.791771] Iteration 65200, train loss = 0.164546, train accuracy = 0.992188\n",
      "[2018-07-16 14:21:55.870483] Iteration 65300, train loss = 0.148074, train accuracy = 1.000000\n",
      "[2018-07-16 14:21:59.960540] Iteration 65400, train loss = 0.160576, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:03.874584] Iteration 65500, train loss = 0.165676, train accuracy = 0.992188\n",
      "[2018-07-16 14:22:07.819211] Iteration 65600, train loss = 0.162096, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:11.868730] Iteration 65700, train loss = 0.152686, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:15.957172] Iteration 65800, train loss = 0.152106, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:20.060089] Iteration 65900, train loss = 0.153280, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:24.147427] Iteration 66000, train loss = 0.169222, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 14:22:29.457888] Iteration 66100, train loss = 0.160898, train accuracy = 0.992188\n",
      "[2018-07-16 14:22:33.600470] Iteration 66200, train loss = 0.170101, train accuracy = 0.992188\n",
      "[2018-07-16 14:22:37.709100] Iteration 66300, train loss = 0.154111, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:41.814045] Iteration 66400, train loss = 0.170189, train accuracy = 0.992188\n",
      "[2018-07-16 14:22:45.870940] Iteration 66500, train loss = 0.157996, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:49.930000] Iteration 66600, train loss = 0.169390, train accuracy = 0.984375\n",
      "[2018-07-16 14:22:53.997679] Iteration 66700, train loss = 0.165038, train accuracy = 1.000000\n",
      "[2018-07-16 14:22:58.066195] Iteration 66800, train loss = 0.181117, train accuracy = 0.992188\n",
      "[2018-07-16 14:23:02.178609] Iteration 66900, train loss = 0.154437, train accuracy = 1.000000\n",
      "[2018-07-16 14:23:06.172972] Iteration 67000, train loss = 0.160363, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-07-16 14:23:11.529987] Iteration 67100, train loss = 0.153088, train accuracy = 1.000000\n",
      "[2018-07-16 14:23:15.602267] Iteration 67200, train loss = 0.159002, train accuracy = 0.992188\n",
      "[2018-07-16 14:23:19.543560] Iteration 67300, train loss = 0.156727, train accuracy = 1.000000\n",
      "[2018-07-16 14:23:23.510488] Iteration 67400, train loss = 0.184181, train accuracy = 0.984375\n",
      "[2018-07-16 14:23:27.415402] Iteration 67500, train loss = 0.154076, train accuracy = 1.000000\n",
      "[2018-07-16 14:23:31.316593] Iteration 67600, train loss = 0.152381, train accuracy = 1.000000\n",
      "[2018-07-16 14:23:35.311593] Iteration 67700, train loss = 0.152110, train accuracy = 1.000000\n",
      "[2018-07-16 14:23:39.384553] Iteration 67800, train loss = 0.153377, train accuracy = 1.000000\n",
      "[2018-07-16 14:23:43.454724] Iteration 67900, train loss = 0.168765, train accuracy = 0.992188\n",
      "[2018-07-16 14:23:47.528228] Iteration 68000, train loss = 0.159225, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-07-16 14:23:52.890465] Iteration 68100, train loss = 0.182000, train accuracy = 0.984375\n",
      "[2018-07-16 14:23:56.995483] Iteration 68200, train loss = 0.143456, train accuracy = 1.000000\n",
      "[2018-07-16 14:24:01.085862] Iteration 68300, train loss = 0.151721, train accuracy = 1.000000\n",
      "[2018-07-16 14:24:05.195077] Iteration 68400, train loss = 0.174756, train accuracy = 0.984375\n",
      "[2018-07-16 14:24:09.320249] Iteration 68500, train loss = 0.159673, train accuracy = 0.992188\n",
      "[2018-07-16 14:24:13.407593] Iteration 68600, train loss = 0.170847, train accuracy = 0.976562\n",
      "[2018-07-16 14:24:17.500553] Iteration 68700, train loss = 0.186164, train accuracy = 0.992188\n",
      "[2018-07-16 14:24:21.553224] Iteration 68800, train loss = 0.152534, train accuracy = 0.992188\n",
      "[2018-07-16 14:24:25.624049] Iteration 68900, train loss = 0.158126, train accuracy = 1.000000\n",
      "[2018-07-16 14:24:29.697390] Iteration 69000, train loss = 0.153267, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 14:24:35.008452] Iteration 69100, train loss = 0.177267, train accuracy = 0.992188\n",
      "[2018-07-16 14:24:39.122632] Iteration 69200, train loss = 0.159828, train accuracy = 0.992188\n",
      "[2018-07-16 14:24:43.215816] Iteration 69300, train loss = 0.150263, train accuracy = 1.000000\n",
      "[2018-07-16 14:24:47.326835] Iteration 69400, train loss = 0.164552, train accuracy = 0.984375\n",
      "[2018-07-16 14:24:51.410176] Iteration 69500, train loss = 0.148361, train accuracy = 1.000000\n",
      "[2018-07-16 14:24:55.498103] Iteration 69600, train loss = 0.144702, train accuracy = 1.000000\n",
      "[2018-07-16 14:24:59.608931] Iteration 69700, train loss = 0.174362, train accuracy = 1.000000\n",
      "[2018-07-16 14:25:03.702693] Iteration 69800, train loss = 0.151445, train accuracy = 1.000000\n",
      "[2018-07-16 14:25:07.780450] Iteration 69900, train loss = 0.164187, train accuracy = 0.992188\n",
      "[2018-07-16 14:25:11.909131] Iteration 70000, train loss = 0.180042, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 14:25:17.216757] Iteration 70100, train loss = 0.168261, train accuracy = 0.992188\n",
      "[2018-07-16 14:25:21.270660] Iteration 70200, train loss = 0.163835, train accuracy = 0.984375\n",
      "[2018-07-16 14:25:25.360406] Iteration 70300, train loss = 0.151801, train accuracy = 1.000000\n",
      "[2018-07-16 14:25:29.464939] Iteration 70400, train loss = 0.160437, train accuracy = 0.992188\n",
      "[2018-07-16 14:25:33.556718] Iteration 70500, train loss = 0.155994, train accuracy = 1.000000\n",
      "[2018-07-16 14:25:37.642804] Iteration 70600, train loss = 0.162010, train accuracy = 0.992188\n",
      "[2018-07-16 14:25:41.803385] Iteration 70700, train loss = 0.151217, train accuracy = 1.000000\n",
      "[2018-07-16 14:25:45.853336] Iteration 70800, train loss = 0.159217, train accuracy = 0.992188\n",
      "[2018-07-16 14:25:49.951794] Iteration 70900, train loss = 0.155121, train accuracy = 0.992188\n",
      "[2018-07-16 14:25:54.048550] Iteration 71000, train loss = 0.158034, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-07-16 14:25:59.395110] Iteration 71100, train loss = 0.153116, train accuracy = 1.000000\n",
      "[2018-07-16 14:26:03.456153] Iteration 71200, train loss = 0.156430, train accuracy = 1.000000\n",
      "[2018-07-16 14:26:07.502896] Iteration 71300, train loss = 0.146125, train accuracy = 1.000000\n",
      "[2018-07-16 14:26:11.562816] Iteration 71400, train loss = 0.161533, train accuracy = 1.000000\n",
      "[2018-07-16 14:26:15.691467] Iteration 71500, train loss = 0.168770, train accuracy = 0.992188\n",
      "[2018-07-16 14:26:19.798260] Iteration 71600, train loss = 0.167479, train accuracy = 0.992188\n",
      "[2018-07-16 14:26:23.909285] Iteration 71700, train loss = 0.182494, train accuracy = 0.992188\n",
      "[2018-07-16 14:26:27.979460] Iteration 71800, train loss = 0.152545, train accuracy = 1.000000\n",
      "[2018-07-16 14:26:32.110440] Iteration 71900, train loss = 0.174380, train accuracy = 0.992188\n",
      "[2018-07-16 14:26:36.198652] Iteration 72000, train loss = 0.164581, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 14:26:41.558027] Iteration 72100, train loss = 0.172357, train accuracy = 0.992188\n",
      "[2018-07-16 14:26:45.671048] Iteration 72200, train loss = 0.160060, train accuracy = 0.992188\n",
      "[2018-07-16 14:26:49.729257] Iteration 72300, train loss = 0.150772, train accuracy = 1.000000\n",
      "[2018-07-16 14:26:53.792226] Iteration 72400, train loss = 0.172568, train accuracy = 0.992188\n",
      "[2018-07-16 14:26:57.873237] Iteration 72500, train loss = 0.155067, train accuracy = 1.000000\n",
      "[2018-07-16 14:27:01.961733] Iteration 72600, train loss = 0.154931, train accuracy = 1.000000\n",
      "[2018-07-16 14:27:06.048351] Iteration 72700, train loss = 0.143712, train accuracy = 1.000000\n",
      "[2018-07-16 14:27:10.130179] Iteration 72800, train loss = 0.149890, train accuracy = 1.000000\n",
      "[2018-07-16 14:27:14.232371] Iteration 72900, train loss = 0.173470, train accuracy = 0.992188\n",
      "[2018-07-16 14:27:18.365969] Iteration 73000, train loss = 0.158176, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 14:27:23.748948] Iteration 73100, train loss = 0.152877, train accuracy = 1.000000\n",
      "[2018-07-16 14:27:27.840820] Iteration 73200, train loss = 0.148396, train accuracy = 1.000000\n",
      "[2018-07-16 14:27:31.928646] Iteration 73300, train loss = 0.147393, train accuracy = 1.000000\n",
      "[2018-07-16 14:27:35.977482] Iteration 73400, train loss = 0.161325, train accuracy = 0.992188\n",
      "[2018-07-16 14:27:40.036269] Iteration 73500, train loss = 0.179540, train accuracy = 0.992188\n",
      "[2018-07-16 14:27:44.092388] Iteration 73600, train loss = 0.180446, train accuracy = 0.992188\n",
      "[2018-07-16 14:27:48.215996] Iteration 73700, train loss = 0.199700, train accuracy = 0.984375\n",
      "[2018-07-16 14:27:52.294950] Iteration 73800, train loss = 0.179498, train accuracy = 0.984375\n",
      "[2018-07-16 14:27:56.398847] Iteration 73900, train loss = 0.163214, train accuracy = 0.992188\n",
      "[2018-07-16 14:28:00.491081] Iteration 74000, train loss = 0.151072, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-07-16 14:28:05.878652] Iteration 74100, train loss = 0.155181, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:09.968113] Iteration 74200, train loss = 0.154412, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:14.081288] Iteration 74300, train loss = 0.163738, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:18.161592] Iteration 74400, train loss = 0.149492, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:22.288239] Iteration 74500, train loss = 0.153206, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:26.350675] Iteration 74600, train loss = 0.156506, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:30.414427] Iteration 74700, train loss = 0.164379, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:34.472173] Iteration 74800, train loss = 0.164815, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:38.579661] Iteration 74900, train loss = 0.145881, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:42.659279] Iteration 75000, train loss = 0.151072, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-07-16 14:28:48.031751] Iteration 75100, train loss = 0.153258, train accuracy = 1.000000\n",
      "[2018-07-16 14:28:52.159511] Iteration 75200, train loss = 0.188733, train accuracy = 0.984375\n",
      "[2018-07-16 14:28:56.266261] Iteration 75300, train loss = 0.148446, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:00.368362] Iteration 75400, train loss = 0.164384, train accuracy = 0.984375\n",
      "[2018-07-16 14:29:04.457628] Iteration 75500, train loss = 0.160580, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:08.537923] Iteration 75600, train loss = 0.153600, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:12.609838] Iteration 75700, train loss = 0.159714, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:16.674377] Iteration 75800, train loss = 0.158292, train accuracy = 0.992188\n",
      "[2018-07-16 14:29:20.736109] Iteration 75900, train loss = 0.159443, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:24.845563] Iteration 76000, train loss = 0.170780, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-07-16 14:29:30.218895] Iteration 76100, train loss = 0.154668, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:34.305487] Iteration 76200, train loss = 0.146105, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:38.410101] Iteration 76300, train loss = 0.162988, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:42.485931] Iteration 76400, train loss = 0.147945, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:46.567034] Iteration 76500, train loss = 0.155234, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:50.670356] Iteration 76600, train loss = 0.154749, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:54.809794] Iteration 76700, train loss = 0.148872, train accuracy = 1.000000\n",
      "[2018-07-16 14:29:58.893358] Iteration 76800, train loss = 0.171157, train accuracy = 0.992188\n",
      "[2018-07-16 14:30:02.953710] Iteration 76900, train loss = 0.163700, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:07.021028] Iteration 77000, train loss = 0.184457, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-07-16 14:30:12.379736] Iteration 77100, train loss = 0.149168, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:16.460956] Iteration 77200, train loss = 0.155616, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:20.550160] Iteration 77300, train loss = 0.152187, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:24.642752] Iteration 77400, train loss = 0.179928, train accuracy = 0.992188\n",
      "[2018-07-16 14:30:28.803688] Iteration 77500, train loss = 0.157163, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:32.897317] Iteration 77600, train loss = 0.147823, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:36.972249] Iteration 77700, train loss = 0.158073, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:41.063388] Iteration 77800, train loss = 0.167129, train accuracy = 0.992188\n",
      "[2018-07-16 14:30:45.131537] Iteration 77900, train loss = 0.162898, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:49.204714] Iteration 78000, train loss = 0.182283, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-07-16 14:30:54.529183] Iteration 78100, train loss = 0.158429, train accuracy = 1.000000\n",
      "[2018-07-16 14:30:58.621448] Iteration 78200, train loss = 0.185552, train accuracy = 0.992188\n",
      "[2018-07-16 14:31:02.713084] Iteration 78300, train loss = 0.168095, train accuracy = 0.984375\n",
      "[2018-07-16 14:31:06.794866] Iteration 78400, train loss = 0.177799, train accuracy = 0.984375\n",
      "[2018-07-16 14:31:10.898177] Iteration 78500, train loss = 0.158403, train accuracy = 0.992188\n",
      "[2018-07-16 14:31:14.994172] Iteration 78600, train loss = 0.154577, train accuracy = 1.000000\n",
      "[2018-07-16 14:31:19.085463] Iteration 78700, train loss = 0.152024, train accuracy = 1.000000\n",
      "[2018-07-16 14:31:23.188042] Iteration 78800, train loss = 0.151406, train accuracy = 1.000000\n",
      "[2018-07-16 14:31:27.266282] Iteration 78900, train loss = 0.171305, train accuracy = 0.992188\n",
      "[2018-07-16 14:31:31.396040] Iteration 79000, train loss = 0.146256, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-07-16 14:31:36.732265] Iteration 79100, train loss = 0.151514, train accuracy = 1.000000\n",
      "[2018-07-16 14:31:40.787449] Iteration 79200, train loss = 0.169540, train accuracy = 0.992188\n",
      "[2018-07-16 14:31:44.860156] Iteration 79300, train loss = 0.158463, train accuracy = 1.000000\n",
      "[2018-07-16 14:31:48.928275] Iteration 79400, train loss = 0.173905, train accuracy = 0.992188\n",
      "[2018-07-16 14:31:53.043694] Iteration 79500, train loss = 0.154306, train accuracy = 0.992188\n",
      "[2018-07-16 14:31:57.144015] Iteration 79600, train loss = 0.154348, train accuracy = 1.000000\n",
      "[2018-07-16 14:32:01.264098] Iteration 79700, train loss = 0.145124, train accuracy = 1.000000\n",
      "[2018-07-16 14:32:05.372582] Iteration 79800, train loss = 0.149543, train accuracy = 1.000000\n",
      "[2018-07-16 14:32:09.449425] Iteration 79900, train loss = 0.169694, train accuracy = 0.992188\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四轮  量化  \n",
    "prune_rate = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.914600\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.05908893  0.125       0.0625     -0.03125\n",
      " -0.00595839 -0.0625      0.03125    -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,1)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-16 14:33:00.294462] Iteration 100, train loss = 0.175085, train accuracy = 0.984375\n",
      "[2018-07-16 14:33:03.385574] Iteration 200, train loss = 0.216012, train accuracy = 0.976562\n",
      "[2018-07-16 14:33:06.531988] Iteration 300, train loss = 0.178736, train accuracy = 0.992188\n",
      "[2018-07-16 14:33:09.612563] Iteration 400, train loss = 0.219113, train accuracy = 0.960938\n",
      "[2018-07-16 14:33:12.749229] Iteration 500, train loss = 0.209105, train accuracy = 0.968750\n",
      "[2018-07-16 14:33:15.895619] Iteration 600, train loss = 0.184170, train accuracy = 0.968750\n",
      "[2018-07-16 14:33:19.065369] Iteration 700, train loss = 0.186260, train accuracy = 0.976562\n",
      "[2018-07-16 14:33:22.254035] Iteration 800, train loss = 0.213631, train accuracy = 0.968750\n",
      "[2018-07-16 14:33:25.464170] Iteration 900, train loss = 0.175624, train accuracy = 0.992188\n",
      "[2018-07-16 14:33:28.709551] Iteration 1000, train loss = 0.202108, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.903500\n",
      "[2018-07-16 14:33:33.114793] Iteration 1100, train loss = 0.222586, train accuracy = 0.976562\n",
      "[2018-07-16 14:33:36.484256] Iteration 1200, train loss = 0.225547, train accuracy = 0.968750\n",
      "[2018-07-16 14:33:39.752651] Iteration 1300, train loss = 0.186112, train accuracy = 0.984375\n",
      "[2018-07-16 14:33:43.079661] Iteration 1400, train loss = 0.169092, train accuracy = 0.992188\n",
      "[2018-07-16 14:33:46.401217] Iteration 1500, train loss = 0.174287, train accuracy = 0.992188\n",
      "[2018-07-16 14:33:49.706634] Iteration 1600, train loss = 0.261702, train accuracy = 0.960938\n",
      "[2018-07-16 14:33:53.016134] Iteration 1700, train loss = 0.187994, train accuracy = 0.976562\n",
      "[2018-07-16 14:33:56.319123] Iteration 1800, train loss = 0.199488, train accuracy = 0.968750\n",
      "[2018-07-16 14:33:59.607502] Iteration 1900, train loss = 0.195038, train accuracy = 0.976562\n",
      "[2018-07-16 14:34:02.916846] Iteration 2000, train loss = 0.246902, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.902800\n",
      "[2018-07-16 14:34:07.446620] Iteration 2100, train loss = 0.196373, train accuracy = 0.984375\n",
      "[2018-07-16 14:34:10.809626] Iteration 2200, train loss = 0.169154, train accuracy = 1.000000\n",
      "[2018-07-16 14:34:14.137439] Iteration 2300, train loss = 0.156631, train accuracy = 1.000000\n",
      "[2018-07-16 14:34:17.495919] Iteration 2400, train loss = 0.201799, train accuracy = 0.984375\n",
      "[2018-07-16 14:34:20.863421] Iteration 2500, train loss = 0.182142, train accuracy = 0.976562\n",
      "[2018-07-16 14:34:24.172709] Iteration 2600, train loss = 0.184591, train accuracy = 0.984375\n",
      "[2018-07-16 14:34:27.497078] Iteration 2700, train loss = 0.176531, train accuracy = 0.992188\n",
      "[2018-07-16 14:34:30.847826] Iteration 2800, train loss = 0.216820, train accuracy = 0.976562\n",
      "[2018-07-16 14:34:34.203175] Iteration 2900, train loss = 0.262148, train accuracy = 0.953125\n",
      "[2018-07-16 14:34:37.574462] Iteration 3000, train loss = 0.176174, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:34:42.257471] Iteration 3100, train loss = 0.210851, train accuracy = 0.976562\n",
      "[2018-07-16 14:34:45.608458] Iteration 3200, train loss = 0.184345, train accuracy = 0.976562\n",
      "[2018-07-16 14:34:48.974529] Iteration 3300, train loss = 0.195441, train accuracy = 0.976562\n",
      "[2018-07-16 14:34:52.316345] Iteration 3400, train loss = 0.177208, train accuracy = 1.000000\n",
      "[2018-07-16 14:34:55.664360] Iteration 3500, train loss = 0.232029, train accuracy = 0.960938\n",
      "[2018-07-16 14:34:59.025854] Iteration 3600, train loss = 0.219733, train accuracy = 0.968750\n",
      "[2018-07-16 14:35:02.387844] Iteration 3700, train loss = 0.195504, train accuracy = 0.984375\n",
      "[2018-07-16 14:35:05.728944] Iteration 3800, train loss = 0.191909, train accuracy = 0.992188\n",
      "[2018-07-16 14:35:09.100817] Iteration 3900, train loss = 0.254922, train accuracy = 0.945312\n",
      "[2018-07-16 14:35:12.521070] Iteration 4000, train loss = 0.211439, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:35:17.146993] Iteration 4100, train loss = 0.201253, train accuracy = 0.984375\n",
      "[2018-07-16 14:35:20.513170] Iteration 4200, train loss = 0.220166, train accuracy = 0.968750\n",
      "[2018-07-16 14:35:23.883706] Iteration 4300, train loss = 0.223342, train accuracy = 0.976562\n",
      "[2018-07-16 14:35:27.260878] Iteration 4400, train loss = 0.199346, train accuracy = 0.976562\n",
      "[2018-07-16 14:35:30.601336] Iteration 4500, train loss = 0.173285, train accuracy = 0.992188\n",
      "[2018-07-16 14:35:33.927173] Iteration 4600, train loss = 0.222801, train accuracy = 0.984375\n",
      "[2018-07-16 14:35:37.280113] Iteration 4700, train loss = 0.240594, train accuracy = 0.953125\n",
      "[2018-07-16 14:35:40.617193] Iteration 4800, train loss = 0.182658, train accuracy = 0.992188\n",
      "[2018-07-16 14:35:44.029368] Iteration 4900, train loss = 0.210459, train accuracy = 0.976562\n",
      "[2018-07-16 14:35:47.387884] Iteration 5000, train loss = 0.214272, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:35:52.015648] Iteration 5100, train loss = 0.193064, train accuracy = 0.984375\n",
      "[2018-07-16 14:35:55.392778] Iteration 5200, train loss = 0.204212, train accuracy = 0.984375\n",
      "[2018-07-16 14:35:58.777663] Iteration 5300, train loss = 0.195885, train accuracy = 0.984375\n",
      "[2018-07-16 14:36:02.158193] Iteration 5400, train loss = 0.188693, train accuracy = 0.984375\n",
      "[2018-07-16 14:36:05.564697] Iteration 5500, train loss = 0.178280, train accuracy = 1.000000\n",
      "[2018-07-16 14:36:08.948468] Iteration 5600, train loss = 0.182250, train accuracy = 0.984375\n",
      "[2018-07-16 14:36:12.325370] Iteration 5700, train loss = 0.227789, train accuracy = 0.960938\n",
      "[2018-07-16 14:36:15.701484] Iteration 5800, train loss = 0.233038, train accuracy = 0.960938\n",
      "[2018-07-16 14:36:19.089032] Iteration 5900, train loss = 0.190388, train accuracy = 0.984375\n",
      "[2018-07-16 14:36:22.446600] Iteration 6000, train loss = 0.178529, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 14:36:27.028728] Iteration 6100, train loss = 0.203667, train accuracy = 0.976562\n",
      "[2018-07-16 14:36:30.403743] Iteration 6200, train loss = 0.232034, train accuracy = 0.984375\n",
      "[2018-07-16 14:36:33.744666] Iteration 6300, train loss = 0.204410, train accuracy = 0.968750\n",
      "[2018-07-16 14:36:37.122483] Iteration 6400, train loss = 0.191038, train accuracy = 0.984375\n",
      "[2018-07-16 14:36:40.508014] Iteration 6500, train loss = 0.177787, train accuracy = 0.992188\n",
      "[2018-07-16 14:36:43.897984] Iteration 6600, train loss = 0.206944, train accuracy = 0.976562\n",
      "[2018-07-16 14:36:47.307265] Iteration 6700, train loss = 0.196568, train accuracy = 0.968750\n",
      "[2018-07-16 14:36:50.617096] Iteration 6800, train loss = 0.180695, train accuracy = 0.992188\n",
      "[2018-07-16 14:36:53.982531] Iteration 6900, train loss = 0.164893, train accuracy = 1.000000\n",
      "[2018-07-16 14:36:57.350444] Iteration 7000, train loss = 0.188236, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:37:02.004046] Iteration 7100, train loss = 0.186456, train accuracy = 0.984375\n",
      "[2018-07-16 14:37:05.399563] Iteration 7200, train loss = 0.197141, train accuracy = 0.984375\n",
      "[2018-07-16 14:37:08.754758] Iteration 7300, train loss = 0.186317, train accuracy = 0.976562\n",
      "[2018-07-16 14:37:12.111936] Iteration 7400, train loss = 0.211264, train accuracy = 0.976562\n",
      "[2018-07-16 14:37:15.484702] Iteration 7500, train loss = 0.206034, train accuracy = 0.968750\n",
      "[2018-07-16 14:37:18.846232] Iteration 7600, train loss = 0.205828, train accuracy = 0.968750\n",
      "[2018-07-16 14:37:22.273154] Iteration 7700, train loss = 0.222227, train accuracy = 0.976562\n",
      "[2018-07-16 14:37:25.647888] Iteration 7800, train loss = 0.258884, train accuracy = 0.945312\n",
      "[2018-07-16 14:37:29.039464] Iteration 7900, train loss = 0.161242, train accuracy = 1.000000\n",
      "[2018-07-16 14:37:32.410138] Iteration 8000, train loss = 0.177208, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 14:37:37.046959] Iteration 8100, train loss = 0.230546, train accuracy = 0.976562\n",
      "[2018-07-16 14:37:40.435613] Iteration 8200, train loss = 0.228132, train accuracy = 0.960938\n",
      "[2018-07-16 14:37:43.809548] Iteration 8300, train loss = 0.163529, train accuracy = 0.992188\n",
      "[2018-07-16 14:37:47.202671] Iteration 8400, train loss = 0.244342, train accuracy = 0.960938\n",
      "[2018-07-16 14:37:50.613309] Iteration 8500, train loss = 0.174863, train accuracy = 0.984375\n",
      "[2018-07-16 14:37:54.044904] Iteration 8600, train loss = 0.184528, train accuracy = 0.984375\n",
      "[2018-07-16 14:37:57.410549] Iteration 8700, train loss = 0.223987, train accuracy = 0.960938\n",
      "[2018-07-16 14:38:00.776461] Iteration 8800, train loss = 0.191166, train accuracy = 0.968750\n",
      "[2018-07-16 14:38:04.127182] Iteration 8900, train loss = 0.162244, train accuracy = 1.000000\n",
      "[2018-07-16 14:38:07.471423] Iteration 9000, train loss = 0.177278, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903400\n",
      "[2018-07-16 14:38:12.082664] Iteration 9100, train loss = 0.185589, train accuracy = 0.976562\n",
      "[2018-07-16 14:38:15.462136] Iteration 9200, train loss = 0.252406, train accuracy = 0.960938\n",
      "[2018-07-16 14:38:18.854173] Iteration 9300, train loss = 0.242973, train accuracy = 0.968750\n",
      "[2018-07-16 14:38:22.215099] Iteration 9400, train loss = 0.218423, train accuracy = 0.968750\n",
      "[2018-07-16 14:38:25.640724] Iteration 9500, train loss = 0.267901, train accuracy = 0.945312\n",
      "[2018-07-16 14:38:29.040755] Iteration 9600, train loss = 0.186501, train accuracy = 0.992188\n",
      "[2018-07-16 14:38:32.399055] Iteration 9700, train loss = 0.187260, train accuracy = 0.976562\n",
      "[2018-07-16 14:38:35.781546] Iteration 9800, train loss = 0.195894, train accuracy = 0.984375\n",
      "[2018-07-16 14:38:39.169240] Iteration 9900, train loss = 0.189490, train accuracy = 0.976562\n",
      "[2018-07-16 14:38:42.548640] Iteration 10000, train loss = 0.265471, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.903400\n",
      "[2018-07-16 14:38:47.141177] Iteration 10100, train loss = 0.209946, train accuracy = 0.976562\n",
      "[2018-07-16 14:38:50.469519] Iteration 10200, train loss = 0.220170, train accuracy = 0.984375\n",
      "[2018-07-16 14:38:53.838190] Iteration 10300, train loss = 0.183742, train accuracy = 0.992188\n",
      "[2018-07-16 14:38:57.240445] Iteration 10400, train loss = 0.191202, train accuracy = 0.992188\n",
      "[2018-07-16 14:39:00.627097] Iteration 10500, train loss = 0.174555, train accuracy = 0.992188\n",
      "[2018-07-16 14:39:04.013979] Iteration 10600, train loss = 0.227499, train accuracy = 0.960938\n",
      "[2018-07-16 14:39:07.396364] Iteration 10700, train loss = 0.240953, train accuracy = 0.960938\n",
      "[2018-07-16 14:39:10.778292] Iteration 10800, train loss = 0.220341, train accuracy = 0.960938\n",
      "[2018-07-16 14:39:14.150800] Iteration 10900, train loss = 0.195829, train accuracy = 0.976562\n",
      "[2018-07-16 14:39:17.515733] Iteration 11000, train loss = 0.323238, train accuracy = 0.921875\n",
      "Evaluating...\n",
      "Test accuracy = 0.903500\n",
      "[2018-07-16 14:39:22.129428] Iteration 11100, train loss = 0.214540, train accuracy = 0.984375\n",
      "[2018-07-16 14:39:25.509348] Iteration 11200, train loss = 0.185577, train accuracy = 0.984375\n",
      "[2018-07-16 14:39:28.941902] Iteration 11300, train loss = 0.177958, train accuracy = 0.984375\n",
      "[2018-07-16 14:39:32.309732] Iteration 11400, train loss = 0.237022, train accuracy = 0.968750\n",
      "[2018-07-16 14:39:35.678148] Iteration 11500, train loss = 0.231943, train accuracy = 0.960938\n",
      "[2018-07-16 14:39:39.030220] Iteration 11600, train loss = 0.211805, train accuracy = 0.976562\n",
      "[2018-07-16 14:39:42.369449] Iteration 11700, train loss = 0.211992, train accuracy = 0.976562\n",
      "[2018-07-16 14:39:45.718946] Iteration 11800, train loss = 0.211004, train accuracy = 0.976562\n",
      "[2018-07-16 14:39:49.081658] Iteration 11900, train loss = 0.179743, train accuracy = 0.992188\n",
      "[2018-07-16 14:39:52.460076] Iteration 12000, train loss = 0.170228, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.904200\n",
      "[2018-07-16 14:39:57.054384] Iteration 12100, train loss = 0.164890, train accuracy = 1.000000\n",
      "[2018-07-16 14:40:00.485296] Iteration 12200, train loss = 0.230036, train accuracy = 0.968750\n",
      "[2018-07-16 14:40:03.858658] Iteration 12300, train loss = 0.273924, train accuracy = 0.968750\n",
      "[2018-07-16 14:40:07.243097] Iteration 12400, train loss = 0.180414, train accuracy = 0.984375\n",
      "[2018-07-16 14:40:10.629804] Iteration 12500, train loss = 0.173780, train accuracy = 0.992188\n",
      "[2018-07-16 14:40:14.007436] Iteration 12600, train loss = 0.174014, train accuracy = 0.984375\n",
      "[2018-07-16 14:40:17.399361] Iteration 12700, train loss = 0.201327, train accuracy = 0.976562\n",
      "[2018-07-16 14:40:20.738814] Iteration 12800, train loss = 0.170190, train accuracy = 0.984375\n",
      "[2018-07-16 14:40:24.100662] Iteration 12900, train loss = 0.234838, train accuracy = 0.968750\n",
      "[2018-07-16 14:40:27.450258] Iteration 13000, train loss = 0.175901, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:40:32.093281] Iteration 13100, train loss = 0.195015, train accuracy = 0.976562\n",
      "[2018-07-16 14:40:35.452058] Iteration 13200, train loss = 0.164369, train accuracy = 0.992188\n",
      "[2018-07-16 14:40:38.845970] Iteration 13300, train loss = 0.220006, train accuracy = 0.976562\n",
      "[2018-07-16 14:40:42.222247] Iteration 13400, train loss = 0.188806, train accuracy = 0.984375\n",
      "[2018-07-16 14:40:45.598338] Iteration 13500, train loss = 0.241690, train accuracy = 0.960938\n",
      "[2018-07-16 14:40:48.924896] Iteration 13600, train loss = 0.203188, train accuracy = 0.976562\n",
      "[2018-07-16 14:40:52.307342] Iteration 13700, train loss = 0.275707, train accuracy = 0.976562\n",
      "[2018-07-16 14:40:55.714967] Iteration 13800, train loss = 0.185013, train accuracy = 1.000000\n",
      "[2018-07-16 14:40:59.078733] Iteration 13900, train loss = 0.178182, train accuracy = 0.992188\n",
      "[2018-07-16 14:41:02.479007] Iteration 14000, train loss = 0.196435, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "[2018-07-16 14:41:07.208567] Iteration 14100, train loss = 0.251740, train accuracy = 0.960938\n",
      "[2018-07-16 14:41:10.573499] Iteration 14200, train loss = 0.206780, train accuracy = 0.976562\n",
      "[2018-07-16 14:41:13.939184] Iteration 14300, train loss = 0.173231, train accuracy = 0.992188\n",
      "[2018-07-16 14:41:17.296180] Iteration 14400, train loss = 0.184431, train accuracy = 0.984375\n",
      "[2018-07-16 14:41:20.651946] Iteration 14500, train loss = 0.200412, train accuracy = 0.976562\n",
      "[2018-07-16 14:41:24.035710] Iteration 14600, train loss = 0.200672, train accuracy = 0.976562\n",
      "[2018-07-16 14:41:27.424682] Iteration 14700, train loss = 0.226012, train accuracy = 0.968750\n",
      "[2018-07-16 14:41:30.813431] Iteration 14800, train loss = 0.174529, train accuracy = 0.984375\n",
      "[2018-07-16 14:41:34.200325] Iteration 14900, train loss = 0.244641, train accuracy = 0.953125\n",
      "[2018-07-16 14:41:37.648453] Iteration 15000, train loss = 0.207914, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.903400\n",
      "[2018-07-16 14:41:42.280709] Iteration 15100, train loss = 0.217996, train accuracy = 0.960938\n",
      "[2018-07-16 14:41:45.632117] Iteration 15200, train loss = 0.204968, train accuracy = 0.976562\n",
      "[2018-07-16 14:41:49.017939] Iteration 15300, train loss = 0.155240, train accuracy = 1.000000\n",
      "[2018-07-16 14:41:52.398864] Iteration 15400, train loss = 0.229169, train accuracy = 0.960938\n",
      "[2018-07-16 14:41:55.807484] Iteration 15500, train loss = 0.199169, train accuracy = 0.976562\n",
      "[2018-07-16 14:41:59.174559] Iteration 15600, train loss = 0.220753, train accuracy = 0.976562\n",
      "[2018-07-16 14:42:02.547055] Iteration 15700, train loss = 0.221279, train accuracy = 0.976562\n",
      "[2018-07-16 14:42:05.895247] Iteration 15800, train loss = 0.204104, train accuracy = 0.984375\n",
      "[2018-07-16 14:42:09.309464] Iteration 15900, train loss = 0.173737, train accuracy = 1.000000\n",
      "[2018-07-16 14:42:12.651889] Iteration 16000, train loss = 0.221460, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "[2018-07-16 14:42:17.216328] Iteration 16100, train loss = 0.187538, train accuracy = 0.984375\n",
      "[2018-07-16 14:42:20.629906] Iteration 16200, train loss = 0.220614, train accuracy = 0.976562\n",
      "[2018-07-16 14:42:24.007379] Iteration 16300, train loss = 0.227756, train accuracy = 0.968750\n",
      "[2018-07-16 14:42:27.365976] Iteration 16400, train loss = 0.178742, train accuracy = 0.992188\n",
      "[2018-07-16 14:42:30.760769] Iteration 16500, train loss = 0.185343, train accuracy = 0.976562\n",
      "[2018-07-16 14:42:34.170247] Iteration 16600, train loss = 0.203347, train accuracy = 0.976562\n",
      "[2018-07-16 14:42:37.554018] Iteration 16700, train loss = 0.178868, train accuracy = 0.992188\n",
      "[2018-07-16 14:42:40.947650] Iteration 16800, train loss = 0.215296, train accuracy = 0.968750\n",
      "[2018-07-16 14:42:44.319728] Iteration 16900, train loss = 0.178646, train accuracy = 0.984375\n",
      "[2018-07-16 14:42:47.690684] Iteration 17000, train loss = 0.202773, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903300\n",
      "[2018-07-16 14:42:52.259301] Iteration 17100, train loss = 0.179540, train accuracy = 0.992188\n",
      "[2018-07-16 14:42:55.625431] Iteration 17200, train loss = 0.192068, train accuracy = 0.976562\n",
      "[2018-07-16 14:42:59.017194] Iteration 17300, train loss = 0.178284, train accuracy = 0.984375\n",
      "[2018-07-16 14:43:02.390868] Iteration 17400, train loss = 0.202209, train accuracy = 0.968750\n",
      "[2018-07-16 14:43:05.755307] Iteration 17500, train loss = 0.204931, train accuracy = 0.960938\n",
      "[2018-07-16 14:43:09.134783] Iteration 17600, train loss = 0.247083, train accuracy = 0.968750\n",
      "[2018-07-16 14:43:12.526681] Iteration 17700, train loss = 0.197673, train accuracy = 0.976562\n",
      "[2018-07-16 14:43:15.931697] Iteration 17800, train loss = 0.200832, train accuracy = 0.984375\n",
      "[2018-07-16 14:43:19.302339] Iteration 17900, train loss = 0.186831, train accuracy = 0.976562\n",
      "[2018-07-16 14:43:22.699931] Iteration 18000, train loss = 0.243551, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 14:43:27.337180] Iteration 18100, train loss = 0.176338, train accuracy = 0.992188\n",
      "[2018-07-16 14:43:30.683099] Iteration 18200, train loss = 0.195699, train accuracy = 0.984375\n",
      "[2018-07-16 14:43:34.062468] Iteration 18300, train loss = 0.170871, train accuracy = 1.000000\n",
      "[2018-07-16 14:43:37.439766] Iteration 18400, train loss = 0.235167, train accuracy = 0.960938\n",
      "[2018-07-16 14:43:40.791277] Iteration 18500, train loss = 0.223397, train accuracy = 0.968750\n",
      "[2018-07-16 14:43:44.210737] Iteration 18600, train loss = 0.239654, train accuracy = 0.960938\n",
      "[2018-07-16 14:43:47.570549] Iteration 18700, train loss = 0.233982, train accuracy = 0.968750\n",
      "[2018-07-16 14:43:50.938314] Iteration 18800, train loss = 0.259757, train accuracy = 0.953125\n",
      "[2018-07-16 14:43:54.304954] Iteration 18900, train loss = 0.174598, train accuracy = 0.992188\n",
      "[2018-07-16 14:43:57.708933] Iteration 19000, train loss = 0.340380, train accuracy = 0.929688\n",
      "Evaluating...\n",
      "Test accuracy = 0.903900\n",
      "[2018-07-16 14:44:02.324548] Iteration 19100, train loss = 0.190993, train accuracy = 0.984375\n",
      "[2018-07-16 14:44:05.704239] Iteration 19200, train loss = 0.201956, train accuracy = 0.984375\n",
      "[2018-07-16 14:44:09.105310] Iteration 19300, train loss = 0.172604, train accuracy = 0.992188\n",
      "[2018-07-16 14:44:12.483780] Iteration 19400, train loss = 0.185155, train accuracy = 0.976562\n",
      "[2018-07-16 14:44:15.923176] Iteration 19500, train loss = 0.207934, train accuracy = 0.968750\n",
      "[2018-07-16 14:44:19.261913] Iteration 19600, train loss = 0.217408, train accuracy = 0.968750\n",
      "[2018-07-16 14:44:22.638730] Iteration 19700, train loss = 0.200327, train accuracy = 0.968750\n",
      "[2018-07-16 14:44:25.997712] Iteration 19800, train loss = 0.173813, train accuracy = 0.992188\n",
      "[2018-07-16 14:44:29.361536] Iteration 19900, train loss = 0.210720, train accuracy = 0.960938\n",
      "[2018-07-16 14:44:32.704813] Iteration 20000, train loss = 0.215008, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 14:44:37.263032] Iteration 20100, train loss = 0.218847, train accuracy = 0.960938\n",
      "[2018-07-16 14:44:40.641826] Iteration 20200, train loss = 0.206390, train accuracy = 0.968750\n",
      "[2018-07-16 14:44:44.027964] Iteration 20300, train loss = 0.187244, train accuracy = 0.976562\n",
      "[2018-07-16 14:44:47.448375] Iteration 20400, train loss = 0.176232, train accuracy = 0.992188\n",
      "[2018-07-16 14:44:50.843443] Iteration 20500, train loss = 0.180276, train accuracy = 0.992188\n",
      "[2018-07-16 14:44:54.230865] Iteration 20600, train loss = 0.224722, train accuracy = 0.976562\n",
      "[2018-07-16 14:44:57.611723] Iteration 20700, train loss = 0.236056, train accuracy = 0.960938\n",
      "[2018-07-16 14:45:00.938575] Iteration 20800, train loss = 0.220247, train accuracy = 0.960938\n",
      "[2018-07-16 14:45:04.319175] Iteration 20900, train loss = 0.231286, train accuracy = 0.968750\n",
      "[2018-07-16 14:45:07.688091] Iteration 21000, train loss = 0.246090, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903400\n",
      "[2018-07-16 14:45:12.279142] Iteration 21100, train loss = 0.186543, train accuracy = 0.992188\n",
      "[2018-07-16 14:45:15.620461] Iteration 21200, train loss = 0.194659, train accuracy = 0.976562\n",
      "[2018-07-16 14:45:18.994889] Iteration 21300, train loss = 0.151350, train accuracy = 1.000000\n",
      "[2018-07-16 14:45:22.375166] Iteration 21400, train loss = 0.176097, train accuracy = 0.992188\n",
      "[2018-07-16 14:45:25.768347] Iteration 21500, train loss = 0.241286, train accuracy = 0.953125\n",
      "[2018-07-16 14:45:29.140324] Iteration 21600, train loss = 0.166619, train accuracy = 1.000000\n",
      "[2018-07-16 14:45:32.534030] Iteration 21700, train loss = 0.207429, train accuracy = 0.968750\n",
      "[2018-07-16 14:45:35.926597] Iteration 21800, train loss = 0.170036, train accuracy = 1.000000\n",
      "[2018-07-16 14:45:39.304937] Iteration 21900, train loss = 0.225991, train accuracy = 0.960938\n",
      "[2018-07-16 14:45:42.691402] Iteration 22000, train loss = 0.156136, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:45:47.302078] Iteration 22100, train loss = 0.201572, train accuracy = 0.984375\n",
      "[2018-07-16 14:45:50.666939] Iteration 22200, train loss = 0.233019, train accuracy = 0.968750\n",
      "[2018-07-16 14:45:54.090048] Iteration 22300, train loss = 0.192896, train accuracy = 0.976562\n",
      "[2018-07-16 14:45:57.460285] Iteration 22400, train loss = 0.222127, train accuracy = 0.960938\n",
      "[2018-07-16 14:46:00.833296] Iteration 22500, train loss = 0.330231, train accuracy = 0.945312\n",
      "[2018-07-16 14:46:04.177740] Iteration 22600, train loss = 0.198400, train accuracy = 0.976562\n",
      "[2018-07-16 14:46:07.523183] Iteration 22700, train loss = 0.206729, train accuracy = 0.968750\n",
      "[2018-07-16 14:46:10.913280] Iteration 22800, train loss = 0.189935, train accuracy = 0.984375\n",
      "[2018-07-16 14:46:14.301628] Iteration 22900, train loss = 0.289473, train accuracy = 0.960938\n",
      "[2018-07-16 14:46:17.700906] Iteration 23000, train loss = 0.173686, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.902500\n",
      "[2018-07-16 14:46:22.330893] Iteration 23100, train loss = 0.223651, train accuracy = 0.968750\n",
      "[2018-07-16 14:46:25.760873] Iteration 23200, train loss = 0.216644, train accuracy = 0.984375\n",
      "[2018-07-16 14:46:29.153774] Iteration 23300, train loss = 0.239192, train accuracy = 0.953125\n",
      "[2018-07-16 14:46:32.549499] Iteration 23400, train loss = 0.225910, train accuracy = 0.968750\n",
      "[2018-07-16 14:46:35.912866] Iteration 23500, train loss = 0.201358, train accuracy = 0.968750\n",
      "[2018-07-16 14:46:39.332473] Iteration 23600, train loss = 0.290346, train accuracy = 0.945312\n",
      "[2018-07-16 14:46:42.734387] Iteration 23700, train loss = 0.207687, train accuracy = 0.968750\n",
      "[2018-07-16 14:46:46.103049] Iteration 23800, train loss = 0.181691, train accuracy = 0.992188\n",
      "[2018-07-16 14:46:49.487815] Iteration 23900, train loss = 0.197841, train accuracy = 0.984375\n",
      "[2018-07-16 14:46:52.868483] Iteration 24000, train loss = 0.188476, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.904000\n",
      "[2018-07-16 14:46:57.491361] Iteration 24100, train loss = 0.175351, train accuracy = 0.992188\n",
      "[2018-07-16 14:47:00.844129] Iteration 24200, train loss = 0.221944, train accuracy = 0.968750\n",
      "[2018-07-16 14:47:04.228968] Iteration 24300, train loss = 0.265384, train accuracy = 0.937500\n",
      "[2018-07-16 14:47:07.617800] Iteration 24400, train loss = 0.240963, train accuracy = 0.960938\n",
      "[2018-07-16 14:47:10.996903] Iteration 24500, train loss = 0.238180, train accuracy = 0.976562\n",
      "[2018-07-16 14:47:14.355349] Iteration 24600, train loss = 0.163672, train accuracy = 0.992188\n",
      "[2018-07-16 14:47:17.763170] Iteration 24700, train loss = 0.186054, train accuracy = 0.984375\n",
      "[2018-07-16 14:47:21.118497] Iteration 24800, train loss = 0.235482, train accuracy = 0.968750\n",
      "[2018-07-16 14:47:24.499924] Iteration 24900, train loss = 0.229156, train accuracy = 0.960938\n",
      "[2018-07-16 14:47:27.923948] Iteration 25000, train loss = 0.220988, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.904000\n",
      "[2018-07-16 14:47:32.542667] Iteration 25100, train loss = 0.192518, train accuracy = 0.984375\n",
      "[2018-07-16 14:47:35.910367] Iteration 25200, train loss = 0.230714, train accuracy = 0.960938\n",
      "[2018-07-16 14:47:39.234149] Iteration 25300, train loss = 0.199299, train accuracy = 0.984375\n",
      "[2018-07-16 14:47:42.582920] Iteration 25400, train loss = 0.208503, train accuracy = 0.976562\n",
      "[2018-07-16 14:47:45.914341] Iteration 25500, train loss = 0.207583, train accuracy = 0.976562\n",
      "[2018-07-16 14:47:49.282881] Iteration 25600, train loss = 0.172362, train accuracy = 0.992188\n",
      "[2018-07-16 14:47:52.655585] Iteration 25700, train loss = 0.211910, train accuracy = 0.976562\n",
      "[2018-07-16 14:47:56.046872] Iteration 25800, train loss = 0.262824, train accuracy = 0.953125\n",
      "[2018-07-16 14:47:59.475875] Iteration 25900, train loss = 0.202476, train accuracy = 0.968750\n",
      "[2018-07-16 14:48:02.831112] Iteration 26000, train loss = 0.206106, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:48:07.429846] Iteration 26100, train loss = 0.264512, train accuracy = 0.929688\n",
      "[2018-07-16 14:48:10.846728] Iteration 26200, train loss = 0.228515, train accuracy = 0.960938\n",
      "[2018-07-16 14:48:14.238787] Iteration 26300, train loss = 0.188133, train accuracy = 0.984375\n",
      "[2018-07-16 14:48:17.597312] Iteration 26400, train loss = 0.294886, train accuracy = 0.960938\n",
      "[2018-07-16 14:48:20.966437] Iteration 26500, train loss = 0.165983, train accuracy = 0.984375\n",
      "[2018-07-16 14:48:24.350300] Iteration 26600, train loss = 0.172288, train accuracy = 0.992188\n",
      "[2018-07-16 14:48:27.720874] Iteration 26700, train loss = 0.178994, train accuracy = 0.984375\n",
      "[2018-07-16 14:48:31.120271] Iteration 26800, train loss = 0.250699, train accuracy = 0.953125\n",
      "[2018-07-16 14:48:34.436457] Iteration 26900, train loss = 0.185406, train accuracy = 0.984375\n",
      "[2018-07-16 14:48:37.835332] Iteration 27000, train loss = 0.230551, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903400\n",
      "[2018-07-16 14:48:42.455877] Iteration 27100, train loss = 0.190482, train accuracy = 0.984375\n",
      "[2018-07-16 14:48:45.829168] Iteration 27200, train loss = 0.211625, train accuracy = 0.976562\n",
      "[2018-07-16 14:48:49.206131] Iteration 27300, train loss = 0.239452, train accuracy = 0.968750\n",
      "[2018-07-16 14:48:52.562531] Iteration 27400, train loss = 0.185830, train accuracy = 0.984375\n",
      "[2018-07-16 14:48:55.958306] Iteration 27500, train loss = 0.223564, train accuracy = 0.968750\n",
      "[2018-07-16 14:48:59.303027] Iteration 27600, train loss = 0.255351, train accuracy = 0.953125\n",
      "[2018-07-16 14:49:02.656559] Iteration 27700, train loss = 0.194148, train accuracy = 0.976562\n",
      "[2018-07-16 14:49:06.045026] Iteration 27800, train loss = 0.269579, train accuracy = 0.960938\n",
      "[2018-07-16 14:49:09.412103] Iteration 27900, train loss = 0.198739, train accuracy = 0.968750\n",
      "[2018-07-16 14:49:12.784478] Iteration 28000, train loss = 0.190371, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 14:49:17.378907] Iteration 28100, train loss = 0.200991, train accuracy = 0.984375\n",
      "[2018-07-16 14:49:20.754451] Iteration 28200, train loss = 0.196547, train accuracy = 0.968750\n",
      "[2018-07-16 14:49:24.142862] Iteration 28300, train loss = 0.215798, train accuracy = 0.960938\n",
      "[2018-07-16 14:49:27.521546] Iteration 28400, train loss = 0.182961, train accuracy = 0.984375\n",
      "[2018-07-16 14:49:30.906166] Iteration 28500, train loss = 0.189937, train accuracy = 0.992188\n",
      "[2018-07-16 14:49:34.322685] Iteration 28600, train loss = 0.232699, train accuracy = 0.960938\n",
      "[2018-07-16 14:49:37.737929] Iteration 28700, train loss = 0.204482, train accuracy = 0.984375\n",
      "[2018-07-16 14:49:41.147708] Iteration 28800, train loss = 0.168658, train accuracy = 0.984375\n",
      "[2018-07-16 14:49:44.528598] Iteration 28900, train loss = 0.160112, train accuracy = 0.992188\n",
      "[2018-07-16 14:49:47.908701] Iteration 29000, train loss = 0.198547, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903200\n",
      "[2018-07-16 14:49:52.558831] Iteration 29100, train loss = 0.259449, train accuracy = 0.968750\n",
      "[2018-07-16 14:49:55.943912] Iteration 29200, train loss = 0.175224, train accuracy = 0.992188\n",
      "[2018-07-16 14:49:59.314108] Iteration 29300, train loss = 0.206767, train accuracy = 0.968750\n",
      "[2018-07-16 14:50:02.674124] Iteration 29400, train loss = 0.269118, train accuracy = 0.960938\n",
      "[2018-07-16 14:50:06.031461] Iteration 29500, train loss = 0.203472, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:09.455451] Iteration 29600, train loss = 0.195080, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:12.833403] Iteration 29700, train loss = 0.209774, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:16.207115] Iteration 29800, train loss = 0.245351, train accuracy = 0.960938\n",
      "[2018-07-16 14:50:19.603178] Iteration 29900, train loss = 0.182090, train accuracy = 0.992188\n",
      "[2018-07-16 14:50:22.982152] Iteration 30000, train loss = 0.193006, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.904100\n",
      "[2018-07-16 14:50:27.594399] Iteration 30100, train loss = 0.204366, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:30.961875] Iteration 30200, train loss = 0.216591, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:34.347603] Iteration 30300, train loss = 0.184788, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:37.698240] Iteration 30400, train loss = 0.244557, train accuracy = 0.953125\n",
      "[2018-07-16 14:50:41.147193] Iteration 30500, train loss = 0.208097, train accuracy = 0.968750\n",
      "[2018-07-16 14:50:44.507726] Iteration 30600, train loss = 0.200646, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:47.864509] Iteration 30700, train loss = 0.242797, train accuracy = 0.953125\n",
      "[2018-07-16 14:50:51.219828] Iteration 30800, train loss = 0.199516, train accuracy = 0.976562\n",
      "[2018-07-16 14:50:54.579243] Iteration 30900, train loss = 0.230851, train accuracy = 0.984375\n",
      "[2018-07-16 14:50:57.923203] Iteration 31000, train loss = 0.210340, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903100\n",
      "[2018-07-16 14:51:02.532044] Iteration 31100, train loss = 0.188254, train accuracy = 0.976562\n",
      "[2018-07-16 14:51:05.927577] Iteration 31200, train loss = 0.181499, train accuracy = 0.976562\n",
      "[2018-07-16 14:51:09.311109] Iteration 31300, train loss = 0.171127, train accuracy = 0.992188\n",
      "[2018-07-16 14:51:12.735992] Iteration 31400, train loss = 0.201571, train accuracy = 0.968750\n",
      "[2018-07-16 14:51:16.134005] Iteration 31500, train loss = 0.166425, train accuracy = 0.992188\n",
      "[2018-07-16 14:51:19.527434] Iteration 31600, train loss = 0.261598, train accuracy = 0.945312\n",
      "[2018-07-16 14:51:22.871893] Iteration 31700, train loss = 0.221599, train accuracy = 0.984375\n",
      "[2018-07-16 14:51:26.257290] Iteration 31800, train loss = 0.232321, train accuracy = 0.968750\n",
      "[2018-07-16 14:51:29.642564] Iteration 31900, train loss = 0.208177, train accuracy = 0.984375\n",
      "[2018-07-16 14:51:33.036070] Iteration 32000, train loss = 0.194890, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "[2018-07-16 14:51:37.617901] Iteration 32100, train loss = 0.246361, train accuracy = 0.968750\n",
      "[2018-07-16 14:51:40.956169] Iteration 32200, train loss = 0.208888, train accuracy = 0.976562\n",
      "[2018-07-16 14:51:44.369049] Iteration 32300, train loss = 0.169228, train accuracy = 0.992188\n",
      "[2018-07-16 14:51:47.761407] Iteration 32400, train loss = 0.214010, train accuracy = 0.960938\n",
      "[2018-07-16 14:51:51.125538] Iteration 32500, train loss = 0.219165, train accuracy = 0.968750\n",
      "[2018-07-16 14:51:54.505701] Iteration 32600, train loss = 0.170061, train accuracy = 1.000000\n",
      "[2018-07-16 14:51:57.894403] Iteration 32700, train loss = 0.253370, train accuracy = 0.945312\n",
      "[2018-07-16 14:52:01.271498] Iteration 32800, train loss = 0.176663, train accuracy = 0.992188\n",
      "[2018-07-16 14:52:04.622836] Iteration 32900, train loss = 0.201810, train accuracy = 0.984375\n",
      "[2018-07-16 14:52:08.026155] Iteration 33000, train loss = 0.216521, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.904000\n",
      "[2018-07-16 14:52:12.630011] Iteration 33100, train loss = 0.181665, train accuracy = 0.992188\n",
      "[2018-07-16 14:52:16.075179] Iteration 33200, train loss = 0.195381, train accuracy = 0.976562\n",
      "[2018-07-16 14:52:19.457146] Iteration 33300, train loss = 0.221971, train accuracy = 0.968750\n",
      "[2018-07-16 14:52:22.833735] Iteration 33400, train loss = 0.189208, train accuracy = 0.984375\n",
      "[2018-07-16 14:52:26.216214] Iteration 33500, train loss = 0.194566, train accuracy = 0.968750\n",
      "[2018-07-16 14:52:29.600192] Iteration 33600, train loss = 0.181527, train accuracy = 0.976562\n",
      "[2018-07-16 14:52:32.953740] Iteration 33700, train loss = 0.252610, train accuracy = 0.976562\n",
      "[2018-07-16 14:52:36.331975] Iteration 33800, train loss = 0.280449, train accuracy = 0.945312\n",
      "[2018-07-16 14:52:39.720043] Iteration 33900, train loss = 0.263926, train accuracy = 0.945312\n",
      "[2018-07-16 14:52:43.112947] Iteration 34000, train loss = 0.193347, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "[2018-07-16 14:52:47.855771] Iteration 34100, train loss = 0.200169, train accuracy = 0.984375\n",
      "[2018-07-16 14:52:51.220800] Iteration 34200, train loss = 0.164617, train accuracy = 1.000000\n",
      "[2018-07-16 14:52:54.614853] Iteration 34300, train loss = 0.199062, train accuracy = 0.968750\n",
      "[2018-07-16 14:52:57.987948] Iteration 34400, train loss = 0.213494, train accuracy = 0.960938\n",
      "[2018-07-16 14:53:01.378942] Iteration 34500, train loss = 0.195471, train accuracy = 0.976562\n",
      "[2018-07-16 14:53:04.768538] Iteration 34600, train loss = 0.178386, train accuracy = 0.984375\n",
      "[2018-07-16 14:53:08.161302] Iteration 34700, train loss = 0.201714, train accuracy = 0.984375\n",
      "[2018-07-16 14:53:11.533259] Iteration 34800, train loss = 0.182375, train accuracy = 0.976562\n",
      "[2018-07-16 14:53:14.895724] Iteration 34900, train loss = 0.169494, train accuracy = 0.992188\n",
      "[2018-07-16 14:53:18.298596] Iteration 35000, train loss = 0.263644, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.904700\n",
      "[2018-07-16 14:53:22.927948] Iteration 35100, train loss = 0.265158, train accuracy = 0.953125\n",
      "[2018-07-16 14:53:26.326180] Iteration 35200, train loss = 0.225998, train accuracy = 0.960938\n",
      "[2018-07-16 14:53:29.718228] Iteration 35300, train loss = 0.185331, train accuracy = 0.984375\n",
      "[2018-07-16 14:53:33.116064] Iteration 35400, train loss = 0.237589, train accuracy = 0.953125\n",
      "[2018-07-16 14:53:36.517513] Iteration 35500, train loss = 0.199220, train accuracy = 0.984375\n",
      "[2018-07-16 14:53:39.897624] Iteration 35600, train loss = 0.247537, train accuracy = 0.945312\n",
      "[2018-07-16 14:53:43.284919] Iteration 35700, train loss = 0.191840, train accuracy = 0.976562\n",
      "[2018-07-16 14:53:46.681821] Iteration 35800, train loss = 0.232349, train accuracy = 0.960938\n",
      "[2018-07-16 14:53:50.074653] Iteration 35900, train loss = 0.235977, train accuracy = 0.953125\n",
      "[2018-07-16 14:53:53.514739] Iteration 36000, train loss = 0.210178, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903200\n",
      "[2018-07-16 14:53:58.098268] Iteration 36100, train loss = 0.269664, train accuracy = 0.945312\n",
      "[2018-07-16 14:54:01.481157] Iteration 36200, train loss = 0.203328, train accuracy = 0.968750\n",
      "[2018-07-16 14:54:04.865533] Iteration 36300, train loss = 0.207613, train accuracy = 0.976562\n",
      "[2018-07-16 14:54:08.237518] Iteration 36400, train loss = 0.267592, train accuracy = 0.968750\n",
      "[2018-07-16 14:54:11.606135] Iteration 36500, train loss = 0.234653, train accuracy = 0.960938\n",
      "[2018-07-16 14:54:14.998488] Iteration 36600, train loss = 0.189074, train accuracy = 0.984375\n",
      "[2018-07-16 14:54:18.382397] Iteration 36700, train loss = 0.185162, train accuracy = 0.984375\n",
      "[2018-07-16 14:54:21.800667] Iteration 36800, train loss = 0.158491, train accuracy = 0.992188\n",
      "[2018-07-16 14:54:25.204104] Iteration 36900, train loss = 0.183423, train accuracy = 0.984375\n",
      "[2018-07-16 14:54:28.595408] Iteration 37000, train loss = 0.184211, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.902800\n",
      "[2018-07-16 14:54:33.248896] Iteration 37100, train loss = 0.225261, train accuracy = 0.968750\n",
      "[2018-07-16 14:54:36.660849] Iteration 37200, train loss = 0.164284, train accuracy = 0.992188\n",
      "[2018-07-16 14:54:40.033350] Iteration 37300, train loss = 0.209777, train accuracy = 0.984375\n",
      "[2018-07-16 14:54:43.406738] Iteration 37400, train loss = 0.231664, train accuracy = 0.953125\n",
      "[2018-07-16 14:54:46.777139] Iteration 37500, train loss = 0.176898, train accuracy = 0.984375\n",
      "[2018-07-16 14:54:50.144936] Iteration 37600, train loss = 0.199583, train accuracy = 0.984375\n",
      "[2018-07-16 14:54:53.538790] Iteration 37700, train loss = 0.214427, train accuracy = 0.953125\n",
      "[2018-07-16 14:54:56.953514] Iteration 37800, train loss = 0.165708, train accuracy = 1.000000\n",
      "[2018-07-16 14:55:00.316745] Iteration 37900, train loss = 0.224946, train accuracy = 0.945312\n",
      "[2018-07-16 14:55:03.703120] Iteration 38000, train loss = 0.204952, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 14:55:08.377336] Iteration 38100, train loss = 0.188423, train accuracy = 0.984375\n",
      "[2018-07-16 14:55:11.766641] Iteration 38200, train loss = 0.199746, train accuracy = 0.984375\n",
      "[2018-07-16 14:55:15.163601] Iteration 38300, train loss = 0.230867, train accuracy = 0.968750\n",
      "[2018-07-16 14:55:18.567573] Iteration 38400, train loss = 0.205906, train accuracy = 0.968750\n",
      "[2018-07-16 14:55:21.948912] Iteration 38500, train loss = 0.231243, train accuracy = 0.953125\n",
      "[2018-07-16 14:55:25.363250] Iteration 38600, train loss = 0.235313, train accuracy = 0.953125\n",
      "[2018-07-16 14:55:28.809191] Iteration 38700, train loss = 0.213395, train accuracy = 0.968750\n",
      "[2018-07-16 14:55:32.194490] Iteration 38800, train loss = 0.221984, train accuracy = 0.976562\n",
      "[2018-07-16 14:55:35.577985] Iteration 38900, train loss = 0.189679, train accuracy = 0.984375\n",
      "[2018-07-16 14:55:38.973664] Iteration 39000, train loss = 0.180316, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 14:55:43.552668] Iteration 39100, train loss = 0.211055, train accuracy = 0.984375\n",
      "[2018-07-16 14:55:46.939108] Iteration 39200, train loss = 0.275842, train accuracy = 0.953125\n",
      "[2018-07-16 14:55:50.345889] Iteration 39300, train loss = 0.178022, train accuracy = 0.984375\n",
      "[2018-07-16 14:55:53.752403] Iteration 39400, train loss = 0.192192, train accuracy = 0.976562\n",
      "[2018-07-16 14:55:57.166976] Iteration 39500, train loss = 0.200647, train accuracy = 0.968750\n",
      "[2018-07-16 14:56:00.628787] Iteration 39600, train loss = 0.168937, train accuracy = 0.992188\n",
      "[2018-07-16 14:56:04.038520] Iteration 39700, train loss = 0.171808, train accuracy = 0.984375\n",
      "[2018-07-16 14:56:07.438667] Iteration 39800, train loss = 0.201337, train accuracy = 0.984375\n",
      "[2018-07-16 14:56:10.866341] Iteration 39900, train loss = 0.253921, train accuracy = 0.968750\n",
      "[2018-07-16 14:56:14.295518] Iteration 40000, train loss = 0.217008, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903000\n",
      "[2018-07-16 14:56:18.939813] Iteration 40100, train loss = 0.180844, train accuracy = 0.992188\n",
      "[2018-07-16 14:56:22.336525] Iteration 40200, train loss = 0.208748, train accuracy = 0.976562\n",
      "[2018-07-16 14:56:25.713704] Iteration 40300, train loss = 0.194328, train accuracy = 0.984375\n",
      "[2018-07-16 14:56:29.115348] Iteration 40400, train loss = 0.182791, train accuracy = 0.984375\n",
      "[2018-07-16 14:56:32.548881] Iteration 40500, train loss = 0.264918, train accuracy = 0.960938\n",
      "[2018-07-16 14:56:35.944957] Iteration 40600, train loss = 0.212967, train accuracy = 0.960938\n",
      "[2018-07-16 14:56:39.360792] Iteration 40700, train loss = 0.210403, train accuracy = 0.984375\n",
      "[2018-07-16 14:56:42.780108] Iteration 40800, train loss = 0.195613, train accuracy = 0.984375\n",
      "[2018-07-16 14:56:46.181366] Iteration 40900, train loss = 0.183486, train accuracy = 0.976562\n",
      "[2018-07-16 14:56:49.568363] Iteration 41000, train loss = 0.218237, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "[2018-07-16 14:56:54.220416] Iteration 41100, train loss = 0.191313, train accuracy = 1.000000\n",
      "[2018-07-16 14:56:57.632352] Iteration 41200, train loss = 0.176471, train accuracy = 0.984375\n",
      "[2018-07-16 14:57:01.040966] Iteration 41300, train loss = 0.207702, train accuracy = 0.976562\n",
      "[2018-07-16 14:57:04.516255] Iteration 41400, train loss = 0.195922, train accuracy = 0.976562\n",
      "[2018-07-16 14:57:07.911699] Iteration 41500, train loss = 0.179325, train accuracy = 0.984375\n",
      "[2018-07-16 14:57:11.297410] Iteration 41600, train loss = 0.206491, train accuracy = 0.976562\n",
      "[2018-07-16 14:57:14.677721] Iteration 41700, train loss = 0.185679, train accuracy = 0.984375\n",
      "[2018-07-16 14:57:18.070108] Iteration 41800, train loss = 0.202149, train accuracy = 0.968750\n",
      "[2018-07-16 14:57:21.464287] Iteration 41900, train loss = 0.218449, train accuracy = 0.976562\n",
      "[2018-07-16 14:57:24.850373] Iteration 42000, train loss = 0.208309, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "[2018-07-16 14:57:29.510636] Iteration 42100, train loss = 0.195726, train accuracy = 0.976562\n",
      "[2018-07-16 14:57:32.908693] Iteration 42200, train loss = 0.215037, train accuracy = 0.960938\n",
      "[2018-07-16 14:57:36.358079] Iteration 42300, train loss = 0.186146, train accuracy = 0.984375\n",
      "[2018-07-16 14:57:39.774253] Iteration 42400, train loss = 0.204569, train accuracy = 0.992188\n",
      "[2018-07-16 14:57:43.176732] Iteration 42500, train loss = 0.246658, train accuracy = 0.968750\n",
      "[2018-07-16 14:57:46.584827] Iteration 42600, train loss = 0.247125, train accuracy = 0.968750\n",
      "[2018-07-16 14:57:49.997388] Iteration 42700, train loss = 0.185234, train accuracy = 0.984375\n",
      "[2018-07-16 14:57:53.402765] Iteration 42800, train loss = 0.220711, train accuracy = 0.960938\n",
      "[2018-07-16 14:57:56.774972] Iteration 42900, train loss = 0.209859, train accuracy = 0.976562\n",
      "[2018-07-16 14:58:00.153141] Iteration 43000, train loss = 0.207014, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 14:58:04.771808] Iteration 43100, train loss = 0.240009, train accuracy = 0.960938\n",
      "[2018-07-16 14:58:08.200126] Iteration 43200, train loss = 0.220196, train accuracy = 0.968750\n",
      "[2018-07-16 14:58:11.584621] Iteration 43300, train loss = 0.291491, train accuracy = 0.937500\n",
      "[2018-07-16 14:58:14.991520] Iteration 43400, train loss = 0.224906, train accuracy = 0.953125\n",
      "[2018-07-16 14:58:18.389489] Iteration 43500, train loss = 0.236399, train accuracy = 0.945312\n",
      "[2018-07-16 14:58:21.803640] Iteration 43600, train loss = 0.191810, train accuracy = 0.984375\n",
      "[2018-07-16 14:58:25.208968] Iteration 43700, train loss = 0.215155, train accuracy = 0.976562\n",
      "[2018-07-16 14:58:28.619976] Iteration 43800, train loss = 0.313837, train accuracy = 0.921875\n",
      "[2018-07-16 14:58:32.038349] Iteration 43900, train loss = 0.220246, train accuracy = 0.968750\n",
      "[2018-07-16 14:58:35.449150] Iteration 44000, train loss = 0.196246, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903500\n",
      "[2018-07-16 14:58:40.172994] Iteration 44100, train loss = 0.199900, train accuracy = 0.976562\n",
      "[2018-07-16 14:58:43.546017] Iteration 44200, train loss = 0.178330, train accuracy = 0.992188\n",
      "[2018-07-16 14:58:46.942298] Iteration 44300, train loss = 0.176749, train accuracy = 0.992188\n",
      "[2018-07-16 14:58:50.326038] Iteration 44400, train loss = 0.193212, train accuracy = 0.976562\n",
      "[2018-07-16 14:58:53.713214] Iteration 44500, train loss = 0.225581, train accuracy = 0.984375\n",
      "[2018-07-16 14:58:57.083730] Iteration 44600, train loss = 0.193047, train accuracy = 0.976562\n",
      "[2018-07-16 14:59:00.474294] Iteration 44700, train loss = 0.204532, train accuracy = 0.968750\n",
      "[2018-07-16 14:59:03.873288] Iteration 44800, train loss = 0.239269, train accuracy = 0.976562\n",
      "[2018-07-16 14:59:07.278808] Iteration 44900, train loss = 0.241052, train accuracy = 0.960938\n",
      "[2018-07-16 14:59:10.692417] Iteration 45000, train loss = 0.185764, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903500\n",
      "[2018-07-16 14:59:15.360789] Iteration 45100, train loss = 0.220375, train accuracy = 0.976562\n",
      "[2018-07-16 14:59:18.770538] Iteration 45200, train loss = 0.222012, train accuracy = 0.968750\n",
      "[2018-07-16 14:59:22.174218] Iteration 45300, train loss = 0.184919, train accuracy = 0.984375\n",
      "[2018-07-16 14:59:25.594321] Iteration 45400, train loss = 0.189735, train accuracy = 0.968750\n",
      "[2018-07-16 14:59:29.022972] Iteration 45500, train loss = 0.216405, train accuracy = 0.968750\n",
      "[2018-07-16 14:59:32.407222] Iteration 45600, train loss = 0.193380, train accuracy = 0.984375\n",
      "[2018-07-16 14:59:35.803776] Iteration 45700, train loss = 0.163739, train accuracy = 0.992188\n",
      "[2018-07-16 14:59:39.170262] Iteration 45800, train loss = 0.215943, train accuracy = 0.976562\n",
      "[2018-07-16 14:59:42.618940] Iteration 45900, train loss = 0.223328, train accuracy = 0.960938\n",
      "[2018-07-16 14:59:46.006662] Iteration 46000, train loss = 0.205498, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903900\n",
      "[2018-07-16 14:59:50.676343] Iteration 46100, train loss = 0.181226, train accuracy = 0.984375\n",
      "[2018-07-16 14:59:54.080456] Iteration 46200, train loss = 0.206779, train accuracy = 0.968750\n",
      "[2018-07-16 14:59:57.496370] Iteration 46300, train loss = 0.221362, train accuracy = 0.976562\n",
      "[2018-07-16 15:00:00.907234] Iteration 46400, train loss = 0.240293, train accuracy = 0.960938\n",
      "[2018-07-16 15:00:04.302621] Iteration 46500, train loss = 0.217694, train accuracy = 0.960938\n",
      "[2018-07-16 15:00:07.704173] Iteration 46600, train loss = 0.172956, train accuracy = 0.992188\n",
      "[2018-07-16 15:00:11.105239] Iteration 46700, train loss = 0.244427, train accuracy = 0.960938\n",
      "[2018-07-16 15:00:14.567833] Iteration 46800, train loss = 0.264459, train accuracy = 0.937500\n",
      "[2018-07-16 15:00:17.964400] Iteration 46900, train loss = 0.268598, train accuracy = 0.953125\n",
      "[2018-07-16 15:00:21.346310] Iteration 47000, train loss = 0.174304, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 15:00:25.954233] Iteration 47100, train loss = 0.213526, train accuracy = 0.984375\n",
      "[2018-07-16 15:00:29.339977] Iteration 47200, train loss = 0.253823, train accuracy = 0.937500\n",
      "[2018-07-16 15:00:32.723675] Iteration 47300, train loss = 0.209496, train accuracy = 0.968750\n",
      "[2018-07-16 15:00:36.113650] Iteration 47400, train loss = 0.251532, train accuracy = 0.953125\n",
      "[2018-07-16 15:00:39.503494] Iteration 47500, train loss = 0.193209, train accuracy = 0.984375\n",
      "[2018-07-16 15:00:42.902442] Iteration 47600, train loss = 0.190564, train accuracy = 0.976562\n",
      "[2018-07-16 15:00:46.325843] Iteration 47700, train loss = 0.200730, train accuracy = 0.984375\n",
      "[2018-07-16 15:00:49.755519] Iteration 47800, train loss = 0.196846, train accuracy = 0.968750\n",
      "[2018-07-16 15:00:53.165570] Iteration 47900, train loss = 0.215498, train accuracy = 0.976562\n",
      "[2018-07-16 15:00:56.571192] Iteration 48000, train loss = 0.218242, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-16 15:01:01.173851] Iteration 48100, train loss = 0.193331, train accuracy = 0.976562\n",
      "[2018-07-16 15:01:04.573753] Iteration 48200, train loss = 0.246474, train accuracy = 0.968750\n",
      "[2018-07-16 15:01:07.976492] Iteration 48300, train loss = 0.185626, train accuracy = 0.976562\n",
      "[2018-07-16 15:01:11.364714] Iteration 48400, train loss = 0.191982, train accuracy = 0.984375\n",
      "[2018-07-16 15:01:14.740215] Iteration 48500, train loss = 0.224977, train accuracy = 0.960938\n",
      "[2018-07-16 15:01:18.181792] Iteration 48600, train loss = 0.164536, train accuracy = 0.984375\n",
      "[2018-07-16 15:01:21.559307] Iteration 48700, train loss = 0.182877, train accuracy = 0.976562\n",
      "[2018-07-16 15:01:24.963330] Iteration 48800, train loss = 0.205728, train accuracy = 0.976562\n",
      "[2018-07-16 15:01:28.364257] Iteration 48900, train loss = 0.258629, train accuracy = 0.945312\n",
      "[2018-07-16 15:01:31.774386] Iteration 49000, train loss = 0.194646, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.903900\n",
      "[2018-07-16 15:01:36.453379] Iteration 49100, train loss = 0.175143, train accuracy = 0.992188\n",
      "[2018-07-16 15:01:39.853975] Iteration 49200, train loss = 0.207118, train accuracy = 0.984375\n",
      "[2018-07-16 15:01:43.254629] Iteration 49300, train loss = 0.198880, train accuracy = 0.984375\n",
      "[2018-07-16 15:01:46.645736] Iteration 49400, train loss = 0.224780, train accuracy = 0.960938\n",
      "[2018-07-16 15:01:50.108959] Iteration 49500, train loss = 0.244122, train accuracy = 0.953125\n",
      "[2018-07-16 15:01:53.518167] Iteration 49600, train loss = 0.184910, train accuracy = 0.984375\n",
      "[2018-07-16 15:01:56.891497] Iteration 49700, train loss = 0.211572, train accuracy = 0.976562\n",
      "[2018-07-16 15:02:00.263828] Iteration 49800, train loss = 0.180137, train accuracy = 0.984375\n",
      "[2018-07-16 15:02:03.661169] Iteration 49900, train loss = 0.251673, train accuracy = 0.976562\n",
      "[2018-07-16 15:02:07.038338] Iteration 50000, train loss = 0.192571, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903300\n",
      "[2018-07-16 15:02:11.681097] Iteration 50100, train loss = 0.192119, train accuracy = 0.976562\n",
      "[2018-07-16 15:02:15.062284] Iteration 50200, train loss = 0.207621, train accuracy = 0.976562\n",
      "[2018-07-16 15:02:18.426784] Iteration 50300, train loss = 0.239302, train accuracy = 0.960938\n",
      "[2018-07-16 15:02:21.873528] Iteration 50400, train loss = 0.270536, train accuracy = 0.960938\n",
      "[2018-07-16 15:02:25.265009] Iteration 50500, train loss = 0.197208, train accuracy = 0.984375\n",
      "[2018-07-16 15:02:28.674359] Iteration 50600, train loss = 0.196034, train accuracy = 0.984375\n",
      "[2018-07-16 15:02:32.091785] Iteration 50700, train loss = 0.183763, train accuracy = 0.984375\n",
      "[2018-07-16 15:02:35.496148] Iteration 50800, train loss = 0.247294, train accuracy = 0.960938\n",
      "[2018-07-16 15:02:38.882982] Iteration 50900, train loss = 0.217761, train accuracy = 0.968750\n",
      "[2018-07-16 15:02:42.270744] Iteration 51000, train loss = 0.186383, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 15:02:46.860622] Iteration 51100, train loss = 0.156207, train accuracy = 1.000000\n",
      "[2018-07-16 15:02:50.248211] Iteration 51200, train loss = 0.263332, train accuracy = 0.968750\n",
      "[2018-07-16 15:02:53.698436] Iteration 51300, train loss = 0.227474, train accuracy = 0.960938\n",
      "[2018-07-16 15:02:57.009850] Iteration 51400, train loss = 0.217745, train accuracy = 0.976562\n",
      "[2018-07-16 15:03:00.334037] Iteration 51500, train loss = 0.182008, train accuracy = 0.992188\n",
      "[2018-07-16 15:03:03.663057] Iteration 51600, train loss = 0.254073, train accuracy = 0.960938\n",
      "[2018-07-16 15:03:06.997451] Iteration 51700, train loss = 0.234352, train accuracy = 0.968750\n",
      "[2018-07-16 15:03:10.328197] Iteration 51800, train loss = 0.325356, train accuracy = 0.945312\n",
      "[2018-07-16 15:03:13.659834] Iteration 51900, train loss = 0.209419, train accuracy = 0.968750\n",
      "[2018-07-16 15:03:17.003789] Iteration 52000, train loss = 0.170382, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.904000\n",
      "[2018-07-16 15:03:21.501501] Iteration 52100, train loss = 0.189377, train accuracy = 0.976562\n",
      "[2018-07-16 15:03:24.827511] Iteration 52200, train loss = 0.187737, train accuracy = 0.984375\n",
      "[2018-07-16 15:03:28.160297] Iteration 52300, train loss = 0.184199, train accuracy = 0.992188\n",
      "[2018-07-16 15:03:31.469433] Iteration 52400, train loss = 0.173822, train accuracy = 0.984375\n",
      "[2018-07-16 15:03:34.778682] Iteration 52500, train loss = 0.222112, train accuracy = 0.968750\n",
      "[2018-07-16 15:03:38.079607] Iteration 52600, train loss = 0.192708, train accuracy = 0.976562\n",
      "[2018-07-16 15:03:41.370080] Iteration 52700, train loss = 0.210980, train accuracy = 0.992188\n",
      "[2018-07-16 15:03:44.645335] Iteration 52800, train loss = 0.195799, train accuracy = 0.968750\n",
      "[2018-07-16 15:03:47.924809] Iteration 52900, train loss = 0.224372, train accuracy = 0.968750\n",
      "[2018-07-16 15:03:51.209764] Iteration 53000, train loss = 0.234945, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 15:03:55.617122] Iteration 53100, train loss = 0.206527, train accuracy = 0.968750\n",
      "[2018-07-16 15:03:58.905967] Iteration 53200, train loss = 0.221110, train accuracy = 0.984375\n",
      "[2018-07-16 15:04:02.199218] Iteration 53300, train loss = 0.202456, train accuracy = 0.968750\n",
      "[2018-07-16 15:04:05.444909] Iteration 53400, train loss = 0.224971, train accuracy = 0.960938\n",
      "[2018-07-16 15:04:08.667154] Iteration 53500, train loss = 0.244139, train accuracy = 0.960938\n",
      "[2018-07-16 15:04:11.926869] Iteration 53600, train loss = 0.198678, train accuracy = 0.984375\n",
      "[2018-07-16 15:04:15.183327] Iteration 53700, train loss = 0.181447, train accuracy = 0.984375\n",
      "[2018-07-16 15:04:18.394280] Iteration 53800, train loss = 0.225855, train accuracy = 0.976562\n",
      "[2018-07-16 15:04:21.588432] Iteration 53900, train loss = 0.177577, train accuracy = 0.992188\n",
      "[2018-07-16 15:04:24.825075] Iteration 54000, train loss = 0.187931, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903100\n",
      "[2018-07-16 15:04:29.128779] Iteration 54100, train loss = 0.171993, train accuracy = 0.992188\n",
      "[2018-07-16 15:04:32.334757] Iteration 54200, train loss = 0.220625, train accuracy = 0.968750\n",
      "[2018-07-16 15:04:35.532150] Iteration 54300, train loss = 0.209506, train accuracy = 0.984375\n",
      "[2018-07-16 15:04:38.723140] Iteration 54400, train loss = 0.202771, train accuracy = 0.968750\n",
      "[2018-07-16 15:04:41.920174] Iteration 54500, train loss = 0.211979, train accuracy = 0.976562\n",
      "[2018-07-16 15:04:45.107449] Iteration 54600, train loss = 0.181709, train accuracy = 0.992188\n",
      "[2018-07-16 15:04:48.291811] Iteration 54700, train loss = 0.160702, train accuracy = 1.000000\n",
      "[2018-07-16 15:04:51.472037] Iteration 54800, train loss = 0.231642, train accuracy = 0.976562\n",
      "[2018-07-16 15:04:54.630406] Iteration 54900, train loss = 0.226855, train accuracy = 0.968750\n",
      "[2018-07-16 15:04:57.786731] Iteration 55000, train loss = 0.188065, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.903400\n",
      "[2018-07-16 15:05:02.051736] Iteration 55100, train loss = 0.209001, train accuracy = 0.976562\n",
      "[2018-07-16 15:05:05.201364] Iteration 55200, train loss = 0.179370, train accuracy = 0.992188\n",
      "[2018-07-16 15:05:08.338650] Iteration 55300, train loss = 0.202746, train accuracy = 0.976562\n",
      "[2018-07-16 15:05:11.487789] Iteration 55400, train loss = 0.228062, train accuracy = 0.968750\n",
      "[2018-07-16 15:05:14.602523] Iteration 55500, train loss = 0.227582, train accuracy = 0.945312\n",
      "[2018-07-16 15:05:17.723414] Iteration 55600, train loss = 0.202056, train accuracy = 0.984375\n",
      "[2018-07-16 15:05:20.851460] Iteration 55700, train loss = 0.211905, train accuracy = 0.968750\n",
      "[2018-07-16 15:05:23.980324] Iteration 55800, train loss = 0.185077, train accuracy = 0.984375\n",
      "[2018-07-16 15:05:27.124121] Iteration 55900, train loss = 0.212499, train accuracy = 0.976562\n",
      "[2018-07-16 15:05:30.254038] Iteration 56000, train loss = 0.261451, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 15:05:34.459971] Iteration 56100, train loss = 0.171016, train accuracy = 0.992188\n",
      "[2018-07-16 15:05:37.575627] Iteration 56200, train loss = 0.195711, train accuracy = 0.976562\n",
      "[2018-07-16 15:05:40.691270] Iteration 56300, train loss = 0.185889, train accuracy = 0.992188\n",
      "[2018-07-16 15:05:43.821373] Iteration 56400, train loss = 0.198569, train accuracy = 0.984375\n",
      "[2018-07-16 15:05:46.936426] Iteration 56500, train loss = 0.221672, train accuracy = 0.960938\n",
      "[2018-07-16 15:05:50.061072] Iteration 56600, train loss = 0.202585, train accuracy = 0.992188\n",
      "[2018-07-16 15:05:53.174333] Iteration 56700, train loss = 0.172197, train accuracy = 0.992188\n",
      "[2018-07-16 15:05:56.260405] Iteration 56800, train loss = 0.220058, train accuracy = 0.976562\n",
      "[2018-07-16 15:05:59.338162] Iteration 56900, train loss = 0.257239, train accuracy = 0.937500\n",
      "[2018-07-16 15:06:02.410491] Iteration 57000, train loss = 0.209408, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.903000\n",
      "[2018-07-16 15:06:06.561811] Iteration 57100, train loss = 0.175942, train accuracy = 0.992188\n",
      "[2018-07-16 15:06:09.632764] Iteration 57200, train loss = 0.197823, train accuracy = 0.968750\n",
      "[2018-07-16 15:06:12.702913] Iteration 57300, train loss = 0.184384, train accuracy = 0.992188\n",
      "[2018-07-16 15:06:15.791888] Iteration 57400, train loss = 0.165062, train accuracy = 0.992188\n",
      "[2018-07-16 15:06:18.876689] Iteration 57500, train loss = 0.193466, train accuracy = 0.984375\n",
      "[2018-07-16 15:06:21.961613] Iteration 57600, train loss = 0.256657, train accuracy = 0.968750\n",
      "[2018-07-16 15:06:25.043060] Iteration 57700, train loss = 0.226517, train accuracy = 0.968750\n",
      "[2018-07-16 15:06:28.117639] Iteration 57800, train loss = 0.204782, train accuracy = 0.976562\n",
      "[2018-07-16 15:06:31.190462] Iteration 57900, train loss = 0.220292, train accuracy = 0.968750\n",
      "[2018-07-16 15:06:34.259585] Iteration 58000, train loss = 0.180241, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.904100\n",
      "[2018-07-16 15:06:38.416530] Iteration 58100, train loss = 0.251999, train accuracy = 0.960938\n",
      "[2018-07-16 15:06:41.484630] Iteration 58200, train loss = 0.189868, train accuracy = 0.984375\n",
      "[2018-07-16 15:06:44.539477] Iteration 58300, train loss = 0.200397, train accuracy = 0.976562\n",
      "[2018-07-16 15:06:47.583180] Iteration 58400, train loss = 0.273121, train accuracy = 0.960938\n",
      "[2018-07-16 15:06:50.640197] Iteration 58500, train loss = 0.223870, train accuracy = 0.976562\n",
      "[2018-07-16 15:06:53.686842] Iteration 58600, train loss = 0.223326, train accuracy = 0.976562\n",
      "[2018-07-16 15:06:56.740337] Iteration 58700, train loss = 0.206102, train accuracy = 0.984375\n",
      "[2018-07-16 15:06:59.799727] Iteration 58800, train loss = 0.175878, train accuracy = 0.984375\n",
      "[2018-07-16 15:07:02.865127] Iteration 58900, train loss = 0.176308, train accuracy = 0.992188\n",
      "[2018-07-16 15:07:05.923170] Iteration 59000, train loss = 0.176272, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903900\n",
      "[2018-07-16 15:07:10.048350] Iteration 59100, train loss = 0.169132, train accuracy = 0.992188\n",
      "[2018-07-16 15:07:13.114400] Iteration 59200, train loss = 0.192692, train accuracy = 0.984375\n",
      "[2018-07-16 15:07:16.179875] Iteration 59300, train loss = 0.184416, train accuracy = 0.984375\n",
      "[2018-07-16 15:07:19.255813] Iteration 59400, train loss = 0.186517, train accuracy = 0.976562\n",
      "[2018-07-16 15:07:22.322638] Iteration 59500, train loss = 0.164598, train accuracy = 0.992188\n",
      "[2018-07-16 15:07:25.385715] Iteration 59600, train loss = 0.162195, train accuracy = 1.000000\n",
      "[2018-07-16 15:07:28.452657] Iteration 59700, train loss = 0.205673, train accuracy = 0.976562\n",
      "[2018-07-16 15:07:31.504268] Iteration 59800, train loss = 0.201496, train accuracy = 0.976562\n",
      "[2018-07-16 15:07:34.550005] Iteration 59900, train loss = 0.182487, train accuracy = 0.976562\n",
      "[2018-07-16 15:07:37.591010] Iteration 60000, train loss = 0.230387, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 15:07:41.697018] Iteration 60100, train loss = 0.245972, train accuracy = 0.960938\n",
      "[2018-07-16 15:07:44.738678] Iteration 60200, train loss = 0.173079, train accuracy = 0.992188\n",
      "[2018-07-16 15:07:47.796606] Iteration 60300, train loss = 0.185107, train accuracy = 0.984375\n",
      "[2018-07-16 15:07:50.868686] Iteration 60400, train loss = 0.222259, train accuracy = 0.976562\n",
      "[2018-07-16 15:07:53.934152] Iteration 60500, train loss = 0.168811, train accuracy = 0.992188\n",
      "[2018-07-16 15:07:56.990584] Iteration 60600, train loss = 0.221830, train accuracy = 0.960938\n",
      "[2018-07-16 15:08:00.050745] Iteration 60700, train loss = 0.250782, train accuracy = 0.960938\n",
      "[2018-07-16 15:08:03.110581] Iteration 60800, train loss = 0.170873, train accuracy = 0.984375\n",
      "[2018-07-16 15:08:06.180359] Iteration 60900, train loss = 0.229423, train accuracy = 0.960938\n",
      "[2018-07-16 15:08:09.247474] Iteration 61000, train loss = 0.188367, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 15:08:13.359669] Iteration 61100, train loss = 0.244251, train accuracy = 0.976562\n",
      "[2018-07-16 15:08:16.420986] Iteration 61200, train loss = 0.191571, train accuracy = 0.984375\n",
      "[2018-07-16 15:08:19.480255] Iteration 61300, train loss = 0.165197, train accuracy = 0.992188\n",
      "[2018-07-16 15:08:22.517596] Iteration 61400, train loss = 0.227877, train accuracy = 0.976562\n",
      "[2018-07-16 15:08:25.554644] Iteration 61500, train loss = 0.210772, train accuracy = 0.976562\n",
      "[2018-07-16 15:08:28.600103] Iteration 61600, train loss = 0.265519, train accuracy = 0.953125\n",
      "[2018-07-16 15:08:31.643140] Iteration 61700, train loss = 0.204934, train accuracy = 0.968750\n",
      "[2018-07-16 15:08:34.689121] Iteration 61800, train loss = 0.193348, train accuracy = 0.976562\n",
      "[2018-07-16 15:08:37.745852] Iteration 61900, train loss = 0.201274, train accuracy = 0.984375\n",
      "[2018-07-16 15:08:40.802685] Iteration 62000, train loss = 0.240124, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.903900\n",
      "[2018-07-16 15:08:44.941407] Iteration 62100, train loss = 0.232087, train accuracy = 0.960938\n",
      "[2018-07-16 15:08:47.996413] Iteration 62200, train loss = 0.241336, train accuracy = 0.945312\n",
      "[2018-07-16 15:08:51.053623] Iteration 62300, train loss = 0.209582, train accuracy = 0.960938\n",
      "[2018-07-16 15:08:54.105504] Iteration 62400, train loss = 0.189545, train accuracy = 0.976562\n",
      "[2018-07-16 15:08:57.176563] Iteration 62500, train loss = 0.226387, train accuracy = 0.968750\n",
      "[2018-07-16 15:09:00.230813] Iteration 62600, train loss = 0.269724, train accuracy = 0.929688\n",
      "[2018-07-16 15:09:03.293385] Iteration 62700, train loss = 0.197184, train accuracy = 0.976562\n",
      "[2018-07-16 15:09:06.333729] Iteration 62800, train loss = 0.232319, train accuracy = 0.960938\n",
      "[2018-07-16 15:09:09.363688] Iteration 62900, train loss = 0.166667, train accuracy = 1.000000\n",
      "[2018-07-16 15:09:12.414497] Iteration 63000, train loss = 0.209955, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.903900\n",
      "[2018-07-16 15:09:16.505417] Iteration 63100, train loss = 0.259030, train accuracy = 0.960938\n",
      "[2018-07-16 15:09:19.536853] Iteration 63200, train loss = 0.278592, train accuracy = 0.960938\n",
      "[2018-07-16 15:09:22.570801] Iteration 63300, train loss = 0.179443, train accuracy = 0.976562\n",
      "[2018-07-16 15:09:25.629384] Iteration 63400, train loss = 0.209738, train accuracy = 0.984375\n",
      "[2018-07-16 15:09:28.681781] Iteration 63500, train loss = 0.222761, train accuracy = 0.968750\n",
      "[2018-07-16 15:09:31.741211] Iteration 63600, train loss = 0.250813, train accuracy = 0.953125\n",
      "[2018-07-16 15:09:34.812241] Iteration 63700, train loss = 0.181212, train accuracy = 0.992188\n",
      "[2018-07-16 15:09:37.869932] Iteration 63800, train loss = 0.185619, train accuracy = 0.992188\n",
      "[2018-07-16 15:09:40.923484] Iteration 63900, train loss = 0.159148, train accuracy = 1.000000\n",
      "[2018-07-16 15:09:43.973599] Iteration 64000, train loss = 0.214251, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 15:09:48.101314] Iteration 64100, train loss = 0.170517, train accuracy = 0.992188\n",
      "[2018-07-16 15:09:51.146542] Iteration 64200, train loss = 0.257896, train accuracy = 0.960938\n",
      "[2018-07-16 15:09:54.208935] Iteration 64300, train loss = 0.217490, train accuracy = 0.968750\n",
      "[2018-07-16 15:09:57.239994] Iteration 64400, train loss = 0.196277, train accuracy = 0.976562\n",
      "[2018-07-16 15:10:00.274382] Iteration 64500, train loss = 0.192344, train accuracy = 0.992188\n",
      "[2018-07-16 15:10:03.309935] Iteration 64600, train loss = 0.163105, train accuracy = 0.984375\n",
      "[2018-07-16 15:10:06.342393] Iteration 64700, train loss = 0.201402, train accuracy = 0.984375\n",
      "[2018-07-16 15:10:09.389952] Iteration 64800, train loss = 0.179552, train accuracy = 0.984375\n",
      "[2018-07-16 15:10:12.435750] Iteration 64900, train loss = 0.204182, train accuracy = 0.976562\n",
      "[2018-07-16 15:10:15.492748] Iteration 65000, train loss = 0.167743, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.903500\n",
      "[2018-07-16 15:10:19.593761] Iteration 65100, train loss = 0.231389, train accuracy = 0.953125\n",
      "[2018-07-16 15:10:22.644182] Iteration 65200, train loss = 0.193196, train accuracy = 0.976562\n",
      "[2018-07-16 15:10:25.690075] Iteration 65300, train loss = 0.222187, train accuracy = 0.976562\n",
      "[2018-07-16 15:10:28.742811] Iteration 65400, train loss = 0.251126, train accuracy = 0.968750\n",
      "[2018-07-16 15:10:31.796766] Iteration 65500, train loss = 0.169654, train accuracy = 0.992188\n",
      "[2018-07-16 15:10:34.856250] Iteration 65600, train loss = 0.218104, train accuracy = 0.960938\n",
      "[2018-07-16 15:10:37.910630] Iteration 65700, train loss = 0.188220, train accuracy = 0.968750\n",
      "[2018-07-16 15:10:40.958203] Iteration 65800, train loss = 0.260641, train accuracy = 0.960938\n",
      "[2018-07-16 15:10:44.004445] Iteration 65900, train loss = 0.240729, train accuracy = 0.953125\n",
      "[2018-07-16 15:10:47.035477] Iteration 66000, train loss = 0.220190, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903600\n",
      "[2018-07-16 15:10:51.124993] Iteration 66100, train loss = 0.275667, train accuracy = 0.945312\n",
      "[2018-07-16 15:10:54.159335] Iteration 66200, train loss = 0.186287, train accuracy = 0.992188\n",
      "[2018-07-16 15:10:57.192739] Iteration 66300, train loss = 0.176866, train accuracy = 0.984375\n",
      "[2018-07-16 15:11:00.243777] Iteration 66400, train loss = 0.210147, train accuracy = 0.960938\n",
      "[2018-07-16 15:11:03.294233] Iteration 66500, train loss = 0.195832, train accuracy = 0.976562\n",
      "[2018-07-16 15:11:06.344825] Iteration 66600, train loss = 0.240556, train accuracy = 0.968750\n",
      "[2018-07-16 15:11:09.392753] Iteration 66700, train loss = 0.227764, train accuracy = 0.968750\n",
      "[2018-07-16 15:11:12.443371] Iteration 66800, train loss = 0.189892, train accuracy = 0.984375\n",
      "[2018-07-16 15:11:15.491302] Iteration 66900, train loss = 0.190832, train accuracy = 0.976562\n",
      "[2018-07-16 15:11:18.541562] Iteration 67000, train loss = 0.204658, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 15:11:22.644247] Iteration 67100, train loss = 0.165125, train accuracy = 0.992188\n",
      "[2018-07-16 15:11:25.697484] Iteration 67200, train loss = 0.247438, train accuracy = 0.937500\n",
      "[2018-07-16 15:11:28.743802] Iteration 67300, train loss = 0.241542, train accuracy = 0.953125\n",
      "[2018-07-16 15:11:31.780328] Iteration 67400, train loss = 0.170033, train accuracy = 0.984375\n",
      "[2018-07-16 15:11:34.813299] Iteration 67500, train loss = 0.148866, train accuracy = 1.000000\n",
      "[2018-07-16 15:11:37.845550] Iteration 67600, train loss = 0.252639, train accuracy = 0.968750\n",
      "[2018-07-16 15:11:40.874830] Iteration 67700, train loss = 0.186330, train accuracy = 0.984375\n",
      "[2018-07-16 15:11:43.910067] Iteration 67800, train loss = 0.172456, train accuracy = 0.992188\n",
      "[2018-07-16 15:11:46.944972] Iteration 67900, train loss = 0.177309, train accuracy = 0.992188\n",
      "[2018-07-16 15:11:49.985490] Iteration 68000, train loss = 0.204003, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903500\n",
      "[2018-07-16 15:11:54.103742] Iteration 68100, train loss = 0.216355, train accuracy = 0.976562\n",
      "[2018-07-16 15:11:57.148032] Iteration 68200, train loss = 0.182718, train accuracy = 0.992188\n",
      "[2018-07-16 15:12:00.200693] Iteration 68300, train loss = 0.167932, train accuracy = 1.000000\n",
      "[2018-07-16 15:12:03.239400] Iteration 68400, train loss = 0.190026, train accuracy = 0.992188\n",
      "[2018-07-16 15:12:06.286131] Iteration 68500, train loss = 0.199348, train accuracy = 0.976562\n",
      "[2018-07-16 15:12:09.331484] Iteration 68600, train loss = 0.163083, train accuracy = 0.992188\n",
      "[2018-07-16 15:12:12.377609] Iteration 68700, train loss = 0.234013, train accuracy = 0.960938\n",
      "[2018-07-16 15:12:15.427007] Iteration 68800, train loss = 0.182212, train accuracy = 0.984375\n",
      "[2018-07-16 15:12:18.467653] Iteration 68900, train loss = 0.209449, train accuracy = 0.968750\n",
      "[2018-07-16 15:12:21.499487] Iteration 69000, train loss = 0.203314, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903300\n",
      "[2018-07-16 15:12:25.586608] Iteration 69100, train loss = 0.174211, train accuracy = 0.992188\n",
      "[2018-07-16 15:12:28.612570] Iteration 69200, train loss = 0.149601, train accuracy = 1.000000\n",
      "[2018-07-16 15:12:31.637646] Iteration 69300, train loss = 0.177297, train accuracy = 0.984375\n",
      "[2018-07-16 15:12:34.664429] Iteration 69400, train loss = 0.196824, train accuracy = 0.968750\n",
      "[2018-07-16 15:12:37.708828] Iteration 69500, train loss = 0.200317, train accuracy = 0.968750\n",
      "[2018-07-16 15:12:40.766024] Iteration 69600, train loss = 0.207409, train accuracy = 0.968750\n",
      "[2018-07-16 15:12:43.810442] Iteration 69700, train loss = 0.223945, train accuracy = 0.968750\n",
      "[2018-07-16 15:12:46.854275] Iteration 69800, train loss = 0.176678, train accuracy = 0.992188\n",
      "[2018-07-16 15:12:49.902501] Iteration 69900, train loss = 0.222510, train accuracy = 0.960938\n",
      "[2018-07-16 15:12:52.942396] Iteration 70000, train loss = 0.219367, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903500\n",
      "[2018-07-16 15:12:57.064429] Iteration 70100, train loss = 0.190676, train accuracy = 0.976562\n",
      "[2018-07-16 15:13:00.108687] Iteration 70200, train loss = 0.210634, train accuracy = 0.953125\n",
      "[2018-07-16 15:13:03.168242] Iteration 70300, train loss = 0.238787, train accuracy = 0.953125\n",
      "[2018-07-16 15:13:06.210588] Iteration 70400, train loss = 0.182540, train accuracy = 0.984375\n",
      "[2018-07-16 15:13:09.233575] Iteration 70500, train loss = 0.194189, train accuracy = 0.984375\n",
      "[2018-07-16 15:13:12.267579] Iteration 70600, train loss = 0.274376, train accuracy = 0.953125\n",
      "[2018-07-16 15:13:15.294464] Iteration 70700, train loss = 0.283802, train accuracy = 0.953125\n",
      "[2018-07-16 15:13:18.323810] Iteration 70800, train loss = 0.194572, train accuracy = 0.984375\n",
      "[2018-07-16 15:13:21.347302] Iteration 70900, train loss = 0.192142, train accuracy = 0.976562\n",
      "[2018-07-16 15:13:24.390809] Iteration 71000, train loss = 0.200968, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.904000\n",
      "[2018-07-16 15:13:28.492679] Iteration 71100, train loss = 0.226314, train accuracy = 0.968750\n",
      "[2018-07-16 15:13:31.561074] Iteration 71200, train loss = 0.179722, train accuracy = 1.000000\n",
      "[2018-07-16 15:13:34.609324] Iteration 71300, train loss = 0.178835, train accuracy = 0.992188\n",
      "[2018-07-16 15:13:37.653650] Iteration 71400, train loss = 0.195704, train accuracy = 0.976562\n",
      "[2018-07-16 15:13:40.704328] Iteration 71500, train loss = 0.243095, train accuracy = 0.945312\n",
      "[2018-07-16 15:13:43.738678] Iteration 71600, train loss = 0.177900, train accuracy = 0.992188\n",
      "[2018-07-16 15:13:46.769037] Iteration 71700, train loss = 0.209893, train accuracy = 0.968750\n",
      "[2018-07-16 15:13:49.819422] Iteration 71800, train loss = 0.218411, train accuracy = 0.953125\n",
      "[2018-07-16 15:13:52.871778] Iteration 71900, train loss = 0.248624, train accuracy = 0.953125\n",
      "[2018-07-16 15:13:55.903004] Iteration 72000, train loss = 0.215831, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903300\n",
      "[2018-07-16 15:13:59.985336] Iteration 72100, train loss = 0.202594, train accuracy = 0.976562\n",
      "[2018-07-16 15:14:03.016380] Iteration 72200, train loss = 0.238515, train accuracy = 0.960938\n",
      "[2018-07-16 15:14:06.043922] Iteration 72300, train loss = 0.243323, train accuracy = 0.960938\n",
      "[2018-07-16 15:14:09.069252] Iteration 72400, train loss = 0.167228, train accuracy = 0.992188\n",
      "[2018-07-16 15:14:12.110680] Iteration 72500, train loss = 0.194220, train accuracy = 0.984375\n",
      "[2018-07-16 15:14:15.150892] Iteration 72600, train loss = 0.189657, train accuracy = 0.976562\n",
      "[2018-07-16 15:14:18.200277] Iteration 72700, train loss = 0.212975, train accuracy = 0.976562\n",
      "[2018-07-16 15:14:21.242843] Iteration 72800, train loss = 0.222288, train accuracy = 0.976562\n",
      "[2018-07-16 15:14:24.284350] Iteration 72900, train loss = 0.248742, train accuracy = 0.984375\n",
      "[2018-07-16 15:14:27.331788] Iteration 73000, train loss = 0.256026, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.903700\n",
      "[2018-07-16 15:14:31.436094] Iteration 73100, train loss = 0.181501, train accuracy = 0.984375\n",
      "[2018-07-16 15:14:34.480453] Iteration 73200, train loss = 0.189118, train accuracy = 0.984375\n",
      "[2018-07-16 15:14:37.527727] Iteration 73300, train loss = 0.218990, train accuracy = 0.976562\n",
      "[2018-07-16 15:14:40.583805] Iteration 73400, train loss = 0.205053, train accuracy = 0.992188\n",
      "[2018-07-16 15:14:43.618594] Iteration 73500, train loss = 0.197534, train accuracy = 0.984375\n",
      "[2018-07-16 15:14:46.643826] Iteration 73600, train loss = 0.204986, train accuracy = 0.968750\n",
      "[2018-07-16 15:14:49.659232] Iteration 73700, train loss = 0.176254, train accuracy = 0.992188\n",
      "[2018-07-16 15:14:52.690541] Iteration 73800, train loss = 0.182062, train accuracy = 0.976562\n",
      "[2018-07-16 15:14:55.726566] Iteration 73900, train loss = 0.182577, train accuracy = 0.984375\n",
      "[2018-07-16 15:14:58.747286] Iteration 74000, train loss = 0.247583, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.904000\n",
      "[2018-07-16 15:15:02.857796] Iteration 74100, train loss = 0.190515, train accuracy = 0.992188\n",
      "[2018-07-16 15:15:05.898146] Iteration 74200, train loss = 0.181222, train accuracy = 1.000000\n",
      "[2018-07-16 15:15:08.945891] Iteration 74300, train loss = 0.168595, train accuracy = 0.992188\n",
      "[2018-07-16 15:15:11.979827] Iteration 74400, train loss = 0.177072, train accuracy = 0.984375\n",
      "[2018-07-16 15:15:15.012892] Iteration 74500, train loss = 0.213890, train accuracy = 0.968750\n",
      "[2018-07-16 15:15:18.047714] Iteration 74600, train loss = 0.215518, train accuracy = 0.960938\n",
      "[2018-07-16 15:15:21.098102] Iteration 74700, train loss = 0.168489, train accuracy = 0.992188\n",
      "[2018-07-16 15:15:24.139080] Iteration 74800, train loss = 0.201608, train accuracy = 0.976562\n",
      "[2018-07-16 15:15:27.179652] Iteration 74900, train loss = 0.200108, train accuracy = 0.976562\n",
      "[2018-07-16 15:15:30.219281] Iteration 75000, train loss = 0.239627, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 15:15:34.295283] Iteration 75100, train loss = 0.180996, train accuracy = 0.992188\n",
      "[2018-07-16 15:15:37.313860] Iteration 75200, train loss = 0.178234, train accuracy = 0.992188\n",
      "[2018-07-16 15:15:40.338221] Iteration 75300, train loss = 0.165882, train accuracy = 0.992188\n",
      "[2018-07-16 15:15:43.359705] Iteration 75400, train loss = 0.164428, train accuracy = 1.000000\n",
      "[2018-07-16 15:15:46.377566] Iteration 75500, train loss = 0.177233, train accuracy = 0.984375\n",
      "[2018-07-16 15:15:49.417707] Iteration 75600, train loss = 0.203940, train accuracy = 0.976562\n",
      "[2018-07-16 15:15:52.452060] Iteration 75700, train loss = 0.177139, train accuracy = 0.984375\n",
      "[2018-07-16 15:15:55.477537] Iteration 75800, train loss = 0.185536, train accuracy = 0.984375\n",
      "[2018-07-16 15:15:58.515155] Iteration 75900, train loss = 0.167511, train accuracy = 1.000000\n",
      "[2018-07-16 15:16:01.552336] Iteration 76000, train loss = 0.211793, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903800\n",
      "[2018-07-16 15:16:05.663346] Iteration 76100, train loss = 0.213635, train accuracy = 0.968750\n",
      "[2018-07-16 15:16:08.706471] Iteration 76200, train loss = 0.180364, train accuracy = 0.984375\n",
      "[2018-07-16 15:16:11.743179] Iteration 76300, train loss = 0.247181, train accuracy = 0.976562\n",
      "[2018-07-16 15:16:14.781010] Iteration 76400, train loss = 0.314077, train accuracy = 0.945312\n",
      "[2018-07-16 15:16:17.821219] Iteration 76500, train loss = 0.238366, train accuracy = 0.953125\n",
      "[2018-07-16 15:16:20.855962] Iteration 76600, train loss = 0.173544, train accuracy = 0.984375\n",
      "[2018-07-16 15:16:23.890430] Iteration 76700, train loss = 0.215928, train accuracy = 0.960938\n",
      "[2018-07-16 15:16:26.906371] Iteration 76800, train loss = 0.203649, train accuracy = 0.976562\n",
      "[2018-07-16 15:16:29.920637] Iteration 76900, train loss = 0.206744, train accuracy = 0.960938\n",
      "[2018-07-16 15:16:32.938158] Iteration 77000, train loss = 0.158559, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.903200\n",
      "[2018-07-16 15:16:37.020009] Iteration 77100, train loss = 0.239488, train accuracy = 0.953125\n",
      "[2018-07-16 15:16:40.059171] Iteration 77200, train loss = 0.172567, train accuracy = 0.992188\n",
      "[2018-07-16 15:16:43.093650] Iteration 77300, train loss = 0.253316, train accuracy = 0.953125\n",
      "[2018-07-16 15:16:46.132047] Iteration 77400, train loss = 0.237721, train accuracy = 0.960938\n",
      "[2018-07-16 15:16:49.184401] Iteration 77500, train loss = 0.206468, train accuracy = 0.968750\n",
      "[2018-07-16 15:16:52.219572] Iteration 77600, train loss = 0.202050, train accuracy = 0.984375\n",
      "[2018-07-16 15:16:55.258353] Iteration 77700, train loss = 0.170222, train accuracy = 0.992188\n",
      "[2018-07-16 15:16:58.305085] Iteration 77800, train loss = 0.189138, train accuracy = 0.984375\n",
      "[2018-07-16 15:17:01.344583] Iteration 77900, train loss = 0.184364, train accuracy = 0.976562\n",
      "[2018-07-16 15:17:04.387328] Iteration 78000, train loss = 0.192204, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.903400\n",
      "[2018-07-16 15:17:08.471449] Iteration 78100, train loss = 0.201116, train accuracy = 0.968750\n",
      "[2018-07-16 15:17:11.489030] Iteration 78200, train loss = 0.183580, train accuracy = 0.984375\n",
      "[2018-07-16 15:17:14.505697] Iteration 78300, train loss = 0.197269, train accuracy = 0.976562\n",
      "[2018-07-16 15:17:17.520637] Iteration 78400, train loss = 0.200744, train accuracy = 0.976562\n",
      "[2018-07-16 15:17:20.531191] Iteration 78500, train loss = 0.229330, train accuracy = 0.960938\n",
      "[2018-07-16 15:17:23.560428] Iteration 78600, train loss = 0.175940, train accuracy = 0.984375\n",
      "[2018-07-16 15:17:26.612220] Iteration 78700, train loss = 0.184921, train accuracy = 0.984375\n",
      "[2018-07-16 15:17:29.656067] Iteration 78800, train loss = 0.229018, train accuracy = 0.960938\n",
      "[2018-07-16 15:17:32.685157] Iteration 78900, train loss = 0.181038, train accuracy = 0.984375\n",
      "[2018-07-16 15:17:35.726821] Iteration 79000, train loss = 0.157189, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.904000\n",
      "[2018-07-16 15:17:39.821609] Iteration 79100, train loss = 0.179222, train accuracy = 0.992188\n",
      "[2018-07-16 15:17:42.853276] Iteration 79200, train loss = 0.205244, train accuracy = 0.976562\n",
      "[2018-07-16 15:17:45.886843] Iteration 79300, train loss = 0.204255, train accuracy = 0.976562\n",
      "[2018-07-16 15:17:48.934838] Iteration 79400, train loss = 0.182470, train accuracy = 0.984375\n",
      "[2018-07-16 15:17:51.970818] Iteration 79500, train loss = 0.166767, train accuracy = 0.992188\n",
      "[2018-07-16 15:17:55.004824] Iteration 79600, train loss = 0.188580, train accuracy = 0.984375\n",
      "[2018-07-16 15:17:58.020531] Iteration 79700, train loss = 0.214911, train accuracy = 0.976562\n",
      "[2018-07-16 15:18:01.038367] Iteration 79800, train loss = 0.196439, train accuracy = 0.968750\n",
      "[2018-07-16 15:18:04.057641] Iteration 79900, train loss = 0.226358, train accuracy = 0.976562\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune后的准确率\n",
      "Test accuracy = 0.903500\n"
     ]
    }
   ],
   "source": [
    "print('prune后的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625  -0.0625   0.0625   0.125    0.0625  -0.03125  0.      -0.0625\n",
      "  0.03125 -0.125  ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
