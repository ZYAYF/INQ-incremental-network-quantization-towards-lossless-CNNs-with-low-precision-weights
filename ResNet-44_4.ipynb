{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "# import ipdb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('residual_net_n', 7, '')\n",
    "tf.app.flags.DEFINE_string('train_tf_path', './data/train.tf', '')\n",
    "tf.app.flags.DEFINE_string('val_tf_path', './data/test.tf', '')\n",
    "tf.app.flags.DEFINE_integer('train_batch_size', 128, '')\n",
    "tf.app.flags.DEFINE_integer('val_batch_size', 100, '')\n",
    "tf.app.flags.DEFINE_float('weight_decay', 0.0005, 'Weight decay')\n",
    "tf.app.flags.DEFINE_integer('summary_interval', 100, 'Interval for summary.')\n",
    "tf.app.flags.DEFINE_integer('val_interval', 1000, 'Interval for evaluation.')\n",
    "tf.app.flags.DEFINE_integer('max_steps', 80000, 'Maximum number of iterations.')\n",
    "tf.app.flags.DEFINE_integer('save_interval', 5000, '')\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_embedding(label, n_classes):\n",
    "  \"\"\"\n",
    "  One-hot embedding\n",
    "  Args:\n",
    "    label: int32 tensor [B]\n",
    "    n_classes: int32, number of classes\n",
    "  Return:\n",
    "    embedding: tensor [B x n_classes]\n",
    "  \"\"\"\n",
    "  embedding_params = np.eye(n_classes, dtype=np.float32)\n",
    "  with tf.device('/cpu:0'):\n",
    "    params = tf.constant(embedding_params)\n",
    "    embedding = tf.gather(params, label)\n",
    "  return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, n_in, n_out, k, s, p='SAME', bias=False, scope='conv'):\n",
    "  with tf.variable_scope(scope):\n",
    "    kernel = tf.Variable(\n",
    "      tf.truncated_normal([k, k, n_in, n_out],\n",
    "        stddev=math.sqrt(2/(k*k*n_in))),\n",
    "      name='weight')\n",
    "    tf.add_to_collection('weights', kernel)\n",
    "    conv = tf.nn.conv2d(x, kernel, [1,s,s,1], padding=p)\n",
    "    if bias:\n",
    "      bias = tf.get_variable('bias', [n_out], initializer=tf.constant_initializer(0.0))\n",
    "      tf.add_to_collection('biases', bias)\n",
    "      conv = tf.nn.bias_add(conv, bias)\n",
    "  return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, scope='bn', affine=True):\n",
    "  \"\"\"\n",
    "  Batch normalization on convolutional maps.\n",
    "  Args:\n",
    "    x: Tensor, 4D BHWD input maps\n",
    "    n_out: integer, depth of input maps\n",
    "    phase_train: boolean tf.Variable, true indicates training phase\n",
    "    scope: string, variable scope\n",
    "    affine: whether to affine-transform outputs\n",
    "  Return:\n",
    "    normed: batch-normalized maps\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope):\n",
    "    beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "      name='beta', trainable=True)\n",
    "    gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "      name='gamma', trainable=affine)\n",
    "    tf.add_to_collection('biases', beta)\n",
    "    tf.add_to_collection('weights', gamma)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "\n",
    "    def mean_var_with_update():\n",
    "      ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "      with tf.control_dependencies([ema_apply_op]):\n",
    "        return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "      mean_var_with_update,\n",
    "      lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var, \n",
    "      beta, gamma, 1e-3, affine)\n",
    "  return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, n_in, n_out, subsample, phase_train, scope='res_block'):\n",
    "  with tf.variable_scope(scope):\n",
    "    if subsample:\n",
    "      y = conv2d(x, n_in, n_out, 3, 2, 'SAME', False, scope='conv_1')\n",
    "      shortcut = conv2d(x, n_in, n_out, 3, 2, 'SAME',\n",
    "                False, scope='shortcut')\n",
    "    else:\n",
    "      y = conv2d(x, n_in, n_out, 3, 1, 'SAME', False, scope='conv_1')\n",
    "      shortcut = tf.identity(x, name='shortcut')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_1')\n",
    "    y = tf.nn.relu(y, name='relu_1')\n",
    "    y = conv2d(y, n_out, n_out, 3, 1, 'SAME', True, scope='conv_2')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_2')\n",
    "    y = y + shortcut\n",
    "    y = tf.nn.relu(y, name='relu_2')\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_group(x, n_in, n_out, n, first_subsample, phase_train, scope='res_group'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = residual_block(x, n_in, n_out, first_subsample, phase_train, scope='block_1')\n",
    "    for i in range(n - 1):\n",
    "      y = residual_block(y, n_out, n_out, False, phase_train, scope='block_%d' % (i + 2))\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_net(x, n, n_classes, phase_train, scope='res_net'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = conv2d(x, 3, 16, 3, 1, 'SAME', False, scope='conv_init')\n",
    "    y = batch_norm(y, 16, phase_train, scope='bn_init')\n",
    "    y = tf.nn.relu(y, name='relu_init')\n",
    "    y = residual_group(y, 16, 16, n, False, phase_train, scope='group_1')\n",
    "    y = residual_group(y, 16, 32, n, True, phase_train, scope='group_2')\n",
    "    y = residual_group(y, 32, 64, n, True, phase_train, scope='group_3')\n",
    "#     y = conv2d(y, 64, n_classes, 1, 1, 'SAME', True, scope='conv_last')\n",
    "    y = tf.nn.avg_pool(y, [1, 8, 8, 1], [1, 1, 1, 1], 'VALID', name='avg_pool')\n",
    "    y = tf.reshape(y, [-1, 64])\n",
    "    w = tf.get_variable(name='weight_fc', shape=[64, n_classes], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    tf.add_to_collection('weights', w)\n",
    "    b = tf.get_variable(name='weight_biase', shape=[n_classes], initializer=tf.constant_initializer(0))\n",
    "    tf.add_to_collection('last_biases', b)\n",
    "    y = tf.matmul(y, w) + b\n",
    "#     y = tf.squeeze(y, squeeze_dims=[1, 2])\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _loss(logits, labels, scope='loss'):\n",
    "  with tf.variable_scope(scope):\n",
    "    # entropy loss\n",
    "    targets = one_hot_embedding(labels, 10)\n",
    "    entropy_loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),\n",
    "      name='entropy_loss')\n",
    "    tf.add_to_collection('losses', entropy_loss)\n",
    "    # weight l2 decay loss\n",
    "    weight_l2_losses = [tf.nn.l2_loss(o) for o in tf.get_collection('weights')]\n",
    "    weight_decay_loss = FLAGS.weight_decay*tf.add_n(weight_l2_losses)\n",
    "    tf.add_to_collection('losses', weight_decay_loss)\n",
    "  # for var in tf.get_collection('losses'):\n",
    "    # tf.scalar_summary('losses/' + var.op.name, var)\n",
    "  # total loss\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _accuracy(logits, gt_label, scope='accuracy'):\n",
    "  with tf.variable_scope(scope):\n",
    "    pred_label = tf.argmax(logits, 1)\n",
    "    acc = 1.0 - tf.nn.zero_fraction(\n",
    "      tf.cast(tf.equal(pred_label, gt_label), tf.int32))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_op(loss, global_step, learning_rate):\n",
    "  params = tf.trainable_variables()\n",
    "  gradients = tf.gradients(loss, params, name='gradients')\n",
    "  optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "  update = optim.apply_gradients(zip(gradients, params))\n",
    "  with tf.control_dependencies([update]):\n",
    "    train_op = tf.no_op(name='train_op')\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar10_input_stream(records_path):\n",
    "  reader = tf.TFRecordReader()\n",
    "  filename_queue = tf.train.string_input_producer([records_path], None)\n",
    "  _, record_value = reader.read(filename_queue)\n",
    "  features = tf.parse_single_example(record_value,\n",
    "    {\n",
    "      'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "  image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "  image = tf.reshape(image, [32,32,3])\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  label = tf.cast(features['label'], tf.int64)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "  # meanstd = joblib.load(FLAGS.mean_std_path)\n",
    "  # mean, std = meanstd['mean'], meanstd['std']\n",
    "  mean = [ 125.30690002,122.95014954,113.86599731]\n",
    "  std = [ 62.9932518,62.08860397,66.70500946]\n",
    "  normed_image = (image - mean) / std\n",
    "  return normed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_distort_image(image):\n",
    "  distorted_image = image\n",
    "  distorted_image = tf.image.pad_to_bounding_box(\n",
    "    image, 4, 4, 40, 40)  # pad 4 pixels to each side\n",
    "  distorted_image = tf.random_crop(distorted_image, [32, 32, 3])\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "  return distorted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_batch(train_records_path, batch_size):\n",
    "  with tf.variable_scope('train_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      train_image, train_label = cifar10_input_stream(train_records_path)\n",
    "      train_image = normalize_image(train_image)\n",
    "      train_image = random_distort_image(train_image)\n",
    "      train_image_batch, train_label_batch = tf.train.shuffle_batch(\n",
    "        [train_image, train_label], batch_size=batch_size, num_threads=4,\n",
    "        capacity=50000,\n",
    "        min_after_dequeue=1000)\n",
    "  return train_image_batch, train_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_validation_batch(test_records_path, batch_size):\n",
    "  with tf.variable_scope('evaluate_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      test_image, test_label = cifar10_input_stream(test_records_path)\n",
    "      test_image = normalize_image(test_image)\n",
    "      test_image_batch, test_label_batch = tf.train.batch(\n",
    "        [test_image, test_label], batch_size=batch_size, num_threads=1,\n",
    "        capacity=10000)\n",
    "  return test_image_batch, test_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5533cdbb8cb6>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "train_image_batch, train_label_batch = make_train_batch(FLAGS.train_tf_path, FLAGS.train_batch_size)\n",
    "val_image_batch, val_label_batch = make_validation_batch(FLAGS.val_tf_path, FLAGS.val_batch_size)\n",
    "\n",
    "image_batch, label_batch = control_flow_ops.cond(phase_train,lambda: (train_image_batch, train_label_batch),lambda: (val_image_batch, val_label_batch))\n",
    "\n",
    "\n",
    "logits = residual_net(image_batch, FLAGS.residual_net_n, 10, phase_train)\n",
    "\n",
    "\n",
    "loss = _loss(logits, label_batch)\n",
    "accuracy = _accuracy(logits, label_batch)\n",
    "\n",
    "# train one step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "INFO:tensorflow:Restoring parameters from ./full_precision/res44/model/res.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-train_batch/input_producer-train_batch/input_producer/input_producer_EnqueueMany, started daemon 140486023046912)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140486031439616)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140486585063168)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140486593455872)>,\n",
       " <Thread(QueueRunnerThread-train_batch/shuffle_batch/random_shuffle_queue-train_batch/shuffle_batch/random_shuffle_queue_enqueue, started daemon 140486014654208)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/input_producer-evaluate_batch/input_producer/input_producer_EnqueueMany, started daemon 140486006261504)>,\n",
       " <Thread(QueueRunnerThread-evaluate_batch/batch/fifo_queue-evaluate_batch/batch/fifo_queue_enqueue, started daemon 140485997868800)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "print('Initializing...')\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'./full_precision/res44/model/res.ckpt')\n",
    "\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Test accuracy = 0.933200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# validation\n",
    "\n",
    "print('Evaluating...')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "  fetches = [logits, label_batch, loss]\n",
    "  session_outputs = sess.run(\n",
    "    fetches, {phase_train.name: False})\n",
    "  val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "  val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "  val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(\n",
    "  pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_prune_on_grads(grads_and_vars, dict_nzidx):\n",
    "    for key, nzidx in dict_nzidx.items():\n",
    "        count = 0\n",
    "        for grad, var in grads_and_vars:\n",
    "            if var.name == key:\n",
    "                nzidx_obj = tf.cast(tf.constant(sess.run(dict_nzidx[key])), tf.float32)\n",
    "                grads_and_vars[count] = (tf.multiply(nzidx_obj, grad), var)\n",
    "            count += 1\n",
    "    return grads_and_vars\n",
    "\n",
    "def apply_inq(weights, inq_dict, var_name, prune_rate):  \n",
    "    for target in var_name:\n",
    "        wl = target\n",
    "        bit = 16\n",
    "\n",
    "        weight_obj = weights[wl]\n",
    "        weight_arr = sess.run(weight_obj)\n",
    "\n",
    "        weight_rest = np.reshape(weight_arr, [-1])\n",
    "        dic_tem = np.reshape(sess.run(inq_dict[wl]), [-1])\n",
    "        idx_rest = np.flip(np.argsort(abs(np.reshape(weight_rest, [-1]))), 0)\n",
    "        num_prune = int(len(weight_rest) * prune_rate)\n",
    "        weight_toINQ = weight_rest[idx_rest[:num_prune]]\n",
    "\n",
    "        n1 = (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        n2 = n1 + 1 - bit / 4\n",
    "        upper_bound = 2 ** (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        lower_bound = 2 ** (n1 + 1 - bit / 4)\n",
    "\n",
    "        weight_toINQ[abs(weight_toINQ) < lower_bound] = 0\n",
    "        weight_toINQ[weight_toINQ != 0] = 2 ** (np.floor(np.log2(abs(weight_toINQ[weight_toINQ != 0] * 4 / 3)))) * np.sign(weight_toINQ[weight_toINQ != 0])\n",
    "\n",
    "        weight_rest[idx_rest[:num_prune]] = weight_toINQ\n",
    "        weight_arr = np.reshape(weight_rest, np.shape(weight_arr))\n",
    "        dic_tem[idx_rest[:num_prune]] = np.zeros_like(dic_tem[idx_rest[:num_prune]])\n",
    "        inq_dict[wl] = tf.cast(np.reshape(dic_tem, np.shape(sess.run(inq_dict[wl]))), tf.float32)\n",
    "        sess.run(weights[wl].assign(weight_arr))\n",
    "    return inq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一轮  量化\n",
    "prune_rate =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.933200\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.08215426 -0.05700303  0.04312498  0.1090302  -0.0417071  -0.07600322\n",
      "  0.00174217 -0.00667335  0.03555666 -0.09022148]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.5)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-17 16:56:16.835255] Iteration 100, train loss = 0.222307, train accuracy = 0.953125\n",
      "[2018-07-17 16:56:24.590957] Iteration 200, train loss = 0.193468, train accuracy = 0.968750\n",
      "[2018-07-17 16:56:32.312508] Iteration 300, train loss = 0.174369, train accuracy = 0.992188\n",
      "[2018-07-17 16:56:40.049974] Iteration 400, train loss = 0.184868, train accuracy = 0.976562\n",
      "[2018-07-17 16:56:47.786589] Iteration 500, train loss = 0.155629, train accuracy = 0.984375\n",
      "[2018-07-17 16:56:55.525187] Iteration 600, train loss = 0.151081, train accuracy = 1.000000\n",
      "[2018-07-17 16:57:03.246430] Iteration 700, train loss = 0.190759, train accuracy = 0.976562\n",
      "[2018-07-17 16:57:10.970059] Iteration 800, train loss = 0.157030, train accuracy = 0.992188\n",
      "[2018-07-17 16:57:18.691398] Iteration 900, train loss = 0.145396, train accuracy = 1.000000\n",
      "[2018-07-17 16:57:26.421515] Iteration 1000, train loss = 0.141149, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.923300\n",
      "[2018-07-17 16:57:36.383960] Iteration 1100, train loss = 0.166690, train accuracy = 0.992188\n",
      "[2018-07-17 16:57:44.136963] Iteration 1200, train loss = 0.149692, train accuracy = 1.000000\n",
      "[2018-07-17 16:57:51.857140] Iteration 1300, train loss = 0.142718, train accuracy = 1.000000\n",
      "[2018-07-17 16:57:59.567057] Iteration 1400, train loss = 0.154054, train accuracy = 0.992188\n",
      "[2018-07-17 16:58:07.305584] Iteration 1500, train loss = 0.150232, train accuracy = 0.992188\n",
      "[2018-07-17 16:58:15.041891] Iteration 1600, train loss = 0.219799, train accuracy = 0.984375\n",
      "[2018-07-17 16:58:22.778151] Iteration 1700, train loss = 0.166723, train accuracy = 0.992188\n",
      "[2018-07-17 16:58:30.496532] Iteration 1800, train loss = 0.158295, train accuracy = 0.992188\n",
      "[2018-07-17 16:58:38.227610] Iteration 1900, train loss = 0.149169, train accuracy = 0.992188\n",
      "[2018-07-17 16:58:45.949009] Iteration 2000, train loss = 0.157734, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.923900\n",
      "[2018-07-17 16:58:55.970848] Iteration 2100, train loss = 0.152622, train accuracy = 0.984375\n",
      "[2018-07-17 16:59:03.700290] Iteration 2200, train loss = 0.143718, train accuracy = 1.000000\n",
      "[2018-07-17 16:59:11.411545] Iteration 2300, train loss = 0.149353, train accuracy = 0.992188\n",
      "[2018-07-17 16:59:19.126061] Iteration 2400, train loss = 0.183801, train accuracy = 0.984375\n",
      "[2018-07-17 16:59:26.858347] Iteration 2500, train loss = 0.150022, train accuracy = 0.992188\n",
      "[2018-07-17 16:59:34.559554] Iteration 2600, train loss = 0.181185, train accuracy = 0.984375\n",
      "[2018-07-17 16:59:42.272103] Iteration 2700, train loss = 0.153625, train accuracy = 0.992188\n",
      "[2018-07-17 16:59:49.987273] Iteration 2800, train loss = 0.138307, train accuracy = 1.000000\n",
      "[2018-07-17 16:59:57.711301] Iteration 2900, train loss = 0.151625, train accuracy = 0.992188\n",
      "[2018-07-17 17:00:05.434614] Iteration 3000, train loss = 0.147331, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.925600\n",
      "[2018-07-17 17:00:15.399339] Iteration 3100, train loss = 0.136431, train accuracy = 1.000000\n",
      "[2018-07-17 17:00:23.107624] Iteration 3200, train loss = 0.161730, train accuracy = 0.992188\n",
      "[2018-07-17 17:00:30.820735] Iteration 3300, train loss = 0.142587, train accuracy = 0.992188\n",
      "[2018-07-17 17:00:38.546186] Iteration 3400, train loss = 0.148227, train accuracy = 1.000000\n",
      "[2018-07-17 17:00:46.265529] Iteration 3500, train loss = 0.142175, train accuracy = 1.000000\n",
      "[2018-07-17 17:00:54.004271] Iteration 3600, train loss = 0.135887, train accuracy = 1.000000\n",
      "[2018-07-17 17:01:01.716633] Iteration 3700, train loss = 0.179480, train accuracy = 0.992188\n",
      "[2018-07-17 17:01:09.434316] Iteration 3800, train loss = 0.149504, train accuracy = 1.000000\n",
      "[2018-07-17 17:01:17.141346] Iteration 3900, train loss = 0.149036, train accuracy = 0.992188\n",
      "[2018-07-17 17:01:24.860201] Iteration 4000, train loss = 0.175571, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.928600\n",
      "[2018-07-17 17:01:34.810770] Iteration 4100, train loss = 0.144718, train accuracy = 1.000000\n",
      "[2018-07-17 17:01:42.509865] Iteration 4200, train loss = 0.142284, train accuracy = 0.992188\n",
      "[2018-07-17 17:01:50.229046] Iteration 4300, train loss = 0.137119, train accuracy = 1.000000\n",
      "[2018-07-17 17:01:57.954418] Iteration 4400, train loss = 0.142565, train accuracy = 0.992188\n",
      "[2018-07-17 17:02:05.672101] Iteration 4500, train loss = 0.139822, train accuracy = 1.000000\n",
      "[2018-07-17 17:02:13.382553] Iteration 4600, train loss = 0.151658, train accuracy = 0.992188\n",
      "[2018-07-17 17:02:21.101354] Iteration 4700, train loss = 0.133043, train accuracy = 1.000000\n",
      "[2018-07-17 17:02:28.806728] Iteration 4800, train loss = 0.134273, train accuracy = 1.000000\n",
      "[2018-07-17 17:02:36.523006] Iteration 4900, train loss = 0.165719, train accuracy = 0.984375\n",
      "[2018-07-17 17:02:44.236201] Iteration 5000, train loss = 0.141606, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.925900\n",
      "[2018-07-17 17:02:54.188004] Iteration 5100, train loss = 0.161579, train accuracy = 0.992188\n",
      "[2018-07-17 17:03:01.903674] Iteration 5200, train loss = 0.143083, train accuracy = 0.992188\n",
      "[2018-07-17 17:03:09.625101] Iteration 5300, train loss = 0.145434, train accuracy = 0.992188\n",
      "[2018-07-17 17:03:17.328848] Iteration 5400, train loss = 0.178198, train accuracy = 0.992188\n",
      "[2018-07-17 17:03:25.048852] Iteration 5500, train loss = 0.174687, train accuracy = 0.992188\n",
      "[2018-07-17 17:03:32.792885] Iteration 5600, train loss = 0.144611, train accuracy = 0.992188\n",
      "[2018-07-17 17:03:40.510124] Iteration 5700, train loss = 0.134297, train accuracy = 1.000000\n",
      "[2018-07-17 17:03:48.221564] Iteration 5800, train loss = 0.135993, train accuracy = 1.000000\n",
      "[2018-07-17 17:03:55.961239] Iteration 5900, train loss = 0.155775, train accuracy = 0.992188\n",
      "[2018-07-17 17:04:03.687377] Iteration 6000, train loss = 0.139922, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927000\n",
      "[2018-07-17 17:04:13.638195] Iteration 6100, train loss = 0.137634, train accuracy = 1.000000\n",
      "[2018-07-17 17:04:21.345041] Iteration 6200, train loss = 0.198208, train accuracy = 0.984375\n",
      "[2018-07-17 17:04:29.057821] Iteration 6300, train loss = 0.142950, train accuracy = 0.992188\n",
      "[2018-07-17 17:04:36.766579] Iteration 6400, train loss = 0.141754, train accuracy = 0.992188\n",
      "[2018-07-17 17:04:44.482595] Iteration 6500, train loss = 0.141140, train accuracy = 1.000000\n",
      "[2018-07-17 17:04:52.200673] Iteration 6600, train loss = 0.139070, train accuracy = 0.992188\n",
      "[2018-07-17 17:04:59.905372] Iteration 6700, train loss = 0.139109, train accuracy = 1.000000\n",
      "[2018-07-17 17:05:07.619684] Iteration 6800, train loss = 0.137650, train accuracy = 1.000000\n",
      "[2018-07-17 17:05:15.353101] Iteration 6900, train loss = 0.158061, train accuracy = 0.984375\n",
      "[2018-07-17 17:05:23.064205] Iteration 7000, train loss = 0.142654, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.926900\n",
      "[2018-07-17 17:05:33.016970] Iteration 7100, train loss = 0.145734, train accuracy = 0.992188\n",
      "[2018-07-17 17:05:40.734435] Iteration 7200, train loss = 0.142026, train accuracy = 1.000000\n",
      "[2018-07-17 17:05:48.447876] Iteration 7300, train loss = 0.136489, train accuracy = 1.000000\n",
      "[2018-07-17 17:05:56.174396] Iteration 7400, train loss = 0.136211, train accuracy = 1.000000\n",
      "[2018-07-17 17:06:03.886866] Iteration 7500, train loss = 0.143304, train accuracy = 0.992188\n",
      "[2018-07-17 17:06:11.603206] Iteration 7600, train loss = 0.139744, train accuracy = 1.000000\n",
      "[2018-07-17 17:06:19.301177] Iteration 7700, train loss = 0.145924, train accuracy = 0.992188\n",
      "[2018-07-17 17:06:27.007789] Iteration 7800, train loss = 0.137111, train accuracy = 1.000000\n",
      "[2018-07-17 17:06:34.718146] Iteration 7900, train loss = 0.139036, train accuracy = 1.000000\n",
      "[2018-07-17 17:06:42.431172] Iteration 8000, train loss = 0.155155, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 17:06:52.373260] Iteration 8100, train loss = 0.136649, train accuracy = 1.000000\n",
      "[2018-07-17 17:07:00.080336] Iteration 8200, train loss = 0.161187, train accuracy = 0.992188\n",
      "[2018-07-17 17:07:07.800908] Iteration 8300, train loss = 0.141367, train accuracy = 1.000000\n",
      "[2018-07-17 17:07:15.513959] Iteration 8400, train loss = 0.147667, train accuracy = 0.992188\n",
      "[2018-07-17 17:07:23.224675] Iteration 8500, train loss = 0.148930, train accuracy = 0.992188\n",
      "[2018-07-17 17:07:30.935324] Iteration 8600, train loss = 0.135050, train accuracy = 1.000000\n",
      "[2018-07-17 17:07:38.655910] Iteration 8700, train loss = 0.134997, train accuracy = 1.000000\n",
      "[2018-07-17 17:07:46.363877] Iteration 8800, train loss = 0.154866, train accuracy = 0.992188\n",
      "[2018-07-17 17:07:54.075881] Iteration 8900, train loss = 0.149723, train accuracy = 0.992188\n",
      "[2018-07-17 17:08:01.795864] Iteration 9000, train loss = 0.136696, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928900\n",
      "[2018-07-17 17:08:11.739279] Iteration 9100, train loss = 0.148769, train accuracy = 0.992188\n",
      "[2018-07-17 17:08:19.455321] Iteration 9200, train loss = 0.141587, train accuracy = 1.000000\n",
      "[2018-07-17 17:08:27.172171] Iteration 9300, train loss = 0.137202, train accuracy = 1.000000\n",
      "[2018-07-17 17:08:34.896654] Iteration 9400, train loss = 0.133812, train accuracy = 1.000000\n",
      "[2018-07-17 17:08:42.611948] Iteration 9500, train loss = 0.152913, train accuracy = 0.992188\n",
      "[2018-07-17 17:08:50.327210] Iteration 9600, train loss = 0.134434, train accuracy = 1.000000\n",
      "[2018-07-17 17:08:58.041291] Iteration 9700, train loss = 0.146243, train accuracy = 0.992188\n",
      "[2018-07-17 17:09:05.753116] Iteration 9800, train loss = 0.138194, train accuracy = 1.000000\n",
      "[2018-07-17 17:09:13.471836] Iteration 9900, train loss = 0.151456, train accuracy = 1.000000\n",
      "[2018-07-17 17:09:21.166659] Iteration 10000, train loss = 0.138125, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930700\n",
      "[2018-07-17 17:09:31.108156] Iteration 10100, train loss = 0.140611, train accuracy = 1.000000\n",
      "[2018-07-17 17:09:38.815095] Iteration 10200, train loss = 0.141774, train accuracy = 1.000000\n",
      "[2018-07-17 17:09:46.527969] Iteration 10300, train loss = 0.142034, train accuracy = 1.000000\n",
      "[2018-07-17 17:09:54.238321] Iteration 10400, train loss = 0.138152, train accuracy = 1.000000\n",
      "[2018-07-17 17:10:01.951914] Iteration 10500, train loss = 0.135309, train accuracy = 1.000000\n",
      "[2018-07-17 17:10:09.658277] Iteration 10600, train loss = 0.134650, train accuracy = 1.000000\n",
      "[2018-07-17 17:10:17.368867] Iteration 10700, train loss = 0.153916, train accuracy = 0.984375\n",
      "[2018-07-17 17:10:25.083415] Iteration 10800, train loss = 0.150654, train accuracy = 0.992188\n",
      "[2018-07-17 17:10:32.793385] Iteration 10900, train loss = 0.134987, train accuracy = 1.000000\n",
      "[2018-07-17 17:10:40.507208] Iteration 11000, train loss = 0.137117, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929500\n",
      "[2018-07-17 17:10:50.443813] Iteration 11100, train loss = 0.137862, train accuracy = 1.000000\n",
      "[2018-07-17 17:10:58.149694] Iteration 11200, train loss = 0.133512, train accuracy = 1.000000\n",
      "[2018-07-17 17:11:05.865536] Iteration 11300, train loss = 0.139724, train accuracy = 1.000000\n",
      "[2018-07-17 17:11:13.575781] Iteration 11400, train loss = 0.144599, train accuracy = 1.000000\n",
      "[2018-07-17 17:11:21.276918] Iteration 11500, train loss = 0.138746, train accuracy = 1.000000\n",
      "[2018-07-17 17:11:28.998822] Iteration 11600, train loss = 0.146810, train accuracy = 0.992188\n",
      "[2018-07-17 17:11:36.718361] Iteration 11700, train loss = 0.142492, train accuracy = 0.992188\n",
      "[2018-07-17 17:11:44.435296] Iteration 11800, train loss = 0.136561, train accuracy = 1.000000\n",
      "[2018-07-17 17:11:52.159530] Iteration 11900, train loss = 0.141187, train accuracy = 1.000000\n",
      "[2018-07-17 17:11:59.885681] Iteration 12000, train loss = 0.134669, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929600\n",
      "[2018-07-17 17:12:09.848657] Iteration 12100, train loss = 0.147771, train accuracy = 1.000000\n",
      "[2018-07-17 17:12:17.531909] Iteration 12200, train loss = 0.136304, train accuracy = 1.000000\n",
      "[2018-07-17 17:12:25.244103] Iteration 12300, train loss = 0.134621, train accuracy = 1.000000\n",
      "[2018-07-17 17:12:32.952494] Iteration 12400, train loss = 0.138965, train accuracy = 1.000000\n",
      "[2018-07-17 17:12:40.664958] Iteration 12500, train loss = 0.144456, train accuracy = 1.000000\n",
      "[2018-07-17 17:12:48.389811] Iteration 12600, train loss = 0.136601, train accuracy = 1.000000\n",
      "[2018-07-17 17:12:56.138156] Iteration 12700, train loss = 0.139386, train accuracy = 1.000000\n",
      "[2018-07-17 17:13:03.855053] Iteration 12800, train loss = 0.138931, train accuracy = 1.000000\n",
      "[2018-07-17 17:13:11.578361] Iteration 12900, train loss = 0.135523, train accuracy = 1.000000\n",
      "[2018-07-17 17:13:19.285275] Iteration 13000, train loss = 0.145481, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.929400\n",
      "[2018-07-17 17:13:29.249609] Iteration 13100, train loss = 0.136609, train accuracy = 1.000000\n",
      "[2018-07-17 17:13:36.969524] Iteration 13200, train loss = 0.133937, train accuracy = 1.000000\n",
      "[2018-07-17 17:13:44.681941] Iteration 13300, train loss = 0.139308, train accuracy = 1.000000\n",
      "[2018-07-17 17:13:52.380683] Iteration 13400, train loss = 0.136237, train accuracy = 1.000000\n",
      "[2018-07-17 17:14:00.097130] Iteration 13500, train loss = 0.141022, train accuracy = 0.992188\n",
      "[2018-07-17 17:14:07.819736] Iteration 13600, train loss = 0.190204, train accuracy = 0.984375\n",
      "[2018-07-17 17:14:15.534961] Iteration 13700, train loss = 0.138178, train accuracy = 1.000000\n",
      "[2018-07-17 17:14:23.251922] Iteration 13800, train loss = 0.141237, train accuracy = 1.000000\n",
      "[2018-07-17 17:14:30.961675] Iteration 13900, train loss = 0.132400, train accuracy = 1.000000\n",
      "[2018-07-17 17:14:38.683206] Iteration 14000, train loss = 0.133550, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929300\n",
      "[2018-07-17 17:14:48.645012] Iteration 14100, train loss = 0.139293, train accuracy = 1.000000\n",
      "[2018-07-17 17:14:56.362510] Iteration 14200, train loss = 0.138119, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:04.079906] Iteration 14300, train loss = 0.138427, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:11.792964] Iteration 14400, train loss = 0.133770, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:19.510837] Iteration 14500, train loss = 0.136397, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:27.229525] Iteration 14600, train loss = 0.132146, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:34.952966] Iteration 14700, train loss = 0.136766, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:42.673975] Iteration 14800, train loss = 0.141190, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:50.394871] Iteration 14900, train loss = 0.141422, train accuracy = 1.000000\n",
      "[2018-07-17 17:15:58.110268] Iteration 15000, train loss = 0.134276, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927300\n",
      "[2018-07-17 17:16:08.067749] Iteration 15100, train loss = 0.138650, train accuracy = 1.000000\n",
      "[2018-07-17 17:16:15.793277] Iteration 15200, train loss = 0.134802, train accuracy = 1.000000\n",
      "[2018-07-17 17:16:23.519933] Iteration 15300, train loss = 0.139396, train accuracy = 1.000000\n",
      "[2018-07-17 17:16:31.230890] Iteration 15400, train loss = 0.136829, train accuracy = 1.000000\n",
      "[2018-07-17 17:16:38.948892] Iteration 15500, train loss = 0.147376, train accuracy = 1.000000\n",
      "[2018-07-17 17:16:46.663366] Iteration 15600, train loss = 0.154151, train accuracy = 0.992188\n",
      "[2018-07-17 17:16:54.372130] Iteration 15700, train loss = 0.137021, train accuracy = 1.000000\n",
      "[2018-07-17 17:17:02.078183] Iteration 15800, train loss = 0.139340, train accuracy = 1.000000\n",
      "[2018-07-17 17:17:09.798172] Iteration 15900, train loss = 0.136421, train accuracy = 1.000000\n",
      "[2018-07-17 17:17:17.506740] Iteration 16000, train loss = 0.155976, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.927700\n",
      "[2018-07-17 17:17:27.462442] Iteration 16100, train loss = 0.133997, train accuracy = 1.000000\n",
      "[2018-07-17 17:17:35.180361] Iteration 16200, train loss = 0.138610, train accuracy = 1.000000\n",
      "[2018-07-17 17:17:42.906383] Iteration 16300, train loss = 0.158140, train accuracy = 0.992188\n",
      "[2018-07-17 17:17:50.634219] Iteration 16400, train loss = 0.146539, train accuracy = 0.984375\n",
      "[2018-07-17 17:17:58.356209] Iteration 16500, train loss = 0.134960, train accuracy = 1.000000\n",
      "[2018-07-17 17:18:06.071586] Iteration 16600, train loss = 0.149824, train accuracy = 0.992188\n",
      "[2018-07-17 17:18:13.790209] Iteration 16700, train loss = 0.136955, train accuracy = 1.000000\n",
      "[2018-07-17 17:18:21.506615] Iteration 16800, train loss = 0.137614, train accuracy = 1.000000\n",
      "[2018-07-17 17:18:29.230955] Iteration 16900, train loss = 0.134644, train accuracy = 1.000000\n",
      "[2018-07-17 17:18:36.944410] Iteration 17000, train loss = 0.139951, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 17:18:46.902905] Iteration 17100, train loss = 0.136533, train accuracy = 1.000000\n",
      "[2018-07-17 17:18:54.624491] Iteration 17200, train loss = 0.139298, train accuracy = 1.000000\n",
      "[2018-07-17 17:19:02.347812] Iteration 17300, train loss = 0.140519, train accuracy = 1.000000\n",
      "[2018-07-17 17:19:10.063954] Iteration 17400, train loss = 0.133158, train accuracy = 1.000000\n",
      "[2018-07-17 17:19:17.810297] Iteration 17500, train loss = 0.142013, train accuracy = 0.992188\n",
      "[2018-07-17 17:19:25.538390] Iteration 17600, train loss = 0.155845, train accuracy = 0.984375\n",
      "[2018-07-17 17:19:33.256470] Iteration 17700, train loss = 0.141793, train accuracy = 1.000000\n",
      "[2018-07-17 17:19:40.972734] Iteration 17800, train loss = 0.144431, train accuracy = 0.992188\n",
      "[2018-07-17 17:19:48.688625] Iteration 17900, train loss = 0.135883, train accuracy = 1.000000\n",
      "[2018-07-17 17:19:56.402222] Iteration 18000, train loss = 0.134246, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928800\n",
      "[2018-07-17 17:20:06.334916] Iteration 18100, train loss = 0.144376, train accuracy = 0.992188\n",
      "[2018-07-17 17:20:14.050445] Iteration 18200, train loss = 0.139305, train accuracy = 1.000000\n",
      "[2018-07-17 17:20:21.769751] Iteration 18300, train loss = 0.133752, train accuracy = 1.000000\n",
      "[2018-07-17 17:20:29.488707] Iteration 18400, train loss = 0.135007, train accuracy = 1.000000\n",
      "[2018-07-17 17:20:37.191692] Iteration 18500, train loss = 0.160468, train accuracy = 0.984375\n",
      "[2018-07-17 17:20:44.901019] Iteration 18600, train loss = 0.138123, train accuracy = 1.000000\n",
      "[2018-07-17 17:20:52.612195] Iteration 18700, train loss = 0.137453, train accuracy = 1.000000\n",
      "[2018-07-17 17:21:00.331381] Iteration 18800, train loss = 0.135043, train accuracy = 1.000000\n",
      "[2018-07-17 17:21:08.051642] Iteration 18900, train loss = 0.139555, train accuracy = 1.000000\n",
      "[2018-07-17 17:21:15.783611] Iteration 19000, train loss = 0.137734, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929300\n",
      "[2018-07-17 17:21:25.757184] Iteration 19100, train loss = 0.138426, train accuracy = 1.000000\n",
      "[2018-07-17 17:21:33.462970] Iteration 19200, train loss = 0.137747, train accuracy = 1.000000\n",
      "[2018-07-17 17:21:41.184046] Iteration 19300, train loss = 0.140083, train accuracy = 1.000000\n",
      "[2018-07-17 17:21:48.908684] Iteration 19400, train loss = 0.165467, train accuracy = 0.984375\n",
      "[2018-07-17 17:21:56.630065] Iteration 19500, train loss = 0.140849, train accuracy = 1.000000\n",
      "[2018-07-17 17:22:04.339784] Iteration 19600, train loss = 0.132761, train accuracy = 1.000000\n",
      "[2018-07-17 17:22:12.059779] Iteration 19700, train loss = 0.138729, train accuracy = 1.000000\n",
      "[2018-07-17 17:22:19.779515] Iteration 19800, train loss = 0.139668, train accuracy = 1.000000\n",
      "[2018-07-17 17:22:27.499202] Iteration 19900, train loss = 0.150271, train accuracy = 0.992188\n",
      "[2018-07-17 17:22:35.222799] Iteration 20000, train loss = 0.138186, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927800\n",
      "[2018-07-17 17:22:45.186926] Iteration 20100, train loss = 0.135105, train accuracy = 1.000000\n",
      "[2018-07-17 17:22:52.904726] Iteration 20200, train loss = 0.132778, train accuracy = 1.000000\n",
      "[2018-07-17 17:23:00.620021] Iteration 20300, train loss = 0.144579, train accuracy = 0.992188\n",
      "[2018-07-17 17:23:08.343695] Iteration 20400, train loss = 0.139737, train accuracy = 0.992188\n",
      "[2018-07-17 17:23:16.049977] Iteration 20500, train loss = 0.134940, train accuracy = 1.000000\n",
      "[2018-07-17 17:23:23.777116] Iteration 20600, train loss = 0.143219, train accuracy = 0.992188\n",
      "[2018-07-17 17:23:31.500671] Iteration 20700, train loss = 0.138947, train accuracy = 1.000000\n",
      "[2018-07-17 17:23:39.210614] Iteration 20800, train loss = 0.133506, train accuracy = 1.000000\n",
      "[2018-07-17 17:23:46.922533] Iteration 20900, train loss = 0.134537, train accuracy = 1.000000\n",
      "[2018-07-17 17:23:54.634504] Iteration 21000, train loss = 0.137221, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928700\n",
      "[2018-07-17 17:24:04.598797] Iteration 21100, train loss = 0.138269, train accuracy = 1.000000\n",
      "[2018-07-17 17:24:12.324419] Iteration 21200, train loss = 0.132193, train accuracy = 1.000000\n",
      "[2018-07-17 17:24:20.025514] Iteration 21300, train loss = 0.133432, train accuracy = 1.000000\n",
      "[2018-07-17 17:24:27.736697] Iteration 21400, train loss = 0.133524, train accuracy = 1.000000\n",
      "[2018-07-17 17:24:35.454152] Iteration 21500, train loss = 0.135069, train accuracy = 1.000000\n",
      "[2018-07-17 17:24:43.171764] Iteration 21600, train loss = 0.138562, train accuracy = 1.000000\n",
      "[2018-07-17 17:24:50.881173] Iteration 21700, train loss = 0.149747, train accuracy = 0.992188\n",
      "[2018-07-17 17:24:58.609618] Iteration 21800, train loss = 0.133477, train accuracy = 1.000000\n",
      "[2018-07-17 17:25:06.332197] Iteration 21900, train loss = 0.137075, train accuracy = 1.000000\n",
      "[2018-07-17 17:25:14.050566] Iteration 22000, train loss = 0.135176, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928600\n",
      "[2018-07-17 17:25:24.020127] Iteration 22100, train loss = 0.132876, train accuracy = 1.000000\n",
      "[2018-07-17 17:25:31.732554] Iteration 22200, train loss = 0.136082, train accuracy = 1.000000\n",
      "[2018-07-17 17:25:39.451075] Iteration 22300, train loss = 0.139014, train accuracy = 0.992188\n",
      "[2018-07-17 17:25:47.153917] Iteration 22400, train loss = 0.137418, train accuracy = 1.000000\n",
      "[2018-07-17 17:25:54.869701] Iteration 22500, train loss = 0.133864, train accuracy = 1.000000\n",
      "[2018-07-17 17:26:02.592843] Iteration 22600, train loss = 0.133252, train accuracy = 1.000000\n",
      "[2018-07-17 17:26:10.298251] Iteration 22700, train loss = 0.131451, train accuracy = 1.000000\n",
      "[2018-07-17 17:26:18.017361] Iteration 22800, train loss = 0.131359, train accuracy = 1.000000\n",
      "[2018-07-17 17:26:25.730910] Iteration 22900, train loss = 0.135072, train accuracy = 1.000000\n",
      "[2018-07-17 17:26:33.443235] Iteration 23000, train loss = 0.132679, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929100\n",
      "[2018-07-17 17:26:43.408220] Iteration 23100, train loss = 0.142168, train accuracy = 1.000000\n",
      "[2018-07-17 17:26:51.132127] Iteration 23200, train loss = 0.132646, train accuracy = 1.000000\n",
      "[2018-07-17 17:26:58.848755] Iteration 23300, train loss = 0.132121, train accuracy = 1.000000\n",
      "[2018-07-17 17:27:06.575428] Iteration 23400, train loss = 0.137820, train accuracy = 1.000000\n",
      "[2018-07-17 17:27:14.295815] Iteration 23500, train loss = 0.153913, train accuracy = 0.992188\n",
      "[2018-07-17 17:27:21.976271] Iteration 23600, train loss = 0.137344, train accuracy = 1.000000\n",
      "[2018-07-17 17:27:29.677753] Iteration 23700, train loss = 0.132581, train accuracy = 1.000000\n",
      "[2018-07-17 17:27:37.394798] Iteration 23800, train loss = 0.136670, train accuracy = 1.000000\n",
      "[2018-07-17 17:27:45.114507] Iteration 23900, train loss = 0.133121, train accuracy = 1.000000\n",
      "[2018-07-17 17:27:52.827182] Iteration 24000, train loss = 0.139303, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930700\n",
      "[2018-07-17 17:28:02.779716] Iteration 24100, train loss = 0.138764, train accuracy = 1.000000\n",
      "[2018-07-17 17:28:10.496673] Iteration 24200, train loss = 0.134351, train accuracy = 1.000000\n",
      "[2018-07-17 17:28:18.211406] Iteration 24300, train loss = 0.133751, train accuracy = 1.000000\n",
      "[2018-07-17 17:28:25.954696] Iteration 24400, train loss = 0.155221, train accuracy = 0.992188\n",
      "[2018-07-17 17:28:33.691223] Iteration 24500, train loss = 0.155180, train accuracy = 0.992188\n",
      "[2018-07-17 17:28:41.403807] Iteration 24600, train loss = 0.133871, train accuracy = 1.000000\n",
      "[2018-07-17 17:28:49.124048] Iteration 24700, train loss = 0.139197, train accuracy = 0.992188\n",
      "[2018-07-17 17:28:56.834770] Iteration 24800, train loss = 0.143152, train accuracy = 0.992188\n",
      "[2018-07-17 17:29:04.544149] Iteration 24900, train loss = 0.132035, train accuracy = 1.000000\n",
      "[2018-07-17 17:29:12.255307] Iteration 25000, train loss = 0.133078, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929900\n",
      "[2018-07-17 17:29:22.208864] Iteration 25100, train loss = 0.134721, train accuracy = 1.000000\n",
      "[2018-07-17 17:29:29.930743] Iteration 25200, train loss = 0.137053, train accuracy = 1.000000\n",
      "[2018-07-17 17:29:37.643236] Iteration 25300, train loss = 0.141191, train accuracy = 0.992188\n",
      "[2018-07-17 17:29:45.366078] Iteration 25400, train loss = 0.137489, train accuracy = 1.000000\n",
      "[2018-07-17 17:29:53.084434] Iteration 25500, train loss = 0.133080, train accuracy = 1.000000\n",
      "[2018-07-17 17:30:00.797473] Iteration 25600, train loss = 0.133804, train accuracy = 1.000000\n",
      "[2018-07-17 17:30:08.519919] Iteration 25700, train loss = 0.135678, train accuracy = 1.000000\n",
      "[2018-07-17 17:30:16.224369] Iteration 25800, train loss = 0.135081, train accuracy = 1.000000\n",
      "[2018-07-17 17:30:23.950365] Iteration 25900, train loss = 0.136508, train accuracy = 1.000000\n",
      "[2018-07-17 17:30:31.678385] Iteration 26000, train loss = 0.135255, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928600\n",
      "[2018-07-17 17:30:41.634498] Iteration 26100, train loss = 0.131717, train accuracy = 1.000000\n",
      "[2018-07-17 17:30:49.348553] Iteration 26200, train loss = 0.151704, train accuracy = 0.992188\n",
      "[2018-07-17 17:30:57.051488] Iteration 26300, train loss = 0.134666, train accuracy = 1.000000\n",
      "[2018-07-17 17:31:04.762370] Iteration 26400, train loss = 0.133043, train accuracy = 1.000000\n",
      "[2018-07-17 17:31:12.474333] Iteration 26500, train loss = 0.134340, train accuracy = 1.000000\n",
      "[2018-07-17 17:31:20.193801] Iteration 26600, train loss = 0.146605, train accuracy = 0.992188\n",
      "[2018-07-17 17:31:27.921504] Iteration 26700, train loss = 0.135375, train accuracy = 1.000000\n",
      "[2018-07-17 17:31:35.656659] Iteration 26800, train loss = 0.144652, train accuracy = 0.984375\n",
      "[2018-07-17 17:31:43.380458] Iteration 26900, train loss = 0.133508, train accuracy = 1.000000\n",
      "[2018-07-17 17:31:51.071221] Iteration 27000, train loss = 0.137284, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930100\n",
      "[2018-07-17 17:32:01.028336] Iteration 27100, train loss = 0.134385, train accuracy = 1.000000\n",
      "[2018-07-17 17:32:08.745293] Iteration 27200, train loss = 0.133187, train accuracy = 1.000000\n",
      "[2018-07-17 17:32:16.465329] Iteration 27300, train loss = 0.135521, train accuracy = 1.000000\n",
      "[2018-07-17 17:32:24.182843] Iteration 27400, train loss = 0.132138, train accuracy = 1.000000\n",
      "[2018-07-17 17:32:31.896312] Iteration 27500, train loss = 0.132409, train accuracy = 1.000000\n",
      "[2018-07-17 17:32:39.608726] Iteration 27600, train loss = 0.144021, train accuracy = 0.992188\n",
      "[2018-07-17 17:32:47.331188] Iteration 27700, train loss = 0.131962, train accuracy = 1.000000\n",
      "[2018-07-17 17:32:55.041306] Iteration 27800, train loss = 0.136987, train accuracy = 1.000000\n",
      "[2018-07-17 17:33:02.754056] Iteration 27900, train loss = 0.132463, train accuracy = 1.000000\n",
      "[2018-07-17 17:33:10.478135] Iteration 28000, train loss = 0.133422, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928800\n",
      "[2018-07-17 17:33:20.415524] Iteration 28100, train loss = 0.133512, train accuracy = 1.000000\n",
      "[2018-07-17 17:33:28.168883] Iteration 28200, train loss = 0.132197, train accuracy = 1.000000\n",
      "[2018-07-17 17:33:35.882512] Iteration 28300, train loss = 0.134944, train accuracy = 1.000000\n",
      "[2018-07-17 17:33:43.602339] Iteration 28400, train loss = 0.133331, train accuracy = 1.000000\n",
      "[2018-07-17 17:33:51.316593] Iteration 28500, train loss = 0.164228, train accuracy = 0.984375\n",
      "[2018-07-17 17:33:59.029338] Iteration 28600, train loss = 0.139923, train accuracy = 0.992188\n",
      "[2018-07-17 17:34:06.735012] Iteration 28700, train loss = 0.136475, train accuracy = 1.000000\n",
      "[2018-07-17 17:34:14.455320] Iteration 28800, train loss = 0.131603, train accuracy = 1.000000\n",
      "[2018-07-17 17:34:22.172121] Iteration 28900, train loss = 0.134394, train accuracy = 1.000000\n",
      "[2018-07-17 17:34:29.896858] Iteration 29000, train loss = 0.135033, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929800\n",
      "[2018-07-17 17:34:39.871352] Iteration 29100, train loss = 0.131976, train accuracy = 1.000000\n",
      "[2018-07-17 17:34:47.574550] Iteration 29200, train loss = 0.130862, train accuracy = 1.000000\n",
      "[2018-07-17 17:34:55.274069] Iteration 29300, train loss = 0.138460, train accuracy = 1.000000\n",
      "[2018-07-17 17:35:02.976475] Iteration 29400, train loss = 0.133007, train accuracy = 1.000000\n",
      "[2018-07-17 17:35:10.699434] Iteration 29500, train loss = 0.138108, train accuracy = 0.992188\n",
      "[2018-07-17 17:35:18.423391] Iteration 29600, train loss = 0.135078, train accuracy = 1.000000\n",
      "[2018-07-17 17:35:26.159647] Iteration 29700, train loss = 0.132653, train accuracy = 1.000000\n",
      "[2018-07-17 17:35:33.881326] Iteration 29800, train loss = 0.145759, train accuracy = 0.992188\n",
      "[2018-07-17 17:35:41.593198] Iteration 29900, train loss = 0.131911, train accuracy = 1.000000\n",
      "[2018-07-17 17:35:49.317226] Iteration 30000, train loss = 0.143683, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 17:35:59.280670] Iteration 30100, train loss = 0.132775, train accuracy = 1.000000\n",
      "[2018-07-17 17:36:07.003628] Iteration 30200, train loss = 0.142554, train accuracy = 0.992188\n",
      "[2018-07-17 17:36:14.723636] Iteration 30300, train loss = 0.136109, train accuracy = 1.000000\n",
      "[2018-07-17 17:36:22.425116] Iteration 30400, train loss = 0.134883, train accuracy = 1.000000\n",
      "[2018-07-17 17:36:30.125803] Iteration 30500, train loss = 0.134353, train accuracy = 1.000000\n",
      "[2018-07-17 17:36:37.842720] Iteration 30600, train loss = 0.131704, train accuracy = 1.000000\n",
      "[2018-07-17 17:36:45.554708] Iteration 30700, train loss = 0.136171, train accuracy = 1.000000\n",
      "[2018-07-17 17:36:53.268742] Iteration 30800, train loss = 0.138122, train accuracy = 1.000000\n",
      "[2018-07-17 17:37:00.986090] Iteration 30900, train loss = 0.134069, train accuracy = 1.000000\n",
      "[2018-07-17 17:37:08.714974] Iteration 31000, train loss = 0.133941, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.931000\n",
      "[2018-07-17 17:37:18.682725] Iteration 31100, train loss = 0.133718, train accuracy = 1.000000\n",
      "[2018-07-17 17:37:26.408538] Iteration 31200, train loss = 0.133434, train accuracy = 1.000000\n",
      "[2018-07-17 17:37:34.130821] Iteration 31300, train loss = 0.136711, train accuracy = 1.000000\n",
      "[2018-07-17 17:37:41.848331] Iteration 31400, train loss = 0.134933, train accuracy = 1.000000\n",
      "[2018-07-17 17:37:49.555917] Iteration 31500, train loss = 0.146123, train accuracy = 0.992188\n",
      "[2018-07-17 17:37:57.261414] Iteration 31600, train loss = 0.140402, train accuracy = 1.000000\n",
      "[2018-07-17 17:38:04.974492] Iteration 31700, train loss = 0.132707, train accuracy = 1.000000\n",
      "[2018-07-17 17:38:12.686074] Iteration 31800, train loss = 0.133631, train accuracy = 1.000000\n",
      "[2018-07-17 17:38:20.409755] Iteration 31900, train loss = 0.135556, train accuracy = 1.000000\n",
      "[2018-07-17 17:38:28.123316] Iteration 32000, train loss = 0.132838, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929500\n",
      "[2018-07-17 17:38:38.084436] Iteration 32100, train loss = 0.131519, train accuracy = 1.000000\n",
      "[2018-07-17 17:38:45.812592] Iteration 32200, train loss = 0.133373, train accuracy = 1.000000\n",
      "[2018-07-17 17:38:53.529812] Iteration 32300, train loss = 0.133194, train accuracy = 1.000000\n",
      "[2018-07-17 17:39:01.247958] Iteration 32400, train loss = 0.141279, train accuracy = 0.992188\n",
      "[2018-07-17 17:39:08.963827] Iteration 32500, train loss = 0.132157, train accuracy = 1.000000\n",
      "[2018-07-17 17:39:16.683546] Iteration 32600, train loss = 0.135180, train accuracy = 1.000000\n",
      "[2018-07-17 17:39:24.405201] Iteration 32700, train loss = 0.166854, train accuracy = 0.984375\n",
      "[2018-07-17 17:39:32.119501] Iteration 32800, train loss = 0.135600, train accuracy = 1.000000\n",
      "[2018-07-17 17:39:39.826538] Iteration 32900, train loss = 0.150420, train accuracy = 0.992188\n",
      "[2018-07-17 17:39:47.543939] Iteration 33000, train loss = 0.133547, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929000\n",
      "[2018-07-17 17:39:57.505112] Iteration 33100, train loss = 0.131261, train accuracy = 1.000000\n",
      "[2018-07-17 17:40:05.230786] Iteration 33200, train loss = 0.148263, train accuracy = 0.992188\n",
      "[2018-07-17 17:40:12.952136] Iteration 33300, train loss = 0.134842, train accuracy = 1.000000\n",
      "[2018-07-17 17:40:20.663380] Iteration 33400, train loss = 0.132888, train accuracy = 1.000000\n",
      "[2018-07-17 17:40:28.391213] Iteration 33500, train loss = 0.134803, train accuracy = 1.000000\n",
      "[2018-07-17 17:40:36.096390] Iteration 33600, train loss = 0.132900, train accuracy = 1.000000\n",
      "[2018-07-17 17:40:43.814877] Iteration 33700, train loss = 0.141588, train accuracy = 0.992188\n",
      "[2018-07-17 17:40:51.541801] Iteration 33800, train loss = 0.140573, train accuracy = 0.992188\n",
      "[2018-07-17 17:40:59.264964] Iteration 33900, train loss = 0.131918, train accuracy = 1.000000\n",
      "[2018-07-17 17:41:06.983407] Iteration 34000, train loss = 0.132452, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930200\n",
      "[2018-07-17 17:41:16.931502] Iteration 34100, train loss = 0.137321, train accuracy = 1.000000\n",
      "[2018-07-17 17:41:24.632956] Iteration 34200, train loss = 0.138885, train accuracy = 1.000000\n",
      "[2018-07-17 17:41:32.344264] Iteration 34300, train loss = 0.132444, train accuracy = 1.000000\n",
      "[2018-07-17 17:41:40.079772] Iteration 34400, train loss = 0.131764, train accuracy = 1.000000\n",
      "[2018-07-17 17:41:47.803719] Iteration 34500, train loss = 0.132999, train accuracy = 1.000000\n",
      "[2018-07-17 17:41:55.532606] Iteration 34600, train loss = 0.135920, train accuracy = 1.000000\n",
      "[2018-07-17 17:42:03.238247] Iteration 34700, train loss = 0.132920, train accuracy = 1.000000\n",
      "[2018-07-17 17:42:10.965305] Iteration 34800, train loss = 0.132032, train accuracy = 1.000000\n",
      "[2018-07-17 17:42:18.664102] Iteration 34900, train loss = 0.132479, train accuracy = 1.000000\n",
      "[2018-07-17 17:42:26.384528] Iteration 35000, train loss = 0.137175, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928800\n",
      "[2018-07-17 17:42:36.347349] Iteration 35100, train loss = 0.144989, train accuracy = 0.992188\n",
      "[2018-07-17 17:42:44.067881] Iteration 35200, train loss = 0.133031, train accuracy = 1.000000\n",
      "[2018-07-17 17:42:51.784095] Iteration 35300, train loss = 0.133084, train accuracy = 1.000000\n",
      "[2018-07-17 17:42:59.513698] Iteration 35400, train loss = 0.135339, train accuracy = 1.000000\n",
      "[2018-07-17 17:43:07.233983] Iteration 35500, train loss = 0.133148, train accuracy = 1.000000\n",
      "[2018-07-17 17:43:14.954049] Iteration 35600, train loss = 0.135791, train accuracy = 1.000000\n",
      "[2018-07-17 17:43:22.662652] Iteration 35700, train loss = 0.136563, train accuracy = 1.000000\n",
      "[2018-07-17 17:43:30.376465] Iteration 35800, train loss = 0.134117, train accuracy = 1.000000\n",
      "[2018-07-17 17:43:38.097454] Iteration 35900, train loss = 0.136039, train accuracy = 1.000000\n",
      "[2018-07-17 17:43:45.821882] Iteration 36000, train loss = 0.132475, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929500\n",
      "[2018-07-17 17:43:55.806877] Iteration 36100, train loss = 0.134477, train accuracy = 1.000000\n",
      "[2018-07-17 17:44:03.531500] Iteration 36200, train loss = 0.141935, train accuracy = 0.992188\n",
      "[2018-07-17 17:44:11.245708] Iteration 36300, train loss = 0.131207, train accuracy = 1.000000\n",
      "[2018-07-17 17:44:18.987030] Iteration 36400, train loss = 0.140872, train accuracy = 1.000000\n",
      "[2018-07-17 17:44:26.708223] Iteration 36500, train loss = 0.130510, train accuracy = 1.000000\n",
      "[2018-07-17 17:44:34.435501] Iteration 36600, train loss = 0.133888, train accuracy = 1.000000\n",
      "[2018-07-17 17:44:42.157366] Iteration 36700, train loss = 0.132482, train accuracy = 1.000000\n",
      "[2018-07-17 17:44:49.858484] Iteration 36800, train loss = 0.139732, train accuracy = 1.000000\n",
      "[2018-07-17 17:44:57.574967] Iteration 36900, train loss = 0.132083, train accuracy = 1.000000\n",
      "[2018-07-17 17:45:05.291382] Iteration 37000, train loss = 0.134315, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.932200\n",
      "[2018-07-17 17:45:15.229067] Iteration 37100, train loss = 0.131747, train accuracy = 1.000000\n",
      "[2018-07-17 17:45:22.913911] Iteration 37200, train loss = 0.130664, train accuracy = 1.000000\n",
      "[2018-07-17 17:45:30.634749] Iteration 37300, train loss = 0.132847, train accuracy = 1.000000\n",
      "[2018-07-17 17:45:38.346812] Iteration 37400, train loss = 0.132944, train accuracy = 1.000000\n",
      "[2018-07-17 17:45:46.056978] Iteration 37500, train loss = 0.144267, train accuracy = 0.992188\n",
      "[2018-07-17 17:45:53.793210] Iteration 37600, train loss = 0.132691, train accuracy = 1.000000\n",
      "[2018-07-17 17:46:01.507039] Iteration 37700, train loss = 0.135427, train accuracy = 1.000000\n",
      "[2018-07-17 17:46:09.213789] Iteration 37800, train loss = 0.134638, train accuracy = 1.000000\n",
      "[2018-07-17 17:46:16.922745] Iteration 37900, train loss = 0.130799, train accuracy = 1.000000\n",
      "[2018-07-17 17:46:24.638557] Iteration 38000, train loss = 0.134610, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929800\n",
      "[2018-07-17 17:46:34.596592] Iteration 38100, train loss = 0.131919, train accuracy = 1.000000\n",
      "[2018-07-17 17:46:42.303710] Iteration 38200, train loss = 0.135933, train accuracy = 1.000000\n",
      "[2018-07-17 17:46:50.002936] Iteration 38300, train loss = 0.131235, train accuracy = 1.000000\n",
      "[2018-07-17 17:46:57.714956] Iteration 38400, train loss = 0.131118, train accuracy = 1.000000\n",
      "[2018-07-17 17:47:05.432969] Iteration 38500, train loss = 0.131293, train accuracy = 1.000000\n",
      "[2018-07-17 17:47:13.157392] Iteration 38600, train loss = 0.131773, train accuracy = 1.000000\n",
      "[2018-07-17 17:47:20.893369] Iteration 38700, train loss = 0.132943, train accuracy = 1.000000\n",
      "[2018-07-17 17:47:28.612643] Iteration 38800, train loss = 0.152797, train accuracy = 0.992188\n",
      "[2018-07-17 17:47:36.335474] Iteration 38900, train loss = 0.130829, train accuracy = 1.000000\n",
      "[2018-07-17 17:47:44.054260] Iteration 39000, train loss = 0.134637, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930400\n",
      "[2018-07-17 17:47:54.022684] Iteration 39100, train loss = 0.131633, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:01.738309] Iteration 39200, train loss = 0.133962, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:09.456835] Iteration 39300, train loss = 0.133390, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:17.188891] Iteration 39400, train loss = 0.132012, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:24.878767] Iteration 39500, train loss = 0.131707, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:32.592267] Iteration 39600, train loss = 0.134847, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:40.302402] Iteration 39700, train loss = 0.131699, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:48.018228] Iteration 39800, train loss = 0.130250, train accuracy = 1.000000\n",
      "[2018-07-17 17:48:55.735511] Iteration 39900, train loss = 0.135067, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "curr_lr = 0\n",
    "for step in range(40000):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二轮 量化\n",
    "prune_rate = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.930400\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.02865927  0.125      -0.05748745 -0.0625\n",
      "  0.00370306  0.01116415  0.06961112 -0.0625    ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.75)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-17 17:50:46.314467] Iteration 100, train loss = 0.229410, train accuracy = 0.960938\n",
      "[2018-07-17 17:50:54.051245] Iteration 200, train loss = 0.178704, train accuracy = 0.992188\n",
      "[2018-07-17 17:51:01.758212] Iteration 300, train loss = 0.168009, train accuracy = 0.992188\n",
      "[2018-07-17 17:51:09.473483] Iteration 400, train loss = 0.152799, train accuracy = 0.992188\n",
      "[2018-07-17 17:51:17.183073] Iteration 500, train loss = 0.150143, train accuracy = 0.992188\n",
      "[2018-07-17 17:51:24.916969] Iteration 600, train loss = 0.147082, train accuracy = 0.992188\n",
      "[2018-07-17 17:51:32.627619] Iteration 700, train loss = 0.150457, train accuracy = 0.984375\n",
      "[2018-07-17 17:51:40.339489] Iteration 800, train loss = 0.185311, train accuracy = 0.992188\n",
      "[2018-07-17 17:51:48.051575] Iteration 900, train loss = 0.147999, train accuracy = 0.992188\n",
      "[2018-07-17 17:51:55.774814] Iteration 1000, train loss = 0.131966, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.920200\n",
      "[2018-07-17 17:52:05.736517] Iteration 1100, train loss = 0.169648, train accuracy = 0.976562\n",
      "[2018-07-17 17:52:13.448719] Iteration 1200, train loss = 0.159013, train accuracy = 0.992188\n",
      "[2018-07-17 17:52:21.160895] Iteration 1300, train loss = 0.147418, train accuracy = 1.000000\n",
      "[2018-07-17 17:52:28.869433] Iteration 1400, train loss = 0.134696, train accuracy = 1.000000\n",
      "[2018-07-17 17:52:36.587968] Iteration 1500, train loss = 0.159457, train accuracy = 0.984375\n",
      "[2018-07-17 17:52:44.303717] Iteration 1600, train loss = 0.154707, train accuracy = 0.992188\n",
      "[2018-07-17 17:52:52.030319] Iteration 1700, train loss = 0.140819, train accuracy = 0.992188\n",
      "[2018-07-17 17:52:59.752924] Iteration 1800, train loss = 0.176998, train accuracy = 0.984375\n",
      "[2018-07-17 17:53:07.465928] Iteration 1900, train loss = 0.138420, train accuracy = 1.000000\n",
      "[2018-07-17 17:53:15.172809] Iteration 2000, train loss = 0.158413, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.926400\n",
      "[2018-07-17 17:53:25.143958] Iteration 2100, train loss = 0.152128, train accuracy = 0.984375\n",
      "[2018-07-17 17:53:32.847074] Iteration 2200, train loss = 0.157357, train accuracy = 1.000000\n",
      "[2018-07-17 17:53:40.561832] Iteration 2300, train loss = 0.138366, train accuracy = 1.000000\n",
      "[2018-07-17 17:53:48.292762] Iteration 2400, train loss = 0.148400, train accuracy = 1.000000\n",
      "[2018-07-17 17:53:56.005761] Iteration 2500, train loss = 0.138147, train accuracy = 1.000000\n",
      "[2018-07-17 17:54:03.721621] Iteration 2600, train loss = 0.178316, train accuracy = 0.984375\n",
      "[2018-07-17 17:54:11.441742] Iteration 2700, train loss = 0.145500, train accuracy = 0.992188\n",
      "[2018-07-17 17:54:19.149983] Iteration 2800, train loss = 0.133335, train accuracy = 1.000000\n",
      "[2018-07-17 17:54:26.863557] Iteration 2900, train loss = 0.144126, train accuracy = 0.992188\n",
      "[2018-07-17 17:54:34.575766] Iteration 3000, train loss = 0.136654, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.924900\n",
      "[2018-07-17 17:54:44.537102] Iteration 3100, train loss = 0.135322, train accuracy = 1.000000\n",
      "[2018-07-17 17:54:52.248707] Iteration 3200, train loss = 0.183363, train accuracy = 0.976562\n",
      "[2018-07-17 17:54:59.975667] Iteration 3300, train loss = 0.146856, train accuracy = 0.992188\n",
      "[2018-07-17 17:55:07.700685] Iteration 3400, train loss = 0.150268, train accuracy = 0.992188\n",
      "[2018-07-17 17:55:15.411369] Iteration 3500, train loss = 0.141122, train accuracy = 1.000000\n",
      "[2018-07-17 17:55:23.142032] Iteration 3600, train loss = 0.144831, train accuracy = 0.992188\n",
      "[2018-07-17 17:55:30.848573] Iteration 3700, train loss = 0.137866, train accuracy = 1.000000\n",
      "[2018-07-17 17:55:38.570844] Iteration 3800, train loss = 0.131874, train accuracy = 1.000000\n",
      "[2018-07-17 17:55:46.283167] Iteration 3900, train loss = 0.140731, train accuracy = 1.000000\n",
      "[2018-07-17 17:55:54.011627] Iteration 4000, train loss = 0.147472, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.925600\n",
      "[2018-07-17 17:56:04.014431] Iteration 4100, train loss = 0.132075, train accuracy = 1.000000\n",
      "[2018-07-17 17:56:11.751417] Iteration 4200, train loss = 0.150432, train accuracy = 0.992188\n",
      "[2018-07-17 17:56:19.487302] Iteration 4300, train loss = 0.135447, train accuracy = 1.000000\n",
      "[2018-07-17 17:56:27.213820] Iteration 4400, train loss = 0.147213, train accuracy = 0.992188\n",
      "[2018-07-17 17:56:34.950748] Iteration 4500, train loss = 0.141013, train accuracy = 1.000000\n",
      "[2018-07-17 17:56:42.692718] Iteration 4600, train loss = 0.148210, train accuracy = 0.992188\n",
      "[2018-07-17 17:56:50.428854] Iteration 4700, train loss = 0.141748, train accuracy = 1.000000\n",
      "[2018-07-17 17:56:58.160469] Iteration 4800, train loss = 0.136910, train accuracy = 0.992188\n",
      "[2018-07-17 17:57:05.889394] Iteration 4900, train loss = 0.141550, train accuracy = 1.000000\n",
      "[2018-07-17 17:57:13.623591] Iteration 5000, train loss = 0.136721, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927500\n",
      "[2018-07-17 17:57:23.618521] Iteration 5100, train loss = 0.160929, train accuracy = 0.984375\n",
      "[2018-07-17 17:57:31.357162] Iteration 5200, train loss = 0.133128, train accuracy = 1.000000\n",
      "[2018-07-17 17:57:39.086185] Iteration 5300, train loss = 0.138885, train accuracy = 1.000000\n",
      "[2018-07-17 17:57:46.814401] Iteration 5400, train loss = 0.168834, train accuracy = 0.992188\n",
      "[2018-07-17 17:57:54.545156] Iteration 5500, train loss = 0.140586, train accuracy = 0.992188\n",
      "[2018-07-17 17:58:02.278295] Iteration 5600, train loss = 0.134233, train accuracy = 1.000000\n",
      "[2018-07-17 17:58:10.010700] Iteration 5700, train loss = 0.132128, train accuracy = 1.000000\n",
      "[2018-07-17 17:58:17.749401] Iteration 5800, train loss = 0.146160, train accuracy = 0.992188\n",
      "[2018-07-17 17:58:25.456749] Iteration 5900, train loss = 0.139615, train accuracy = 1.000000\n",
      "[2018-07-17 17:58:33.165746] Iteration 6000, train loss = 0.147493, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.927400\n",
      "[2018-07-17 17:58:43.150775] Iteration 6100, train loss = 0.160870, train accuracy = 0.984375\n",
      "[2018-07-17 17:58:50.848779] Iteration 6200, train loss = 0.136914, train accuracy = 1.000000\n",
      "[2018-07-17 17:58:58.556114] Iteration 6300, train loss = 0.133897, train accuracy = 1.000000\n",
      "[2018-07-17 17:59:06.269663] Iteration 6400, train loss = 0.136979, train accuracy = 1.000000\n",
      "[2018-07-17 17:59:13.980995] Iteration 6500, train loss = 0.143933, train accuracy = 0.992188\n",
      "[2018-07-17 17:59:21.694688] Iteration 6600, train loss = 0.132203, train accuracy = 1.000000\n",
      "[2018-07-17 17:59:29.409441] Iteration 6700, train loss = 0.136550, train accuracy = 1.000000\n",
      "[2018-07-17 17:59:37.130561] Iteration 6800, train loss = 0.136101, train accuracy = 1.000000\n",
      "[2018-07-17 17:59:44.855363] Iteration 6900, train loss = 0.132062, train accuracy = 1.000000\n",
      "[2018-07-17 17:59:52.584303] Iteration 7000, train loss = 0.134628, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.925900\n",
      "[2018-07-17 18:00:02.552319] Iteration 7100, train loss = 0.144948, train accuracy = 0.992188\n",
      "[2018-07-17 18:00:10.267481] Iteration 7200, train loss = 0.137367, train accuracy = 1.000000\n",
      "[2018-07-17 18:00:18.007188] Iteration 7300, train loss = 0.136126, train accuracy = 1.000000\n",
      "[2018-07-17 18:00:25.733344] Iteration 7400, train loss = 0.148107, train accuracy = 0.992188\n",
      "[2018-07-17 18:00:33.461624] Iteration 7500, train loss = 0.150504, train accuracy = 0.992188\n",
      "[2018-07-17 18:00:41.178545] Iteration 7600, train loss = 0.152549, train accuracy = 0.992188\n",
      "[2018-07-17 18:00:48.902945] Iteration 7700, train loss = 0.141697, train accuracy = 0.992188\n",
      "[2018-07-17 18:00:56.630372] Iteration 7800, train loss = 0.153776, train accuracy = 0.992188\n",
      "[2018-07-17 18:01:04.353856] Iteration 7900, train loss = 0.135972, train accuracy = 0.992188\n",
      "[2018-07-17 18:01:12.071104] Iteration 8000, train loss = 0.135863, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 18:01:22.032742] Iteration 8100, train loss = 0.147294, train accuracy = 0.992188\n",
      "[2018-07-17 18:01:29.760413] Iteration 8200, train loss = 0.152135, train accuracy = 0.992188\n",
      "[2018-07-17 18:01:37.476844] Iteration 8300, train loss = 0.150914, train accuracy = 0.992188\n",
      "[2018-07-17 18:01:45.182268] Iteration 8400, train loss = 0.138103, train accuracy = 1.000000\n",
      "[2018-07-17 18:01:52.889565] Iteration 8500, train loss = 0.151863, train accuracy = 0.992188\n",
      "[2018-07-17 18:02:00.603870] Iteration 8600, train loss = 0.129192, train accuracy = 1.000000\n",
      "[2018-07-17 18:02:08.325485] Iteration 8700, train loss = 0.134860, train accuracy = 1.000000\n",
      "[2018-07-17 18:02:16.057272] Iteration 8800, train loss = 0.148538, train accuracy = 0.992188\n",
      "[2018-07-17 18:02:23.772276] Iteration 8900, train loss = 0.134275, train accuracy = 1.000000\n",
      "[2018-07-17 18:02:31.488237] Iteration 9000, train loss = 0.133964, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.925900\n",
      "[2018-07-17 18:02:41.456654] Iteration 9100, train loss = 0.133369, train accuracy = 1.000000\n",
      "[2018-07-17 18:02:49.156479] Iteration 9200, train loss = 0.129781, train accuracy = 1.000000\n",
      "[2018-07-17 18:02:56.875573] Iteration 9300, train loss = 0.147455, train accuracy = 0.992188\n",
      "[2018-07-17 18:03:04.580051] Iteration 9400, train loss = 0.130728, train accuracy = 1.000000\n",
      "[2018-07-17 18:03:12.302607] Iteration 9500, train loss = 0.128800, train accuracy = 1.000000\n",
      "[2018-07-17 18:03:20.011982] Iteration 9600, train loss = 0.133163, train accuracy = 1.000000\n",
      "[2018-07-17 18:03:27.719597] Iteration 9700, train loss = 0.133088, train accuracy = 1.000000\n",
      "[2018-07-17 18:03:35.434647] Iteration 9800, train loss = 0.155251, train accuracy = 0.984375\n",
      "[2018-07-17 18:03:43.170872] Iteration 9900, train loss = 0.200756, train accuracy = 0.984375\n",
      "[2018-07-17 18:03:50.897964] Iteration 10000, train loss = 0.135794, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 18:04:00.850208] Iteration 10100, train loss = 0.130572, train accuracy = 1.000000\n",
      "[2018-07-17 18:04:08.571134] Iteration 10200, train loss = 0.138913, train accuracy = 1.000000\n",
      "[2018-07-17 18:04:16.296374] Iteration 10300, train loss = 0.147479, train accuracy = 0.992188\n",
      "[2018-07-17 18:04:24.015260] Iteration 10400, train loss = 0.173149, train accuracy = 0.984375\n",
      "[2018-07-17 18:04:31.732484] Iteration 10500, train loss = 0.133925, train accuracy = 1.000000\n",
      "[2018-07-17 18:04:39.457065] Iteration 10600, train loss = 0.152647, train accuracy = 0.992188\n",
      "[2018-07-17 18:04:47.168208] Iteration 10700, train loss = 0.134665, train accuracy = 1.000000\n",
      "[2018-07-17 18:04:54.880011] Iteration 10800, train loss = 0.136744, train accuracy = 1.000000\n",
      "[2018-07-17 18:05:02.601103] Iteration 10900, train loss = 0.134455, train accuracy = 1.000000\n",
      "[2018-07-17 18:05:10.314942] Iteration 11000, train loss = 0.141201, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.926400\n",
      "[2018-07-17 18:05:20.285118] Iteration 11100, train loss = 0.130120, train accuracy = 1.000000\n",
      "[2018-07-17 18:05:28.007722] Iteration 11200, train loss = 0.139673, train accuracy = 0.992188\n",
      "[2018-07-17 18:05:35.721241] Iteration 11300, train loss = 0.131347, train accuracy = 1.000000\n",
      "[2018-07-17 18:05:43.420696] Iteration 11400, train loss = 0.140201, train accuracy = 0.992188\n",
      "[2018-07-17 18:05:51.145137] Iteration 11500, train loss = 0.128783, train accuracy = 1.000000\n",
      "[2018-07-17 18:05:58.863251] Iteration 11600, train loss = 0.130038, train accuracy = 1.000000\n",
      "[2018-07-17 18:06:06.585984] Iteration 11700, train loss = 0.129336, train accuracy = 1.000000\n",
      "[2018-07-17 18:06:14.301180] Iteration 11800, train loss = 0.139579, train accuracy = 1.000000\n",
      "[2018-07-17 18:06:22.026310] Iteration 11900, train loss = 0.132048, train accuracy = 1.000000\n",
      "[2018-07-17 18:06:29.737932] Iteration 12000, train loss = 0.143054, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.927000\n",
      "[2018-07-17 18:06:39.687589] Iteration 12100, train loss = 0.128635, train accuracy = 1.000000\n",
      "[2018-07-17 18:06:47.403137] Iteration 12200, train loss = 0.133454, train accuracy = 1.000000\n",
      "[2018-07-17 18:06:55.126141] Iteration 12300, train loss = 0.129173, train accuracy = 1.000000\n",
      "[2018-07-17 18:07:02.863870] Iteration 12400, train loss = 0.141625, train accuracy = 1.000000\n",
      "[2018-07-17 18:07:10.583531] Iteration 12500, train loss = 0.128902, train accuracy = 1.000000\n",
      "[2018-07-17 18:07:18.308378] Iteration 12600, train loss = 0.144727, train accuracy = 0.992188\n",
      "[2018-07-17 18:07:26.034783] Iteration 12700, train loss = 0.143922, train accuracy = 0.992188\n",
      "[2018-07-17 18:07:33.747164] Iteration 12800, train loss = 0.132015, train accuracy = 1.000000\n",
      "[2018-07-17 18:07:41.466631] Iteration 12900, train loss = 0.135164, train accuracy = 1.000000\n",
      "[2018-07-17 18:07:49.152521] Iteration 13000, train loss = 0.138074, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.927000\n",
      "[2018-07-17 18:07:59.110368] Iteration 13100, train loss = 0.130388, train accuracy = 1.000000\n",
      "[2018-07-17 18:08:06.845817] Iteration 13200, train loss = 0.169417, train accuracy = 0.992188\n",
      "[2018-07-17 18:08:14.552339] Iteration 13300, train loss = 0.147234, train accuracy = 0.992188\n",
      "[2018-07-17 18:08:22.258856] Iteration 13400, train loss = 0.135009, train accuracy = 1.000000\n",
      "[2018-07-17 18:08:29.994736] Iteration 13500, train loss = 0.131031, train accuracy = 1.000000\n",
      "[2018-07-17 18:08:37.720548] Iteration 13600, train loss = 0.138765, train accuracy = 0.992188\n",
      "[2018-07-17 18:08:45.438771] Iteration 13700, train loss = 0.134753, train accuracy = 1.000000\n",
      "[2018-07-17 18:08:53.151968] Iteration 13800, train loss = 0.139007, train accuracy = 1.000000\n",
      "[2018-07-17 18:09:00.870709] Iteration 13900, train loss = 0.130185, train accuracy = 1.000000\n",
      "[2018-07-17 18:09:08.579063] Iteration 14000, train loss = 0.153552, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928000\n",
      "[2018-07-17 18:09:18.577836] Iteration 14100, train loss = 0.150909, train accuracy = 0.984375\n",
      "[2018-07-17 18:09:26.305193] Iteration 14200, train loss = 0.133594, train accuracy = 1.000000\n",
      "[2018-07-17 18:09:34.035760] Iteration 14300, train loss = 0.139041, train accuracy = 0.992188\n",
      "[2018-07-17 18:09:41.754813] Iteration 14400, train loss = 0.165423, train accuracy = 0.992188\n",
      "[2018-07-17 18:09:49.490261] Iteration 14500, train loss = 0.172353, train accuracy = 0.984375\n",
      "[2018-07-17 18:09:57.212858] Iteration 14600, train loss = 0.130880, train accuracy = 1.000000\n",
      "[2018-07-17 18:10:04.933340] Iteration 14700, train loss = 0.133243, train accuracy = 1.000000\n",
      "[2018-07-17 18:10:12.649945] Iteration 14800, train loss = 0.135972, train accuracy = 1.000000\n",
      "[2018-07-17 18:10:20.373098] Iteration 14900, train loss = 0.132913, train accuracy = 1.000000\n",
      "[2018-07-17 18:10:28.099618] Iteration 15000, train loss = 0.135918, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929600\n",
      "[2018-07-17 18:10:38.056111] Iteration 15100, train loss = 0.132218, train accuracy = 1.000000\n",
      "[2018-07-17 18:10:45.792557] Iteration 15200, train loss = 0.154092, train accuracy = 0.992188\n",
      "[2018-07-17 18:10:53.505883] Iteration 15300, train loss = 0.138388, train accuracy = 1.000000\n",
      "[2018-07-17 18:11:01.220529] Iteration 15400, train loss = 0.140861, train accuracy = 0.992188\n",
      "[2018-07-17 18:11:08.936579] Iteration 15500, train loss = 0.134044, train accuracy = 1.000000\n",
      "[2018-07-17 18:11:16.643771] Iteration 15600, train loss = 0.129377, train accuracy = 1.000000\n",
      "[2018-07-17 18:11:24.354255] Iteration 15700, train loss = 0.148231, train accuracy = 0.992188\n",
      "[2018-07-17 18:11:32.071642] Iteration 15800, train loss = 0.128349, train accuracy = 1.000000\n",
      "[2018-07-17 18:11:39.797970] Iteration 15900, train loss = 0.135197, train accuracy = 1.000000\n",
      "[2018-07-17 18:11:47.517341] Iteration 16000, train loss = 0.132244, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929800\n",
      "[2018-07-17 18:11:57.483857] Iteration 16100, train loss = 0.140292, train accuracy = 0.992188\n",
      "[2018-07-17 18:12:05.202964] Iteration 16200, train loss = 0.145168, train accuracy = 0.992188\n",
      "[2018-07-17 18:12:12.918651] Iteration 16300, train loss = 0.135884, train accuracy = 1.000000\n",
      "[2018-07-17 18:12:20.653110] Iteration 16400, train loss = 0.131158, train accuracy = 1.000000\n",
      "[2018-07-17 18:12:28.371668] Iteration 16500, train loss = 0.132633, train accuracy = 1.000000\n",
      "[2018-07-17 18:12:36.107125] Iteration 16600, train loss = 0.129352, train accuracy = 1.000000\n",
      "[2018-07-17 18:12:43.829448] Iteration 16700, train loss = 0.142519, train accuracy = 0.992188\n",
      "[2018-07-17 18:12:51.554750] Iteration 16800, train loss = 0.134081, train accuracy = 1.000000\n",
      "[2018-07-17 18:12:59.293474] Iteration 16900, train loss = 0.135352, train accuracy = 1.000000\n",
      "[2018-07-17 18:13:07.025912] Iteration 17000, train loss = 0.147796, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 18:13:16.993218] Iteration 17100, train loss = 0.192772, train accuracy = 0.976562\n",
      "[2018-07-17 18:13:24.704957] Iteration 17200, train loss = 0.137755, train accuracy = 1.000000\n",
      "[2018-07-17 18:13:32.425147] Iteration 17300, train loss = 0.143936, train accuracy = 1.000000\n",
      "[2018-07-17 18:13:40.145645] Iteration 17400, train loss = 0.132403, train accuracy = 1.000000\n",
      "[2018-07-17 18:13:47.856363] Iteration 17500, train loss = 0.132275, train accuracy = 1.000000\n",
      "[2018-07-17 18:13:55.577516] Iteration 17600, train loss = 0.137618, train accuracy = 1.000000\n",
      "[2018-07-17 18:14:03.296096] Iteration 17700, train loss = 0.134562, train accuracy = 1.000000\n",
      "[2018-07-17 18:14:11.004883] Iteration 17800, train loss = 0.148293, train accuracy = 0.992188\n",
      "[2018-07-17 18:14:18.724972] Iteration 17900, train loss = 0.133746, train accuracy = 1.000000\n",
      "[2018-07-17 18:14:26.445884] Iteration 18000, train loss = 0.133320, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929200\n",
      "[2018-07-17 18:14:36.411361] Iteration 18100, train loss = 0.134728, train accuracy = 1.000000\n",
      "[2018-07-17 18:14:44.129787] Iteration 18200, train loss = 0.128743, train accuracy = 1.000000\n",
      "[2018-07-17 18:14:51.853000] Iteration 18300, train loss = 0.130801, train accuracy = 1.000000\n",
      "[2018-07-17 18:14:59.586452] Iteration 18400, train loss = 0.132056, train accuracy = 1.000000\n",
      "[2018-07-17 18:15:07.307003] Iteration 18500, train loss = 0.132439, train accuracy = 1.000000\n",
      "[2018-07-17 18:15:15.037413] Iteration 18600, train loss = 0.138955, train accuracy = 1.000000\n",
      "[2018-07-17 18:15:22.755785] Iteration 18700, train loss = 0.134412, train accuracy = 1.000000\n",
      "[2018-07-17 18:15:30.495807] Iteration 18800, train loss = 0.130289, train accuracy = 1.000000\n",
      "[2018-07-17 18:15:38.215011] Iteration 18900, train loss = 0.133669, train accuracy = 1.000000\n",
      "[2018-07-17 18:15:45.930818] Iteration 19000, train loss = 0.127437, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928500\n",
      "[2018-07-17 18:15:55.891523] Iteration 19100, train loss = 0.150956, train accuracy = 0.984375\n",
      "[2018-07-17 18:16:03.619883] Iteration 19200, train loss = 0.130175, train accuracy = 1.000000\n",
      "[2018-07-17 18:16:11.338731] Iteration 19300, train loss = 0.135692, train accuracy = 1.000000\n",
      "[2018-07-17 18:16:19.061452] Iteration 19400, train loss = 0.129216, train accuracy = 1.000000\n",
      "[2018-07-17 18:16:26.781239] Iteration 19500, train loss = 0.128751, train accuracy = 1.000000\n",
      "[2018-07-17 18:16:34.504190] Iteration 19600, train loss = 0.140580, train accuracy = 0.992188\n",
      "[2018-07-17 18:16:42.226801] Iteration 19700, train loss = 0.134853, train accuracy = 1.000000\n",
      "[2018-07-17 18:16:49.929552] Iteration 19800, train loss = 0.143716, train accuracy = 0.992188\n",
      "[2018-07-17 18:16:57.650985] Iteration 19900, train loss = 0.132499, train accuracy = 1.000000\n",
      "[2018-07-17 18:17:05.376276] Iteration 20000, train loss = 0.133089, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 18:17:15.321962] Iteration 20100, train loss = 0.136440, train accuracy = 0.992188\n",
      "[2018-07-17 18:17:23.044120] Iteration 20200, train loss = 0.136731, train accuracy = 1.000000\n",
      "[2018-07-17 18:17:30.760844] Iteration 20300, train loss = 0.130640, train accuracy = 1.000000\n",
      "[2018-07-17 18:17:38.479401] Iteration 20400, train loss = 0.139155, train accuracy = 1.000000\n",
      "[2018-07-17 18:17:46.198591] Iteration 20500, train loss = 0.135056, train accuracy = 1.000000\n",
      "[2018-07-17 18:17:53.911362] Iteration 20600, train loss = 0.136371, train accuracy = 1.000000\n",
      "[2018-07-17 18:18:01.635954] Iteration 20700, train loss = 0.136007, train accuracy = 1.000000\n",
      "[2018-07-17 18:18:09.351002] Iteration 20800, train loss = 0.130365, train accuracy = 1.000000\n",
      "[2018-07-17 18:18:17.074753] Iteration 20900, train loss = 0.129170, train accuracy = 1.000000\n",
      "[2018-07-17 18:18:24.799122] Iteration 21000, train loss = 0.131369, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928900\n",
      "[2018-07-17 18:18:34.769885] Iteration 21100, train loss = 0.134275, train accuracy = 1.000000\n",
      "[2018-07-17 18:18:42.487182] Iteration 21200, train loss = 0.137855, train accuracy = 1.000000\n",
      "[2018-07-17 18:18:50.201993] Iteration 21300, train loss = 0.139835, train accuracy = 1.000000\n",
      "[2018-07-17 18:18:57.927496] Iteration 21400, train loss = 0.140592, train accuracy = 1.000000\n",
      "[2018-07-17 18:19:05.639979] Iteration 21500, train loss = 0.142175, train accuracy = 0.992188\n",
      "[2018-07-17 18:19:13.362433] Iteration 21600, train loss = 0.138323, train accuracy = 1.000000\n",
      "[2018-07-17 18:19:21.085297] Iteration 21700, train loss = 0.141837, train accuracy = 0.992188\n",
      "[2018-07-17 18:19:28.796543] Iteration 21800, train loss = 0.155208, train accuracy = 0.984375\n",
      "[2018-07-17 18:19:36.512763] Iteration 21900, train loss = 0.138817, train accuracy = 0.992188\n",
      "[2018-07-17 18:19:44.244785] Iteration 22000, train loss = 0.128563, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930500\n",
      "[2018-07-17 18:19:54.241835] Iteration 22100, train loss = 0.130476, train accuracy = 1.000000\n",
      "[2018-07-17 18:20:01.960958] Iteration 22200, train loss = 0.151958, train accuracy = 0.992188\n",
      "[2018-07-17 18:20:09.682707] Iteration 22300, train loss = 0.130535, train accuracy = 1.000000\n",
      "[2018-07-17 18:20:17.390289] Iteration 22400, train loss = 0.143295, train accuracy = 0.992188\n",
      "[2018-07-17 18:20:25.127566] Iteration 22500, train loss = 0.141319, train accuracy = 1.000000\n",
      "[2018-07-17 18:20:32.842814] Iteration 22600, train loss = 0.130729, train accuracy = 1.000000\n",
      "[2018-07-17 18:20:40.555432] Iteration 22700, train loss = 0.148544, train accuracy = 0.992188\n",
      "[2018-07-17 18:20:48.270028] Iteration 22800, train loss = 0.145991, train accuracy = 0.992188\n",
      "[2018-07-17 18:20:55.974728] Iteration 22900, train loss = 0.156796, train accuracy = 0.984375\n",
      "[2018-07-17 18:21:03.688775] Iteration 23000, train loss = 0.137252, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929300\n",
      "[2018-07-17 18:21:13.649661] Iteration 23100, train loss = 0.150995, train accuracy = 0.976562\n",
      "[2018-07-17 18:21:21.356684] Iteration 23200, train loss = 0.132345, train accuracy = 1.000000\n",
      "[2018-07-17 18:21:29.072052] Iteration 23300, train loss = 0.145296, train accuracy = 0.992188\n",
      "[2018-07-17 18:21:36.791124] Iteration 23400, train loss = 0.132640, train accuracy = 1.000000\n",
      "[2018-07-17 18:21:44.515630] Iteration 23500, train loss = 0.143748, train accuracy = 0.992188\n",
      "[2018-07-17 18:21:52.247330] Iteration 23600, train loss = 0.133605, train accuracy = 1.000000\n",
      "[2018-07-17 18:21:59.965364] Iteration 23700, train loss = 0.141721, train accuracy = 0.992188\n",
      "[2018-07-17 18:22:07.699138] Iteration 23800, train loss = 0.133895, train accuracy = 1.000000\n",
      "[2018-07-17 18:22:15.410544] Iteration 23900, train loss = 0.131825, train accuracy = 1.000000\n",
      "[2018-07-17 18:22:23.143585] Iteration 24000, train loss = 0.128409, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929800\n",
      "[2018-07-17 18:22:33.113106] Iteration 24100, train loss = 0.133234, train accuracy = 1.000000\n",
      "[2018-07-17 18:22:40.828098] Iteration 24200, train loss = 0.130519, train accuracy = 1.000000\n",
      "[2018-07-17 18:22:48.555944] Iteration 24300, train loss = 0.128748, train accuracy = 1.000000\n",
      "[2018-07-17 18:22:56.274660] Iteration 24400, train loss = 0.131370, train accuracy = 1.000000\n",
      "[2018-07-17 18:23:03.985632] Iteration 24500, train loss = 0.128922, train accuracy = 1.000000\n",
      "[2018-07-17 18:23:11.699300] Iteration 24600, train loss = 0.143124, train accuracy = 0.984375\n",
      "[2018-07-17 18:23:19.419908] Iteration 24700, train loss = 0.130465, train accuracy = 1.000000\n",
      "[2018-07-17 18:23:27.129698] Iteration 24800, train loss = 0.131682, train accuracy = 1.000000\n",
      "[2018-07-17 18:23:34.846970] Iteration 24900, train loss = 0.130877, train accuracy = 1.000000\n",
      "[2018-07-17 18:23:42.564660] Iteration 25000, train loss = 0.132676, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 18:23:52.518565] Iteration 25100, train loss = 0.133217, train accuracy = 1.000000\n",
      "[2018-07-17 18:24:00.239906] Iteration 25200, train loss = 0.129446, train accuracy = 1.000000\n",
      "[2018-07-17 18:24:07.954898] Iteration 25300, train loss = 0.148694, train accuracy = 0.992188\n",
      "[2018-07-17 18:24:15.668589] Iteration 25400, train loss = 0.131119, train accuracy = 1.000000\n",
      "[2018-07-17 18:24:23.365397] Iteration 25500, train loss = 0.130366, train accuracy = 1.000000\n",
      "[2018-07-17 18:24:31.076879] Iteration 25600, train loss = 0.131269, train accuracy = 1.000000\n",
      "[2018-07-17 18:24:38.789460] Iteration 25700, train loss = 0.133543, train accuracy = 1.000000\n",
      "[2018-07-17 18:24:46.508276] Iteration 25800, train loss = 0.131309, train accuracy = 1.000000\n",
      "[2018-07-17 18:24:54.231916] Iteration 25900, train loss = 0.129402, train accuracy = 1.000000\n",
      "[2018-07-17 18:25:01.947368] Iteration 26000, train loss = 0.129133, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 18:25:11.919757] Iteration 26100, train loss = 0.133008, train accuracy = 1.000000\n",
      "[2018-07-17 18:25:19.641724] Iteration 26200, train loss = 0.128261, train accuracy = 1.000000\n",
      "[2018-07-17 18:25:27.357387] Iteration 26300, train loss = 0.129772, train accuracy = 1.000000\n",
      "[2018-07-17 18:25:35.085524] Iteration 26400, train loss = 0.138522, train accuracy = 0.992188\n",
      "[2018-07-17 18:25:42.806079] Iteration 26500, train loss = 0.134242, train accuracy = 1.000000\n",
      "[2018-07-17 18:25:50.527346] Iteration 26600, train loss = 0.133828, train accuracy = 1.000000\n",
      "[2018-07-17 18:25:58.222158] Iteration 26700, train loss = 0.129376, train accuracy = 1.000000\n",
      "[2018-07-17 18:26:05.959549] Iteration 26800, train loss = 0.128101, train accuracy = 1.000000\n",
      "[2018-07-17 18:26:13.683911] Iteration 26900, train loss = 0.135121, train accuracy = 1.000000\n",
      "[2018-07-17 18:26:21.411365] Iteration 27000, train loss = 0.129387, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929700\n",
      "[2018-07-17 18:26:31.393116] Iteration 27100, train loss = 0.132809, train accuracy = 1.000000\n",
      "[2018-07-17 18:26:39.128128] Iteration 27200, train loss = 0.139357, train accuracy = 0.992188\n",
      "[2018-07-17 18:26:46.851463] Iteration 27300, train loss = 0.136489, train accuracy = 1.000000\n",
      "[2018-07-17 18:26:54.572304] Iteration 27400, train loss = 0.136400, train accuracy = 1.000000\n",
      "[2018-07-17 18:27:02.291099] Iteration 27500, train loss = 0.131069, train accuracy = 1.000000\n",
      "[2018-07-17 18:27:10.007786] Iteration 27600, train loss = 0.138583, train accuracy = 0.992188\n",
      "[2018-07-17 18:27:17.724473] Iteration 27700, train loss = 0.132975, train accuracy = 1.000000\n",
      "[2018-07-17 18:27:25.417892] Iteration 27800, train loss = 0.134007, train accuracy = 1.000000\n",
      "[2018-07-17 18:27:33.140007] Iteration 27900, train loss = 0.139517, train accuracy = 1.000000\n",
      "[2018-07-17 18:27:40.857160] Iteration 28000, train loss = 0.138175, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.929900\n",
      "[2018-07-17 18:27:50.832580] Iteration 28100, train loss = 0.133237, train accuracy = 1.000000\n",
      "[2018-07-17 18:27:58.547837] Iteration 28200, train loss = 0.130329, train accuracy = 1.000000\n",
      "[2018-07-17 18:28:06.270181] Iteration 28300, train loss = 0.142764, train accuracy = 0.992188\n",
      "[2018-07-17 18:28:13.981202] Iteration 28400, train loss = 0.134862, train accuracy = 0.992188\n",
      "[2018-07-17 18:28:21.698574] Iteration 28500, train loss = 0.148166, train accuracy = 0.992188\n",
      "[2018-07-17 18:28:29.432442] Iteration 28600, train loss = 0.134998, train accuracy = 1.000000\n",
      "[2018-07-17 18:28:37.147200] Iteration 28700, train loss = 0.129836, train accuracy = 1.000000\n",
      "[2018-07-17 18:28:44.869904] Iteration 28800, train loss = 0.137659, train accuracy = 1.000000\n",
      "[2018-07-17 18:28:52.582918] Iteration 28900, train loss = 0.133523, train accuracy = 1.000000\n",
      "[2018-07-17 18:29:00.292732] Iteration 29000, train loss = 0.136200, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930600\n",
      "[2018-07-17 18:29:10.264479] Iteration 29100, train loss = 0.131504, train accuracy = 1.000000\n",
      "[2018-07-17 18:29:17.977957] Iteration 29200, train loss = 0.129522, train accuracy = 1.000000\n",
      "[2018-07-17 18:29:25.686575] Iteration 29300, train loss = 0.143026, train accuracy = 0.984375\n",
      "[2018-07-17 18:29:33.410176] Iteration 29400, train loss = 0.134036, train accuracy = 1.000000\n",
      "[2018-07-17 18:29:41.132506] Iteration 29500, train loss = 0.129931, train accuracy = 1.000000\n",
      "[2018-07-17 18:29:48.856843] Iteration 29600, train loss = 0.138147, train accuracy = 0.992188\n",
      "[2018-07-17 18:29:56.573867] Iteration 29700, train loss = 0.138819, train accuracy = 1.000000\n",
      "[2018-07-17 18:30:04.296699] Iteration 29800, train loss = 0.140944, train accuracy = 0.992188\n",
      "[2018-07-17 18:30:12.012436] Iteration 29900, train loss = 0.128536, train accuracy = 1.000000\n",
      "[2018-07-17 18:30:19.727553] Iteration 30000, train loss = 0.133028, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928700\n",
      "[2018-07-17 18:30:29.739961] Iteration 30100, train loss = 0.130526, train accuracy = 1.000000\n",
      "[2018-07-17 18:30:37.455497] Iteration 30200, train loss = 0.143153, train accuracy = 0.992188\n",
      "[2018-07-17 18:30:45.175125] Iteration 30300, train loss = 0.130021, train accuracy = 1.000000\n",
      "[2018-07-17 18:30:52.892910] Iteration 30400, train loss = 0.156494, train accuracy = 0.992188\n",
      "[2018-07-17 18:31:00.612341] Iteration 30500, train loss = 0.137935, train accuracy = 1.000000\n",
      "[2018-07-17 18:31:08.340247] Iteration 30600, train loss = 0.130874, train accuracy = 1.000000\n",
      "[2018-07-17 18:31:16.064278] Iteration 30700, train loss = 0.139848, train accuracy = 0.992188\n",
      "[2018-07-17 18:31:23.781008] Iteration 30800, train loss = 0.138915, train accuracy = 0.992188\n",
      "[2018-07-17 18:31:31.498338] Iteration 30900, train loss = 0.128979, train accuracy = 1.000000\n",
      "[2018-07-17 18:31:39.215681] Iteration 31000, train loss = 0.146807, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.930400\n",
      "[2018-07-17 18:31:49.185820] Iteration 31100, train loss = 0.128353, train accuracy = 1.000000\n",
      "[2018-07-17 18:31:56.877426] Iteration 31200, train loss = 0.138255, train accuracy = 1.000000\n",
      "[2018-07-17 18:32:04.591799] Iteration 31300, train loss = 0.134523, train accuracy = 1.000000\n",
      "[2018-07-17 18:32:12.325008] Iteration 31400, train loss = 0.137529, train accuracy = 0.992188\n",
      "[2018-07-17 18:32:20.053320] Iteration 31500, train loss = 0.128412, train accuracy = 1.000000\n",
      "[2018-07-17 18:32:27.780075] Iteration 31600, train loss = 0.146238, train accuracy = 0.992188\n",
      "[2018-07-17 18:32:35.494672] Iteration 31700, train loss = 0.131706, train accuracy = 1.000000\n",
      "[2018-07-17 18:32:43.215815] Iteration 31800, train loss = 0.133350, train accuracy = 1.000000\n",
      "[2018-07-17 18:32:50.931917] Iteration 31900, train loss = 0.129608, train accuracy = 1.000000\n",
      "[2018-07-17 18:32:58.645383] Iteration 32000, train loss = 0.128789, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930100\n",
      "[2018-07-17 18:33:08.596640] Iteration 32100, train loss = 0.142136, train accuracy = 1.000000\n",
      "[2018-07-17 18:33:16.308577] Iteration 32200, train loss = 0.136983, train accuracy = 1.000000\n",
      "[2018-07-17 18:33:24.012615] Iteration 32300, train loss = 0.130890, train accuracy = 1.000000\n",
      "[2018-07-17 18:33:31.741575] Iteration 32400, train loss = 0.131407, train accuracy = 1.000000\n",
      "[2018-07-17 18:33:39.455653] Iteration 32500, train loss = 0.130167, train accuracy = 1.000000\n",
      "[2018-07-17 18:33:47.178176] Iteration 32600, train loss = 0.145252, train accuracy = 0.992188\n",
      "[2018-07-17 18:33:54.898304] Iteration 32700, train loss = 0.130624, train accuracy = 1.000000\n",
      "[2018-07-17 18:34:02.624230] Iteration 32800, train loss = 0.136468, train accuracy = 0.992188\n",
      "[2018-07-17 18:34:10.347916] Iteration 32900, train loss = 0.145778, train accuracy = 0.992188\n",
      "[2018-07-17 18:34:18.065991] Iteration 33000, train loss = 0.131404, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.931300\n",
      "[2018-07-17 18:34:28.027003] Iteration 33100, train loss = 0.128925, train accuracy = 1.000000\n",
      "[2018-07-17 18:34:35.747327] Iteration 33200, train loss = 0.137295, train accuracy = 0.992188\n",
      "[2018-07-17 18:34:43.466033] Iteration 33300, train loss = 0.132382, train accuracy = 1.000000\n",
      "[2018-07-17 18:34:51.176610] Iteration 33400, train loss = 0.139389, train accuracy = 0.992188\n",
      "[2018-07-17 18:34:58.883367] Iteration 33500, train loss = 0.137672, train accuracy = 0.992188\n",
      "[2018-07-17 18:35:06.596255] Iteration 33600, train loss = 0.150508, train accuracy = 0.992188\n",
      "[2018-07-17 18:35:14.323879] Iteration 33700, train loss = 0.138567, train accuracy = 1.000000\n",
      "[2018-07-17 18:35:22.032373] Iteration 33800, train loss = 0.132708, train accuracy = 1.000000\n",
      "[2018-07-17 18:35:29.747479] Iteration 33900, train loss = 0.129413, train accuracy = 1.000000\n",
      "[2018-07-17 18:35:37.469762] Iteration 34000, train loss = 0.133921, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930100\n",
      "[2018-07-17 18:35:47.443669] Iteration 34100, train loss = 0.130631, train accuracy = 1.000000\n",
      "[2018-07-17 18:35:55.157025] Iteration 34200, train loss = 0.129623, train accuracy = 1.000000\n",
      "[2018-07-17 18:36:02.870550] Iteration 34300, train loss = 0.145699, train accuracy = 1.000000\n",
      "[2018-07-17 18:36:10.580138] Iteration 34400, train loss = 0.134127, train accuracy = 1.000000\n",
      "[2018-07-17 18:36:18.305380] Iteration 34500, train loss = 0.130400, train accuracy = 1.000000\n",
      "[2018-07-17 18:36:26.006625] Iteration 34600, train loss = 0.162454, train accuracy = 0.992188\n",
      "[2018-07-17 18:36:33.735001] Iteration 34700, train loss = 0.138982, train accuracy = 0.992188\n",
      "[2018-07-17 18:36:41.460339] Iteration 34800, train loss = 0.131528, train accuracy = 1.000000\n",
      "[2018-07-17 18:36:49.183841] Iteration 34900, train loss = 0.131335, train accuracy = 1.000000\n",
      "[2018-07-17 18:36:56.898447] Iteration 35000, train loss = 0.138360, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 18:37:06.878350] Iteration 35100, train loss = 0.132629, train accuracy = 1.000000\n",
      "[2018-07-17 18:37:14.600576] Iteration 35200, train loss = 0.131493, train accuracy = 1.000000\n",
      "[2018-07-17 18:37:22.319324] Iteration 35300, train loss = 0.128153, train accuracy = 1.000000\n",
      "[2018-07-17 18:37:30.036788] Iteration 35400, train loss = 0.130388, train accuracy = 1.000000\n",
      "[2018-07-17 18:37:37.763827] Iteration 35500, train loss = 0.131763, train accuracy = 1.000000\n",
      "[2018-07-17 18:37:45.482314] Iteration 35600, train loss = 0.140757, train accuracy = 0.992188\n",
      "[2018-07-17 18:37:53.209182] Iteration 35700, train loss = 0.157134, train accuracy = 0.992188\n",
      "[2018-07-17 18:38:00.926518] Iteration 35800, train loss = 0.130462, train accuracy = 1.000000\n",
      "[2018-07-17 18:38:08.653419] Iteration 35900, train loss = 0.137500, train accuracy = 0.992188\n",
      "[2018-07-17 18:38:16.369222] Iteration 36000, train loss = 0.130103, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928900\n",
      "[2018-07-17 18:38:26.346712] Iteration 36100, train loss = 0.132186, train accuracy = 1.000000\n",
      "[2018-07-17 18:38:34.070013] Iteration 36200, train loss = 0.138465, train accuracy = 0.992188\n",
      "[2018-07-17 18:38:41.782899] Iteration 36300, train loss = 0.135040, train accuracy = 1.000000\n",
      "[2018-07-17 18:38:49.525401] Iteration 36400, train loss = 0.132379, train accuracy = 1.000000\n",
      "[2018-07-17 18:38:57.271730] Iteration 36500, train loss = 0.141049, train accuracy = 0.992188\n",
      "[2018-07-17 18:39:05.005789] Iteration 36600, train loss = 0.128153, train accuracy = 1.000000\n",
      "[2018-07-17 18:39:12.720255] Iteration 36700, train loss = 0.128596, train accuracy = 1.000000\n",
      "[2018-07-17 18:39:20.446417] Iteration 36800, train loss = 0.131492, train accuracy = 1.000000\n",
      "[2018-07-17 18:39:28.155353] Iteration 36900, train loss = 0.132699, train accuracy = 1.000000\n",
      "[2018-07-17 18:39:35.866955] Iteration 37000, train loss = 0.141131, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928500\n",
      "[2018-07-17 18:39:45.824335] Iteration 37100, train loss = 0.138541, train accuracy = 1.000000\n",
      "[2018-07-17 18:39:53.539529] Iteration 37200, train loss = 0.133035, train accuracy = 1.000000\n",
      "[2018-07-17 18:40:01.244372] Iteration 37300, train loss = 0.132220, train accuracy = 1.000000\n",
      "[2018-07-17 18:40:08.964823] Iteration 37400, train loss = 0.131166, train accuracy = 1.000000\n",
      "[2018-07-17 18:40:16.705532] Iteration 37500, train loss = 0.136981, train accuracy = 1.000000\n",
      "[2018-07-17 18:40:24.432590] Iteration 37600, train loss = 0.144166, train accuracy = 0.992188\n",
      "[2018-07-17 18:40:32.165090] Iteration 37700, train loss = 0.132487, train accuracy = 1.000000\n",
      "[2018-07-17 18:40:39.880756] Iteration 37800, train loss = 0.135742, train accuracy = 1.000000\n",
      "[2018-07-17 18:40:47.608552] Iteration 37900, train loss = 0.133195, train accuracy = 1.000000\n",
      "[2018-07-17 18:40:55.331950] Iteration 38000, train loss = 0.129208, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930300\n",
      "[2018-07-17 18:41:05.296364] Iteration 38100, train loss = 0.131501, train accuracy = 1.000000\n",
      "[2018-07-17 18:41:13.007321] Iteration 38200, train loss = 0.129892, train accuracy = 1.000000\n",
      "[2018-07-17 18:41:20.724780] Iteration 38300, train loss = 0.130431, train accuracy = 1.000000\n",
      "[2018-07-17 18:41:28.440167] Iteration 38400, train loss = 0.132552, train accuracy = 1.000000\n",
      "[2018-07-17 18:41:36.157662] Iteration 38500, train loss = 0.130434, train accuracy = 1.000000\n",
      "[2018-07-17 18:41:43.866901] Iteration 38600, train loss = 0.133459, train accuracy = 1.000000\n",
      "[2018-07-17 18:41:51.580244] Iteration 38700, train loss = 0.133144, train accuracy = 1.000000\n",
      "[2018-07-17 18:41:59.318231] Iteration 38800, train loss = 0.130145, train accuracy = 1.000000\n",
      "[2018-07-17 18:42:07.045380] Iteration 38900, train loss = 0.134757, train accuracy = 1.000000\n",
      "[2018-07-17 18:42:14.751767] Iteration 39000, train loss = 0.133824, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930800\n",
      "[2018-07-17 18:42:24.688953] Iteration 39100, train loss = 0.153363, train accuracy = 0.992188\n",
      "[2018-07-17 18:42:32.404073] Iteration 39200, train loss = 0.133895, train accuracy = 1.000000\n",
      "[2018-07-17 18:42:40.123247] Iteration 39300, train loss = 0.128127, train accuracy = 1.000000\n",
      "[2018-07-17 18:42:47.840068] Iteration 39400, train loss = 0.129663, train accuracy = 1.000000\n",
      "[2018-07-17 18:42:55.555453] Iteration 39500, train loss = 0.128791, train accuracy = 1.000000\n",
      "[2018-07-17 18:43:03.281436] Iteration 39600, train loss = 0.129600, train accuracy = 1.000000\n",
      "[2018-07-17 18:43:10.995391] Iteration 39700, train loss = 0.131434, train accuracy = 1.000000\n",
      "[2018-07-17 18:43:18.710050] Iteration 39800, train loss = 0.131741, train accuracy = 1.000000\n",
      "[2018-07-17 18:43:26.429779] Iteration 39900, train loss = 0.130007, train accuracy = 1.000000\n",
      "[2018-07-17 18:43:34.160628] Iteration 40000, train loss = 0.129512, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930300\n",
      "[2018-07-17 18:43:44.129393] Iteration 40100, train loss = 0.136997, train accuracy = 0.992188\n",
      "[2018-07-17 18:43:51.853519] Iteration 40200, train loss = 0.143491, train accuracy = 0.992188\n",
      "[2018-07-17 18:43:59.556187] Iteration 40300, train loss = 0.135315, train accuracy = 1.000000\n",
      "[2018-07-17 18:44:07.273025] Iteration 40400, train loss = 0.132920, train accuracy = 1.000000\n",
      "[2018-07-17 18:44:15.000886] Iteration 40500, train loss = 0.131399, train accuracy = 1.000000\n",
      "[2018-07-17 18:44:22.731847] Iteration 40600, train loss = 0.138005, train accuracy = 1.000000\n",
      "[2018-07-17 18:44:30.452022] Iteration 40700, train loss = 0.129156, train accuracy = 1.000000\n",
      "[2018-07-17 18:44:38.171546] Iteration 40800, train loss = 0.129728, train accuracy = 1.000000\n",
      "[2018-07-17 18:44:45.883151] Iteration 40900, train loss = 0.134474, train accuracy = 1.000000\n",
      "[2018-07-17 18:44:53.604489] Iteration 41000, train loss = 0.132113, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929600\n",
      "[2018-07-17 18:45:03.575962] Iteration 41100, train loss = 0.130397, train accuracy = 1.000000\n",
      "[2018-07-17 18:45:11.311082] Iteration 41200, train loss = 0.134636, train accuracy = 1.000000\n",
      "[2018-07-17 18:45:19.019507] Iteration 41300, train loss = 0.127864, train accuracy = 1.000000\n",
      "[2018-07-17 18:45:26.725665] Iteration 41400, train loss = 0.132033, train accuracy = 1.000000\n",
      "[2018-07-17 18:45:34.444672] Iteration 41500, train loss = 0.146522, train accuracy = 0.992188\n",
      "[2018-07-17 18:45:42.155248] Iteration 41600, train loss = 0.153847, train accuracy = 0.992188\n",
      "[2018-07-17 18:45:49.882264] Iteration 41700, train loss = 0.129355, train accuracy = 1.000000\n",
      "[2018-07-17 18:45:57.597584] Iteration 41800, train loss = 0.150941, train accuracy = 0.984375\n",
      "[2018-07-17 18:46:05.322704] Iteration 41900, train loss = 0.129910, train accuracy = 1.000000\n",
      "[2018-07-17 18:46:13.037642] Iteration 42000, train loss = 0.141381, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.930200\n",
      "[2018-07-17 18:46:23.027145] Iteration 42100, train loss = 0.131731, train accuracy = 1.000000\n",
      "[2018-07-17 18:46:30.731041] Iteration 42200, train loss = 0.133803, train accuracy = 1.000000\n",
      "[2018-07-17 18:46:38.442611] Iteration 42300, train loss = 0.133933, train accuracy = 1.000000\n",
      "[2018-07-17 18:46:46.180805] Iteration 42400, train loss = 0.133099, train accuracy = 1.000000\n",
      "[2018-07-17 18:46:53.910818] Iteration 42500, train loss = 0.140852, train accuracy = 0.992188\n",
      "[2018-07-17 18:47:01.605389] Iteration 42600, train loss = 0.131986, train accuracy = 1.000000\n",
      "[2018-07-17 18:47:09.321251] Iteration 42700, train loss = 0.129655, train accuracy = 1.000000\n",
      "[2018-07-17 18:47:17.049354] Iteration 42800, train loss = 0.138498, train accuracy = 1.000000\n",
      "[2018-07-17 18:47:24.773334] Iteration 42900, train loss = 0.139694, train accuracy = 0.992188\n",
      "[2018-07-17 18:47:32.498332] Iteration 43000, train loss = 0.152697, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.930300\n",
      "[2018-07-17 18:47:42.461140] Iteration 43100, train loss = 0.129149, train accuracy = 1.000000\n",
      "[2018-07-17 18:47:50.196396] Iteration 43200, train loss = 0.136468, train accuracy = 1.000000\n",
      "[2018-07-17 18:47:57.919102] Iteration 43300, train loss = 0.130822, train accuracy = 1.000000\n",
      "[2018-07-17 18:48:05.632334] Iteration 43400, train loss = 0.134326, train accuracy = 1.000000\n",
      "[2018-07-17 18:48:13.350852] Iteration 43500, train loss = 0.137408, train accuracy = 1.000000\n",
      "[2018-07-17 18:48:21.081523] Iteration 43600, train loss = 0.130314, train accuracy = 1.000000\n",
      "[2018-07-17 18:48:28.797642] Iteration 43700, train loss = 0.134350, train accuracy = 1.000000\n",
      "[2018-07-17 18:48:36.507813] Iteration 43800, train loss = 0.133319, train accuracy = 1.000000\n",
      "[2018-07-17 18:48:44.221821] Iteration 43900, train loss = 0.139318, train accuracy = 1.000000\n",
      "[2018-07-17 18:48:51.951654] Iteration 44000, train loss = 0.130138, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 18:49:01.938332] Iteration 44100, train loss = 0.136297, train accuracy = 1.000000\n",
      "[2018-07-17 18:49:09.647781] Iteration 44200, train loss = 0.134315, train accuracy = 1.000000\n",
      "[2018-07-17 18:49:17.373612] Iteration 44300, train loss = 0.128971, train accuracy = 1.000000\n",
      "[2018-07-17 18:49:25.104923] Iteration 44400, train loss = 0.131585, train accuracy = 1.000000\n",
      "[2018-07-17 18:49:32.816158] Iteration 44500, train loss = 0.154906, train accuracy = 0.992188\n",
      "[2018-07-17 18:49:40.532444] Iteration 44600, train loss = 0.129350, train accuracy = 1.000000\n",
      "[2018-07-17 18:49:48.245142] Iteration 44700, train loss = 0.142219, train accuracy = 0.992188\n",
      "[2018-07-17 18:49:55.969759] Iteration 44800, train loss = 0.131668, train accuracy = 1.000000\n",
      "[2018-07-17 18:50:03.676350] Iteration 44900, train loss = 0.130826, train accuracy = 1.000000\n",
      "[2018-07-17 18:50:11.414447] Iteration 45000, train loss = 0.129698, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929300\n",
      "[2018-07-17 18:50:21.385533] Iteration 45100, train loss = 0.155778, train accuracy = 0.992188\n",
      "[2018-07-17 18:50:29.104718] Iteration 45200, train loss = 0.130749, train accuracy = 1.000000\n",
      "[2018-07-17 18:50:36.826685] Iteration 45300, train loss = 0.138547, train accuracy = 1.000000\n",
      "[2018-07-17 18:50:44.549161] Iteration 45400, train loss = 0.132158, train accuracy = 1.000000\n",
      "[2018-07-17 18:50:52.260248] Iteration 45500, train loss = 0.128403, train accuracy = 1.000000\n",
      "[2018-07-17 18:50:59.997622] Iteration 45600, train loss = 0.131158, train accuracy = 1.000000\n",
      "[2018-07-17 18:51:07.723023] Iteration 45700, train loss = 0.131809, train accuracy = 1.000000\n",
      "[2018-07-17 18:51:15.441604] Iteration 45800, train loss = 0.131270, train accuracy = 1.000000\n",
      "[2018-07-17 18:51:23.160378] Iteration 45900, train loss = 0.132183, train accuracy = 1.000000\n",
      "[2018-07-17 18:51:30.885911] Iteration 46000, train loss = 0.129320, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930100\n",
      "[2018-07-17 18:51:40.885098] Iteration 46100, train loss = 0.134074, train accuracy = 1.000000\n",
      "[2018-07-17 18:51:48.596386] Iteration 46200, train loss = 0.132048, train accuracy = 1.000000\n",
      "[2018-07-17 18:51:56.325660] Iteration 46300, train loss = 0.130738, train accuracy = 1.000000\n",
      "[2018-07-17 18:52:04.038325] Iteration 46400, train loss = 0.128298, train accuracy = 1.000000\n",
      "[2018-07-17 18:52:11.764425] Iteration 46500, train loss = 0.134764, train accuracy = 1.000000\n",
      "[2018-07-17 18:52:19.493142] Iteration 46600, train loss = 0.142351, train accuracy = 0.992188\n",
      "[2018-07-17 18:52:27.220304] Iteration 46700, train loss = 0.128001, train accuracy = 1.000000\n",
      "[2018-07-17 18:52:34.927819] Iteration 46800, train loss = 0.131462, train accuracy = 1.000000\n",
      "[2018-07-17 18:52:42.654519] Iteration 46900, train loss = 0.131000, train accuracy = 1.000000\n",
      "[2018-07-17 18:52:50.369668] Iteration 47000, train loss = 0.133896, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930200\n",
      "[2018-07-17 18:53:00.309194] Iteration 47100, train loss = 0.129574, train accuracy = 1.000000\n",
      "[2018-07-17 18:53:08.028533] Iteration 47200, train loss = 0.128652, train accuracy = 1.000000\n",
      "[2018-07-17 18:53:15.743003] Iteration 47300, train loss = 0.130360, train accuracy = 1.000000\n",
      "[2018-07-17 18:53:23.459500] Iteration 47400, train loss = 0.129098, train accuracy = 1.000000\n",
      "[2018-07-17 18:53:31.175412] Iteration 47500, train loss = 0.135228, train accuracy = 0.992188\n",
      "[2018-07-17 18:53:38.891135] Iteration 47600, train loss = 0.130364, train accuracy = 1.000000\n",
      "[2018-07-17 18:53:46.604649] Iteration 47700, train loss = 0.135067, train accuracy = 1.000000\n",
      "[2018-07-17 18:53:54.351533] Iteration 47800, train loss = 0.131158, train accuracy = 1.000000\n",
      "[2018-07-17 18:54:02.072272] Iteration 47900, train loss = 0.129011, train accuracy = 1.000000\n",
      "[2018-07-17 18:54:09.797654] Iteration 48000, train loss = 0.136602, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930200\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-17 18:54:19.786404] Iteration 48100, train loss = 0.129578, train accuracy = 1.000000\n",
      "[2018-07-17 18:54:27.484708] Iteration 48200, train loss = 0.127332, train accuracy = 1.000000\n",
      "[2018-07-17 18:54:35.202184] Iteration 48300, train loss = 0.129476, train accuracy = 1.000000\n",
      "[2018-07-17 18:54:42.930886] Iteration 48400, train loss = 0.132901, train accuracy = 1.000000\n",
      "[2018-07-17 18:54:50.643052] Iteration 48500, train loss = 0.131560, train accuracy = 1.000000\n",
      "[2018-07-17 18:54:58.372148] Iteration 48600, train loss = 0.130720, train accuracy = 1.000000\n",
      "[2018-07-17 18:55:06.080415] Iteration 48700, train loss = 0.148396, train accuracy = 0.992188\n",
      "[2018-07-17 18:55:13.807745] Iteration 48800, train loss = 0.136884, train accuracy = 0.992188\n",
      "[2018-07-17 18:55:21.535594] Iteration 48900, train loss = 0.129403, train accuracy = 1.000000\n",
      "[2018-07-17 18:55:29.244196] Iteration 49000, train loss = 0.129056, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930400\n",
      "[2018-07-17 18:55:39.220500] Iteration 49100, train loss = 0.128620, train accuracy = 1.000000\n",
      "[2018-07-17 18:55:46.946403] Iteration 49200, train loss = 0.135051, train accuracy = 1.000000\n",
      "[2018-07-17 18:55:54.674303] Iteration 49300, train loss = 0.128473, train accuracy = 1.000000\n",
      "[2018-07-17 18:56:02.385454] Iteration 49400, train loss = 0.130011, train accuracy = 1.000000\n",
      "[2018-07-17 18:56:10.105976] Iteration 49500, train loss = 0.130433, train accuracy = 1.000000\n",
      "[2018-07-17 18:56:17.827994] Iteration 49600, train loss = 0.140814, train accuracy = 0.992188\n",
      "[2018-07-17 18:56:25.554621] Iteration 49700, train loss = 0.128878, train accuracy = 1.000000\n",
      "[2018-07-17 18:56:33.278657] Iteration 49800, train loss = 0.132548, train accuracy = 1.000000\n",
      "[2018-07-17 18:56:40.994271] Iteration 49900, train loss = 0.133863, train accuracy = 1.000000\n",
      "[2018-07-17 18:56:48.721616] Iteration 50000, train loss = 0.129507, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929900\n",
      "[2018-07-17 18:56:58.719775] Iteration 50100, train loss = 0.131010, train accuracy = 1.000000\n",
      "[2018-07-17 18:57:06.436566] Iteration 50200, train loss = 0.129620, train accuracy = 1.000000\n",
      "[2018-07-17 18:57:14.150349] Iteration 50300, train loss = 0.139365, train accuracy = 0.992188\n",
      "[2018-07-17 18:57:21.878386] Iteration 50400, train loss = 0.128985, train accuracy = 1.000000\n",
      "[2018-07-17 18:57:29.570729] Iteration 50500, train loss = 0.130217, train accuracy = 1.000000\n",
      "[2018-07-17 18:57:37.294075] Iteration 50600, train loss = 0.136274, train accuracy = 1.000000\n",
      "[2018-07-17 18:57:45.008904] Iteration 50700, train loss = 0.135039, train accuracy = 1.000000\n",
      "[2018-07-17 18:57:52.733897] Iteration 50800, train loss = 0.129045, train accuracy = 1.000000\n",
      "[2018-07-17 18:58:00.451368] Iteration 50900, train loss = 0.128876, train accuracy = 1.000000\n",
      "[2018-07-17 18:58:08.190830] Iteration 51000, train loss = 0.131327, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 18:58:18.178437] Iteration 51100, train loss = 0.129135, train accuracy = 1.000000\n",
      "[2018-07-17 18:58:25.892070] Iteration 51200, train loss = 0.132732, train accuracy = 1.000000\n",
      "[2018-07-17 18:58:33.623146] Iteration 51300, train loss = 0.129813, train accuracy = 1.000000\n",
      "[2018-07-17 18:58:41.366950] Iteration 51400, train loss = 0.130476, train accuracy = 1.000000\n",
      "[2018-07-17 18:58:49.096500] Iteration 51500, train loss = 0.129946, train accuracy = 1.000000\n",
      "[2018-07-17 18:58:56.817334] Iteration 51600, train loss = 0.129805, train accuracy = 1.000000\n",
      "[2018-07-17 18:59:04.520000] Iteration 51700, train loss = 0.132518, train accuracy = 1.000000\n",
      "[2018-07-17 18:59:12.245279] Iteration 51800, train loss = 0.128699, train accuracy = 1.000000\n",
      "[2018-07-17 18:59:19.990294] Iteration 51900, train loss = 0.128692, train accuracy = 1.000000\n",
      "[2018-07-17 18:59:27.707532] Iteration 52000, train loss = 0.128919, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930400\n",
      "[2018-07-17 18:59:37.672154] Iteration 52100, train loss = 0.134507, train accuracy = 1.000000\n",
      "[2018-07-17 18:59:45.400526] Iteration 52200, train loss = 0.132881, train accuracy = 1.000000\n",
      "[2018-07-17 18:59:53.128981] Iteration 52300, train loss = 0.130317, train accuracy = 1.000000\n",
      "[2018-07-17 19:00:00.863394] Iteration 52400, train loss = 0.138655, train accuracy = 1.000000\n",
      "[2018-07-17 19:00:08.578797] Iteration 52500, train loss = 0.133993, train accuracy = 1.000000\n",
      "[2018-07-17 19:00:16.295721] Iteration 52600, train loss = 0.163674, train accuracy = 0.992188\n",
      "[2018-07-17 19:00:24.013578] Iteration 52700, train loss = 0.130035, train accuracy = 1.000000\n",
      "[2018-07-17 19:00:31.727861] Iteration 52800, train loss = 0.128453, train accuracy = 1.000000\n",
      "[2018-07-17 19:00:39.438635] Iteration 52900, train loss = 0.136029, train accuracy = 1.000000\n",
      "[2018-07-17 19:00:47.147634] Iteration 53000, train loss = 0.130026, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929700\n",
      "[2018-07-17 19:00:57.110080] Iteration 53100, train loss = 0.137601, train accuracy = 0.992188\n",
      "[2018-07-17 19:01:04.827501] Iteration 53200, train loss = 0.137311, train accuracy = 0.992188\n",
      "[2018-07-17 19:01:12.538695] Iteration 53300, train loss = 0.133225, train accuracy = 1.000000\n",
      "[2018-07-17 19:01:20.250553] Iteration 53400, train loss = 0.152907, train accuracy = 0.984375\n",
      "[2018-07-17 19:01:27.964916] Iteration 53500, train loss = 0.129127, train accuracy = 1.000000\n",
      "[2018-07-17 19:01:35.675371] Iteration 53600, train loss = 0.128939, train accuracy = 1.000000\n",
      "[2018-07-17 19:01:43.393126] Iteration 53700, train loss = 0.127636, train accuracy = 1.000000\n",
      "[2018-07-17 19:01:51.111910] Iteration 53800, train loss = 0.139669, train accuracy = 1.000000\n",
      "[2018-07-17 19:01:58.808698] Iteration 53900, train loss = 0.131582, train accuracy = 1.000000\n",
      "[2018-07-17 19:02:06.538436] Iteration 54000, train loss = 0.130585, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929500\n",
      "[2018-07-17 19:02:16.528843] Iteration 54100, train loss = 0.138810, train accuracy = 1.000000\n",
      "[2018-07-17 19:02:24.239051] Iteration 54200, train loss = 0.130525, train accuracy = 1.000000\n",
      "[2018-07-17 19:02:31.968137] Iteration 54300, train loss = 0.132663, train accuracy = 1.000000\n",
      "[2018-07-17 19:02:39.683935] Iteration 54400, train loss = 0.130536, train accuracy = 1.000000\n",
      "[2018-07-17 19:02:47.405048] Iteration 54500, train loss = 0.129829, train accuracy = 1.000000\n",
      "[2018-07-17 19:02:55.115178] Iteration 54600, train loss = 0.129865, train accuracy = 1.000000\n",
      "[2018-07-17 19:03:02.846946] Iteration 54700, train loss = 0.129023, train accuracy = 1.000000\n",
      "[2018-07-17 19:03:10.571040] Iteration 54800, train loss = 0.130574, train accuracy = 1.000000\n",
      "[2018-07-17 19:03:18.286833] Iteration 54900, train loss = 0.139552, train accuracy = 0.992188\n",
      "[2018-07-17 19:03:25.992225] Iteration 55000, train loss = 0.130806, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 19:03:36.026383] Iteration 55100, train loss = 0.130804, train accuracy = 1.000000\n",
      "[2018-07-17 19:03:43.745809] Iteration 55200, train loss = 0.131694, train accuracy = 1.000000\n",
      "[2018-07-17 19:03:51.462349] Iteration 55300, train loss = 0.144034, train accuracy = 0.992188\n",
      "[2018-07-17 19:03:59.187127] Iteration 55400, train loss = 0.131132, train accuracy = 1.000000\n",
      "[2018-07-17 19:04:06.915000] Iteration 55500, train loss = 0.130728, train accuracy = 1.000000\n",
      "[2018-07-17 19:04:14.631069] Iteration 55600, train loss = 0.128944, train accuracy = 1.000000\n",
      "[2018-07-17 19:04:22.349537] Iteration 55700, train loss = 0.132415, train accuracy = 1.000000\n",
      "[2018-07-17 19:04:30.063460] Iteration 55800, train loss = 0.134620, train accuracy = 1.000000\n",
      "[2018-07-17 19:04:37.775187] Iteration 55900, train loss = 0.130386, train accuracy = 1.000000\n",
      "[2018-07-17 19:04:45.503331] Iteration 56000, train loss = 0.132857, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929700\n",
      "[2018-07-17 19:04:55.477853] Iteration 56100, train loss = 0.128487, train accuracy = 1.000000\n",
      "[2018-07-17 19:05:03.194149] Iteration 56200, train loss = 0.131186, train accuracy = 1.000000\n",
      "[2018-07-17 19:05:10.908512] Iteration 56300, train loss = 0.134090, train accuracy = 1.000000\n",
      "[2018-07-17 19:05:18.625539] Iteration 56400, train loss = 0.143530, train accuracy = 0.992188\n",
      "[2018-07-17 19:05:26.354589] Iteration 56500, train loss = 0.129562, train accuracy = 1.000000\n",
      "[2018-07-17 19:05:34.085574] Iteration 56600, train loss = 0.131501, train accuracy = 1.000000\n",
      "[2018-07-17 19:05:41.801584] Iteration 56700, train loss = 0.136980, train accuracy = 0.992188\n",
      "[2018-07-17 19:05:49.524937] Iteration 56800, train loss = 0.130529, train accuracy = 1.000000\n",
      "[2018-07-17 19:05:57.269272] Iteration 56900, train loss = 0.128664, train accuracy = 1.000000\n",
      "[2018-07-17 19:06:04.987370] Iteration 57000, train loss = 0.133989, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930300\n",
      "[2018-07-17 19:06:14.952803] Iteration 57100, train loss = 0.130489, train accuracy = 1.000000\n",
      "[2018-07-17 19:06:22.674488] Iteration 57200, train loss = 0.134094, train accuracy = 1.000000\n",
      "[2018-07-17 19:06:30.387147] Iteration 57300, train loss = 0.128218, train accuracy = 1.000000\n",
      "[2018-07-17 19:06:38.109946] Iteration 57400, train loss = 0.128440, train accuracy = 1.000000\n",
      "[2018-07-17 19:06:45.840701] Iteration 57500, train loss = 0.129164, train accuracy = 1.000000\n",
      "[2018-07-17 19:06:53.555834] Iteration 57600, train loss = 0.130883, train accuracy = 1.000000\n",
      "[2018-07-17 19:07:01.271006] Iteration 57700, train loss = 0.131421, train accuracy = 1.000000\n",
      "[2018-07-17 19:07:08.990090] Iteration 57800, train loss = 0.129460, train accuracy = 1.000000\n",
      "[2018-07-17 19:07:16.712207] Iteration 57900, train loss = 0.135186, train accuracy = 1.000000\n",
      "[2018-07-17 19:07:24.435528] Iteration 58000, train loss = 0.132802, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 19:07:34.414467] Iteration 58100, train loss = 0.152601, train accuracy = 0.992188\n",
      "[2018-07-17 19:07:42.140212] Iteration 58200, train loss = 0.129288, train accuracy = 1.000000\n",
      "[2018-07-17 19:07:49.853726] Iteration 58300, train loss = 0.128665, train accuracy = 1.000000\n",
      "[2018-07-17 19:07:57.546905] Iteration 58400, train loss = 0.133727, train accuracy = 1.000000\n",
      "[2018-07-17 19:08:05.264745] Iteration 58500, train loss = 0.133060, train accuracy = 1.000000\n",
      "[2018-07-17 19:08:12.988203] Iteration 58600, train loss = 0.130739, train accuracy = 1.000000\n",
      "[2018-07-17 19:08:20.709791] Iteration 58700, train loss = 0.135746, train accuracy = 1.000000\n",
      "[2018-07-17 19:08:28.430497] Iteration 58800, train loss = 0.130219, train accuracy = 1.000000\n",
      "[2018-07-17 19:08:36.149814] Iteration 58900, train loss = 0.128262, train accuracy = 1.000000\n",
      "[2018-07-17 19:08:43.871530] Iteration 59000, train loss = 0.128968, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 19:08:53.830252] Iteration 59100, train loss = 0.137060, train accuracy = 0.992188\n",
      "[2018-07-17 19:09:01.554309] Iteration 59200, train loss = 0.129921, train accuracy = 1.000000\n",
      "[2018-07-17 19:09:09.262156] Iteration 59300, train loss = 0.134022, train accuracy = 1.000000\n",
      "[2018-07-17 19:09:16.984388] Iteration 59400, train loss = 0.139007, train accuracy = 0.992188\n",
      "[2018-07-17 19:09:24.711796] Iteration 59500, train loss = 0.135860, train accuracy = 1.000000\n",
      "[2018-07-17 19:09:32.412999] Iteration 59600, train loss = 0.147855, train accuracy = 0.992188\n",
      "[2018-07-17 19:09:40.137882] Iteration 59700, train loss = 0.136045, train accuracy = 1.000000\n",
      "[2018-07-17 19:09:47.858902] Iteration 59800, train loss = 0.132080, train accuracy = 1.000000\n",
      "[2018-07-17 19:09:55.573081] Iteration 59900, train loss = 0.131937, train accuracy = 1.000000\n",
      "[2018-07-17 19:10:03.296427] Iteration 60000, train loss = 0.128321, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929900\n",
      "[2018-07-17 19:10:13.274414] Iteration 60100, train loss = 0.128653, train accuracy = 1.000000\n",
      "[2018-07-17 19:10:20.996974] Iteration 60200, train loss = 0.131411, train accuracy = 1.000000\n",
      "[2018-07-17 19:10:28.720987] Iteration 60300, train loss = 0.136103, train accuracy = 0.992188\n",
      "[2018-07-17 19:10:36.429329] Iteration 60400, train loss = 0.163693, train accuracy = 0.992188\n",
      "[2018-07-17 19:10:44.147070] Iteration 60500, train loss = 0.129309, train accuracy = 1.000000\n",
      "[2018-07-17 19:10:51.869969] Iteration 60600, train loss = 0.132470, train accuracy = 1.000000\n",
      "[2018-07-17 19:10:59.590567] Iteration 60700, train loss = 0.135984, train accuracy = 1.000000\n",
      "[2018-07-17 19:11:07.313540] Iteration 60800, train loss = 0.146067, train accuracy = 0.992188\n",
      "[2018-07-17 19:11:15.038406] Iteration 60900, train loss = 0.132438, train accuracy = 1.000000\n",
      "[2018-07-17 19:11:22.751345] Iteration 61000, train loss = 0.167884, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.930300\n",
      "[2018-07-17 19:11:32.698073] Iteration 61100, train loss = 0.139557, train accuracy = 0.992188\n",
      "[2018-07-17 19:11:40.416151] Iteration 61200, train loss = 0.128790, train accuracy = 1.000000\n",
      "[2018-07-17 19:11:48.119965] Iteration 61300, train loss = 0.128580, train accuracy = 1.000000\n",
      "[2018-07-17 19:11:55.846226] Iteration 61400, train loss = 0.133561, train accuracy = 1.000000\n",
      "[2018-07-17 19:12:03.560945] Iteration 61500, train loss = 0.132864, train accuracy = 1.000000\n",
      "[2018-07-17 19:12:11.269355] Iteration 61600, train loss = 0.131575, train accuracy = 1.000000\n",
      "[2018-07-17 19:12:18.996789] Iteration 61700, train loss = 0.143246, train accuracy = 0.992188\n",
      "[2018-07-17 19:12:26.707275] Iteration 61800, train loss = 0.131856, train accuracy = 1.000000\n",
      "[2018-07-17 19:12:34.417225] Iteration 61900, train loss = 0.128302, train accuracy = 1.000000\n",
      "[2018-07-17 19:12:42.134066] Iteration 62000, train loss = 0.139868, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.929800\n",
      "[2018-07-17 19:12:52.092152] Iteration 62100, train loss = 0.136079, train accuracy = 1.000000\n",
      "[2018-07-17 19:12:59.816734] Iteration 62200, train loss = 0.136944, train accuracy = 1.000000\n",
      "[2018-07-17 19:13:07.528354] Iteration 62300, train loss = 0.132273, train accuracy = 1.000000\n",
      "[2018-07-17 19:13:15.268533] Iteration 62400, train loss = 0.135427, train accuracy = 0.992188\n",
      "[2018-07-17 19:13:22.991312] Iteration 62500, train loss = 0.129724, train accuracy = 1.000000\n",
      "[2018-07-17 19:13:30.715325] Iteration 62600, train loss = 0.129160, train accuracy = 1.000000\n",
      "[2018-07-17 19:13:38.429733] Iteration 62700, train loss = 0.130236, train accuracy = 1.000000\n",
      "[2018-07-17 19:13:46.152735] Iteration 62800, train loss = 0.131723, train accuracy = 1.000000\n",
      "[2018-07-17 19:13:53.869727] Iteration 62900, train loss = 0.136792, train accuracy = 1.000000\n",
      "[2018-07-17 19:14:01.594683] Iteration 63000, train loss = 0.134418, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929800\n",
      "[2018-07-17 19:14:11.569188] Iteration 63100, train loss = 0.129339, train accuracy = 1.000000\n",
      "[2018-07-17 19:14:19.285605] Iteration 63200, train loss = 0.135550, train accuracy = 1.000000\n",
      "[2018-07-17 19:14:27.002441] Iteration 63300, train loss = 0.129615, train accuracy = 1.000000\n",
      "[2018-07-17 19:14:34.716740] Iteration 63400, train loss = 0.130998, train accuracy = 1.000000\n",
      "[2018-07-17 19:14:42.443927] Iteration 63500, train loss = 0.171986, train accuracy = 0.976562\n",
      "[2018-07-17 19:14:50.166223] Iteration 63600, train loss = 0.130089, train accuracy = 1.000000\n",
      "[2018-07-17 19:14:57.889996] Iteration 63700, train loss = 0.134006, train accuracy = 1.000000\n",
      "[2018-07-17 19:15:05.611591] Iteration 63800, train loss = 0.131409, train accuracy = 1.000000\n",
      "[2018-07-17 19:15:13.325648] Iteration 63900, train loss = 0.131461, train accuracy = 1.000000\n",
      "[2018-07-17 19:15:21.046891] Iteration 64000, train loss = 0.130211, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929100\n",
      "[2018-07-17 19:15:30.993573] Iteration 64100, train loss = 0.128426, train accuracy = 1.000000\n",
      "[2018-07-17 19:15:38.719194] Iteration 64200, train loss = 0.135778, train accuracy = 1.000000\n",
      "[2018-07-17 19:15:46.448151] Iteration 64300, train loss = 0.146051, train accuracy = 0.984375\n",
      "[2018-07-17 19:15:54.163246] Iteration 64400, train loss = 0.138892, train accuracy = 0.992188\n",
      "[2018-07-17 19:16:01.891878] Iteration 64500, train loss = 0.134979, train accuracy = 1.000000\n",
      "[2018-07-17 19:16:09.605696] Iteration 64600, train loss = 0.128512, train accuracy = 1.000000\n",
      "[2018-07-17 19:16:17.330420] Iteration 64700, train loss = 0.130846, train accuracy = 1.000000\n",
      "[2018-07-17 19:16:25.050610] Iteration 64800, train loss = 0.130225, train accuracy = 1.000000\n",
      "[2018-07-17 19:16:32.774796] Iteration 64900, train loss = 0.132970, train accuracy = 1.000000\n",
      "[2018-07-17 19:16:40.486733] Iteration 65000, train loss = 0.130073, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929300\n",
      "[2018-07-17 19:16:50.459773] Iteration 65100, train loss = 0.133703, train accuracy = 1.000000\n",
      "[2018-07-17 19:16:58.194380] Iteration 65200, train loss = 0.129939, train accuracy = 1.000000\n",
      "[2018-07-17 19:17:05.891537] Iteration 65300, train loss = 0.130223, train accuracy = 1.000000\n",
      "[2018-07-17 19:17:13.618915] Iteration 65400, train loss = 0.128534, train accuracy = 1.000000\n",
      "[2018-07-17 19:17:21.343343] Iteration 65500, train loss = 0.131832, train accuracy = 1.000000\n",
      "[2018-07-17 19:17:29.070678] Iteration 65600, train loss = 0.131525, train accuracy = 1.000000\n",
      "[2018-07-17 19:17:36.785091] Iteration 65700, train loss = 0.132246, train accuracy = 1.000000\n",
      "[2018-07-17 19:17:44.507537] Iteration 65800, train loss = 0.143469, train accuracy = 0.984375\n",
      "[2018-07-17 19:17:52.238598] Iteration 65900, train loss = 0.130151, train accuracy = 1.000000\n",
      "[2018-07-17 19:17:59.964524] Iteration 66000, train loss = 0.128710, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929600\n",
      "[2018-07-17 19:18:09.941002] Iteration 66100, train loss = 0.131621, train accuracy = 1.000000\n",
      "[2018-07-17 19:18:17.647258] Iteration 66200, train loss = 0.143407, train accuracy = 1.000000\n",
      "[2018-07-17 19:18:25.373732] Iteration 66300, train loss = 0.147748, train accuracy = 0.992188\n",
      "[2018-07-17 19:18:33.087858] Iteration 66400, train loss = 0.133942, train accuracy = 1.000000\n",
      "[2018-07-17 19:18:40.798083] Iteration 66500, train loss = 0.137450, train accuracy = 1.000000\n",
      "[2018-07-17 19:18:48.517362] Iteration 66600, train loss = 0.129214, train accuracy = 1.000000\n",
      "[2018-07-17 19:18:56.241102] Iteration 66700, train loss = 0.136559, train accuracy = 0.992188\n",
      "[2018-07-17 19:19:03.965091] Iteration 66800, train loss = 0.130790, train accuracy = 1.000000\n",
      "[2018-07-17 19:19:11.684175] Iteration 66900, train loss = 0.134417, train accuracy = 0.992188\n",
      "[2018-07-17 19:19:19.411711] Iteration 67000, train loss = 0.129545, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 19:19:29.387174] Iteration 67100, train loss = 0.130886, train accuracy = 1.000000\n",
      "[2018-07-17 19:19:37.108783] Iteration 67200, train loss = 0.131687, train accuracy = 1.000000\n",
      "[2018-07-17 19:19:44.829959] Iteration 67300, train loss = 0.129395, train accuracy = 1.000000\n",
      "[2018-07-17 19:19:52.562568] Iteration 67400, train loss = 0.131189, train accuracy = 1.000000\n",
      "[2018-07-17 19:20:00.296119] Iteration 67500, train loss = 0.135980, train accuracy = 0.992188\n",
      "[2018-07-17 19:20:08.012833] Iteration 67600, train loss = 0.131163, train accuracy = 1.000000\n",
      "[2018-07-17 19:20:15.728143] Iteration 67700, train loss = 0.143113, train accuracy = 0.992188\n",
      "[2018-07-17 19:20:23.459278] Iteration 67800, train loss = 0.139751, train accuracy = 1.000000\n",
      "[2018-07-17 19:20:31.184894] Iteration 67900, train loss = 0.131264, train accuracy = 1.000000\n",
      "[2018-07-17 19:20:38.905105] Iteration 68000, train loss = 0.147622, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.930200\n",
      "[2018-07-17 19:20:48.863736] Iteration 68100, train loss = 0.131439, train accuracy = 1.000000\n",
      "[2018-07-17 19:20:56.579357] Iteration 68200, train loss = 0.128434, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:04.306329] Iteration 68300, train loss = 0.129016, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:12.028733] Iteration 68400, train loss = 0.128970, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:19.751403] Iteration 68500, train loss = 0.131807, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:27.485242] Iteration 68600, train loss = 0.131302, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:35.215637] Iteration 68700, train loss = 0.130565, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:42.932632] Iteration 68800, train loss = 0.134161, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:50.653516] Iteration 68900, train loss = 0.132049, train accuracy = 1.000000\n",
      "[2018-07-17 19:21:58.369516] Iteration 69000, train loss = 0.139193, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.930300\n",
      "[2018-07-17 19:22:08.362923] Iteration 69100, train loss = 0.129167, train accuracy = 1.000000\n",
      "[2018-07-17 19:22:16.076167] Iteration 69200, train loss = 0.129924, train accuracy = 1.000000\n",
      "[2018-07-17 19:22:23.800694] Iteration 69300, train loss = 0.131193, train accuracy = 1.000000\n",
      "[2018-07-17 19:22:31.512621] Iteration 69400, train loss = 0.131726, train accuracy = 1.000000\n",
      "[2018-07-17 19:22:39.225113] Iteration 69500, train loss = 0.141924, train accuracy = 0.992188\n",
      "[2018-07-17 19:22:46.942101] Iteration 69600, train loss = 0.127987, train accuracy = 1.000000\n",
      "[2018-07-17 19:22:54.651398] Iteration 69700, train loss = 0.129255, train accuracy = 1.000000\n",
      "[2018-07-17 19:23:02.343205] Iteration 69800, train loss = 0.128275, train accuracy = 1.000000\n",
      "[2018-07-17 19:23:10.070748] Iteration 69900, train loss = 0.131953, train accuracy = 1.000000\n",
      "[2018-07-17 19:23:17.780549] Iteration 70000, train loss = 0.134030, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930000\n",
      "[2018-07-17 19:23:27.758460] Iteration 70100, train loss = 0.128801, train accuracy = 1.000000\n",
      "[2018-07-17 19:23:35.478317] Iteration 70200, train loss = 0.135715, train accuracy = 0.992188\n",
      "[2018-07-17 19:23:43.203745] Iteration 70300, train loss = 0.129714, train accuracy = 1.000000\n",
      "[2018-07-17 19:23:50.917625] Iteration 70400, train loss = 0.152634, train accuracy = 0.992188\n",
      "[2018-07-17 19:23:58.637392] Iteration 70500, train loss = 0.148967, train accuracy = 0.992188\n",
      "[2018-07-17 19:24:06.358128] Iteration 70600, train loss = 0.129497, train accuracy = 1.000000\n",
      "[2018-07-17 19:24:14.084376] Iteration 70700, train loss = 0.128437, train accuracy = 1.000000\n",
      "[2018-07-17 19:24:21.809361] Iteration 70800, train loss = 0.129156, train accuracy = 1.000000\n",
      "[2018-07-17 19:24:29.528403] Iteration 70900, train loss = 0.136343, train accuracy = 1.000000\n",
      "[2018-07-17 19:24:37.230864] Iteration 71000, train loss = 0.128236, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929600\n",
      "[2018-07-17 19:24:47.194750] Iteration 71100, train loss = 0.129151, train accuracy = 1.000000\n",
      "[2018-07-17 19:24:54.913593] Iteration 71200, train loss = 0.129445, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:02.636434] Iteration 71300, train loss = 0.128804, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:10.348677] Iteration 71400, train loss = 0.132419, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:18.063578] Iteration 71500, train loss = 0.130245, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:25.786673] Iteration 71600, train loss = 0.130373, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:33.509375] Iteration 71700, train loss = 0.128616, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:41.215960] Iteration 71800, train loss = 0.129896, train accuracy = 1.000000\n",
      "[2018-07-17 19:25:48.928668] Iteration 71900, train loss = 0.142774, train accuracy = 0.992188\n",
      "[2018-07-17 19:25:56.646239] Iteration 72000, train loss = 0.143217, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.929800\n",
      "[2018-07-17 19:26:06.605764] Iteration 72100, train loss = 0.139148, train accuracy = 0.992188\n",
      "[2018-07-17 19:26:14.315809] Iteration 72200, train loss = 0.133927, train accuracy = 1.000000\n",
      "[2018-07-17 19:26:22.035561] Iteration 72300, train loss = 0.131176, train accuracy = 1.000000\n",
      "[2018-07-17 19:26:29.753741] Iteration 72400, train loss = 0.134356, train accuracy = 1.000000\n",
      "[2018-07-17 19:26:37.488123] Iteration 72500, train loss = 0.128550, train accuracy = 1.000000\n",
      "[2018-07-17 19:26:45.199901] Iteration 72600, train loss = 0.131994, train accuracy = 1.000000\n",
      "[2018-07-17 19:26:52.920705] Iteration 72700, train loss = 0.132453, train accuracy = 1.000000\n",
      "[2018-07-17 19:27:00.637269] Iteration 72800, train loss = 0.130356, train accuracy = 1.000000\n",
      "[2018-07-17 19:27:08.351149] Iteration 72900, train loss = 0.138072, train accuracy = 1.000000\n",
      "[2018-07-17 19:27:16.070841] Iteration 73000, train loss = 0.137266, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929200\n",
      "[2018-07-17 19:27:26.022986] Iteration 73100, train loss = 0.129073, train accuracy = 1.000000\n",
      "[2018-07-17 19:27:33.724323] Iteration 73200, train loss = 0.131166, train accuracy = 1.000000\n",
      "[2018-07-17 19:27:41.448213] Iteration 73300, train loss = 0.131311, train accuracy = 1.000000\n",
      "[2018-07-17 19:27:49.168035] Iteration 73400, train loss = 0.129320, train accuracy = 1.000000\n",
      "[2018-07-17 19:27:56.882407] Iteration 73500, train loss = 0.128001, train accuracy = 1.000000\n",
      "[2018-07-17 19:28:04.606612] Iteration 73600, train loss = 0.130885, train accuracy = 1.000000\n",
      "[2018-07-17 19:28:12.326186] Iteration 73700, train loss = 0.133215, train accuracy = 1.000000\n",
      "[2018-07-17 19:28:20.052163] Iteration 73800, train loss = 0.128765, train accuracy = 1.000000\n",
      "[2018-07-17 19:28:27.767597] Iteration 73900, train loss = 0.129194, train accuracy = 1.000000\n",
      "[2018-07-17 19:28:35.480823] Iteration 74000, train loss = 0.131623, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929400\n",
      "[2018-07-17 19:28:45.439417] Iteration 74100, train loss = 0.128923, train accuracy = 1.000000\n",
      "[2018-07-17 19:28:53.158049] Iteration 74200, train loss = 0.131357, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:00.889850] Iteration 74300, train loss = 0.132017, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:08.606659] Iteration 74400, train loss = 0.135930, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:16.327119] Iteration 74500, train loss = 0.132855, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:24.049713] Iteration 74600, train loss = 0.130883, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:31.772141] Iteration 74700, train loss = 0.130371, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:39.492279] Iteration 74800, train loss = 0.133228, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:47.223419] Iteration 74900, train loss = 0.129802, train accuracy = 1.000000\n",
      "[2018-07-17 19:29:54.941376] Iteration 75000, train loss = 0.129221, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929900\n",
      "[2018-07-17 19:30:04.909445] Iteration 75100, train loss = 0.133426, train accuracy = 1.000000\n",
      "[2018-07-17 19:30:12.620425] Iteration 75200, train loss = 0.129232, train accuracy = 1.000000\n",
      "[2018-07-17 19:30:20.345725] Iteration 75300, train loss = 0.139417, train accuracy = 0.992188\n",
      "[2018-07-17 19:30:28.078279] Iteration 75400, train loss = 0.129961, train accuracy = 1.000000\n",
      "[2018-07-17 19:30:35.759564] Iteration 75500, train loss = 0.137443, train accuracy = 1.000000\n",
      "[2018-07-17 19:30:43.486277] Iteration 75600, train loss = 0.134285, train accuracy = 0.992188\n",
      "[2018-07-17 19:30:51.208678] Iteration 75700, train loss = 0.138278, train accuracy = 1.000000\n",
      "[2018-07-17 19:30:58.931689] Iteration 75800, train loss = 0.130083, train accuracy = 1.000000\n",
      "[2018-07-17 19:31:06.653678] Iteration 75900, train loss = 0.131107, train accuracy = 1.000000\n",
      "[2018-07-17 19:31:14.380198] Iteration 76000, train loss = 0.138917, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929400\n",
      "[2018-07-17 19:31:24.350286] Iteration 76100, train loss = 0.142178, train accuracy = 0.992188\n",
      "[2018-07-17 19:31:32.067017] Iteration 76200, train loss = 0.131644, train accuracy = 1.000000\n",
      "[2018-07-17 19:31:39.780700] Iteration 76300, train loss = 0.131767, train accuracy = 1.000000\n",
      "[2018-07-17 19:31:47.511095] Iteration 76400, train loss = 0.131010, train accuracy = 1.000000\n",
      "[2018-07-17 19:31:55.226080] Iteration 76500, train loss = 0.128894, train accuracy = 1.000000\n",
      "[2018-07-17 19:32:02.932755] Iteration 76600, train loss = 0.127906, train accuracy = 1.000000\n",
      "[2018-07-17 19:32:10.646018] Iteration 76700, train loss = 0.136306, train accuracy = 1.000000\n",
      "[2018-07-17 19:32:18.368944] Iteration 76800, train loss = 0.128491, train accuracy = 1.000000\n",
      "[2018-07-17 19:32:26.093130] Iteration 76900, train loss = 0.128791, train accuracy = 1.000000\n",
      "[2018-07-17 19:32:33.812818] Iteration 77000, train loss = 0.128661, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929300\n",
      "[2018-07-17 19:32:43.781814] Iteration 77100, train loss = 0.130429, train accuracy = 1.000000\n",
      "[2018-07-17 19:32:51.506350] Iteration 77200, train loss = 0.139522, train accuracy = 0.992188\n",
      "[2018-07-17 19:32:59.210548] Iteration 77300, train loss = 0.137691, train accuracy = 1.000000\n",
      "[2018-07-17 19:33:06.939230] Iteration 77400, train loss = 0.129106, train accuracy = 1.000000\n",
      "[2018-07-17 19:33:14.650538] Iteration 77500, train loss = 0.133125, train accuracy = 1.000000\n",
      "[2018-07-17 19:33:22.372734] Iteration 77600, train loss = 0.143031, train accuracy = 0.984375\n",
      "[2018-07-17 19:33:30.098847] Iteration 77700, train loss = 0.128165, train accuracy = 1.000000\n",
      "[2018-07-17 19:33:37.811889] Iteration 77800, train loss = 0.129005, train accuracy = 1.000000\n",
      "[2018-07-17 19:33:45.523385] Iteration 77900, train loss = 0.129637, train accuracy = 1.000000\n",
      "[2018-07-17 19:33:53.240125] Iteration 78000, train loss = 0.139553, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.929700\n",
      "[2018-07-17 19:34:03.204024] Iteration 78100, train loss = 0.130645, train accuracy = 1.000000\n",
      "[2018-07-17 19:34:10.921945] Iteration 78200, train loss = 0.129261, train accuracy = 1.000000\n",
      "[2018-07-17 19:34:18.645876] Iteration 78300, train loss = 0.129944, train accuracy = 1.000000\n",
      "[2018-07-17 19:34:26.358088] Iteration 78400, train loss = 0.128524, train accuracy = 1.000000\n",
      "[2018-07-17 19:34:34.094660] Iteration 78500, train loss = 0.129983, train accuracy = 1.000000\n",
      "[2018-07-17 19:34:41.812197] Iteration 78600, train loss = 0.131043, train accuracy = 1.000000\n",
      "[2018-07-17 19:34:49.543395] Iteration 78700, train loss = 0.135994, train accuracy = 0.992188\n",
      "[2018-07-17 19:34:57.269197] Iteration 78800, train loss = 0.130055, train accuracy = 1.000000\n",
      "[2018-07-17 19:35:04.968438] Iteration 78900, train loss = 0.129915, train accuracy = 1.000000\n",
      "[2018-07-17 19:35:12.686520] Iteration 79000, train loss = 0.130278, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930200\n",
      "[2018-07-17 19:35:22.637111] Iteration 79100, train loss = 0.141961, train accuracy = 0.992188\n",
      "[2018-07-17 19:35:30.358183] Iteration 79200, train loss = 0.130729, train accuracy = 1.000000\n",
      "[2018-07-17 19:35:38.081625] Iteration 79300, train loss = 0.136946, train accuracy = 0.992188\n",
      "[2018-07-17 19:35:45.801752] Iteration 79400, train loss = 0.130778, train accuracy = 1.000000\n",
      "[2018-07-17 19:35:53.527930] Iteration 79500, train loss = 0.134937, train accuracy = 0.992188\n",
      "[2018-07-17 19:36:01.246228] Iteration 79600, train loss = 0.128605, train accuracy = 1.000000\n",
      "[2018-07-17 19:36:08.969538] Iteration 79700, train loss = 0.128154, train accuracy = 1.000000\n",
      "[2018-07-17 19:36:16.696246] Iteration 79800, train loss = 0.129100, train accuracy = 1.000000\n",
      "[2018-07-17 19:36:24.415268] Iteration 79900, train loss = 0.129517, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三轮  量化\n",
    "prune_rate = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.929500\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.02871008  0.125      -0.0625     -0.0625\n",
      "  0.00685834  0.01626123  0.0625     -0.0625    ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.85)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-17 19:39:01.459782] Iteration 100, train loss = 0.149328, train accuracy = 1.000000\n",
      "[2018-07-17 19:39:09.204048] Iteration 200, train loss = 0.151742, train accuracy = 0.992188\n",
      "[2018-07-17 19:39:16.909169] Iteration 300, train loss = 0.151722, train accuracy = 0.992188\n",
      "[2018-07-17 19:39:24.635694] Iteration 400, train loss = 0.151113, train accuracy = 0.984375\n",
      "[2018-07-17 19:39:32.396408] Iteration 500, train loss = 0.151448, train accuracy = 0.984375\n",
      "[2018-07-17 19:39:40.127521] Iteration 600, train loss = 0.152545, train accuracy = 0.992188\n",
      "[2018-07-17 19:39:47.863908] Iteration 700, train loss = 0.138615, train accuracy = 0.992188\n",
      "[2018-07-17 19:39:55.608382] Iteration 800, train loss = 0.217566, train accuracy = 0.984375\n",
      "[2018-07-17 19:40:03.338223] Iteration 900, train loss = 0.144380, train accuracy = 1.000000\n",
      "[2018-07-17 19:40:11.062280] Iteration 1000, train loss = 0.131584, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.922700\n",
      "[2018-07-17 19:40:21.047742] Iteration 1100, train loss = 0.149928, train accuracy = 1.000000\n",
      "[2018-07-17 19:40:28.795313] Iteration 1200, train loss = 0.152726, train accuracy = 0.992188\n",
      "[2018-07-17 19:40:36.519241] Iteration 1300, train loss = 0.146578, train accuracy = 0.992188\n",
      "[2018-07-17 19:40:44.247396] Iteration 1400, train loss = 0.139525, train accuracy = 1.000000\n",
      "[2018-07-17 19:40:51.981253] Iteration 1500, train loss = 0.157277, train accuracy = 0.984375\n",
      "[2018-07-17 19:40:59.702574] Iteration 1600, train loss = 0.149092, train accuracy = 0.984375\n",
      "[2018-07-17 19:41:07.441249] Iteration 1700, train loss = 0.131879, train accuracy = 1.000000\n",
      "[2018-07-17 19:41:15.163525] Iteration 1800, train loss = 0.151614, train accuracy = 0.992188\n",
      "[2018-07-17 19:41:22.892962] Iteration 1900, train loss = 0.132426, train accuracy = 1.000000\n",
      "[2018-07-17 19:41:30.617796] Iteration 2000, train loss = 0.149513, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.923700\n",
      "[2018-07-17 19:41:40.593087] Iteration 2100, train loss = 0.138343, train accuracy = 0.992188\n",
      "[2018-07-17 19:41:48.317358] Iteration 2200, train loss = 0.165106, train accuracy = 0.984375\n",
      "[2018-07-17 19:41:56.056014] Iteration 2300, train loss = 0.147970, train accuracy = 0.992188\n",
      "[2018-07-17 19:42:03.778714] Iteration 2400, train loss = 0.150317, train accuracy = 0.992188\n",
      "[2018-07-17 19:42:11.500234] Iteration 2500, train loss = 0.131920, train accuracy = 1.000000\n",
      "[2018-07-17 19:42:19.238038] Iteration 2600, train loss = 0.142290, train accuracy = 0.992188\n",
      "[2018-07-17 19:42:26.949982] Iteration 2700, train loss = 0.149725, train accuracy = 1.000000\n",
      "[2018-07-17 19:42:34.687697] Iteration 2800, train loss = 0.147332, train accuracy = 0.984375\n",
      "[2018-07-17 19:42:42.415490] Iteration 2900, train loss = 0.134576, train accuracy = 1.000000\n",
      "[2018-07-17 19:42:50.157258] Iteration 3000, train loss = 0.172819, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.924900\n",
      "[2018-07-17 19:43:00.123020] Iteration 3100, train loss = 0.134026, train accuracy = 1.000000\n",
      "[2018-07-17 19:43:07.847928] Iteration 3200, train loss = 0.163118, train accuracy = 0.976562\n",
      "[2018-07-17 19:43:15.569583] Iteration 3300, train loss = 0.135767, train accuracy = 1.000000\n",
      "[2018-07-17 19:43:23.300105] Iteration 3400, train loss = 0.141502, train accuracy = 0.992188\n",
      "[2018-07-17 19:43:31.029606] Iteration 3500, train loss = 0.147124, train accuracy = 0.992188\n",
      "[2018-07-17 19:43:38.753213] Iteration 3600, train loss = 0.141405, train accuracy = 1.000000\n",
      "[2018-07-17 19:43:46.482956] Iteration 3700, train loss = 0.137613, train accuracy = 1.000000\n",
      "[2018-07-17 19:43:54.203650] Iteration 3800, train loss = 0.131481, train accuracy = 1.000000\n",
      "[2018-07-17 19:44:01.931437] Iteration 3900, train loss = 0.129271, train accuracy = 1.000000\n",
      "[2018-07-17 19:44:09.650629] Iteration 4000, train loss = 0.152887, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.926900\n",
      "[2018-07-17 19:44:19.611962] Iteration 4100, train loss = 0.138067, train accuracy = 1.000000\n",
      "[2018-07-17 19:44:27.334488] Iteration 4200, train loss = 0.133806, train accuracy = 1.000000\n",
      "[2018-07-17 19:44:35.072955] Iteration 4300, train loss = 0.129766, train accuracy = 1.000000\n",
      "[2018-07-17 19:44:42.796591] Iteration 4400, train loss = 0.169582, train accuracy = 0.984375\n",
      "[2018-07-17 19:44:50.538560] Iteration 4500, train loss = 0.145427, train accuracy = 0.992188\n",
      "[2018-07-17 19:44:58.260957] Iteration 4600, train loss = 0.130828, train accuracy = 1.000000\n",
      "[2018-07-17 19:45:05.994195] Iteration 4700, train loss = 0.148383, train accuracy = 1.000000\n",
      "[2018-07-17 19:45:13.725457] Iteration 4800, train loss = 0.129575, train accuracy = 1.000000\n",
      "[2018-07-17 19:45:21.450366] Iteration 4900, train loss = 0.153208, train accuracy = 0.992188\n",
      "[2018-07-17 19:45:29.180645] Iteration 5000, train loss = 0.140381, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.926500\n",
      "[2018-07-17 19:45:39.144554] Iteration 5100, train loss = 0.134217, train accuracy = 1.000000\n",
      "[2018-07-17 19:45:46.877905] Iteration 5200, train loss = 0.146659, train accuracy = 0.992188\n",
      "[2018-07-17 19:45:54.618528] Iteration 5300, train loss = 0.138019, train accuracy = 0.992188\n",
      "[2018-07-17 19:46:02.357062] Iteration 5400, train loss = 0.151591, train accuracy = 0.992188\n",
      "[2018-07-17 19:46:10.080949] Iteration 5500, train loss = 0.141751, train accuracy = 1.000000\n",
      "[2018-07-17 19:46:17.805579] Iteration 5600, train loss = 0.152934, train accuracy = 0.992188\n",
      "[2018-07-17 19:46:25.534084] Iteration 5700, train loss = 0.132896, train accuracy = 1.000000\n",
      "[2018-07-17 19:46:33.259588] Iteration 5800, train loss = 0.138827, train accuracy = 1.000000\n",
      "[2018-07-17 19:46:40.985625] Iteration 5900, train loss = 0.138231, train accuracy = 1.000000\n",
      "[2018-07-17 19:46:48.708216] Iteration 6000, train loss = 0.132867, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927500\n",
      "[2018-07-17 19:46:58.679068] Iteration 6100, train loss = 0.155006, train accuracy = 0.992188\n",
      "[2018-07-17 19:47:06.408092] Iteration 6200, train loss = 0.140143, train accuracy = 1.000000\n",
      "[2018-07-17 19:47:14.153505] Iteration 6300, train loss = 0.143220, train accuracy = 1.000000\n",
      "[2018-07-17 19:47:21.878810] Iteration 6400, train loss = 0.135737, train accuracy = 1.000000\n",
      "[2018-07-17 19:47:29.602224] Iteration 6500, train loss = 0.149430, train accuracy = 0.992188\n",
      "[2018-07-17 19:47:37.334910] Iteration 6600, train loss = 0.128902, train accuracy = 1.000000\n",
      "[2018-07-17 19:47:45.058748] Iteration 6700, train loss = 0.133484, train accuracy = 1.000000\n",
      "[2018-07-17 19:47:52.768154] Iteration 6800, train loss = 0.142102, train accuracy = 0.992188\n",
      "[2018-07-17 19:48:00.504676] Iteration 6900, train loss = 0.134147, train accuracy = 1.000000\n",
      "[2018-07-17 19:48:08.229502] Iteration 7000, train loss = 0.138166, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927300\n",
      "[2018-07-17 19:48:18.207466] Iteration 7100, train loss = 0.145797, train accuracy = 0.992188\n",
      "[2018-07-17 19:48:25.908476] Iteration 7200, train loss = 0.160171, train accuracy = 0.992188\n",
      "[2018-07-17 19:48:33.628191] Iteration 7300, train loss = 0.135607, train accuracy = 1.000000\n",
      "[2018-07-17 19:48:41.357486] Iteration 7400, train loss = 0.172276, train accuracy = 0.984375\n",
      "[2018-07-17 19:48:49.079498] Iteration 7500, train loss = 0.139254, train accuracy = 1.000000\n",
      "[2018-07-17 19:48:56.809355] Iteration 7600, train loss = 0.137557, train accuracy = 0.992188\n",
      "[2018-07-17 19:49:04.537267] Iteration 7700, train loss = 0.129307, train accuracy = 1.000000\n",
      "[2018-07-17 19:49:12.269699] Iteration 7800, train loss = 0.141829, train accuracy = 0.992188\n",
      "[2018-07-17 19:49:19.998387] Iteration 7900, train loss = 0.135695, train accuracy = 1.000000\n",
      "[2018-07-17 19:49:27.722368] Iteration 8000, train loss = 0.138656, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927800\n",
      "[2018-07-17 19:49:37.690355] Iteration 8100, train loss = 0.130789, train accuracy = 1.000000\n",
      "[2018-07-17 19:49:45.407840] Iteration 8200, train loss = 0.131687, train accuracy = 1.000000\n",
      "[2018-07-17 19:49:53.128100] Iteration 8300, train loss = 0.139173, train accuracy = 0.992188\n",
      "[2018-07-17 19:50:00.832197] Iteration 8400, train loss = 0.140402, train accuracy = 0.992188\n",
      "[2018-07-17 19:50:08.561833] Iteration 8500, train loss = 0.155575, train accuracy = 0.992188\n",
      "[2018-07-17 19:50:16.276193] Iteration 8600, train loss = 0.150048, train accuracy = 0.992188\n",
      "[2018-07-17 19:50:24.019565] Iteration 8700, train loss = 0.148004, train accuracy = 0.984375\n",
      "[2018-07-17 19:50:31.745166] Iteration 8800, train loss = 0.159577, train accuracy = 0.984375\n",
      "[2018-07-17 19:50:39.476812] Iteration 8900, train loss = 0.131507, train accuracy = 1.000000\n",
      "[2018-07-17 19:50:47.204071] Iteration 9000, train loss = 0.141813, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.927200\n",
      "[2018-07-17 19:50:57.175370] Iteration 9100, train loss = 0.162337, train accuracy = 0.992188\n",
      "[2018-07-17 19:51:04.925796] Iteration 9200, train loss = 0.131293, train accuracy = 1.000000\n",
      "[2018-07-17 19:51:12.650415] Iteration 9300, train loss = 0.133467, train accuracy = 1.000000\n",
      "[2018-07-17 19:51:20.386486] Iteration 9400, train loss = 0.130587, train accuracy = 1.000000\n",
      "[2018-07-17 19:51:28.170014] Iteration 9500, train loss = 0.145265, train accuracy = 0.992188\n",
      "[2018-07-17 19:51:35.911168] Iteration 9600, train loss = 0.138006, train accuracy = 1.000000\n",
      "[2018-07-17 19:51:43.631403] Iteration 9700, train loss = 0.140772, train accuracy = 0.992188\n",
      "[2018-07-17 19:51:51.359634] Iteration 9800, train loss = 0.141425, train accuracy = 0.992188\n",
      "[2018-07-17 19:51:59.086052] Iteration 9900, train loss = 0.131044, train accuracy = 1.000000\n",
      "[2018-07-17 19:52:06.815774] Iteration 10000, train loss = 0.138114, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928000\n",
      "[2018-07-17 19:52:16.810940] Iteration 10100, train loss = 0.153737, train accuracy = 0.992188\n",
      "[2018-07-17 19:52:24.551418] Iteration 10200, train loss = 0.134741, train accuracy = 1.000000\n",
      "[2018-07-17 19:52:32.283644] Iteration 10300, train loss = 0.133937, train accuracy = 1.000000\n",
      "[2018-07-17 19:52:40.002689] Iteration 10400, train loss = 0.133049, train accuracy = 1.000000\n",
      "[2018-07-17 19:52:47.724956] Iteration 10500, train loss = 0.135641, train accuracy = 0.992188\n",
      "[2018-07-17 19:52:55.458255] Iteration 10600, train loss = 0.138254, train accuracy = 1.000000\n",
      "[2018-07-17 19:53:03.169449] Iteration 10700, train loss = 0.135088, train accuracy = 1.000000\n",
      "[2018-07-17 19:53:10.904590] Iteration 10800, train loss = 0.167874, train accuracy = 0.984375\n",
      "[2018-07-17 19:53:18.638608] Iteration 10900, train loss = 0.133262, train accuracy = 1.000000\n",
      "[2018-07-17 19:53:26.378669] Iteration 11000, train loss = 0.130724, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928500\n",
      "[2018-07-17 19:53:36.344250] Iteration 11100, train loss = 0.146540, train accuracy = 0.984375\n",
      "[2018-07-17 19:53:44.081213] Iteration 11200, train loss = 0.141448, train accuracy = 1.000000\n",
      "[2018-07-17 19:53:51.804695] Iteration 11300, train loss = 0.140484, train accuracy = 1.000000\n",
      "[2018-07-17 19:53:59.532165] Iteration 11400, train loss = 0.131654, train accuracy = 1.000000\n",
      "[2018-07-17 19:54:07.255270] Iteration 11500, train loss = 0.134566, train accuracy = 0.992188\n",
      "[2018-07-17 19:54:14.988127] Iteration 11600, train loss = 0.129150, train accuracy = 1.000000\n",
      "[2018-07-17 19:54:22.710137] Iteration 11700, train loss = 0.144612, train accuracy = 0.992188\n",
      "[2018-07-17 19:54:30.433377] Iteration 11800, train loss = 0.140614, train accuracy = 0.992188\n",
      "[2018-07-17 19:54:38.167341] Iteration 11900, train loss = 0.140748, train accuracy = 1.000000\n",
      "[2018-07-17 19:54:45.894148] Iteration 12000, train loss = 0.130858, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927700\n",
      "[2018-07-17 19:54:55.878298] Iteration 12100, train loss = 0.132486, train accuracy = 1.000000\n",
      "[2018-07-17 19:55:03.619463] Iteration 12200, train loss = 0.137077, train accuracy = 1.000000\n",
      "[2018-07-17 19:55:11.349061] Iteration 12300, train loss = 0.129389, train accuracy = 1.000000\n",
      "[2018-07-17 19:55:19.074800] Iteration 12400, train loss = 0.149198, train accuracy = 0.992188\n",
      "[2018-07-17 19:55:26.817842] Iteration 12500, train loss = 0.136679, train accuracy = 1.000000\n",
      "[2018-07-17 19:55:34.536853] Iteration 12600, train loss = 0.129985, train accuracy = 1.000000\n",
      "[2018-07-17 19:55:42.262379] Iteration 12700, train loss = 0.141258, train accuracy = 0.992188\n",
      "[2018-07-17 19:55:49.995475] Iteration 12800, train loss = 0.152501, train accuracy = 0.984375\n",
      "[2018-07-17 19:55:57.706994] Iteration 12900, train loss = 0.150191, train accuracy = 0.984375\n",
      "[2018-07-17 19:56:05.428974] Iteration 13000, train loss = 0.133114, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928100\n",
      "[2018-07-17 19:56:15.407851] Iteration 13100, train loss = 0.131605, train accuracy = 1.000000\n",
      "[2018-07-17 19:56:23.145298] Iteration 13200, train loss = 0.130797, train accuracy = 1.000000\n",
      "[2018-07-17 19:56:30.867360] Iteration 13300, train loss = 0.136373, train accuracy = 1.000000\n",
      "[2018-07-17 19:56:38.602522] Iteration 13400, train loss = 0.133602, train accuracy = 1.000000\n",
      "[2018-07-17 19:56:46.338608] Iteration 13500, train loss = 0.128488, train accuracy = 1.000000\n",
      "[2018-07-17 19:56:54.076335] Iteration 13600, train loss = 0.130465, train accuracy = 1.000000\n",
      "[2018-07-17 19:57:01.792939] Iteration 13700, train loss = 0.151768, train accuracy = 0.992188\n",
      "[2018-07-17 19:57:09.529519] Iteration 13800, train loss = 0.133643, train accuracy = 1.000000\n",
      "[2018-07-17 19:57:17.254880] Iteration 13900, train loss = 0.134366, train accuracy = 1.000000\n",
      "[2018-07-17 19:57:24.991234] Iteration 14000, train loss = 0.156116, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 19:57:35.059675] Iteration 14100, train loss = 0.131671, train accuracy = 1.000000\n",
      "[2018-07-17 19:57:42.803183] Iteration 14200, train loss = 0.131889, train accuracy = 1.000000\n",
      "[2018-07-17 19:57:50.543714] Iteration 14300, train loss = 0.134905, train accuracy = 0.992188\n",
      "[2018-07-17 19:57:58.284312] Iteration 14400, train loss = 0.131739, train accuracy = 1.000000\n",
      "[2018-07-17 19:58:06.033127] Iteration 14500, train loss = 0.128956, train accuracy = 1.000000\n",
      "[2018-07-17 19:58:13.779059] Iteration 14600, train loss = 0.134396, train accuracy = 1.000000\n",
      "[2018-07-17 19:58:21.519176] Iteration 14700, train loss = 0.129972, train accuracy = 1.000000\n",
      "[2018-07-17 19:58:29.255558] Iteration 14800, train loss = 0.132030, train accuracy = 1.000000\n",
      "[2018-07-17 19:58:36.987824] Iteration 14900, train loss = 0.134576, train accuracy = 1.000000\n",
      "[2018-07-17 19:58:44.731030] Iteration 15000, train loss = 0.160728, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.927300\n",
      "[2018-07-17 19:58:54.740225] Iteration 15100, train loss = 0.136753, train accuracy = 1.000000\n",
      "[2018-07-17 19:59:02.484865] Iteration 15200, train loss = 0.136784, train accuracy = 0.992188\n",
      "[2018-07-17 19:59:10.234207] Iteration 15300, train loss = 0.134337, train accuracy = 1.000000\n",
      "[2018-07-17 19:59:17.970708] Iteration 15400, train loss = 0.130756, train accuracy = 1.000000\n",
      "[2018-07-17 19:59:25.719393] Iteration 15500, train loss = 0.145160, train accuracy = 0.992188\n",
      "[2018-07-17 19:59:33.462560] Iteration 15600, train loss = 0.157637, train accuracy = 0.992188\n",
      "[2018-07-17 19:59:41.206792] Iteration 15700, train loss = 0.130177, train accuracy = 1.000000\n",
      "[2018-07-17 19:59:48.959903] Iteration 15800, train loss = 0.130161, train accuracy = 1.000000\n",
      "[2018-07-17 19:59:56.706428] Iteration 15900, train loss = 0.135763, train accuracy = 1.000000\n",
      "[2018-07-17 20:00:04.472116] Iteration 16000, train loss = 0.132110, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.925600\n",
      "[2018-07-17 20:00:14.475607] Iteration 16100, train loss = 0.141949, train accuracy = 0.992188\n",
      "[2018-07-17 20:00:22.217690] Iteration 16200, train loss = 0.134040, train accuracy = 1.000000\n",
      "[2018-07-17 20:00:29.955664] Iteration 16300, train loss = 0.139741, train accuracy = 1.000000\n",
      "[2018-07-17 20:00:37.698480] Iteration 16400, train loss = 0.128694, train accuracy = 1.000000\n",
      "[2018-07-17 20:00:45.434999] Iteration 16500, train loss = 0.131124, train accuracy = 1.000000\n",
      "[2018-07-17 20:00:53.156275] Iteration 16600, train loss = 0.141660, train accuracy = 0.992188\n",
      "[2018-07-17 20:01:00.881685] Iteration 16700, train loss = 0.130863, train accuracy = 1.000000\n",
      "[2018-07-17 20:01:08.625676] Iteration 16800, train loss = 0.130727, train accuracy = 1.000000\n",
      "[2018-07-17 20:01:16.346232] Iteration 16900, train loss = 0.137071, train accuracy = 0.992188\n",
      "[2018-07-17 20:01:24.071281] Iteration 17000, train loss = 0.132236, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.926300\n",
      "[2018-07-17 20:01:34.044401] Iteration 17100, train loss = 0.128320, train accuracy = 1.000000\n",
      "[2018-07-17 20:01:41.759291] Iteration 17200, train loss = 0.130392, train accuracy = 1.000000\n",
      "[2018-07-17 20:01:49.485249] Iteration 17300, train loss = 0.129992, train accuracy = 1.000000\n",
      "[2018-07-17 20:01:57.216361] Iteration 17400, train loss = 0.135157, train accuracy = 1.000000\n",
      "[2018-07-17 20:02:04.950963] Iteration 17500, train loss = 0.138032, train accuracy = 0.992188\n",
      "[2018-07-17 20:02:12.683311] Iteration 17600, train loss = 0.132100, train accuracy = 1.000000\n",
      "[2018-07-17 20:02:20.418858] Iteration 17700, train loss = 0.134465, train accuracy = 1.000000\n",
      "[2018-07-17 20:02:28.138380] Iteration 17800, train loss = 0.130634, train accuracy = 1.000000\n",
      "[2018-07-17 20:02:35.857874] Iteration 17900, train loss = 0.133209, train accuracy = 1.000000\n",
      "[2018-07-17 20:02:43.568467] Iteration 18000, train loss = 0.133050, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927100\n",
      "[2018-07-17 20:02:53.529789] Iteration 18100, train loss = 0.130443, train accuracy = 1.000000\n",
      "[2018-07-17 20:03:01.249665] Iteration 18200, train loss = 0.138798, train accuracy = 0.992188\n",
      "[2018-07-17 20:03:08.972735] Iteration 18300, train loss = 0.130441, train accuracy = 1.000000\n",
      "[2018-07-17 20:03:16.698169] Iteration 18400, train loss = 0.139320, train accuracy = 0.992188\n",
      "[2018-07-17 20:03:24.432259] Iteration 18500, train loss = 0.127949, train accuracy = 1.000000\n",
      "[2018-07-17 20:03:32.179883] Iteration 18600, train loss = 0.136851, train accuracy = 0.992188\n",
      "[2018-07-17 20:03:39.915598] Iteration 18700, train loss = 0.129563, train accuracy = 1.000000\n",
      "[2018-07-17 20:03:47.641766] Iteration 18800, train loss = 0.162416, train accuracy = 0.984375\n",
      "[2018-07-17 20:03:55.359632] Iteration 18900, train loss = 0.133899, train accuracy = 1.000000\n",
      "[2018-07-17 20:04:03.097914] Iteration 19000, train loss = 0.132531, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927600\n",
      "[2018-07-17 20:04:13.067689] Iteration 19100, train loss = 0.135411, train accuracy = 1.000000\n",
      "[2018-07-17 20:04:20.802760] Iteration 19200, train loss = 0.135195, train accuracy = 1.000000\n",
      "[2018-07-17 20:04:28.516975] Iteration 19300, train loss = 0.139183, train accuracy = 1.000000\n",
      "[2018-07-17 20:04:36.250577] Iteration 19400, train loss = 0.150234, train accuracy = 0.984375\n",
      "[2018-07-17 20:04:43.981214] Iteration 19500, train loss = 0.137887, train accuracy = 0.992188\n",
      "[2018-07-17 20:04:51.716038] Iteration 19600, train loss = 0.134304, train accuracy = 1.000000\n",
      "[2018-07-17 20:04:59.446071] Iteration 19700, train loss = 0.129584, train accuracy = 1.000000\n",
      "[2018-07-17 20:05:07.174989] Iteration 19800, train loss = 0.128820, train accuracy = 1.000000\n",
      "[2018-07-17 20:05:14.895495] Iteration 19900, train loss = 0.129444, train accuracy = 1.000000\n",
      "[2018-07-17 20:05:22.635776] Iteration 20000, train loss = 0.130058, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 20:05:32.587358] Iteration 20100, train loss = 0.138628, train accuracy = 1.000000\n",
      "[2018-07-17 20:05:40.319692] Iteration 20200, train loss = 0.133529, train accuracy = 1.000000\n",
      "[2018-07-17 20:05:48.053807] Iteration 20300, train loss = 0.139081, train accuracy = 1.000000\n",
      "[2018-07-17 20:05:55.781832] Iteration 20400, train loss = 0.141427, train accuracy = 0.992188\n",
      "[2018-07-17 20:06:03.507228] Iteration 20500, train loss = 0.133927, train accuracy = 1.000000\n",
      "[2018-07-17 20:06:11.238211] Iteration 20600, train loss = 0.149169, train accuracy = 0.992188\n",
      "[2018-07-17 20:06:18.961039] Iteration 20700, train loss = 0.139307, train accuracy = 0.992188\n",
      "[2018-07-17 20:06:26.705839] Iteration 20800, train loss = 0.129824, train accuracy = 1.000000\n",
      "[2018-07-17 20:06:34.430941] Iteration 20900, train loss = 0.130901, train accuracy = 1.000000\n",
      "[2018-07-17 20:06:42.170987] Iteration 21000, train loss = 0.136967, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929100\n",
      "[2018-07-17 20:06:52.143941] Iteration 21100, train loss = 0.133867, train accuracy = 1.000000\n",
      "[2018-07-17 20:06:59.870335] Iteration 21200, train loss = 0.131458, train accuracy = 1.000000\n",
      "[2018-07-17 20:07:07.596730] Iteration 21300, train loss = 0.136920, train accuracy = 0.992188\n",
      "[2018-07-17 20:07:15.304474] Iteration 21400, train loss = 0.156371, train accuracy = 0.992188\n",
      "[2018-07-17 20:07:23.032837] Iteration 21500, train loss = 0.129504, train accuracy = 1.000000\n",
      "[2018-07-17 20:07:30.766181] Iteration 21600, train loss = 0.133418, train accuracy = 1.000000\n",
      "[2018-07-17 20:07:38.504841] Iteration 21700, train loss = 0.140707, train accuracy = 0.992188\n",
      "[2018-07-17 20:07:46.227729] Iteration 21800, train loss = 0.135877, train accuracy = 1.000000\n",
      "[2018-07-17 20:07:53.952572] Iteration 21900, train loss = 0.132438, train accuracy = 1.000000\n",
      "[2018-07-17 20:08:01.674785] Iteration 22000, train loss = 0.133082, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928500\n",
      "[2018-07-17 20:08:11.664007] Iteration 22100, train loss = 0.128846, train accuracy = 1.000000\n",
      "[2018-07-17 20:08:19.384637] Iteration 22200, train loss = 0.134778, train accuracy = 1.000000\n",
      "[2018-07-17 20:08:27.105864] Iteration 22300, train loss = 0.129991, train accuracy = 1.000000\n",
      "[2018-07-17 20:08:34.826563] Iteration 22400, train loss = 0.133873, train accuracy = 1.000000\n",
      "[2018-07-17 20:08:42.570397] Iteration 22500, train loss = 0.134735, train accuracy = 1.000000\n",
      "[2018-07-17 20:08:50.294892] Iteration 22600, train loss = 0.157052, train accuracy = 0.992188\n",
      "[2018-07-17 20:08:58.031379] Iteration 22700, train loss = 0.129222, train accuracy = 1.000000\n",
      "[2018-07-17 20:09:05.758726] Iteration 22800, train loss = 0.130637, train accuracy = 1.000000\n",
      "[2018-07-17 20:09:13.485966] Iteration 22900, train loss = 0.127442, train accuracy = 1.000000\n",
      "[2018-07-17 20:09:21.211344] Iteration 23000, train loss = 0.130236, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928100\n",
      "[2018-07-17 20:09:31.183238] Iteration 23100, train loss = 0.128517, train accuracy = 1.000000\n",
      "[2018-07-17 20:09:38.921307] Iteration 23200, train loss = 0.141501, train accuracy = 0.992188\n",
      "[2018-07-17 20:09:46.657819] Iteration 23300, train loss = 0.136792, train accuracy = 1.000000\n",
      "[2018-07-17 20:09:54.387935] Iteration 23400, train loss = 0.130511, train accuracy = 1.000000\n",
      "[2018-07-17 20:10:02.115851] Iteration 23500, train loss = 0.132640, train accuracy = 1.000000\n",
      "[2018-07-17 20:10:09.812613] Iteration 23600, train loss = 0.147524, train accuracy = 0.992188\n",
      "[2018-07-17 20:10:17.527982] Iteration 23700, train loss = 0.129342, train accuracy = 1.000000\n",
      "[2018-07-17 20:10:25.262589] Iteration 23800, train loss = 0.131505, train accuracy = 1.000000\n",
      "[2018-07-17 20:10:32.986125] Iteration 23900, train loss = 0.137003, train accuracy = 1.000000\n",
      "[2018-07-17 20:10:40.710064] Iteration 24000, train loss = 0.135884, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.926700\n",
      "[2018-07-17 20:10:50.692529] Iteration 24100, train loss = 0.130139, train accuracy = 1.000000\n",
      "[2018-07-17 20:10:58.428861] Iteration 24200, train loss = 0.131866, train accuracy = 1.000000\n",
      "[2018-07-17 20:11:06.158321] Iteration 24300, train loss = 0.131290, train accuracy = 1.000000\n",
      "[2018-07-17 20:11:13.883322] Iteration 24400, train loss = 0.136358, train accuracy = 1.000000\n",
      "[2018-07-17 20:11:21.602774] Iteration 24500, train loss = 0.130842, train accuracy = 1.000000\n",
      "[2018-07-17 20:11:29.326093] Iteration 24600, train loss = 0.159430, train accuracy = 0.992188\n",
      "[2018-07-17 20:11:37.062912] Iteration 24700, train loss = 0.132677, train accuracy = 1.000000\n",
      "[2018-07-17 20:11:44.785056] Iteration 24800, train loss = 0.129449, train accuracy = 1.000000\n",
      "[2018-07-17 20:11:52.526232] Iteration 24900, train loss = 0.134567, train accuracy = 1.000000\n",
      "[2018-07-17 20:12:00.253004] Iteration 25000, train loss = 0.142607, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 20:12:10.235838] Iteration 25100, train loss = 0.137849, train accuracy = 0.992188\n",
      "[2018-07-17 20:12:17.976805] Iteration 25200, train loss = 0.145099, train accuracy = 0.992188\n",
      "[2018-07-17 20:12:25.717553] Iteration 25300, train loss = 0.131780, train accuracy = 1.000000\n",
      "[2018-07-17 20:12:33.435496] Iteration 25400, train loss = 0.133570, train accuracy = 1.000000\n",
      "[2018-07-17 20:12:41.163703] Iteration 25500, train loss = 0.129103, train accuracy = 1.000000\n",
      "[2018-07-17 20:12:48.879771] Iteration 25600, train loss = 0.132088, train accuracy = 1.000000\n",
      "[2018-07-17 20:12:56.595414] Iteration 25700, train loss = 0.131040, train accuracy = 1.000000\n",
      "[2018-07-17 20:13:04.317205] Iteration 25800, train loss = 0.131489, train accuracy = 1.000000\n",
      "[2018-07-17 20:13:12.014032] Iteration 25900, train loss = 0.129794, train accuracy = 1.000000\n",
      "[2018-07-17 20:13:19.748392] Iteration 26000, train loss = 0.129543, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927500\n",
      "[2018-07-17 20:13:29.724592] Iteration 26100, train loss = 0.144491, train accuracy = 0.992188\n",
      "[2018-07-17 20:13:37.452092] Iteration 26200, train loss = 0.129801, train accuracy = 1.000000\n",
      "[2018-07-17 20:13:45.176357] Iteration 26300, train loss = 0.130929, train accuracy = 1.000000\n",
      "[2018-07-17 20:13:52.908634] Iteration 26400, train loss = 0.133118, train accuracy = 1.000000\n",
      "[2018-07-17 20:14:00.633894] Iteration 26500, train loss = 0.136171, train accuracy = 1.000000\n",
      "[2018-07-17 20:14:08.349630] Iteration 26600, train loss = 0.132786, train accuracy = 1.000000\n",
      "[2018-07-17 20:14:16.074813] Iteration 26700, train loss = 0.133683, train accuracy = 1.000000\n",
      "[2018-07-17 20:14:23.806638] Iteration 26800, train loss = 0.136034, train accuracy = 1.000000\n",
      "[2018-07-17 20:14:31.531279] Iteration 26900, train loss = 0.129606, train accuracy = 1.000000\n",
      "[2018-07-17 20:14:39.275298] Iteration 27000, train loss = 0.142681, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.926800\n",
      "[2018-07-17 20:14:49.262722] Iteration 27100, train loss = 0.131809, train accuracy = 1.000000\n",
      "[2018-07-17 20:14:56.986040] Iteration 27200, train loss = 0.135868, train accuracy = 0.992188\n",
      "[2018-07-17 20:15:04.708495] Iteration 27300, train loss = 0.133709, train accuracy = 1.000000\n",
      "[2018-07-17 20:15:12.432389] Iteration 27400, train loss = 0.139203, train accuracy = 0.992188\n",
      "[2018-07-17 20:15:20.166327] Iteration 27500, train loss = 0.131514, train accuracy = 1.000000\n",
      "[2018-07-17 20:15:27.896702] Iteration 27600, train loss = 0.136332, train accuracy = 1.000000\n",
      "[2018-07-17 20:15:35.622141] Iteration 27700, train loss = 0.139154, train accuracy = 1.000000\n",
      "[2018-07-17 20:15:43.344224] Iteration 27800, train loss = 0.132242, train accuracy = 1.000000\n",
      "[2018-07-17 20:15:51.086537] Iteration 27900, train loss = 0.137756, train accuracy = 1.000000\n",
      "[2018-07-17 20:15:58.814127] Iteration 28000, train loss = 0.132059, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927200\n",
      "[2018-07-17 20:16:08.786530] Iteration 28100, train loss = 0.127972, train accuracy = 1.000000\n",
      "[2018-07-17 20:16:16.511879] Iteration 28200, train loss = 0.137088, train accuracy = 0.992188\n",
      "[2018-07-17 20:16:24.241420] Iteration 28300, train loss = 0.142026, train accuracy = 1.000000\n",
      "[2018-07-17 20:16:31.979724] Iteration 28400, train loss = 0.134524, train accuracy = 1.000000\n",
      "[2018-07-17 20:16:39.723472] Iteration 28500, train loss = 0.132061, train accuracy = 1.000000\n",
      "[2018-07-17 20:16:47.445546] Iteration 28600, train loss = 0.134189, train accuracy = 1.000000\n",
      "[2018-07-17 20:16:55.177664] Iteration 28700, train loss = 0.134254, train accuracy = 1.000000\n",
      "[2018-07-17 20:17:02.908580] Iteration 28800, train loss = 0.135798, train accuracy = 1.000000\n",
      "[2018-07-17 20:17:10.638987] Iteration 28900, train loss = 0.129933, train accuracy = 1.000000\n",
      "[2018-07-17 20:17:18.390191] Iteration 29000, train loss = 0.130568, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927200\n",
      "[2018-07-17 20:17:28.393447] Iteration 29100, train loss = 0.130436, train accuracy = 1.000000\n",
      "[2018-07-17 20:17:36.118679] Iteration 29200, train loss = 0.133655, train accuracy = 1.000000\n",
      "[2018-07-17 20:17:43.820827] Iteration 29300, train loss = 0.134593, train accuracy = 0.992188\n",
      "[2018-07-17 20:17:51.553802] Iteration 29400, train loss = 0.140165, train accuracy = 0.992188\n",
      "[2018-07-17 20:17:59.275294] Iteration 29500, train loss = 0.145127, train accuracy = 0.992188\n",
      "[2018-07-17 20:18:07.007762] Iteration 29600, train loss = 0.131378, train accuracy = 1.000000\n",
      "[2018-07-17 20:18:14.737340] Iteration 29700, train loss = 0.138010, train accuracy = 0.992188\n",
      "[2018-07-17 20:18:22.462184] Iteration 29800, train loss = 0.131218, train accuracy = 1.000000\n",
      "[2018-07-17 20:18:30.174344] Iteration 29900, train loss = 0.133114, train accuracy = 1.000000\n",
      "[2018-07-17 20:18:37.904737] Iteration 30000, train loss = 0.142653, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.927400\n",
      "[2018-07-17 20:18:47.878021] Iteration 30100, train loss = 0.129456, train accuracy = 1.000000\n",
      "[2018-07-17 20:18:55.607666] Iteration 30200, train loss = 0.131782, train accuracy = 1.000000\n",
      "[2018-07-17 20:19:03.346927] Iteration 30300, train loss = 0.132831, train accuracy = 1.000000\n",
      "[2018-07-17 20:19:11.069276] Iteration 30400, train loss = 0.142508, train accuracy = 0.992188\n",
      "[2018-07-17 20:19:18.798050] Iteration 30500, train loss = 0.130404, train accuracy = 1.000000\n",
      "[2018-07-17 20:19:26.523892] Iteration 30600, train loss = 0.139114, train accuracy = 1.000000\n",
      "[2018-07-17 20:19:34.249909] Iteration 30700, train loss = 0.140296, train accuracy = 0.992188\n",
      "[2018-07-17 20:19:41.967177] Iteration 30800, train loss = 0.144162, train accuracy = 0.992188\n",
      "[2018-07-17 20:19:49.689787] Iteration 30900, train loss = 0.129931, train accuracy = 1.000000\n",
      "[2018-07-17 20:19:57.421992] Iteration 31000, train loss = 0.133177, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928700\n",
      "[2018-07-17 20:20:07.396688] Iteration 31100, train loss = 0.130030, train accuracy = 1.000000\n",
      "[2018-07-17 20:20:15.122201] Iteration 31200, train loss = 0.128856, train accuracy = 1.000000\n",
      "[2018-07-17 20:20:22.847435] Iteration 31300, train loss = 0.128222, train accuracy = 1.000000\n",
      "[2018-07-17 20:20:30.571591] Iteration 31400, train loss = 0.127773, train accuracy = 1.000000\n",
      "[2018-07-17 20:20:38.273882] Iteration 31500, train loss = 0.129624, train accuracy = 1.000000\n",
      "[2018-07-17 20:20:45.996462] Iteration 31600, train loss = 0.127830, train accuracy = 1.000000\n",
      "[2018-07-17 20:20:53.725414] Iteration 31700, train loss = 0.132017, train accuracy = 1.000000\n",
      "[2018-07-17 20:21:01.457750] Iteration 31800, train loss = 0.135073, train accuracy = 1.000000\n",
      "[2018-07-17 20:21:09.192581] Iteration 31900, train loss = 0.131805, train accuracy = 1.000000\n",
      "[2018-07-17 20:21:16.916640] Iteration 32000, train loss = 0.177268, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928600\n",
      "[2018-07-17 20:21:26.894636] Iteration 32100, train loss = 0.134729, train accuracy = 1.000000\n",
      "[2018-07-17 20:21:34.606407] Iteration 32200, train loss = 0.132829, train accuracy = 1.000000\n",
      "[2018-07-17 20:21:42.339147] Iteration 32300, train loss = 0.138861, train accuracy = 1.000000\n",
      "[2018-07-17 20:21:50.059882] Iteration 32400, train loss = 0.130986, train accuracy = 1.000000\n",
      "[2018-07-17 20:21:57.777053] Iteration 32500, train loss = 0.135636, train accuracy = 1.000000\n",
      "[2018-07-17 20:22:05.514865] Iteration 32600, train loss = 0.128044, train accuracy = 1.000000\n",
      "[2018-07-17 20:22:13.254983] Iteration 32700, train loss = 0.135197, train accuracy = 1.000000\n",
      "[2018-07-17 20:22:20.979725] Iteration 32800, train loss = 0.128727, train accuracy = 1.000000\n",
      "[2018-07-17 20:22:28.698123] Iteration 32900, train loss = 0.130956, train accuracy = 1.000000\n",
      "[2018-07-17 20:22:36.440506] Iteration 33000, train loss = 0.129241, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927100\n",
      "[2018-07-17 20:22:46.441172] Iteration 33100, train loss = 0.133401, train accuracy = 1.000000\n",
      "[2018-07-17 20:22:54.169836] Iteration 33200, train loss = 0.132133, train accuracy = 1.000000\n",
      "[2018-07-17 20:23:01.891316] Iteration 33300, train loss = 0.128045, train accuracy = 1.000000\n",
      "[2018-07-17 20:23:09.617299] Iteration 33400, train loss = 0.128064, train accuracy = 1.000000\n",
      "[2018-07-17 20:23:17.332626] Iteration 33500, train loss = 0.130381, train accuracy = 1.000000\n",
      "[2018-07-17 20:23:25.051689] Iteration 33600, train loss = 0.145533, train accuracy = 0.992188\n",
      "[2018-07-17 20:23:32.793946] Iteration 33700, train loss = 0.131778, train accuracy = 1.000000\n",
      "[2018-07-17 20:23:40.520135] Iteration 33800, train loss = 0.134184, train accuracy = 1.000000\n",
      "[2018-07-17 20:23:48.244704] Iteration 33900, train loss = 0.128665, train accuracy = 1.000000\n",
      "[2018-07-17 20:23:55.975618] Iteration 34000, train loss = 0.133427, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 20:24:05.938544] Iteration 34100, train loss = 0.150452, train accuracy = 0.992188\n",
      "[2018-07-17 20:24:13.659186] Iteration 34200, train loss = 0.141617, train accuracy = 0.992188\n",
      "[2018-07-17 20:24:21.377300] Iteration 34300, train loss = 0.129455, train accuracy = 1.000000\n",
      "[2018-07-17 20:24:29.104810] Iteration 34400, train loss = 0.134998, train accuracy = 0.992188\n",
      "[2018-07-17 20:24:36.846678] Iteration 34500, train loss = 0.140011, train accuracy = 0.992188\n",
      "[2018-07-17 20:24:44.581935] Iteration 34600, train loss = 0.140685, train accuracy = 0.992188\n",
      "[2018-07-17 20:24:52.306942] Iteration 34700, train loss = 0.134432, train accuracy = 0.992188\n",
      "[2018-07-17 20:25:00.047469] Iteration 34800, train loss = 0.131316, train accuracy = 1.000000\n",
      "[2018-07-17 20:25:07.763844] Iteration 34900, train loss = 0.133741, train accuracy = 1.000000\n",
      "[2018-07-17 20:25:15.479371] Iteration 35000, train loss = 0.134632, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927600\n",
      "[2018-07-17 20:25:25.491645] Iteration 35100, train loss = 0.155575, train accuracy = 0.984375\n",
      "[2018-07-17 20:25:33.217087] Iteration 35200, train loss = 0.130468, train accuracy = 1.000000\n",
      "[2018-07-17 20:25:40.932311] Iteration 35300, train loss = 0.133806, train accuracy = 1.000000\n",
      "[2018-07-17 20:25:48.658282] Iteration 35400, train loss = 0.134145, train accuracy = 1.000000\n",
      "[2018-07-17 20:25:56.385578] Iteration 35500, train loss = 0.129913, train accuracy = 1.000000\n",
      "[2018-07-17 20:26:04.105406] Iteration 35600, train loss = 0.134111, train accuracy = 1.000000\n",
      "[2018-07-17 20:26:11.820627] Iteration 35700, train loss = 0.129310, train accuracy = 1.000000\n",
      "[2018-07-17 20:26:19.546887] Iteration 35800, train loss = 0.136069, train accuracy = 1.000000\n",
      "[2018-07-17 20:26:27.275295] Iteration 35900, train loss = 0.142390, train accuracy = 0.992188\n",
      "[2018-07-17 20:26:35.004375] Iteration 36000, train loss = 0.129281, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 20:26:45.028887] Iteration 36100, train loss = 0.131694, train accuracy = 1.000000\n",
      "[2018-07-17 20:26:52.760527] Iteration 36200, train loss = 0.129654, train accuracy = 1.000000\n",
      "[2018-07-17 20:27:00.483657] Iteration 36300, train loss = 0.141716, train accuracy = 0.992188\n",
      "[2018-07-17 20:27:08.211459] Iteration 36400, train loss = 0.130730, train accuracy = 1.000000\n",
      "[2018-07-17 20:27:15.932523] Iteration 36500, train loss = 0.129551, train accuracy = 1.000000\n",
      "[2018-07-17 20:27:23.692526] Iteration 36600, train loss = 0.135120, train accuracy = 1.000000\n",
      "[2018-07-17 20:27:31.415472] Iteration 36700, train loss = 0.128047, train accuracy = 1.000000\n",
      "[2018-07-17 20:27:39.149130] Iteration 36800, train loss = 0.135166, train accuracy = 1.000000\n",
      "[2018-07-17 20:27:46.876067] Iteration 36900, train loss = 0.133824, train accuracy = 1.000000\n",
      "[2018-07-17 20:27:54.595343] Iteration 37000, train loss = 0.134421, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 20:28:04.580208] Iteration 37100, train loss = 0.142157, train accuracy = 1.000000\n",
      "[2018-07-17 20:28:12.309951] Iteration 37200, train loss = 0.129142, train accuracy = 1.000000\n",
      "[2018-07-17 20:28:20.038854] Iteration 37300, train loss = 0.134678, train accuracy = 1.000000\n",
      "[2018-07-17 20:28:27.776546] Iteration 37400, train loss = 0.133781, train accuracy = 1.000000\n",
      "[2018-07-17 20:28:35.509906] Iteration 37500, train loss = 0.132246, train accuracy = 1.000000\n",
      "[2018-07-17 20:28:43.236346] Iteration 37600, train loss = 0.134135, train accuracy = 1.000000\n",
      "[2018-07-17 20:28:50.975279] Iteration 37700, train loss = 0.127761, train accuracy = 1.000000\n",
      "[2018-07-17 20:28:58.697935] Iteration 37800, train loss = 0.129811, train accuracy = 1.000000\n",
      "[2018-07-17 20:29:06.421036] Iteration 37900, train loss = 0.132617, train accuracy = 1.000000\n",
      "[2018-07-17 20:29:14.153343] Iteration 38000, train loss = 0.143998, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928100\n",
      "[2018-07-17 20:29:24.128707] Iteration 38100, train loss = 0.129875, train accuracy = 1.000000\n",
      "[2018-07-17 20:29:31.855149] Iteration 38200, train loss = 0.135684, train accuracy = 1.000000\n",
      "[2018-07-17 20:29:39.588023] Iteration 38300, train loss = 0.131197, train accuracy = 1.000000\n",
      "[2018-07-17 20:29:47.317061] Iteration 38400, train loss = 0.138351, train accuracy = 1.000000\n",
      "[2018-07-17 20:29:55.046786] Iteration 38500, train loss = 0.132745, train accuracy = 1.000000\n",
      "[2018-07-17 20:30:02.776693] Iteration 38600, train loss = 0.131881, train accuracy = 1.000000\n",
      "[2018-07-17 20:30:10.505048] Iteration 38700, train loss = 0.133776, train accuracy = 1.000000\n",
      "[2018-07-17 20:30:18.242767] Iteration 38800, train loss = 0.130497, train accuracy = 1.000000\n",
      "[2018-07-17 20:30:25.970853] Iteration 38900, train loss = 0.132508, train accuracy = 1.000000\n",
      "[2018-07-17 20:30:33.702481] Iteration 39000, train loss = 0.130473, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 20:30:43.700144] Iteration 39100, train loss = 0.132086, train accuracy = 1.000000\n",
      "[2018-07-17 20:30:51.415477] Iteration 39200, train loss = 0.130327, train accuracy = 1.000000\n",
      "[2018-07-17 20:30:59.142267] Iteration 39300, train loss = 0.130031, train accuracy = 1.000000\n",
      "[2018-07-17 20:31:06.881928] Iteration 39400, train loss = 0.129526, train accuracy = 1.000000\n",
      "[2018-07-17 20:31:14.602502] Iteration 39500, train loss = 0.134119, train accuracy = 1.000000\n",
      "[2018-07-17 20:31:22.337781] Iteration 39600, train loss = 0.131876, train accuracy = 1.000000\n",
      "[2018-07-17 20:31:30.075929] Iteration 39700, train loss = 0.128930, train accuracy = 1.000000\n",
      "[2018-07-17 20:31:37.805048] Iteration 39800, train loss = 0.136404, train accuracy = 1.000000\n",
      "[2018-07-17 20:31:45.543783] Iteration 39900, train loss = 0.137351, train accuracy = 1.000000\n",
      "[2018-07-17 20:31:53.279801] Iteration 40000, train loss = 0.135898, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928900\n",
      "[2018-07-17 20:32:03.247132] Iteration 40100, train loss = 0.134589, train accuracy = 1.000000\n",
      "[2018-07-17 20:32:10.969653] Iteration 40200, train loss = 0.129158, train accuracy = 1.000000\n",
      "[2018-07-17 20:32:18.705189] Iteration 40300, train loss = 0.131734, train accuracy = 1.000000\n",
      "[2018-07-17 20:32:26.449792] Iteration 40400, train loss = 0.127914, train accuracy = 1.000000\n",
      "[2018-07-17 20:32:34.178473] Iteration 40500, train loss = 0.136471, train accuracy = 1.000000\n",
      "[2018-07-17 20:32:41.890646] Iteration 40600, train loss = 0.132304, train accuracy = 1.000000\n",
      "[2018-07-17 20:32:49.638076] Iteration 40700, train loss = 0.129628, train accuracy = 1.000000\n",
      "[2018-07-17 20:32:57.371182] Iteration 40800, train loss = 0.135419, train accuracy = 1.000000\n",
      "[2018-07-17 20:33:05.100130] Iteration 40900, train loss = 0.138473, train accuracy = 1.000000\n",
      "[2018-07-17 20:33:12.825569] Iteration 41000, train loss = 0.130733, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928800\n",
      "[2018-07-17 20:33:22.794592] Iteration 41100, train loss = 0.130472, train accuracy = 1.000000\n",
      "[2018-07-17 20:33:30.525878] Iteration 41200, train loss = 0.130961, train accuracy = 1.000000\n",
      "[2018-07-17 20:33:38.259001] Iteration 41300, train loss = 0.129363, train accuracy = 1.000000\n",
      "[2018-07-17 20:33:45.970762] Iteration 41400, train loss = 0.141069, train accuracy = 0.992188\n",
      "[2018-07-17 20:33:53.693124] Iteration 41500, train loss = 0.135676, train accuracy = 1.000000\n",
      "[2018-07-17 20:34:01.433102] Iteration 41600, train loss = 0.135289, train accuracy = 1.000000\n",
      "[2018-07-17 20:34:09.144146] Iteration 41700, train loss = 0.135097, train accuracy = 0.992188\n",
      "[2018-07-17 20:34:16.867317] Iteration 41800, train loss = 0.129587, train accuracy = 1.000000\n",
      "[2018-07-17 20:34:24.592350] Iteration 41900, train loss = 0.127766, train accuracy = 1.000000\n",
      "[2018-07-17 20:34:32.319483] Iteration 42000, train loss = 0.131696, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.930100\n",
      "[2018-07-17 20:34:42.277145] Iteration 42100, train loss = 0.140968, train accuracy = 0.992188\n",
      "[2018-07-17 20:34:50.018071] Iteration 42200, train loss = 0.131917, train accuracy = 1.000000\n",
      "[2018-07-17 20:34:57.737631] Iteration 42300, train loss = 0.142977, train accuracy = 0.992188\n",
      "[2018-07-17 20:35:05.460711] Iteration 42400, train loss = 0.132796, train accuracy = 1.000000\n",
      "[2018-07-17 20:35:13.181738] Iteration 42500, train loss = 0.135792, train accuracy = 0.992188\n",
      "[2018-07-17 20:35:20.913088] Iteration 42600, train loss = 0.131787, train accuracy = 1.000000\n",
      "[2018-07-17 20:35:28.642784] Iteration 42700, train loss = 0.134119, train accuracy = 1.000000\n",
      "[2018-07-17 20:35:36.373655] Iteration 42800, train loss = 0.134015, train accuracy = 0.992188\n",
      "[2018-07-17 20:35:44.088390] Iteration 42900, train loss = 0.132694, train accuracy = 1.000000\n",
      "[2018-07-17 20:35:51.811208] Iteration 43000, train loss = 0.136992, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927400\n",
      "[2018-07-17 20:36:01.790245] Iteration 43100, train loss = 0.177012, train accuracy = 0.984375\n",
      "[2018-07-17 20:36:09.510550] Iteration 43200, train loss = 0.129599, train accuracy = 1.000000\n",
      "[2018-07-17 20:36:17.234859] Iteration 43300, train loss = 0.128570, train accuracy = 1.000000\n",
      "[2018-07-17 20:36:24.953378] Iteration 43400, train loss = 0.132784, train accuracy = 1.000000\n",
      "[2018-07-17 20:36:32.677072] Iteration 43500, train loss = 0.142436, train accuracy = 0.984375\n",
      "[2018-07-17 20:36:40.407800] Iteration 43600, train loss = 0.129768, train accuracy = 1.000000\n",
      "[2018-07-17 20:36:48.138083] Iteration 43700, train loss = 0.135792, train accuracy = 1.000000\n",
      "[2018-07-17 20:36:55.861067] Iteration 43800, train loss = 0.139481, train accuracy = 0.992188\n",
      "[2018-07-17 20:37:03.589780] Iteration 43900, train loss = 0.141090, train accuracy = 0.984375\n",
      "[2018-07-17 20:37:11.296869] Iteration 44000, train loss = 0.129165, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929500\n",
      "[2018-07-17 20:37:21.267374] Iteration 44100, train loss = 0.130639, train accuracy = 1.000000\n",
      "[2018-07-17 20:37:29.001929] Iteration 44200, train loss = 0.128099, train accuracy = 1.000000\n",
      "[2018-07-17 20:37:36.718896] Iteration 44300, train loss = 0.130539, train accuracy = 1.000000\n",
      "[2018-07-17 20:37:44.425013] Iteration 44400, train loss = 0.132786, train accuracy = 1.000000\n",
      "[2018-07-17 20:37:52.161540] Iteration 44500, train loss = 0.130319, train accuracy = 1.000000\n",
      "[2018-07-17 20:37:59.886339] Iteration 44600, train loss = 0.133748, train accuracy = 1.000000\n",
      "[2018-07-17 20:38:07.602310] Iteration 44700, train loss = 0.135359, train accuracy = 1.000000\n",
      "[2018-07-17 20:38:15.340858] Iteration 44800, train loss = 0.141616, train accuracy = 0.992188\n",
      "[2018-07-17 20:38:23.061325] Iteration 44900, train loss = 0.135249, train accuracy = 1.000000\n",
      "[2018-07-17 20:38:30.785077] Iteration 45000, train loss = 0.140192, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.929700\n",
      "[2018-07-17 20:38:40.748391] Iteration 45100, train loss = 0.129883, train accuracy = 1.000000\n",
      "[2018-07-17 20:38:48.473297] Iteration 45200, train loss = 0.135789, train accuracy = 1.000000\n",
      "[2018-07-17 20:38:56.202150] Iteration 45300, train loss = 0.129566, train accuracy = 1.000000\n",
      "[2018-07-17 20:39:03.921861] Iteration 45400, train loss = 0.131750, train accuracy = 1.000000\n",
      "[2018-07-17 20:39:11.643528] Iteration 45500, train loss = 0.131439, train accuracy = 1.000000\n",
      "[2018-07-17 20:39:19.378457] Iteration 45600, train loss = 0.128931, train accuracy = 1.000000\n",
      "[2018-07-17 20:39:27.110312] Iteration 45700, train loss = 0.133388, train accuracy = 1.000000\n",
      "[2018-07-17 20:39:34.841132] Iteration 45800, train loss = 0.133667, train accuracy = 1.000000\n",
      "[2018-07-17 20:39:42.578013] Iteration 45900, train loss = 0.131239, train accuracy = 1.000000\n",
      "[2018-07-17 20:39:50.306026] Iteration 46000, train loss = 0.132809, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928600\n",
      "[2018-07-17 20:40:00.286453] Iteration 46100, train loss = 0.132812, train accuracy = 1.000000\n",
      "[2018-07-17 20:40:08.041142] Iteration 46200, train loss = 0.129982, train accuracy = 1.000000\n",
      "[2018-07-17 20:40:15.761361] Iteration 46300, train loss = 0.130730, train accuracy = 1.000000\n",
      "[2018-07-17 20:40:23.481139] Iteration 46400, train loss = 0.129878, train accuracy = 1.000000\n",
      "[2018-07-17 20:40:31.210426] Iteration 46500, train loss = 0.128805, train accuracy = 1.000000\n",
      "[2018-07-17 20:40:38.936713] Iteration 46600, train loss = 0.131337, train accuracy = 1.000000\n",
      "[2018-07-17 20:40:46.675354] Iteration 46700, train loss = 0.133378, train accuracy = 1.000000\n",
      "[2018-07-17 20:40:54.409587] Iteration 46800, train loss = 0.127363, train accuracy = 1.000000\n",
      "[2018-07-17 20:41:02.151082] Iteration 46900, train loss = 0.128332, train accuracy = 1.000000\n",
      "[2018-07-17 20:41:09.879076] Iteration 47000, train loss = 0.128983, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928900\n",
      "[2018-07-17 20:41:19.856494] Iteration 47100, train loss = 0.136861, train accuracy = 1.000000\n",
      "[2018-07-17 20:41:27.578345] Iteration 47200, train loss = 0.128277, train accuracy = 1.000000\n",
      "[2018-07-17 20:41:35.298073] Iteration 47300, train loss = 0.134181, train accuracy = 1.000000\n",
      "[2018-07-17 20:41:43.011251] Iteration 47400, train loss = 0.143124, train accuracy = 0.992188\n",
      "[2018-07-17 20:41:50.746163] Iteration 47500, train loss = 0.132538, train accuracy = 1.000000\n",
      "[2018-07-17 20:41:58.463164] Iteration 47600, train loss = 0.129291, train accuracy = 1.000000\n",
      "[2018-07-17 20:42:06.205494] Iteration 47700, train loss = 0.127829, train accuracy = 1.000000\n",
      "[2018-07-17 20:42:13.938444] Iteration 47800, train loss = 0.131946, train accuracy = 1.000000\n",
      "[2018-07-17 20:42:21.666236] Iteration 47900, train loss = 0.128259, train accuracy = 1.000000\n",
      "[2018-07-17 20:42:29.387109] Iteration 48000, train loss = 0.129138, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927800\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-17 20:42:39.344636] Iteration 48100, train loss = 0.135553, train accuracy = 1.000000\n",
      "[2018-07-17 20:42:47.067979] Iteration 48200, train loss = 0.139278, train accuracy = 0.992188\n",
      "[2018-07-17 20:42:54.793834] Iteration 48300, train loss = 0.129615, train accuracy = 1.000000\n",
      "[2018-07-17 20:43:02.525897] Iteration 48400, train loss = 0.128897, train accuracy = 1.000000\n",
      "[2018-07-17 20:43:10.242599] Iteration 48500, train loss = 0.134857, train accuracy = 1.000000\n",
      "[2018-07-17 20:43:17.955344] Iteration 48600, train loss = 0.132744, train accuracy = 1.000000\n",
      "[2018-07-17 20:43:25.679349] Iteration 48700, train loss = 0.140580, train accuracy = 0.992188\n",
      "[2018-07-17 20:43:33.409590] Iteration 48800, train loss = 0.128964, train accuracy = 1.000000\n",
      "[2018-07-17 20:43:41.136106] Iteration 48900, train loss = 0.138151, train accuracy = 0.992188\n",
      "[2018-07-17 20:43:48.874587] Iteration 49000, train loss = 0.134087, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 20:43:58.848497] Iteration 49100, train loss = 0.129764, train accuracy = 1.000000\n",
      "[2018-07-17 20:44:06.575081] Iteration 49200, train loss = 0.141233, train accuracy = 0.992188\n",
      "[2018-07-17 20:44:14.300790] Iteration 49300, train loss = 0.129373, train accuracy = 1.000000\n",
      "[2018-07-17 20:44:22.034937] Iteration 49400, train loss = 0.132311, train accuracy = 1.000000\n",
      "[2018-07-17 20:44:29.762874] Iteration 49500, train loss = 0.133984, train accuracy = 1.000000\n",
      "[2018-07-17 20:44:37.453977] Iteration 49600, train loss = 0.127790, train accuracy = 1.000000\n",
      "[2018-07-17 20:44:45.175687] Iteration 49700, train loss = 0.155797, train accuracy = 0.992188\n",
      "[2018-07-17 20:44:52.912576] Iteration 49800, train loss = 0.146414, train accuracy = 0.992188\n",
      "[2018-07-17 20:45:00.633140] Iteration 49900, train loss = 0.133195, train accuracy = 1.000000\n",
      "[2018-07-17 20:45:08.369214] Iteration 50000, train loss = 0.131154, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 20:45:18.364873] Iteration 50100, train loss = 0.129833, train accuracy = 1.000000\n",
      "[2018-07-17 20:45:26.087262] Iteration 50200, train loss = 0.134243, train accuracy = 1.000000\n",
      "[2018-07-17 20:45:33.821911] Iteration 50300, train loss = 0.138775, train accuracy = 0.992188\n",
      "[2018-07-17 20:45:41.547244] Iteration 50400, train loss = 0.131573, train accuracy = 1.000000\n",
      "[2018-07-17 20:45:49.266733] Iteration 50500, train loss = 0.134159, train accuracy = 1.000000\n",
      "[2018-07-17 20:45:57.000552] Iteration 50600, train loss = 0.131827, train accuracy = 1.000000\n",
      "[2018-07-17 20:46:04.721662] Iteration 50700, train loss = 0.128753, train accuracy = 1.000000\n",
      "[2018-07-17 20:46:12.429882] Iteration 50800, train loss = 0.133809, train accuracy = 1.000000\n",
      "[2018-07-17 20:46:20.154918] Iteration 50900, train loss = 0.129267, train accuracy = 1.000000\n",
      "[2018-07-17 20:46:27.876995] Iteration 51000, train loss = 0.138567, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 20:46:37.841461] Iteration 51100, train loss = 0.133914, train accuracy = 1.000000\n",
      "[2018-07-17 20:46:45.566813] Iteration 51200, train loss = 0.130958, train accuracy = 1.000000\n",
      "[2018-07-17 20:46:53.304844] Iteration 51300, train loss = 0.128928, train accuracy = 1.000000\n",
      "[2018-07-17 20:47:01.027576] Iteration 51400, train loss = 0.129814, train accuracy = 1.000000\n",
      "[2018-07-17 20:47:08.751987] Iteration 51500, train loss = 0.130942, train accuracy = 1.000000\n",
      "[2018-07-17 20:47:16.488381] Iteration 51600, train loss = 0.138900, train accuracy = 0.992188\n",
      "[2018-07-17 20:47:24.218791] Iteration 51700, train loss = 0.135099, train accuracy = 1.000000\n",
      "[2018-07-17 20:47:31.944261] Iteration 51800, train loss = 0.131332, train accuracy = 1.000000\n",
      "[2018-07-17 20:47:39.652503] Iteration 51900, train loss = 0.135280, train accuracy = 1.000000\n",
      "[2018-07-17 20:47:47.388441] Iteration 52000, train loss = 0.154296, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.928000\n",
      "[2018-07-17 20:47:57.364925] Iteration 52100, train loss = 0.128218, train accuracy = 1.000000\n",
      "[2018-07-17 20:48:05.101560] Iteration 52200, train loss = 0.129516, train accuracy = 1.000000\n",
      "[2018-07-17 20:48:12.831642] Iteration 52300, train loss = 0.140882, train accuracy = 1.000000\n",
      "[2018-07-17 20:48:20.557247] Iteration 52400, train loss = 0.139996, train accuracy = 0.992188\n",
      "[2018-07-17 20:48:28.286765] Iteration 52500, train loss = 0.129605, train accuracy = 1.000000\n",
      "[2018-07-17 20:48:36.002931] Iteration 52600, train loss = 0.128785, train accuracy = 1.000000\n",
      "[2018-07-17 20:48:43.723928] Iteration 52700, train loss = 0.130078, train accuracy = 1.000000\n",
      "[2018-07-17 20:48:51.456783] Iteration 52800, train loss = 0.132961, train accuracy = 1.000000\n",
      "[2018-07-17 20:48:59.188565] Iteration 52900, train loss = 0.129928, train accuracy = 1.000000\n",
      "[2018-07-17 20:49:06.885928] Iteration 53000, train loss = 0.135230, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 20:49:16.858649] Iteration 53100, train loss = 0.153223, train accuracy = 0.992188\n",
      "[2018-07-17 20:49:24.590002] Iteration 53200, train loss = 0.129205, train accuracy = 1.000000\n",
      "[2018-07-17 20:49:32.298245] Iteration 53300, train loss = 0.130596, train accuracy = 1.000000\n",
      "[2018-07-17 20:49:40.005976] Iteration 53400, train loss = 0.132813, train accuracy = 1.000000\n",
      "[2018-07-17 20:49:47.726966] Iteration 53500, train loss = 0.133521, train accuracy = 1.000000\n",
      "[2018-07-17 20:49:55.464336] Iteration 53600, train loss = 0.134714, train accuracy = 1.000000\n",
      "[2018-07-17 20:50:03.196755] Iteration 53700, train loss = 0.135922, train accuracy = 1.000000\n",
      "[2018-07-17 20:50:10.924286] Iteration 53800, train loss = 0.132950, train accuracy = 1.000000\n",
      "[2018-07-17 20:50:18.655028] Iteration 53900, train loss = 0.130886, train accuracy = 1.000000\n",
      "[2018-07-17 20:50:26.392590] Iteration 54000, train loss = 0.138643, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928800\n",
      "[2018-07-17 20:50:36.351157] Iteration 54100, train loss = 0.130969, train accuracy = 1.000000\n",
      "[2018-07-17 20:50:44.078240] Iteration 54200, train loss = 0.129315, train accuracy = 1.000000\n",
      "[2018-07-17 20:50:51.813397] Iteration 54300, train loss = 0.131278, train accuracy = 1.000000\n",
      "[2018-07-17 20:50:59.540384] Iteration 54400, train loss = 0.135182, train accuracy = 1.000000\n",
      "[2018-07-17 20:51:07.262908] Iteration 54500, train loss = 0.132946, train accuracy = 1.000000\n",
      "[2018-07-17 20:51:14.997704] Iteration 54600, train loss = 0.128921, train accuracy = 1.000000\n",
      "[2018-07-17 20:51:22.719639] Iteration 54700, train loss = 0.129011, train accuracy = 1.000000\n",
      "[2018-07-17 20:51:30.451839] Iteration 54800, train loss = 0.130903, train accuracy = 1.000000\n",
      "[2018-07-17 20:51:38.176516] Iteration 54900, train loss = 0.129940, train accuracy = 1.000000\n",
      "[2018-07-17 20:51:45.906691] Iteration 55000, train loss = 0.132244, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 20:51:55.878514] Iteration 55100, train loss = 0.133017, train accuracy = 1.000000\n",
      "[2018-07-17 20:52:03.600454] Iteration 55200, train loss = 0.130156, train accuracy = 1.000000\n",
      "[2018-07-17 20:52:11.297411] Iteration 55300, train loss = 0.152155, train accuracy = 0.984375\n",
      "[2018-07-17 20:52:19.024522] Iteration 55400, train loss = 0.129102, train accuracy = 1.000000\n",
      "[2018-07-17 20:52:26.759922] Iteration 55500, train loss = 0.129138, train accuracy = 1.000000\n",
      "[2018-07-17 20:52:34.483147] Iteration 55600, train loss = 0.128644, train accuracy = 1.000000\n",
      "[2018-07-17 20:52:42.219727] Iteration 55700, train loss = 0.134520, train accuracy = 1.000000\n",
      "[2018-07-17 20:52:49.941208] Iteration 55800, train loss = 0.132350, train accuracy = 1.000000\n",
      "[2018-07-17 20:52:57.662800] Iteration 55900, train loss = 0.130105, train accuracy = 1.000000\n",
      "[2018-07-17 20:53:05.403474] Iteration 56000, train loss = 0.131614, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929100\n",
      "[2018-07-17 20:53:15.391392] Iteration 56100, train loss = 0.132793, train accuracy = 1.000000\n",
      "[2018-07-17 20:53:23.110172] Iteration 56200, train loss = 0.129476, train accuracy = 1.000000\n",
      "[2018-07-17 20:53:30.844586] Iteration 56300, train loss = 0.139827, train accuracy = 0.992188\n",
      "[2018-07-17 20:53:38.562938] Iteration 56400, train loss = 0.148508, train accuracy = 0.984375\n",
      "[2018-07-17 20:53:46.281251] Iteration 56500, train loss = 0.140872, train accuracy = 0.992188\n",
      "[2018-07-17 20:53:54.007125] Iteration 56600, train loss = 0.128621, train accuracy = 1.000000\n",
      "[2018-07-17 20:54:01.743640] Iteration 56700, train loss = 0.131900, train accuracy = 1.000000\n",
      "[2018-07-17 20:54:09.471421] Iteration 56800, train loss = 0.136227, train accuracy = 1.000000\n",
      "[2018-07-17 20:54:17.216936] Iteration 56900, train loss = 0.153700, train accuracy = 0.992188\n",
      "[2018-07-17 20:54:24.949460] Iteration 57000, train loss = 0.130441, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929500\n",
      "[2018-07-17 20:54:34.934104] Iteration 57100, train loss = 0.129202, train accuracy = 1.000000\n",
      "[2018-07-17 20:54:42.659940] Iteration 57200, train loss = 0.128795, train accuracy = 1.000000\n",
      "[2018-07-17 20:54:50.405018] Iteration 57300, train loss = 0.133324, train accuracy = 1.000000\n",
      "[2018-07-17 20:54:58.130757] Iteration 57400, train loss = 0.130466, train accuracy = 1.000000\n",
      "[2018-07-17 20:55:05.845328] Iteration 57500, train loss = 0.131645, train accuracy = 1.000000\n",
      "[2018-07-17 20:55:13.571527] Iteration 57600, train loss = 0.128783, train accuracy = 1.000000\n",
      "[2018-07-17 20:55:21.300312] Iteration 57700, train loss = 0.129755, train accuracy = 1.000000\n",
      "[2018-07-17 20:55:29.036109] Iteration 57800, train loss = 0.128701, train accuracy = 1.000000\n",
      "[2018-07-17 20:55:36.761141] Iteration 57900, train loss = 0.134458, train accuracy = 1.000000\n",
      "[2018-07-17 20:55:44.495337] Iteration 58000, train loss = 0.133065, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928900\n",
      "[2018-07-17 20:55:54.504513] Iteration 58100, train loss = 0.127565, train accuracy = 1.000000\n",
      "[2018-07-17 20:56:02.228796] Iteration 58200, train loss = 0.128035, train accuracy = 1.000000\n",
      "[2018-07-17 20:56:09.951290] Iteration 58300, train loss = 0.146966, train accuracy = 0.992188\n",
      "[2018-07-17 20:56:17.670514] Iteration 58400, train loss = 0.130737, train accuracy = 1.000000\n",
      "[2018-07-17 20:56:25.393453] Iteration 58500, train loss = 0.129841, train accuracy = 1.000000\n",
      "[2018-07-17 20:56:33.100367] Iteration 58600, train loss = 0.134015, train accuracy = 1.000000\n",
      "[2018-07-17 20:56:40.825498] Iteration 58700, train loss = 0.127799, train accuracy = 1.000000\n",
      "[2018-07-17 20:56:48.552295] Iteration 58800, train loss = 0.129778, train accuracy = 1.000000\n",
      "[2018-07-17 20:56:56.285019] Iteration 58900, train loss = 0.129356, train accuracy = 1.000000\n",
      "[2018-07-17 20:57:04.003491] Iteration 59000, train loss = 0.140551, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928700\n",
      "[2018-07-17 20:57:13.957838] Iteration 59100, train loss = 0.136081, train accuracy = 1.000000\n",
      "[2018-07-17 20:57:21.683175] Iteration 59200, train loss = 0.128690, train accuracy = 1.000000\n",
      "[2018-07-17 20:57:29.425419] Iteration 59300, train loss = 0.134606, train accuracy = 0.992188\n",
      "[2018-07-17 20:57:37.157216] Iteration 59400, train loss = 0.129829, train accuracy = 1.000000\n",
      "[2018-07-17 20:57:44.913723] Iteration 59500, train loss = 0.128568, train accuracy = 1.000000\n",
      "[2018-07-17 20:57:52.657571] Iteration 59600, train loss = 0.129480, train accuracy = 1.000000\n",
      "[2018-07-17 20:58:00.388006] Iteration 59700, train loss = 0.136452, train accuracy = 1.000000\n",
      "[2018-07-17 20:58:08.095516] Iteration 59800, train loss = 0.129738, train accuracy = 1.000000\n",
      "[2018-07-17 20:58:15.818026] Iteration 59900, train loss = 0.135001, train accuracy = 1.000000\n",
      "[2018-07-17 20:58:23.544455] Iteration 60000, train loss = 0.136969, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.929400\n",
      "[2018-07-17 20:58:33.508364] Iteration 60100, train loss = 0.132924, train accuracy = 1.000000\n",
      "[2018-07-17 20:58:41.240289] Iteration 60200, train loss = 0.130179, train accuracy = 1.000000\n",
      "[2018-07-17 20:58:48.970500] Iteration 60300, train loss = 0.130294, train accuracy = 1.000000\n",
      "[2018-07-17 20:58:56.691250] Iteration 60400, train loss = 0.128575, train accuracy = 1.000000\n",
      "[2018-07-17 20:59:04.418215] Iteration 60500, train loss = 0.130791, train accuracy = 1.000000\n",
      "[2018-07-17 20:59:12.155168] Iteration 60600, train loss = 0.131936, train accuracy = 1.000000\n",
      "[2018-07-17 20:59:19.885551] Iteration 60700, train loss = 0.128626, train accuracy = 1.000000\n",
      "[2018-07-17 20:59:27.607128] Iteration 60800, train loss = 0.129430, train accuracy = 1.000000\n",
      "[2018-07-17 20:59:35.349145] Iteration 60900, train loss = 0.132670, train accuracy = 1.000000\n",
      "[2018-07-17 20:59:43.077907] Iteration 61000, train loss = 0.131010, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928600\n",
      "[2018-07-17 20:59:53.053515] Iteration 61100, train loss = 0.128365, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:00.781503] Iteration 61200, train loss = 0.131886, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:08.503302] Iteration 61300, train loss = 0.130550, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:16.234252] Iteration 61400, train loss = 0.131190, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:23.974701] Iteration 61500, train loss = 0.135276, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:31.722832] Iteration 61600, train loss = 0.131754, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:39.462816] Iteration 61700, train loss = 0.133773, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:47.190967] Iteration 61800, train loss = 0.144952, train accuracy = 1.000000\n",
      "[2018-07-17 21:00:54.911581] Iteration 61900, train loss = 0.134094, train accuracy = 1.000000\n",
      "[2018-07-17 21:01:02.633552] Iteration 62000, train loss = 0.135239, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928500\n",
      "[2018-07-17 21:01:12.599518] Iteration 62100, train loss = 0.128319, train accuracy = 1.000000\n",
      "[2018-07-17 21:01:20.321420] Iteration 62200, train loss = 0.130782, train accuracy = 1.000000\n",
      "[2018-07-17 21:01:28.045741] Iteration 62300, train loss = 0.135343, train accuracy = 1.000000\n",
      "[2018-07-17 21:01:35.768915] Iteration 62400, train loss = 0.136579, train accuracy = 1.000000\n",
      "[2018-07-17 21:01:43.500742] Iteration 62500, train loss = 0.131848, train accuracy = 1.000000\n",
      "[2018-07-17 21:01:51.229504] Iteration 62600, train loss = 0.130025, train accuracy = 1.000000\n",
      "[2018-07-17 21:01:58.958352] Iteration 62700, train loss = 0.140719, train accuracy = 0.992188\n",
      "[2018-07-17 21:02:06.678002] Iteration 62800, train loss = 0.128197, train accuracy = 1.000000\n",
      "[2018-07-17 21:02:14.413183] Iteration 62900, train loss = 0.130046, train accuracy = 1.000000\n",
      "[2018-07-17 21:02:22.138986] Iteration 63000, train loss = 0.127459, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928000\n",
      "[2018-07-17 21:02:32.109166] Iteration 63100, train loss = 0.152309, train accuracy = 0.992188\n",
      "[2018-07-17 21:02:39.823413] Iteration 63200, train loss = 0.137403, train accuracy = 1.000000\n",
      "[2018-07-17 21:02:47.541597] Iteration 63300, train loss = 0.130083, train accuracy = 1.000000\n",
      "[2018-07-17 21:02:55.278598] Iteration 63400, train loss = 0.128012, train accuracy = 1.000000\n",
      "[2018-07-17 21:03:02.999872] Iteration 63500, train loss = 0.130341, train accuracy = 1.000000\n",
      "[2018-07-17 21:03:10.726595] Iteration 63600, train loss = 0.136318, train accuracy = 0.992188\n",
      "[2018-07-17 21:03:18.451597] Iteration 63700, train loss = 0.127661, train accuracy = 1.000000\n",
      "[2018-07-17 21:03:26.185333] Iteration 63800, train loss = 0.136464, train accuracy = 0.992188\n",
      "[2018-07-17 21:03:33.924064] Iteration 63900, train loss = 0.130765, train accuracy = 1.000000\n",
      "[2018-07-17 21:03:41.653993] Iteration 64000, train loss = 0.130152, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 21:03:51.641050] Iteration 64100, train loss = 0.132218, train accuracy = 1.000000\n",
      "[2018-07-17 21:03:59.358758] Iteration 64200, train loss = 0.131998, train accuracy = 1.000000\n",
      "[2018-07-17 21:04:07.083093] Iteration 64300, train loss = 0.134478, train accuracy = 1.000000\n",
      "[2018-07-17 21:04:14.808862] Iteration 64400, train loss = 0.131428, train accuracy = 1.000000\n",
      "[2018-07-17 21:04:22.531617] Iteration 64500, train loss = 0.132595, train accuracy = 1.000000\n",
      "[2018-07-17 21:04:30.258236] Iteration 64600, train loss = 0.129250, train accuracy = 1.000000\n",
      "[2018-07-17 21:04:38.006099] Iteration 64700, train loss = 0.129650, train accuracy = 1.000000\n",
      "[2018-07-17 21:04:45.724388] Iteration 64800, train loss = 0.135353, train accuracy = 1.000000\n",
      "[2018-07-17 21:04:53.453632] Iteration 64900, train loss = 0.129095, train accuracy = 1.000000\n",
      "[2018-07-17 21:05:01.200947] Iteration 65000, train loss = 0.128100, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 21:05:11.177876] Iteration 65100, train loss = 0.131204, train accuracy = 1.000000\n",
      "[2018-07-17 21:05:18.901723] Iteration 65200, train loss = 0.129168, train accuracy = 1.000000\n",
      "[2018-07-17 21:05:26.633286] Iteration 65300, train loss = 0.141107, train accuracy = 0.992188\n",
      "[2018-07-17 21:05:34.355623] Iteration 65400, train loss = 0.128625, train accuracy = 1.000000\n",
      "[2018-07-17 21:05:42.091627] Iteration 65500, train loss = 0.137583, train accuracy = 1.000000\n",
      "[2018-07-17 21:05:49.827283] Iteration 65600, train loss = 0.131456, train accuracy = 1.000000\n",
      "[2018-07-17 21:05:57.557606] Iteration 65700, train loss = 0.129029, train accuracy = 1.000000\n",
      "[2018-07-17 21:06:05.280638] Iteration 65800, train loss = 0.130893, train accuracy = 1.000000\n",
      "[2018-07-17 21:06:12.996520] Iteration 65900, train loss = 0.128961, train accuracy = 1.000000\n",
      "[2018-07-17 21:06:20.732234] Iteration 66000, train loss = 0.128319, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.927900\n",
      "[2018-07-17 21:06:30.705546] Iteration 66100, train loss = 0.141570, train accuracy = 0.992188\n",
      "[2018-07-17 21:06:38.444014] Iteration 66200, train loss = 0.131764, train accuracy = 1.000000\n",
      "[2018-07-17 21:06:46.171354] Iteration 66300, train loss = 0.130594, train accuracy = 1.000000\n",
      "[2018-07-17 21:06:53.903403] Iteration 66400, train loss = 0.146136, train accuracy = 0.992188\n",
      "[2018-07-17 21:07:01.648403] Iteration 66500, train loss = 0.130501, train accuracy = 1.000000\n",
      "[2018-07-17 21:07:09.370996] Iteration 66600, train loss = 0.127491, train accuracy = 1.000000\n",
      "[2018-07-17 21:07:17.104051] Iteration 66700, train loss = 0.132688, train accuracy = 1.000000\n",
      "[2018-07-17 21:07:24.837515] Iteration 66800, train loss = 0.128489, train accuracy = 1.000000\n",
      "[2018-07-17 21:07:32.554337] Iteration 66900, train loss = 0.133271, train accuracy = 1.000000\n",
      "[2018-07-17 21:07:40.283548] Iteration 67000, train loss = 0.129078, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928100\n",
      "[2018-07-17 21:07:50.260739] Iteration 67100, train loss = 0.130729, train accuracy = 1.000000\n",
      "[2018-07-17 21:07:57.986033] Iteration 67200, train loss = 0.131867, train accuracy = 1.000000\n",
      "[2018-07-17 21:08:05.710582] Iteration 67300, train loss = 0.131028, train accuracy = 1.000000\n",
      "[2018-07-17 21:08:13.455655] Iteration 67400, train loss = 0.136606, train accuracy = 1.000000\n",
      "[2018-07-17 21:08:21.182545] Iteration 67500, train loss = 0.130199, train accuracy = 1.000000\n",
      "[2018-07-17 21:08:28.905103] Iteration 67600, train loss = 0.136033, train accuracy = 0.992188\n",
      "[2018-07-17 21:08:36.614820] Iteration 67700, train loss = 0.141929, train accuracy = 0.992188\n",
      "[2018-07-17 21:08:44.345377] Iteration 67800, train loss = 0.130024, train accuracy = 1.000000\n",
      "[2018-07-17 21:08:52.087073] Iteration 67900, train loss = 0.132161, train accuracy = 1.000000\n",
      "[2018-07-17 21:08:59.819513] Iteration 68000, train loss = 0.128397, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928100\n",
      "[2018-07-17 21:09:09.811553] Iteration 68100, train loss = 0.130668, train accuracy = 1.000000\n",
      "[2018-07-17 21:09:17.557120] Iteration 68200, train loss = 0.133142, train accuracy = 1.000000\n",
      "[2018-07-17 21:09:25.284904] Iteration 68300, train loss = 0.130866, train accuracy = 1.000000\n",
      "[2018-07-17 21:09:33.022206] Iteration 68400, train loss = 0.132865, train accuracy = 1.000000\n",
      "[2018-07-17 21:09:40.744477] Iteration 68500, train loss = 0.129153, train accuracy = 1.000000\n",
      "[2018-07-17 21:09:48.460699] Iteration 68600, train loss = 0.128918, train accuracy = 1.000000\n",
      "[2018-07-17 21:09:56.194258] Iteration 68700, train loss = 0.135309, train accuracy = 1.000000\n",
      "[2018-07-17 21:10:03.905405] Iteration 68800, train loss = 0.131302, train accuracy = 1.000000\n",
      "[2018-07-17 21:10:11.631918] Iteration 68900, train loss = 0.134102, train accuracy = 1.000000\n",
      "[2018-07-17 21:10:19.357907] Iteration 69000, train loss = 0.132337, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928100\n",
      "[2018-07-17 21:10:29.356463] Iteration 69100, train loss = 0.129801, train accuracy = 1.000000\n",
      "[2018-07-17 21:10:37.087275] Iteration 69200, train loss = 0.130548, train accuracy = 1.000000\n",
      "[2018-07-17 21:10:44.809274] Iteration 69300, train loss = 0.134310, train accuracy = 1.000000\n",
      "[2018-07-17 21:10:52.524002] Iteration 69400, train loss = 0.130102, train accuracy = 1.000000\n",
      "[2018-07-17 21:11:00.246241] Iteration 69500, train loss = 0.135522, train accuracy = 0.992188\n",
      "[2018-07-17 21:11:07.977636] Iteration 69600, train loss = 0.128490, train accuracy = 1.000000\n",
      "[2018-07-17 21:11:15.710882] Iteration 69700, train loss = 0.150222, train accuracy = 0.992188\n",
      "[2018-07-17 21:11:23.429739] Iteration 69800, train loss = 0.134015, train accuracy = 1.000000\n",
      "[2018-07-17 21:11:31.143602] Iteration 69900, train loss = 0.129792, train accuracy = 1.000000\n",
      "[2018-07-17 21:11:38.834121] Iteration 70000, train loss = 0.133790, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 21:11:48.800462] Iteration 70100, train loss = 0.135485, train accuracy = 1.000000\n",
      "[2018-07-17 21:11:56.532393] Iteration 70200, train loss = 0.129684, train accuracy = 1.000000\n",
      "[2018-07-17 21:12:04.251191] Iteration 70300, train loss = 0.128101, train accuracy = 1.000000\n",
      "[2018-07-17 21:12:11.991355] Iteration 70400, train loss = 0.142840, train accuracy = 0.992188\n",
      "[2018-07-17 21:12:19.714279] Iteration 70500, train loss = 0.129867, train accuracy = 1.000000\n",
      "[2018-07-17 21:12:27.442656] Iteration 70600, train loss = 0.130826, train accuracy = 1.000000\n",
      "[2018-07-17 21:12:35.171839] Iteration 70700, train loss = 0.138677, train accuracy = 0.992188\n",
      "[2018-07-17 21:12:42.905329] Iteration 70800, train loss = 0.148708, train accuracy = 0.984375\n",
      "[2018-07-17 21:12:50.622413] Iteration 70900, train loss = 0.129858, train accuracy = 1.000000\n",
      "[2018-07-17 21:12:58.347558] Iteration 71000, train loss = 0.135204, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.928200\n",
      "[2018-07-17 21:13:08.304686] Iteration 71100, train loss = 0.128997, train accuracy = 1.000000\n",
      "[2018-07-17 21:13:16.026894] Iteration 71200, train loss = 0.128497, train accuracy = 1.000000\n",
      "[2018-07-17 21:13:23.752299] Iteration 71300, train loss = 0.130707, train accuracy = 1.000000\n",
      "[2018-07-17 21:13:31.470474] Iteration 71400, train loss = 0.148762, train accuracy = 0.992188\n",
      "[2018-07-17 21:13:39.181499] Iteration 71500, train loss = 0.133525, train accuracy = 1.000000\n",
      "[2018-07-17 21:13:46.909958] Iteration 71600, train loss = 0.145523, train accuracy = 1.000000\n",
      "[2018-07-17 21:13:54.635285] Iteration 71700, train loss = 0.151561, train accuracy = 0.992188\n",
      "[2018-07-17 21:14:02.356482] Iteration 71800, train loss = 0.129643, train accuracy = 1.000000\n",
      "[2018-07-17 21:14:10.080386] Iteration 71900, train loss = 0.135441, train accuracy = 1.000000\n",
      "[2018-07-17 21:14:17.810805] Iteration 72000, train loss = 0.130742, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928300\n",
      "[2018-07-17 21:14:27.779286] Iteration 72100, train loss = 0.141234, train accuracy = 1.000000\n",
      "[2018-07-17 21:14:35.491251] Iteration 72200, train loss = 0.131245, train accuracy = 1.000000\n",
      "[2018-07-17 21:14:43.233510] Iteration 72300, train loss = 0.127675, train accuracy = 1.000000\n",
      "[2018-07-17 21:14:50.970575] Iteration 72400, train loss = 0.128825, train accuracy = 1.000000\n",
      "[2018-07-17 21:14:58.698167] Iteration 72500, train loss = 0.130988, train accuracy = 1.000000\n",
      "[2018-07-17 21:15:06.413667] Iteration 72600, train loss = 0.135427, train accuracy = 1.000000\n",
      "[2018-07-17 21:15:14.146280] Iteration 72700, train loss = 0.133155, train accuracy = 1.000000\n",
      "[2018-07-17 21:15:21.872781] Iteration 72800, train loss = 0.135966, train accuracy = 1.000000\n",
      "[2018-07-17 21:15:29.596860] Iteration 72900, train loss = 0.128441, train accuracy = 1.000000\n",
      "[2018-07-17 21:15:37.317390] Iteration 73000, train loss = 0.132786, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928500\n",
      "[2018-07-17 21:15:47.290817] Iteration 73100, train loss = 0.129767, train accuracy = 1.000000\n",
      "[2018-07-17 21:15:55.006994] Iteration 73200, train loss = 0.130035, train accuracy = 1.000000\n",
      "[2018-07-17 21:16:02.721268] Iteration 73300, train loss = 0.130796, train accuracy = 1.000000\n",
      "[2018-07-17 21:16:10.437594] Iteration 73400, train loss = 0.139221, train accuracy = 0.992188\n",
      "[2018-07-17 21:16:18.164649] Iteration 73500, train loss = 0.133325, train accuracy = 1.000000\n",
      "[2018-07-17 21:16:25.893784] Iteration 73600, train loss = 0.130358, train accuracy = 1.000000\n",
      "[2018-07-17 21:16:33.625860] Iteration 73700, train loss = 0.132453, train accuracy = 1.000000\n",
      "[2018-07-17 21:16:41.357412] Iteration 73800, train loss = 0.128846, train accuracy = 1.000000\n",
      "[2018-07-17 21:16:49.091679] Iteration 73900, train loss = 0.136158, train accuracy = 1.000000\n",
      "[2018-07-17 21:16:56.822429] Iteration 74000, train loss = 0.134899, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928300\n",
      "[2018-07-17 21:17:06.826304] Iteration 74100, train loss = 0.130907, train accuracy = 1.000000\n",
      "[2018-07-17 21:17:14.557835] Iteration 74200, train loss = 0.137689, train accuracy = 1.000000\n",
      "[2018-07-17 21:17:22.280926] Iteration 74300, train loss = 0.130926, train accuracy = 1.000000\n",
      "[2018-07-17 21:17:30.022315] Iteration 74400, train loss = 0.132698, train accuracy = 1.000000\n",
      "[2018-07-17 21:17:37.733338] Iteration 74500, train loss = 0.133726, train accuracy = 1.000000\n",
      "[2018-07-17 21:17:45.457953] Iteration 74600, train loss = 0.129832, train accuracy = 1.000000\n",
      "[2018-07-17 21:17:53.191055] Iteration 74700, train loss = 0.134132, train accuracy = 1.000000\n",
      "[2018-07-17 21:18:00.908475] Iteration 74800, train loss = 0.137641, train accuracy = 1.000000\n",
      "[2018-07-17 21:18:08.637944] Iteration 74900, train loss = 0.130377, train accuracy = 1.000000\n",
      "[2018-07-17 21:18:16.377959] Iteration 75000, train loss = 0.130897, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928000\n",
      "[2018-07-17 21:18:26.352231] Iteration 75100, train loss = 0.128499, train accuracy = 1.000000\n",
      "[2018-07-17 21:18:34.080672] Iteration 75200, train loss = 0.129843, train accuracy = 1.000000\n",
      "[2018-07-17 21:18:41.817513] Iteration 75300, train loss = 0.145426, train accuracy = 0.992188\n",
      "[2018-07-17 21:18:49.538815] Iteration 75400, train loss = 0.130250, train accuracy = 1.000000\n",
      "[2018-07-17 21:18:57.263503] Iteration 75500, train loss = 0.128091, train accuracy = 1.000000\n",
      "[2018-07-17 21:19:04.989307] Iteration 75600, train loss = 0.133504, train accuracy = 1.000000\n",
      "[2018-07-17 21:19:12.715372] Iteration 75700, train loss = 0.129884, train accuracy = 1.000000\n",
      "[2018-07-17 21:19:20.434995] Iteration 75800, train loss = 0.133099, train accuracy = 1.000000\n",
      "[2018-07-17 21:19:28.160257] Iteration 75900, train loss = 0.139212, train accuracy = 1.000000\n",
      "[2018-07-17 21:19:35.895918] Iteration 76000, train loss = 0.128336, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928800\n",
      "[2018-07-17 21:19:45.860446] Iteration 76100, train loss = 0.127983, train accuracy = 1.000000\n",
      "[2018-07-17 21:19:53.576932] Iteration 76200, train loss = 0.162054, train accuracy = 0.992188\n",
      "[2018-07-17 21:20:01.305519] Iteration 76300, train loss = 0.135597, train accuracy = 1.000000\n",
      "[2018-07-17 21:20:09.032687] Iteration 76400, train loss = 0.129719, train accuracy = 1.000000\n",
      "[2018-07-17 21:20:16.747650] Iteration 76500, train loss = 0.134352, train accuracy = 1.000000\n",
      "[2018-07-17 21:20:24.461942] Iteration 76600, train loss = 0.130388, train accuracy = 1.000000\n",
      "[2018-07-17 21:20:32.206864] Iteration 76700, train loss = 0.130239, train accuracy = 1.000000\n",
      "[2018-07-17 21:20:39.936602] Iteration 76800, train loss = 0.130772, train accuracy = 1.000000\n",
      "[2018-07-17 21:20:47.660606] Iteration 76900, train loss = 0.145144, train accuracy = 0.992188\n",
      "[2018-07-17 21:20:55.394192] Iteration 77000, train loss = 0.131932, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928400\n",
      "[2018-07-17 21:21:05.380513] Iteration 77100, train loss = 0.132191, train accuracy = 1.000000\n",
      "[2018-07-17 21:21:13.105416] Iteration 77200, train loss = 0.128593, train accuracy = 1.000000\n",
      "[2018-07-17 21:21:20.820624] Iteration 77300, train loss = 0.128370, train accuracy = 1.000000\n",
      "[2018-07-17 21:21:28.542658] Iteration 77400, train loss = 0.134911, train accuracy = 1.000000\n",
      "[2018-07-17 21:21:36.284993] Iteration 77500, train loss = 0.129554, train accuracy = 1.000000\n",
      "[2018-07-17 21:21:44.009137] Iteration 77600, train loss = 0.130888, train accuracy = 1.000000\n",
      "[2018-07-17 21:21:51.728209] Iteration 77700, train loss = 0.132247, train accuracy = 1.000000\n",
      "[2018-07-17 21:21:59.451341] Iteration 77800, train loss = 0.134599, train accuracy = 1.000000\n",
      "[2018-07-17 21:22:07.176907] Iteration 77900, train loss = 0.132261, train accuracy = 1.000000\n",
      "[2018-07-17 21:22:14.900702] Iteration 78000, train loss = 0.129874, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928100\n",
      "[2018-07-17 21:22:24.882872] Iteration 78100, train loss = 0.132869, train accuracy = 1.000000\n",
      "[2018-07-17 21:22:32.615164] Iteration 78200, train loss = 0.134667, train accuracy = 1.000000\n",
      "[2018-07-17 21:22:40.329042] Iteration 78300, train loss = 0.132656, train accuracy = 1.000000\n",
      "[2018-07-17 21:22:48.048406] Iteration 78400, train loss = 0.151933, train accuracy = 0.992188\n",
      "[2018-07-17 21:22:55.784228] Iteration 78500, train loss = 0.134670, train accuracy = 1.000000\n",
      "[2018-07-17 21:23:03.523189] Iteration 78600, train loss = 0.140692, train accuracy = 0.992188\n",
      "[2018-07-17 21:23:11.258249] Iteration 78700, train loss = 0.128360, train accuracy = 1.000000\n",
      "[2018-07-17 21:23:18.985385] Iteration 78800, train loss = 0.131223, train accuracy = 1.000000\n",
      "[2018-07-17 21:23:26.712622] Iteration 78900, train loss = 0.130393, train accuracy = 1.000000\n",
      "[2018-07-17 21:23:34.434880] Iteration 79000, train loss = 0.140756, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.928500\n",
      "[2018-07-17 21:23:44.412509] Iteration 79100, train loss = 0.151277, train accuracy = 0.992188\n",
      "[2018-07-17 21:23:52.134010] Iteration 79200, train loss = 0.146301, train accuracy = 0.984375\n",
      "[2018-07-17 21:23:59.882044] Iteration 79300, train loss = 0.129406, train accuracy = 1.000000\n",
      "[2018-07-17 21:24:07.623847] Iteration 79400, train loss = 0.128688, train accuracy = 1.000000\n",
      "[2018-07-17 21:24:15.367770] Iteration 79500, train loss = 0.127765, train accuracy = 1.000000\n",
      "[2018-07-17 21:24:23.097803] Iteration 79600, train loss = 0.131961, train accuracy = 1.000000\n",
      "[2018-07-17 21:24:30.834452] Iteration 79700, train loss = 0.135003, train accuracy = 0.992188\n",
      "[2018-07-17 21:24:38.558244] Iteration 79800, train loss = 0.133283, train accuracy = 1.000000\n",
      "[2018-07-17 21:24:46.287191] Iteration 79900, train loss = 0.136537, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四轮  量化  \n",
    "prune_rate = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.928000\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.03125     0.125      -0.0625     -0.0625\n",
      "  0.00659172  0.03734787  0.0625     -0.0625    ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,1)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-07-17 21:28:11.379301] Iteration 100, train loss = 0.167113, train accuracy = 0.984375\n",
      "[2018-07-17 21:28:17.856134] Iteration 200, train loss = 0.204747, train accuracy = 0.976562\n",
      "[2018-07-17 21:28:24.337392] Iteration 300, train loss = 0.175083, train accuracy = 0.992188\n",
      "[2018-07-17 21:28:30.822777] Iteration 400, train loss = 0.150842, train accuracy = 0.992188\n",
      "[2018-07-17 21:28:37.314555] Iteration 500, train loss = 0.183020, train accuracy = 0.976562\n",
      "[2018-07-17 21:28:43.799296] Iteration 600, train loss = 0.177092, train accuracy = 0.976562\n",
      "[2018-07-17 21:28:50.285719] Iteration 700, train loss = 0.163846, train accuracy = 0.984375\n",
      "[2018-07-17 21:28:56.787509] Iteration 800, train loss = 0.173139, train accuracy = 0.976562\n",
      "[2018-07-17 21:29:03.274592] Iteration 900, train loss = 0.162839, train accuracy = 0.984375\n",
      "[2018-07-17 21:29:09.755865] Iteration 1000, train loss = 0.148046, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 21:29:18.521936] Iteration 1100, train loss = 0.181068, train accuracy = 0.976562\n",
      "[2018-07-17 21:29:25.011782] Iteration 1200, train loss = 0.158663, train accuracy = 0.984375\n",
      "[2018-07-17 21:29:31.503642] Iteration 1300, train loss = 0.242267, train accuracy = 0.968750\n",
      "[2018-07-17 21:29:38.000209] Iteration 1400, train loss = 0.175035, train accuracy = 0.976562\n",
      "[2018-07-17 21:29:44.485162] Iteration 1500, train loss = 0.183970, train accuracy = 0.976562\n",
      "[2018-07-17 21:29:50.975839] Iteration 1600, train loss = 0.174011, train accuracy = 0.976562\n",
      "[2018-07-17 21:29:57.462601] Iteration 1700, train loss = 0.200858, train accuracy = 0.968750\n",
      "[2018-07-17 21:30:03.967986] Iteration 1800, train loss = 0.220211, train accuracy = 0.945312\n",
      "[2018-07-17 21:30:10.451655] Iteration 1900, train loss = 0.185120, train accuracy = 0.976562\n",
      "[2018-07-17 21:30:16.938173] Iteration 2000, train loss = 0.182009, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-17 21:30:25.678714] Iteration 2100, train loss = 0.189428, train accuracy = 0.976562\n",
      "[2018-07-17 21:30:32.183076] Iteration 2200, train loss = 0.176075, train accuracy = 0.984375\n",
      "[2018-07-17 21:30:38.664160] Iteration 2300, train loss = 0.149584, train accuracy = 0.992188\n",
      "[2018-07-17 21:30:45.159164] Iteration 2400, train loss = 0.142409, train accuracy = 0.992188\n",
      "[2018-07-17 21:30:51.646767] Iteration 2500, train loss = 0.278641, train accuracy = 0.960938\n",
      "[2018-07-17 21:30:58.149216] Iteration 2600, train loss = 0.230646, train accuracy = 0.960938\n",
      "[2018-07-17 21:31:04.632620] Iteration 2700, train loss = 0.182563, train accuracy = 0.976562\n",
      "[2018-07-17 21:31:11.136003] Iteration 2800, train loss = 0.155558, train accuracy = 0.992188\n",
      "[2018-07-17 21:31:17.628458] Iteration 2900, train loss = 0.170425, train accuracy = 0.984375\n",
      "[2018-07-17 21:31:24.110093] Iteration 3000, train loss = 0.179528, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 21:31:32.861623] Iteration 3100, train loss = 0.150456, train accuracy = 0.992188\n",
      "[2018-07-17 21:31:39.346525] Iteration 3200, train loss = 0.142522, train accuracy = 0.992188\n",
      "[2018-07-17 21:31:45.840613] Iteration 3300, train loss = 0.189473, train accuracy = 0.976562\n",
      "[2018-07-17 21:31:52.358671] Iteration 3400, train loss = 0.220923, train accuracy = 0.968750\n",
      "[2018-07-17 21:31:58.863040] Iteration 3500, train loss = 0.177334, train accuracy = 0.984375\n",
      "[2018-07-17 21:32:05.347834] Iteration 3600, train loss = 0.176390, train accuracy = 0.976562\n",
      "[2018-07-17 21:32:11.840788] Iteration 3700, train loss = 0.198532, train accuracy = 0.968750\n",
      "[2018-07-17 21:32:18.356596] Iteration 3800, train loss = 0.181937, train accuracy = 0.968750\n",
      "[2018-07-17 21:32:24.872094] Iteration 3900, train loss = 0.297319, train accuracy = 0.929688\n",
      "[2018-07-17 21:32:31.358961] Iteration 4000, train loss = 0.207611, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 21:32:40.119825] Iteration 4100, train loss = 0.226606, train accuracy = 0.976562\n",
      "[2018-07-17 21:32:46.614811] Iteration 4200, train loss = 0.159814, train accuracy = 0.984375\n",
      "[2018-07-17 21:32:53.111651] Iteration 4300, train loss = 0.153570, train accuracy = 0.992188\n",
      "[2018-07-17 21:32:59.602509] Iteration 4400, train loss = 0.184352, train accuracy = 0.984375\n",
      "[2018-07-17 21:33:06.103375] Iteration 4500, train loss = 0.155517, train accuracy = 0.992188\n",
      "[2018-07-17 21:33:12.599116] Iteration 4600, train loss = 0.143507, train accuracy = 1.000000\n",
      "[2018-07-17 21:33:19.095196] Iteration 4700, train loss = 0.219171, train accuracy = 0.976562\n",
      "[2018-07-17 21:33:25.597648] Iteration 4800, train loss = 0.155369, train accuracy = 0.984375\n",
      "[2018-07-17 21:33:32.098891] Iteration 4900, train loss = 0.182476, train accuracy = 0.976562\n",
      "[2018-07-17 21:33:38.598228] Iteration 5000, train loss = 0.187798, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911200\n",
      "[2018-07-17 21:33:47.329231] Iteration 5100, train loss = 0.196171, train accuracy = 0.976562\n",
      "[2018-07-17 21:33:53.860991] Iteration 5200, train loss = 0.143616, train accuracy = 0.992188\n",
      "[2018-07-17 21:34:00.350266] Iteration 5300, train loss = 0.216788, train accuracy = 0.976562\n",
      "[2018-07-17 21:34:06.848315] Iteration 5400, train loss = 0.149549, train accuracy = 0.992188\n",
      "[2018-07-17 21:34:13.344768] Iteration 5500, train loss = 0.154748, train accuracy = 1.000000\n",
      "[2018-07-17 21:34:19.829622] Iteration 5600, train loss = 0.147113, train accuracy = 1.000000\n",
      "[2018-07-17 21:34:26.347045] Iteration 5700, train loss = 0.150221, train accuracy = 1.000000\n",
      "[2018-07-17 21:34:32.845956] Iteration 5800, train loss = 0.231068, train accuracy = 0.960938\n",
      "[2018-07-17 21:34:39.336836] Iteration 5900, train loss = 0.232479, train accuracy = 0.945312\n",
      "[2018-07-17 21:34:45.839868] Iteration 6000, train loss = 0.172715, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-17 21:34:54.578775] Iteration 6100, train loss = 0.196043, train accuracy = 0.968750\n",
      "[2018-07-17 21:35:01.062699] Iteration 6200, train loss = 0.182961, train accuracy = 0.984375\n",
      "[2018-07-17 21:35:07.550170] Iteration 6300, train loss = 0.171156, train accuracy = 0.984375\n",
      "[2018-07-17 21:35:14.039846] Iteration 6400, train loss = 0.150318, train accuracy = 0.992188\n",
      "[2018-07-17 21:35:20.549849] Iteration 6500, train loss = 0.239235, train accuracy = 0.953125\n",
      "[2018-07-17 21:35:27.050805] Iteration 6600, train loss = 0.168172, train accuracy = 0.984375\n",
      "[2018-07-17 21:35:33.558920] Iteration 6700, train loss = 0.142354, train accuracy = 1.000000\n",
      "[2018-07-17 21:35:40.061113] Iteration 6800, train loss = 0.161335, train accuracy = 0.992188\n",
      "[2018-07-17 21:35:46.554925] Iteration 6900, train loss = 0.158561, train accuracy = 0.992188\n",
      "[2018-07-17 21:35:53.056665] Iteration 7000, train loss = 0.228780, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.911400\n",
      "[2018-07-17 21:36:01.788840] Iteration 7100, train loss = 0.165326, train accuracy = 0.984375\n",
      "[2018-07-17 21:36:08.279832] Iteration 7200, train loss = 0.160690, train accuracy = 0.992188\n",
      "[2018-07-17 21:36:14.775060] Iteration 7300, train loss = 0.218215, train accuracy = 0.976562\n",
      "[2018-07-17 21:36:21.269706] Iteration 7400, train loss = 0.158352, train accuracy = 0.992188\n",
      "[2018-07-17 21:36:27.771583] Iteration 7500, train loss = 0.175749, train accuracy = 0.976562\n",
      "[2018-07-17 21:36:34.259167] Iteration 7600, train loss = 0.166496, train accuracy = 0.984375\n",
      "[2018-07-17 21:36:40.758715] Iteration 7700, train loss = 0.154062, train accuracy = 0.992188\n",
      "[2018-07-17 21:36:47.233414] Iteration 7800, train loss = 0.141907, train accuracy = 1.000000\n",
      "[2018-07-17 21:36:53.748805] Iteration 7900, train loss = 0.154042, train accuracy = 0.992188\n",
      "[2018-07-17 21:37:00.250849] Iteration 8000, train loss = 0.185672, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.912000\n",
      "[2018-07-17 21:37:08.998379] Iteration 8100, train loss = 0.177425, train accuracy = 0.992188\n",
      "[2018-07-17 21:37:15.503489] Iteration 8200, train loss = 0.210803, train accuracy = 0.976562\n",
      "[2018-07-17 21:37:21.990979] Iteration 8300, train loss = 0.149899, train accuracy = 0.992188\n",
      "[2018-07-17 21:37:28.512179] Iteration 8400, train loss = 0.176063, train accuracy = 0.992188\n",
      "[2018-07-17 21:37:34.993996] Iteration 8500, train loss = 0.159105, train accuracy = 0.992188\n",
      "[2018-07-17 21:37:41.484932] Iteration 8600, train loss = 0.175765, train accuracy = 0.984375\n",
      "[2018-07-17 21:37:47.989031] Iteration 8700, train loss = 0.158711, train accuracy = 0.984375\n",
      "[2018-07-17 21:37:54.481133] Iteration 8800, train loss = 0.212511, train accuracy = 0.968750\n",
      "[2018-07-17 21:38:00.980047] Iteration 8900, train loss = 0.139075, train accuracy = 1.000000\n",
      "[2018-07-17 21:38:07.481691] Iteration 9000, train loss = 0.163891, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 21:38:16.218177] Iteration 9100, train loss = 0.170257, train accuracy = 0.984375\n",
      "[2018-07-17 21:38:22.733908] Iteration 9200, train loss = 0.164553, train accuracy = 0.984375\n",
      "[2018-07-17 21:38:29.212430] Iteration 9300, train loss = 0.178339, train accuracy = 0.984375\n",
      "[2018-07-17 21:38:35.699638] Iteration 9400, train loss = 0.145024, train accuracy = 1.000000\n",
      "[2018-07-17 21:38:42.196089] Iteration 9500, train loss = 0.191668, train accuracy = 0.968750\n",
      "[2018-07-17 21:38:48.699458] Iteration 9600, train loss = 0.216970, train accuracy = 0.945312\n",
      "[2018-07-17 21:38:55.184106] Iteration 9700, train loss = 0.164089, train accuracy = 0.992188\n",
      "[2018-07-17 21:39:01.679927] Iteration 9800, train loss = 0.153550, train accuracy = 0.992188\n",
      "[2018-07-17 21:39:08.165413] Iteration 9900, train loss = 0.151518, train accuracy = 0.992188\n",
      "[2018-07-17 21:39:14.658562] Iteration 10000, train loss = 0.199133, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 21:39:23.386013] Iteration 10100, train loss = 0.234183, train accuracy = 0.960938\n",
      "[2018-07-17 21:39:29.876002] Iteration 10200, train loss = 0.188927, train accuracy = 0.968750\n",
      "[2018-07-17 21:39:36.355524] Iteration 10300, train loss = 0.187523, train accuracy = 0.968750\n",
      "[2018-07-17 21:39:42.843946] Iteration 10400, train loss = 0.154015, train accuracy = 0.992188\n",
      "[2018-07-17 21:39:49.353951] Iteration 10500, train loss = 0.169157, train accuracy = 0.992188\n",
      "[2018-07-17 21:39:55.850428] Iteration 10600, train loss = 0.194557, train accuracy = 0.968750\n",
      "[2018-07-17 21:40:02.336511] Iteration 10700, train loss = 0.138218, train accuracy = 0.992188\n",
      "[2018-07-17 21:40:08.823145] Iteration 10800, train loss = 0.166567, train accuracy = 0.984375\n",
      "[2018-07-17 21:40:15.309921] Iteration 10900, train loss = 0.144061, train accuracy = 1.000000\n",
      "[2018-07-17 21:40:21.805169] Iteration 11000, train loss = 0.168873, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911200\n",
      "[2018-07-17 21:40:30.544765] Iteration 11100, train loss = 0.156943, train accuracy = 1.000000\n",
      "[2018-07-17 21:40:37.023423] Iteration 11200, train loss = 0.177716, train accuracy = 0.968750\n",
      "[2018-07-17 21:40:43.528321] Iteration 11300, train loss = 0.141798, train accuracy = 1.000000\n",
      "[2018-07-17 21:40:50.036656] Iteration 11400, train loss = 0.142421, train accuracy = 1.000000\n",
      "[2018-07-17 21:40:56.536464] Iteration 11500, train loss = 0.185062, train accuracy = 0.976562\n",
      "[2018-07-17 21:41:03.030434] Iteration 11600, train loss = 0.195803, train accuracy = 0.968750\n",
      "[2018-07-17 21:41:09.525804] Iteration 11700, train loss = 0.180646, train accuracy = 0.976562\n",
      "[2018-07-17 21:41:16.019761] Iteration 11800, train loss = 0.136332, train accuracy = 1.000000\n",
      "[2018-07-17 21:41:22.537966] Iteration 11900, train loss = 0.154778, train accuracy = 0.992188\n",
      "[2018-07-17 21:41:29.034967] Iteration 12000, train loss = 0.136351, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911300\n",
      "[2018-07-17 21:41:37.790480] Iteration 12100, train loss = 0.200912, train accuracy = 0.984375\n",
      "[2018-07-17 21:41:44.270646] Iteration 12200, train loss = 0.194281, train accuracy = 0.968750\n",
      "[2018-07-17 21:41:50.758284] Iteration 12300, train loss = 0.222551, train accuracy = 0.953125\n",
      "[2018-07-17 21:41:57.254837] Iteration 12400, train loss = 0.186444, train accuracy = 0.976562\n",
      "[2018-07-17 21:42:03.743475] Iteration 12500, train loss = 0.150226, train accuracy = 1.000000\n",
      "[2018-07-17 21:42:10.231874] Iteration 12600, train loss = 0.143896, train accuracy = 1.000000\n",
      "[2018-07-17 21:42:16.728769] Iteration 12700, train loss = 0.157855, train accuracy = 0.992188\n",
      "[2018-07-17 21:42:23.221878] Iteration 12800, train loss = 0.216906, train accuracy = 0.976562\n",
      "[2018-07-17 21:42:29.725730] Iteration 12900, train loss = 0.164711, train accuracy = 0.992188\n",
      "[2018-07-17 21:42:36.219051] Iteration 13000, train loss = 0.148624, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 21:42:44.968741] Iteration 13100, train loss = 0.183714, train accuracy = 0.968750\n",
      "[2018-07-17 21:42:51.499603] Iteration 13200, train loss = 0.171817, train accuracy = 0.984375\n",
      "[2018-07-17 21:42:58.010064] Iteration 13300, train loss = 0.203130, train accuracy = 0.960938\n",
      "[2018-07-17 21:43:04.505289] Iteration 13400, train loss = 0.138468, train accuracy = 1.000000\n",
      "[2018-07-17 21:43:10.998678] Iteration 13500, train loss = 0.173686, train accuracy = 0.984375\n",
      "[2018-07-17 21:43:17.482039] Iteration 13600, train loss = 0.165609, train accuracy = 0.984375\n",
      "[2018-07-17 21:43:23.972087] Iteration 13700, train loss = 0.141689, train accuracy = 1.000000\n",
      "[2018-07-17 21:43:30.466431] Iteration 13800, train loss = 0.164201, train accuracy = 0.976562\n",
      "[2018-07-17 21:43:36.985881] Iteration 13900, train loss = 0.191602, train accuracy = 0.984375\n",
      "[2018-07-17 21:43:43.482495] Iteration 14000, train loss = 0.180898, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911400\n",
      "[2018-07-17 21:43:52.223068] Iteration 14100, train loss = 0.151167, train accuracy = 1.000000\n",
      "[2018-07-17 21:43:58.714948] Iteration 14200, train loss = 0.152985, train accuracy = 0.984375\n",
      "[2018-07-17 21:44:05.219481] Iteration 14300, train loss = 0.153582, train accuracy = 0.992188\n",
      "[2018-07-17 21:44:11.731753] Iteration 14400, train loss = 0.199530, train accuracy = 0.976562\n",
      "[2018-07-17 21:44:18.253700] Iteration 14500, train loss = 0.169749, train accuracy = 0.992188\n",
      "[2018-07-17 21:44:24.746164] Iteration 14600, train loss = 0.165776, train accuracy = 0.992188\n",
      "[2018-07-17 21:44:31.209698] Iteration 14700, train loss = 0.156629, train accuracy = 0.992188\n",
      "[2018-07-17 21:44:37.698940] Iteration 14800, train loss = 0.160762, train accuracy = 0.992188\n",
      "[2018-07-17 21:44:44.197594] Iteration 14900, train loss = 0.277328, train accuracy = 0.945312\n",
      "[2018-07-17 21:44:50.678061] Iteration 15000, train loss = 0.205581, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 21:44:59.416978] Iteration 15100, train loss = 0.197600, train accuracy = 0.960938\n",
      "[2018-07-17 21:45:05.908870] Iteration 15200, train loss = 0.154063, train accuracy = 0.992188\n",
      "[2018-07-17 21:45:12.392134] Iteration 15300, train loss = 0.174555, train accuracy = 0.992188\n",
      "[2018-07-17 21:45:18.893810] Iteration 15400, train loss = 0.171626, train accuracy = 0.976562\n",
      "[2018-07-17 21:45:25.389661] Iteration 15500, train loss = 0.160618, train accuracy = 0.984375\n",
      "[2018-07-17 21:45:31.888922] Iteration 15600, train loss = 0.140546, train accuracy = 0.992188\n",
      "[2018-07-17 21:45:38.377083] Iteration 15700, train loss = 0.162902, train accuracy = 0.992188\n",
      "[2018-07-17 21:45:44.870261] Iteration 15800, train loss = 0.189598, train accuracy = 0.968750\n",
      "[2018-07-17 21:45:51.402939] Iteration 15900, train loss = 0.162295, train accuracy = 0.984375\n",
      "[2018-07-17 21:45:57.905242] Iteration 16000, train loss = 0.168983, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912200\n",
      "[2018-07-17 21:46:06.651310] Iteration 16100, train loss = 0.161205, train accuracy = 0.992188\n",
      "[2018-07-17 21:46:13.122024] Iteration 16200, train loss = 0.166132, train accuracy = 0.984375\n",
      "[2018-07-17 21:46:19.621359] Iteration 16300, train loss = 0.196920, train accuracy = 0.976562\n",
      "[2018-07-17 21:46:26.123536] Iteration 16400, train loss = 0.151179, train accuracy = 0.992188\n",
      "[2018-07-17 21:46:32.618855] Iteration 16500, train loss = 0.237707, train accuracy = 0.976562\n",
      "[2018-07-17 21:46:39.125242] Iteration 16600, train loss = 0.140645, train accuracy = 1.000000\n",
      "[2018-07-17 21:46:45.624678] Iteration 16700, train loss = 0.165504, train accuracy = 0.984375\n",
      "[2018-07-17 21:46:52.113128] Iteration 16800, train loss = 0.186441, train accuracy = 0.976562\n",
      "[2018-07-17 21:46:58.618443] Iteration 16900, train loss = 0.232572, train accuracy = 0.976562\n",
      "[2018-07-17 21:47:05.120593] Iteration 17000, train loss = 0.193132, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 21:47:13.854842] Iteration 17100, train loss = 0.263705, train accuracy = 0.953125\n",
      "[2018-07-17 21:47:20.361821] Iteration 17200, train loss = 0.206282, train accuracy = 0.976562\n",
      "[2018-07-17 21:47:26.861552] Iteration 17300, train loss = 0.149154, train accuracy = 0.992188\n",
      "[2018-07-17 21:47:33.364932] Iteration 17400, train loss = 0.229904, train accuracy = 0.968750\n",
      "[2018-07-17 21:47:39.856545] Iteration 17500, train loss = 0.176162, train accuracy = 0.976562\n",
      "[2018-07-17 21:47:46.337933] Iteration 17600, train loss = 0.154097, train accuracy = 0.984375\n",
      "[2018-07-17 21:47:52.839148] Iteration 17700, train loss = 0.224928, train accuracy = 0.960938\n",
      "[2018-07-17 21:47:59.339791] Iteration 17800, train loss = 0.252088, train accuracy = 0.953125\n",
      "[2018-07-17 21:48:05.814685] Iteration 17900, train loss = 0.151393, train accuracy = 0.992188\n",
      "[2018-07-17 21:48:12.304428] Iteration 18000, train loss = 0.224734, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 21:48:21.053924] Iteration 18100, train loss = 0.152291, train accuracy = 0.992188\n",
      "[2018-07-17 21:48:27.538509] Iteration 18200, train loss = 0.139237, train accuracy = 1.000000\n",
      "[2018-07-17 21:48:34.029504] Iteration 18300, train loss = 0.195434, train accuracy = 0.992188\n",
      "[2018-07-17 21:48:40.523387] Iteration 18400, train loss = 0.161754, train accuracy = 0.984375\n",
      "[2018-07-17 21:48:47.011310] Iteration 18500, train loss = 0.244574, train accuracy = 0.960938\n",
      "[2018-07-17 21:48:53.515407] Iteration 18600, train loss = 0.198141, train accuracy = 0.968750\n",
      "[2018-07-17 21:49:00.014382] Iteration 18700, train loss = 0.204250, train accuracy = 0.968750\n",
      "[2018-07-17 21:49:06.506288] Iteration 18800, train loss = 0.171590, train accuracy = 0.976562\n",
      "[2018-07-17 21:49:13.006718] Iteration 18900, train loss = 0.195628, train accuracy = 0.976562\n",
      "[2018-07-17 21:49:19.508221] Iteration 19000, train loss = 0.154333, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-17 21:49:28.257686] Iteration 19100, train loss = 0.200851, train accuracy = 0.968750\n",
      "[2018-07-17 21:49:34.726042] Iteration 19200, train loss = 0.170376, train accuracy = 0.984375\n",
      "[2018-07-17 21:49:41.220845] Iteration 19300, train loss = 0.241940, train accuracy = 0.945312\n",
      "[2018-07-17 21:49:47.721058] Iteration 19400, train loss = 0.184807, train accuracy = 0.984375\n",
      "[2018-07-17 21:49:54.215626] Iteration 19500, train loss = 0.146690, train accuracy = 0.992188\n",
      "[2018-07-17 21:50:00.705979] Iteration 19600, train loss = 0.169535, train accuracy = 0.984375\n",
      "[2018-07-17 21:50:07.185590] Iteration 19700, train loss = 0.203896, train accuracy = 0.968750\n",
      "[2018-07-17 21:50:13.676289] Iteration 19800, train loss = 0.182443, train accuracy = 0.976562\n",
      "[2018-07-17 21:50:20.204113] Iteration 19900, train loss = 0.162353, train accuracy = 0.992188\n",
      "[2018-07-17 21:50:26.698699] Iteration 20000, train loss = 0.198520, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911300\n",
      "[2018-07-17 21:50:35.435147] Iteration 20100, train loss = 0.146542, train accuracy = 0.992188\n",
      "[2018-07-17 21:50:41.935085] Iteration 20200, train loss = 0.147056, train accuracy = 1.000000\n",
      "[2018-07-17 21:50:48.442371] Iteration 20300, train loss = 0.200211, train accuracy = 0.976562\n",
      "[2018-07-17 21:50:54.939695] Iteration 20400, train loss = 0.144905, train accuracy = 1.000000\n",
      "[2018-07-17 21:51:01.435908] Iteration 20500, train loss = 0.174440, train accuracy = 0.984375\n",
      "[2018-07-17 21:51:07.937854] Iteration 20600, train loss = 0.181396, train accuracy = 0.960938\n",
      "[2018-07-17 21:51:14.430834] Iteration 20700, train loss = 0.185558, train accuracy = 0.984375\n",
      "[2018-07-17 21:51:20.929299] Iteration 20800, train loss = 0.150549, train accuracy = 0.992188\n",
      "[2018-07-17 21:51:27.423084] Iteration 20900, train loss = 0.208021, train accuracy = 0.976562\n",
      "[2018-07-17 21:51:33.910099] Iteration 21000, train loss = 0.194855, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 21:51:42.659002] Iteration 21100, train loss = 0.135031, train accuracy = 1.000000\n",
      "[2018-07-17 21:51:49.162777] Iteration 21200, train loss = 0.218614, train accuracy = 0.968750\n",
      "[2018-07-17 21:51:55.663707] Iteration 21300, train loss = 0.148561, train accuracy = 0.984375\n",
      "[2018-07-17 21:52:02.153605] Iteration 21400, train loss = 0.172910, train accuracy = 0.984375\n",
      "[2018-07-17 21:52:08.650810] Iteration 21500, train loss = 0.238501, train accuracy = 0.953125\n",
      "[2018-07-17 21:52:15.150146] Iteration 21600, train loss = 0.156464, train accuracy = 0.992188\n",
      "[2018-07-17 21:52:21.644487] Iteration 21700, train loss = 0.170726, train accuracy = 0.984375\n",
      "[2018-07-17 21:52:28.136371] Iteration 21800, train loss = 0.196969, train accuracy = 0.984375\n",
      "[2018-07-17 21:52:34.617114] Iteration 21900, train loss = 0.198266, train accuracy = 0.976562\n",
      "[2018-07-17 21:52:41.106329] Iteration 22000, train loss = 0.183327, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 21:52:49.842257] Iteration 22100, train loss = 0.160217, train accuracy = 0.984375\n",
      "[2018-07-17 21:52:56.342396] Iteration 22200, train loss = 0.154089, train accuracy = 0.976562\n",
      "[2018-07-17 21:53:02.834253] Iteration 22300, train loss = 0.187529, train accuracy = 0.992188\n",
      "[2018-07-17 21:53:09.329962] Iteration 22400, train loss = 0.196204, train accuracy = 0.984375\n",
      "[2018-07-17 21:53:15.823140] Iteration 22500, train loss = 0.185091, train accuracy = 0.984375\n",
      "[2018-07-17 21:53:22.334812] Iteration 22600, train loss = 0.185698, train accuracy = 0.976562\n",
      "[2018-07-17 21:53:28.836711] Iteration 22700, train loss = 0.169626, train accuracy = 0.984375\n",
      "[2018-07-17 21:53:35.328189] Iteration 22800, train loss = 0.154700, train accuracy = 0.992188\n",
      "[2018-07-17 21:53:41.824013] Iteration 22900, train loss = 0.166582, train accuracy = 0.984375\n",
      "[2018-07-17 21:53:48.329428] Iteration 23000, train loss = 0.186067, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 21:53:57.077832] Iteration 23100, train loss = 0.164155, train accuracy = 0.984375\n",
      "[2018-07-17 21:54:03.575311] Iteration 23200, train loss = 0.168284, train accuracy = 0.984375\n",
      "[2018-07-17 21:54:10.067756] Iteration 23300, train loss = 0.157597, train accuracy = 0.992188\n",
      "[2018-07-17 21:54:16.568840] Iteration 23400, train loss = 0.153007, train accuracy = 0.984375\n",
      "[2018-07-17 21:54:23.055936] Iteration 23500, train loss = 0.220622, train accuracy = 0.960938\n",
      "[2018-07-17 21:54:29.548676] Iteration 23600, train loss = 0.210520, train accuracy = 0.984375\n",
      "[2018-07-17 21:54:36.036847] Iteration 23700, train loss = 0.161209, train accuracy = 0.984375\n",
      "[2018-07-17 21:54:42.521004] Iteration 23800, train loss = 0.174697, train accuracy = 0.992188\n",
      "[2018-07-17 21:54:49.039264] Iteration 23900, train loss = 0.157648, train accuracy = 0.984375\n",
      "[2018-07-17 21:54:55.543313] Iteration 24000, train loss = 0.174389, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 21:55:04.267007] Iteration 24100, train loss = 0.197747, train accuracy = 0.976562\n",
      "[2018-07-17 21:55:10.772160] Iteration 24200, train loss = 0.166607, train accuracy = 0.976562\n",
      "[2018-07-17 21:55:17.271453] Iteration 24300, train loss = 0.142935, train accuracy = 0.992188\n",
      "[2018-07-17 21:55:23.771660] Iteration 24400, train loss = 0.159404, train accuracy = 0.984375\n",
      "[2018-07-17 21:55:30.259271] Iteration 24500, train loss = 0.169019, train accuracy = 0.976562\n",
      "[2018-07-17 21:55:36.756698] Iteration 24600, train loss = 0.215625, train accuracy = 0.976562\n",
      "[2018-07-17 21:55:43.243515] Iteration 24700, train loss = 0.183195, train accuracy = 0.960938\n",
      "[2018-07-17 21:55:49.744021] Iteration 24800, train loss = 0.154540, train accuracy = 0.992188\n",
      "[2018-07-17 21:55:56.240132] Iteration 24900, train loss = 0.218119, train accuracy = 0.976562\n",
      "[2018-07-17 21:56:02.727484] Iteration 25000, train loss = 0.194429, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.911800\n",
      "[2018-07-17 21:56:11.470306] Iteration 25100, train loss = 0.161445, train accuracy = 1.000000\n",
      "[2018-07-17 21:56:17.962653] Iteration 25200, train loss = 0.146558, train accuracy = 0.992188\n",
      "[2018-07-17 21:56:24.485333] Iteration 25300, train loss = 0.180811, train accuracy = 0.984375\n",
      "[2018-07-17 21:56:30.986192] Iteration 25400, train loss = 0.167332, train accuracy = 0.984375\n",
      "[2018-07-17 21:56:37.511118] Iteration 25500, train loss = 0.178227, train accuracy = 0.984375\n",
      "[2018-07-17 21:56:44.006605] Iteration 25600, train loss = 0.164241, train accuracy = 0.984375\n",
      "[2018-07-17 21:56:50.500451] Iteration 25700, train loss = 0.176654, train accuracy = 0.984375\n",
      "[2018-07-17 21:56:57.000189] Iteration 25800, train loss = 0.146278, train accuracy = 1.000000\n",
      "[2018-07-17 21:57:03.498240] Iteration 25900, train loss = 0.197862, train accuracy = 0.976562\n",
      "[2018-07-17 21:57:10.015667] Iteration 26000, train loss = 0.207837, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "[2018-07-17 21:57:18.758075] Iteration 26100, train loss = 0.156820, train accuracy = 0.984375\n",
      "[2018-07-17 21:57:25.263300] Iteration 26200, train loss = 0.193176, train accuracy = 0.984375\n",
      "[2018-07-17 21:57:31.761596] Iteration 26300, train loss = 0.207563, train accuracy = 0.976562\n",
      "[2018-07-17 21:57:38.277452] Iteration 26400, train loss = 0.152256, train accuracy = 0.992188\n",
      "[2018-07-17 21:57:44.760209] Iteration 26500, train loss = 0.193321, train accuracy = 0.968750\n",
      "[2018-07-17 21:57:51.280455] Iteration 26600, train loss = 0.143411, train accuracy = 0.992188\n",
      "[2018-07-17 21:57:57.767683] Iteration 26700, train loss = 0.230541, train accuracy = 0.976562\n",
      "[2018-07-17 21:58:04.253464] Iteration 26800, train loss = 0.154361, train accuracy = 0.992188\n",
      "[2018-07-17 21:58:10.740715] Iteration 26900, train loss = 0.199194, train accuracy = 0.968750\n",
      "[2018-07-17 21:58:17.237660] Iteration 27000, train loss = 0.185954, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.912200\n",
      "[2018-07-17 21:58:25.962811] Iteration 27100, train loss = 0.187573, train accuracy = 0.976562\n",
      "[2018-07-17 21:58:32.449335] Iteration 27200, train loss = 0.153553, train accuracy = 0.984375\n",
      "[2018-07-17 21:58:38.945353] Iteration 27300, train loss = 0.177139, train accuracy = 0.976562\n",
      "[2018-07-17 21:58:45.430816] Iteration 27400, train loss = 0.145529, train accuracy = 0.992188\n",
      "[2018-07-17 21:58:51.926978] Iteration 27500, train loss = 0.203092, train accuracy = 0.968750\n",
      "[2018-07-17 21:58:58.426962] Iteration 27600, train loss = 0.190652, train accuracy = 0.976562\n",
      "[2018-07-17 21:59:04.930584] Iteration 27700, train loss = 0.151825, train accuracy = 0.992188\n",
      "[2018-07-17 21:59:11.424915] Iteration 27800, train loss = 0.145543, train accuracy = 1.000000\n",
      "[2018-07-17 21:59:17.918905] Iteration 27900, train loss = 0.174365, train accuracy = 0.976562\n",
      "[2018-07-17 21:59:24.444222] Iteration 28000, train loss = 0.147078, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911300\n",
      "[2018-07-17 21:59:33.229792] Iteration 28100, train loss = 0.156761, train accuracy = 0.992188\n",
      "[2018-07-17 21:59:39.751884] Iteration 28200, train loss = 0.190673, train accuracy = 0.984375\n",
      "[2018-07-17 21:59:46.283539] Iteration 28300, train loss = 0.286063, train accuracy = 0.960938\n",
      "[2018-07-17 21:59:52.815353] Iteration 28400, train loss = 0.157060, train accuracy = 0.992188\n",
      "[2018-07-17 21:59:59.342397] Iteration 28500, train loss = 0.197848, train accuracy = 0.976562\n",
      "[2018-07-17 22:00:05.867066] Iteration 28600, train loss = 0.185304, train accuracy = 0.968750\n",
      "[2018-07-17 22:00:12.386766] Iteration 28700, train loss = 0.192373, train accuracy = 0.968750\n",
      "[2018-07-17 22:00:18.907885] Iteration 28800, train loss = 0.205551, train accuracy = 0.976562\n",
      "[2018-07-17 22:00:25.429717] Iteration 28900, train loss = 0.177452, train accuracy = 0.984375\n",
      "[2018-07-17 22:00:31.950391] Iteration 29000, train loss = 0.152122, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:00:40.728131] Iteration 29100, train loss = 0.227373, train accuracy = 0.976562\n",
      "[2018-07-17 22:00:47.255498] Iteration 29200, train loss = 0.210245, train accuracy = 0.968750\n",
      "[2018-07-17 22:00:53.756883] Iteration 29300, train loss = 0.168972, train accuracy = 0.992188\n",
      "[2018-07-17 22:01:00.281779] Iteration 29400, train loss = 0.199673, train accuracy = 0.960938\n",
      "[2018-07-17 22:01:06.802076] Iteration 29500, train loss = 0.205417, train accuracy = 0.960938\n",
      "[2018-07-17 22:01:13.322633] Iteration 29600, train loss = 0.176006, train accuracy = 0.984375\n",
      "[2018-07-17 22:01:19.848492] Iteration 29700, train loss = 0.176206, train accuracy = 0.976562\n",
      "[2018-07-17 22:01:26.370367] Iteration 29800, train loss = 0.176904, train accuracy = 0.976562\n",
      "[2018-07-17 22:01:32.892626] Iteration 29900, train loss = 0.181093, train accuracy = 0.976562\n",
      "[2018-07-17 22:01:39.409641] Iteration 30000, train loss = 0.195381, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:01:48.192033] Iteration 30100, train loss = 0.191767, train accuracy = 0.976562\n",
      "[2018-07-17 22:01:54.714796] Iteration 30200, train loss = 0.220973, train accuracy = 0.976562\n",
      "[2018-07-17 22:02:01.233432] Iteration 30300, train loss = 0.137643, train accuracy = 1.000000\n",
      "[2018-07-17 22:02:07.755164] Iteration 30400, train loss = 0.153283, train accuracy = 1.000000\n",
      "[2018-07-17 22:02:14.269730] Iteration 30500, train loss = 0.149266, train accuracy = 1.000000\n",
      "[2018-07-17 22:02:20.789284] Iteration 30600, train loss = 0.144803, train accuracy = 0.992188\n",
      "[2018-07-17 22:02:27.310054] Iteration 30700, train loss = 0.183559, train accuracy = 0.968750\n",
      "[2018-07-17 22:02:33.810545] Iteration 30800, train loss = 0.216501, train accuracy = 0.968750\n",
      "[2018-07-17 22:02:40.297287] Iteration 30900, train loss = 0.190078, train accuracy = 0.984375\n",
      "[2018-07-17 22:02:46.746365] Iteration 31000, train loss = 0.171746, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 22:02:55.456175] Iteration 31100, train loss = 0.172430, train accuracy = 0.992188\n",
      "[2018-07-17 22:03:01.947223] Iteration 31200, train loss = 0.149462, train accuracy = 0.992188\n",
      "[2018-07-17 22:03:08.440317] Iteration 31300, train loss = 0.180505, train accuracy = 0.976562\n",
      "[2018-07-17 22:03:14.961694] Iteration 31400, train loss = 0.157803, train accuracy = 0.992188\n",
      "[2018-07-17 22:03:21.458754] Iteration 31500, train loss = 0.172990, train accuracy = 0.976562\n",
      "[2018-07-17 22:03:27.966758] Iteration 31600, train loss = 0.159422, train accuracy = 0.984375\n",
      "[2018-07-17 22:03:34.492366] Iteration 31700, train loss = 0.212998, train accuracy = 0.976562\n",
      "[2018-07-17 22:03:41.029922] Iteration 31800, train loss = 0.223673, train accuracy = 0.968750\n",
      "[2018-07-17 22:03:47.531034] Iteration 31900, train loss = 0.137926, train accuracy = 1.000000\n",
      "[2018-07-17 22:03:54.034184] Iteration 32000, train loss = 0.218060, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:04:02.807218] Iteration 32100, train loss = 0.155550, train accuracy = 0.992188\n",
      "[2018-07-17 22:04:09.302754] Iteration 32200, train loss = 0.241258, train accuracy = 0.968750\n",
      "[2018-07-17 22:04:15.808830] Iteration 32300, train loss = 0.261325, train accuracy = 0.976562\n",
      "[2018-07-17 22:04:22.301743] Iteration 32400, train loss = 0.146593, train accuracy = 0.992188\n",
      "[2018-07-17 22:04:28.785045] Iteration 32500, train loss = 0.168834, train accuracy = 0.992188\n",
      "[2018-07-17 22:04:35.301065] Iteration 32600, train loss = 0.190296, train accuracy = 0.976562\n",
      "[2018-07-17 22:04:41.803174] Iteration 32700, train loss = 0.175505, train accuracy = 0.976562\n",
      "[2018-07-17 22:04:48.306964] Iteration 32800, train loss = 0.178398, train accuracy = 0.976562\n",
      "[2018-07-17 22:04:54.805424] Iteration 32900, train loss = 0.167399, train accuracy = 0.992188\n",
      "[2018-07-17 22:05:01.306731] Iteration 33000, train loss = 0.161117, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912000\n",
      "[2018-07-17 22:05:10.061154] Iteration 33100, train loss = 0.153221, train accuracy = 0.984375\n",
      "[2018-07-17 22:05:16.555520] Iteration 33200, train loss = 0.159252, train accuracy = 0.984375\n",
      "[2018-07-17 22:05:23.054843] Iteration 33300, train loss = 0.150872, train accuracy = 0.992188\n",
      "[2018-07-17 22:05:29.564434] Iteration 33400, train loss = 0.191167, train accuracy = 0.984375\n",
      "[2018-07-17 22:05:36.072944] Iteration 33500, train loss = 0.241089, train accuracy = 0.968750\n",
      "[2018-07-17 22:05:42.571961] Iteration 33600, train loss = 0.140957, train accuracy = 1.000000\n",
      "[2018-07-17 22:05:49.068577] Iteration 33700, train loss = 0.161592, train accuracy = 0.992188\n",
      "[2018-07-17 22:05:55.566544] Iteration 33800, train loss = 0.162975, train accuracy = 0.992188\n",
      "[2018-07-17 22:06:02.067347] Iteration 33900, train loss = 0.154197, train accuracy = 0.984375\n",
      "[2018-07-17 22:06:08.589980] Iteration 34000, train loss = 0.155504, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 22:06:17.351660] Iteration 34100, train loss = 0.152923, train accuracy = 0.992188\n",
      "[2018-07-17 22:06:23.852413] Iteration 34200, train loss = 0.143442, train accuracy = 1.000000\n",
      "[2018-07-17 22:06:30.361610] Iteration 34300, train loss = 0.211170, train accuracy = 0.976562\n",
      "[2018-07-17 22:06:36.864538] Iteration 34400, train loss = 0.175899, train accuracy = 0.984375\n",
      "[2018-07-17 22:06:43.356768] Iteration 34500, train loss = 0.185172, train accuracy = 0.976562\n",
      "[2018-07-17 22:06:49.865114] Iteration 34600, train loss = 0.169697, train accuracy = 0.984375\n",
      "[2018-07-17 22:06:56.363327] Iteration 34700, train loss = 0.205371, train accuracy = 0.976562\n",
      "[2018-07-17 22:07:02.876375] Iteration 34800, train loss = 0.171289, train accuracy = 0.992188\n",
      "[2018-07-17 22:07:09.375798] Iteration 34900, train loss = 0.207284, train accuracy = 0.960938\n",
      "[2018-07-17 22:07:15.904286] Iteration 35000, train loss = 0.190629, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:07:24.668097] Iteration 35100, train loss = 0.149802, train accuracy = 0.992188\n",
      "[2018-07-17 22:07:31.149960] Iteration 35200, train loss = 0.194470, train accuracy = 0.968750\n",
      "[2018-07-17 22:07:37.655493] Iteration 35300, train loss = 0.178504, train accuracy = 0.984375\n",
      "[2018-07-17 22:07:44.165128] Iteration 35400, train loss = 0.231137, train accuracy = 0.960938\n",
      "[2018-07-17 22:07:50.669377] Iteration 35500, train loss = 0.245107, train accuracy = 0.968750\n",
      "[2018-07-17 22:07:57.179554] Iteration 35600, train loss = 0.187841, train accuracy = 0.968750\n",
      "[2018-07-17 22:08:03.677849] Iteration 35700, train loss = 0.214459, train accuracy = 0.968750\n",
      "[2018-07-17 22:08:10.166339] Iteration 35800, train loss = 0.136659, train accuracy = 1.000000\n",
      "[2018-07-17 22:08:16.680461] Iteration 35900, train loss = 0.203596, train accuracy = 0.960938\n",
      "[2018-07-17 22:08:23.194231] Iteration 36000, train loss = 0.343910, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "[2018-07-17 22:08:31.958517] Iteration 36100, train loss = 0.129552, train accuracy = 1.000000\n",
      "[2018-07-17 22:08:38.452861] Iteration 36200, train loss = 0.181987, train accuracy = 0.976562\n",
      "[2018-07-17 22:08:44.945512] Iteration 36300, train loss = 0.158092, train accuracy = 0.984375\n",
      "[2018-07-17 22:08:51.438136] Iteration 36400, train loss = 0.154570, train accuracy = 0.992188\n",
      "[2018-07-17 22:08:57.939109] Iteration 36500, train loss = 0.139957, train accuracy = 1.000000\n",
      "[2018-07-17 22:09:04.458203] Iteration 36600, train loss = 0.211756, train accuracy = 0.976562\n",
      "[2018-07-17 22:09:10.964784] Iteration 36700, train loss = 0.167480, train accuracy = 0.984375\n",
      "[2018-07-17 22:09:17.459636] Iteration 36800, train loss = 0.184552, train accuracy = 0.968750\n",
      "[2018-07-17 22:09:23.963591] Iteration 36900, train loss = 0.150250, train accuracy = 0.992188\n",
      "[2018-07-17 22:09:30.457480] Iteration 37000, train loss = 0.207100, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.911800\n",
      "[2018-07-17 22:09:39.202925] Iteration 37100, train loss = 0.171177, train accuracy = 0.984375\n",
      "[2018-07-17 22:09:45.737339] Iteration 37200, train loss = 0.179833, train accuracy = 0.984375\n",
      "[2018-07-17 22:09:52.253959] Iteration 37300, train loss = 0.206862, train accuracy = 0.992188\n",
      "[2018-07-17 22:09:58.766767] Iteration 37400, train loss = 0.225758, train accuracy = 0.960938\n",
      "[2018-07-17 22:10:05.273297] Iteration 37500, train loss = 0.202691, train accuracy = 0.976562\n",
      "[2018-07-17 22:10:11.786996] Iteration 37600, train loss = 0.208163, train accuracy = 0.976562\n",
      "[2018-07-17 22:10:18.272100] Iteration 37700, train loss = 0.178272, train accuracy = 0.976562\n",
      "[2018-07-17 22:10:24.776620] Iteration 37800, train loss = 0.202569, train accuracy = 0.968750\n",
      "[2018-07-17 22:10:31.275447] Iteration 37900, train loss = 0.203022, train accuracy = 0.976562\n",
      "[2018-07-17 22:10:37.789078] Iteration 38000, train loss = 0.213140, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 22:10:46.550543] Iteration 38100, train loss = 0.164240, train accuracy = 0.976562\n",
      "[2018-07-17 22:10:53.059045] Iteration 38200, train loss = 0.188778, train accuracy = 0.984375\n",
      "[2018-07-17 22:10:59.575677] Iteration 38300, train loss = 0.194317, train accuracy = 0.984375\n",
      "[2018-07-17 22:11:06.086416] Iteration 38400, train loss = 0.189364, train accuracy = 0.968750\n",
      "[2018-07-17 22:11:12.571221] Iteration 38500, train loss = 0.185399, train accuracy = 0.976562\n",
      "[2018-07-17 22:11:19.080229] Iteration 38600, train loss = 0.141726, train accuracy = 1.000000\n",
      "[2018-07-17 22:11:25.591940] Iteration 38700, train loss = 0.182624, train accuracy = 0.984375\n",
      "[2018-07-17 22:11:32.104094] Iteration 38800, train loss = 0.147256, train accuracy = 0.984375\n",
      "[2018-07-17 22:11:38.603511] Iteration 38900, train loss = 0.239163, train accuracy = 0.976562\n",
      "[2018-07-17 22:11:45.105973] Iteration 39000, train loss = 0.144506, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911800\n",
      "[2018-07-17 22:11:53.866570] Iteration 39100, train loss = 0.164255, train accuracy = 0.992188\n",
      "[2018-07-17 22:12:00.358975] Iteration 39200, train loss = 0.177841, train accuracy = 0.984375\n",
      "[2018-07-17 22:12:06.855718] Iteration 39300, train loss = 0.191450, train accuracy = 0.968750\n",
      "[2018-07-17 22:12:13.374198] Iteration 39400, train loss = 0.135022, train accuracy = 1.000000\n",
      "[2018-07-17 22:12:19.886368] Iteration 39500, train loss = 0.142335, train accuracy = 1.000000\n",
      "[2018-07-17 22:12:26.403492] Iteration 39600, train loss = 0.188697, train accuracy = 0.976562\n",
      "[2018-07-17 22:12:32.906576] Iteration 39700, train loss = 0.159066, train accuracy = 0.992188\n",
      "[2018-07-17 22:12:39.430221] Iteration 39800, train loss = 0.244259, train accuracy = 0.960938\n",
      "[2018-07-17 22:12:45.941725] Iteration 39900, train loss = 0.153450, train accuracy = 1.000000\n",
      "[2018-07-17 22:12:52.435920] Iteration 40000, train loss = 0.214852, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:13:01.196280] Iteration 40100, train loss = 0.168275, train accuracy = 0.984375\n",
      "[2018-07-17 22:13:07.694734] Iteration 40200, train loss = 0.293009, train accuracy = 0.929688\n",
      "[2018-07-17 22:13:14.183561] Iteration 40300, train loss = 0.162638, train accuracy = 0.992188\n",
      "[2018-07-17 22:13:20.691454] Iteration 40400, train loss = 0.160302, train accuracy = 0.976562\n",
      "[2018-07-17 22:13:27.187235] Iteration 40500, train loss = 0.188141, train accuracy = 0.960938\n",
      "[2018-07-17 22:13:33.683287] Iteration 40600, train loss = 0.157230, train accuracy = 0.984375\n",
      "[2018-07-17 22:13:40.176185] Iteration 40700, train loss = 0.134661, train accuracy = 1.000000\n",
      "[2018-07-17 22:13:46.669398] Iteration 40800, train loss = 0.161177, train accuracy = 0.992188\n",
      "[2018-07-17 22:13:53.174412] Iteration 40900, train loss = 0.154700, train accuracy = 0.984375\n",
      "[2018-07-17 22:13:59.670521] Iteration 41000, train loss = 0.161347, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "[2018-07-17 22:14:08.417227] Iteration 41100, train loss = 0.195479, train accuracy = 0.976562\n",
      "[2018-07-17 22:14:14.911278] Iteration 41200, train loss = 0.179016, train accuracy = 0.968750\n",
      "[2018-07-17 22:14:21.400744] Iteration 41300, train loss = 0.193174, train accuracy = 0.976562\n",
      "[2018-07-17 22:14:27.895175] Iteration 41400, train loss = 0.140449, train accuracy = 1.000000\n",
      "[2018-07-17 22:14:34.428553] Iteration 41500, train loss = 0.161597, train accuracy = 0.984375\n",
      "[2018-07-17 22:14:40.911156] Iteration 41600, train loss = 0.159510, train accuracy = 0.984375\n",
      "[2018-07-17 22:14:47.392805] Iteration 41700, train loss = 0.175056, train accuracy = 0.976562\n",
      "[2018-07-17 22:14:53.889409] Iteration 41800, train loss = 0.187075, train accuracy = 0.976562\n",
      "[2018-07-17 22:15:00.392625] Iteration 41900, train loss = 0.151048, train accuracy = 0.992188\n",
      "[2018-07-17 22:15:06.903298] Iteration 42000, train loss = 0.170242, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 22:15:15.648890] Iteration 42100, train loss = 0.188841, train accuracy = 0.992188\n",
      "[2018-07-17 22:15:22.146042] Iteration 42200, train loss = 0.182993, train accuracy = 0.976562\n",
      "[2018-07-17 22:15:28.642363] Iteration 42300, train loss = 0.154543, train accuracy = 0.976562\n",
      "[2018-07-17 22:15:35.136807] Iteration 42400, train loss = 0.150800, train accuracy = 0.992188\n",
      "[2018-07-17 22:15:41.632317] Iteration 42500, train loss = 0.268456, train accuracy = 0.968750\n",
      "[2018-07-17 22:15:48.162024] Iteration 42600, train loss = 0.158549, train accuracy = 0.992188\n",
      "[2018-07-17 22:15:54.652848] Iteration 42700, train loss = 0.202236, train accuracy = 0.976562\n",
      "[2018-07-17 22:16:01.153963] Iteration 42800, train loss = 0.198091, train accuracy = 0.968750\n",
      "[2018-07-17 22:16:07.655204] Iteration 42900, train loss = 0.134460, train accuracy = 1.000000\n",
      "[2018-07-17 22:16:14.164956] Iteration 43000, train loss = 0.164558, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:16:22.917300] Iteration 43100, train loss = 0.178557, train accuracy = 0.992188\n",
      "[2018-07-17 22:16:29.409926] Iteration 43200, train loss = 0.148018, train accuracy = 0.992188\n",
      "[2018-07-17 22:16:35.915424] Iteration 43300, train loss = 0.160264, train accuracy = 0.984375\n",
      "[2018-07-17 22:16:42.414737] Iteration 43400, train loss = 0.142170, train accuracy = 1.000000\n",
      "[2018-07-17 22:16:48.920118] Iteration 43500, train loss = 0.177325, train accuracy = 0.984375\n",
      "[2018-07-17 22:16:55.418857] Iteration 43600, train loss = 0.167347, train accuracy = 0.984375\n",
      "[2018-07-17 22:17:01.964258] Iteration 43700, train loss = 0.168685, train accuracy = 0.992188\n",
      "[2018-07-17 22:17:08.448640] Iteration 43800, train loss = 0.177717, train accuracy = 0.976562\n",
      "[2018-07-17 22:17:14.939627] Iteration 43900, train loss = 0.133949, train accuracy = 1.000000\n",
      "[2018-07-17 22:17:21.433962] Iteration 44000, train loss = 0.146104, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "[2018-07-17 22:17:30.200644] Iteration 44100, train loss = 0.148234, train accuracy = 1.000000\n",
      "[2018-07-17 22:17:36.699695] Iteration 44200, train loss = 0.143063, train accuracy = 0.992188\n",
      "[2018-07-17 22:17:43.182973] Iteration 44300, train loss = 0.159219, train accuracy = 0.992188\n",
      "[2018-07-17 22:17:49.695895] Iteration 44400, train loss = 0.181701, train accuracy = 0.984375\n",
      "[2018-07-17 22:17:56.225918] Iteration 44500, train loss = 0.173929, train accuracy = 0.992188\n",
      "[2018-07-17 22:18:02.730941] Iteration 44600, train loss = 0.177018, train accuracy = 0.976562\n",
      "[2018-07-17 22:18:09.221265] Iteration 44700, train loss = 0.150711, train accuracy = 0.992188\n",
      "[2018-07-17 22:18:15.756283] Iteration 44800, train loss = 0.158898, train accuracy = 0.984375\n",
      "[2018-07-17 22:18:22.251511] Iteration 44900, train loss = 0.225098, train accuracy = 0.968750\n",
      "[2018-07-17 22:18:28.757477] Iteration 45000, train loss = 0.216064, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911100\n",
      "[2018-07-17 22:18:37.531908] Iteration 45100, train loss = 0.161325, train accuracy = 0.984375\n",
      "[2018-07-17 22:18:44.024522] Iteration 45200, train loss = 0.150943, train accuracy = 0.992188\n",
      "[2018-07-17 22:18:50.545785] Iteration 45300, train loss = 0.221739, train accuracy = 0.953125\n",
      "[2018-07-17 22:18:57.051548] Iteration 45400, train loss = 0.154232, train accuracy = 0.992188\n",
      "[2018-07-17 22:19:03.546901] Iteration 45500, train loss = 0.189205, train accuracy = 0.976562\n",
      "[2018-07-17 22:19:10.043988] Iteration 45600, train loss = 0.192678, train accuracy = 0.953125\n",
      "[2018-07-17 22:19:16.544783] Iteration 45700, train loss = 0.162931, train accuracy = 0.992188\n",
      "[2018-07-17 22:19:23.033951] Iteration 45800, train loss = 0.136672, train accuracy = 1.000000\n",
      "[2018-07-17 22:19:29.552627] Iteration 45900, train loss = 0.218540, train accuracy = 0.976562\n",
      "[2018-07-17 22:19:36.051473] Iteration 46000, train loss = 0.168047, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:19:44.792049] Iteration 46100, train loss = 0.165621, train accuracy = 0.976562\n",
      "[2018-07-17 22:19:51.286919] Iteration 46200, train loss = 0.168010, train accuracy = 0.984375\n",
      "[2018-07-17 22:19:57.786310] Iteration 46300, train loss = 0.164885, train accuracy = 0.984375\n",
      "[2018-07-17 22:20:04.304356] Iteration 46400, train loss = 0.208332, train accuracy = 0.976562\n",
      "[2018-07-17 22:20:10.799349] Iteration 46500, train loss = 0.190629, train accuracy = 0.968750\n",
      "[2018-07-17 22:20:17.298243] Iteration 46600, train loss = 0.167522, train accuracy = 0.984375\n",
      "[2018-07-17 22:20:23.794164] Iteration 46700, train loss = 0.143941, train accuracy = 0.992188\n",
      "[2018-07-17 22:20:30.292667] Iteration 46800, train loss = 0.146793, train accuracy = 1.000000\n",
      "[2018-07-17 22:20:36.792435] Iteration 46900, train loss = 0.142616, train accuracy = 1.000000\n",
      "[2018-07-17 22:20:43.310304] Iteration 47000, train loss = 0.150017, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 22:20:52.077989] Iteration 47100, train loss = 0.182463, train accuracy = 0.976562\n",
      "[2018-07-17 22:20:58.588648] Iteration 47200, train loss = 0.150342, train accuracy = 0.992188\n",
      "[2018-07-17 22:21:05.098713] Iteration 47300, train loss = 0.167885, train accuracy = 0.976562\n",
      "[2018-07-17 22:21:11.585822] Iteration 47400, train loss = 0.239087, train accuracy = 0.960938\n",
      "[2018-07-17 22:21:18.085268] Iteration 47500, train loss = 0.140852, train accuracy = 1.000000\n",
      "[2018-07-17 22:21:24.585906] Iteration 47600, train loss = 0.163207, train accuracy = 0.992188\n",
      "[2018-07-17 22:21:31.080576] Iteration 47700, train loss = 0.203857, train accuracy = 0.984375\n",
      "[2018-07-17 22:21:37.609136] Iteration 47800, train loss = 0.152180, train accuracy = 0.984375\n",
      "[2018-07-17 22:21:44.110058] Iteration 47900, train loss = 0.234120, train accuracy = 0.976562\n",
      "[2018-07-17 22:21:50.650172] Iteration 48000, train loss = 0.148788, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "Learning rate set to 0.001000\n",
      "[2018-07-17 22:21:59.408583] Iteration 48100, train loss = 0.214066, train accuracy = 0.968750\n",
      "[2018-07-17 22:22:05.909576] Iteration 48200, train loss = 0.216028, train accuracy = 0.960938\n",
      "[2018-07-17 22:22:12.410578] Iteration 48300, train loss = 0.152891, train accuracy = 0.992188\n",
      "[2018-07-17 22:22:18.921590] Iteration 48400, train loss = 0.169864, train accuracy = 0.984375\n",
      "[2018-07-17 22:22:25.423640] Iteration 48500, train loss = 0.200866, train accuracy = 0.968750\n",
      "[2018-07-17 22:22:31.925191] Iteration 48600, train loss = 0.147387, train accuracy = 0.992188\n",
      "[2018-07-17 22:22:38.415423] Iteration 48700, train loss = 0.174409, train accuracy = 0.984375\n",
      "[2018-07-17 22:22:44.925756] Iteration 48800, train loss = 0.190055, train accuracy = 0.984375\n",
      "[2018-07-17 22:22:51.428213] Iteration 48900, train loss = 0.188764, train accuracy = 0.968750\n",
      "[2018-07-17 22:22:57.934788] Iteration 49000, train loss = 0.139718, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:23:06.718678] Iteration 49100, train loss = 0.135373, train accuracy = 1.000000\n",
      "[2018-07-17 22:23:13.223998] Iteration 49200, train loss = 0.174846, train accuracy = 0.976562\n",
      "[2018-07-17 22:23:19.727888] Iteration 49300, train loss = 0.132522, train accuracy = 1.000000\n",
      "[2018-07-17 22:23:26.228180] Iteration 49400, train loss = 0.170371, train accuracy = 0.984375\n",
      "[2018-07-17 22:23:32.729360] Iteration 49500, train loss = 0.159048, train accuracy = 0.984375\n",
      "[2018-07-17 22:23:39.227864] Iteration 49600, train loss = 0.182095, train accuracy = 0.984375\n",
      "[2018-07-17 22:23:45.730494] Iteration 49700, train loss = 0.231580, train accuracy = 0.953125\n",
      "[2018-07-17 22:23:52.226709] Iteration 49800, train loss = 0.197501, train accuracy = 0.976562\n",
      "[2018-07-17 22:23:58.717397] Iteration 49900, train loss = 0.180923, train accuracy = 0.968750\n",
      "[2018-07-17 22:24:05.213794] Iteration 50000, train loss = 0.177896, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:24:13.983762] Iteration 50100, train loss = 0.263551, train accuracy = 0.945312\n",
      "[2018-07-17 22:24:20.497625] Iteration 50200, train loss = 0.149872, train accuracy = 0.992188\n",
      "[2018-07-17 22:24:26.994765] Iteration 50300, train loss = 0.137306, train accuracy = 1.000000\n",
      "[2018-07-17 22:24:33.499037] Iteration 50400, train loss = 0.162914, train accuracy = 0.984375\n",
      "[2018-07-17 22:24:39.992351] Iteration 50500, train loss = 0.187406, train accuracy = 0.976562\n",
      "[2018-07-17 22:24:46.496904] Iteration 50600, train loss = 0.187815, train accuracy = 0.976562\n",
      "[2018-07-17 22:24:53.009896] Iteration 50700, train loss = 0.253217, train accuracy = 0.976562\n",
      "[2018-07-17 22:24:59.517211] Iteration 50800, train loss = 0.234134, train accuracy = 0.960938\n",
      "[2018-07-17 22:25:06.017217] Iteration 50900, train loss = 0.135602, train accuracy = 1.000000\n",
      "[2018-07-17 22:25:12.510833] Iteration 51000, train loss = 0.209458, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.911300\n",
      "[2018-07-17 22:25:21.281759] Iteration 51100, train loss = 0.177066, train accuracy = 0.992188\n",
      "[2018-07-17 22:25:27.790878] Iteration 51200, train loss = 0.164139, train accuracy = 0.984375\n",
      "[2018-07-17 22:25:34.311169] Iteration 51300, train loss = 0.156919, train accuracy = 0.984375\n",
      "[2018-07-17 22:25:40.832615] Iteration 51400, train loss = 0.178451, train accuracy = 0.984375\n",
      "[2018-07-17 22:25:47.321809] Iteration 51500, train loss = 0.238732, train accuracy = 0.953125\n",
      "[2018-07-17 22:25:53.818419] Iteration 51600, train loss = 0.204584, train accuracy = 0.984375\n",
      "[2018-07-17 22:26:00.318525] Iteration 51700, train loss = 0.198346, train accuracy = 0.960938\n",
      "[2018-07-17 22:26:06.820998] Iteration 51800, train loss = 0.142312, train accuracy = 1.000000\n",
      "[2018-07-17 22:26:13.305864] Iteration 51900, train loss = 0.162946, train accuracy = 0.992188\n",
      "[2018-07-17 22:26:19.806221] Iteration 52000, train loss = 0.195607, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:26:28.566497] Iteration 52100, train loss = 0.142186, train accuracy = 1.000000\n",
      "[2018-07-17 22:26:35.068495] Iteration 52200, train loss = 0.170973, train accuracy = 0.976562\n",
      "[2018-07-17 22:26:41.595873] Iteration 52300, train loss = 0.150245, train accuracy = 0.992188\n",
      "[2018-07-17 22:26:48.089294] Iteration 52400, train loss = 0.178399, train accuracy = 0.984375\n",
      "[2018-07-17 22:26:54.588981] Iteration 52500, train loss = 0.221006, train accuracy = 0.976562\n",
      "[2018-07-17 22:27:01.100170] Iteration 52600, train loss = 0.158247, train accuracy = 0.984375\n",
      "[2018-07-17 22:27:07.592979] Iteration 52700, train loss = 0.198167, train accuracy = 0.976562\n",
      "[2018-07-17 22:27:14.088569] Iteration 52800, train loss = 0.207019, train accuracy = 0.984375\n",
      "[2018-07-17 22:27:20.607368] Iteration 52900, train loss = 0.166764, train accuracy = 0.992188\n",
      "[2018-07-17 22:27:27.098880] Iteration 53000, train loss = 0.175873, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-17 22:27:35.870428] Iteration 53100, train loss = 0.187931, train accuracy = 0.984375\n",
      "[2018-07-17 22:27:42.364591] Iteration 53200, train loss = 0.219519, train accuracy = 0.953125\n",
      "[2018-07-17 22:27:48.870698] Iteration 53300, train loss = 0.178386, train accuracy = 0.984375\n",
      "[2018-07-17 22:27:55.392849] Iteration 53400, train loss = 0.168971, train accuracy = 0.992188\n",
      "[2018-07-17 22:28:01.894661] Iteration 53500, train loss = 0.157640, train accuracy = 0.984375\n",
      "[2018-07-17 22:28:08.393586] Iteration 53600, train loss = 0.140203, train accuracy = 1.000000\n",
      "[2018-07-17 22:28:14.888287] Iteration 53700, train loss = 0.171328, train accuracy = 0.976562\n",
      "[2018-07-17 22:28:21.407359] Iteration 53800, train loss = 0.195436, train accuracy = 0.976562\n",
      "[2018-07-17 22:28:27.905442] Iteration 53900, train loss = 0.218783, train accuracy = 0.960938\n",
      "[2018-07-17 22:28:34.405247] Iteration 54000, train loss = 0.196462, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911300\n",
      "[2018-07-17 22:28:43.172973] Iteration 54100, train loss = 0.176820, train accuracy = 0.984375\n",
      "[2018-07-17 22:28:49.683743] Iteration 54200, train loss = 0.196176, train accuracy = 0.960938\n",
      "[2018-07-17 22:28:56.186185] Iteration 54300, train loss = 0.187049, train accuracy = 0.968750\n",
      "[2018-07-17 22:29:02.683431] Iteration 54400, train loss = 0.228270, train accuracy = 0.976562\n",
      "[2018-07-17 22:29:09.201571] Iteration 54500, train loss = 0.214905, train accuracy = 0.976562\n",
      "[2018-07-17 22:29:15.700886] Iteration 54600, train loss = 0.140931, train accuracy = 1.000000\n",
      "[2018-07-17 22:29:22.216201] Iteration 54700, train loss = 0.164607, train accuracy = 0.984375\n",
      "[2018-07-17 22:29:28.725540] Iteration 54800, train loss = 0.156949, train accuracy = 0.992188\n",
      "[2018-07-17 22:29:35.238479] Iteration 54900, train loss = 0.259239, train accuracy = 0.968750\n",
      "[2018-07-17 22:29:41.746688] Iteration 55000, train loss = 0.218425, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-17 22:29:50.501585] Iteration 55100, train loss = 0.159220, train accuracy = 0.992188\n",
      "[2018-07-17 22:29:57.010613] Iteration 55200, train loss = 0.163167, train accuracy = 0.984375\n",
      "[2018-07-17 22:30:03.512348] Iteration 55300, train loss = 0.240177, train accuracy = 0.984375\n",
      "[2018-07-17 22:30:10.002109] Iteration 55400, train loss = 0.203295, train accuracy = 0.984375\n",
      "[2018-07-17 22:30:16.512196] Iteration 55500, train loss = 0.187000, train accuracy = 0.984375\n",
      "[2018-07-17 22:30:23.021202] Iteration 55600, train loss = 0.170666, train accuracy = 0.976562\n",
      "[2018-07-17 22:30:29.519041] Iteration 55700, train loss = 0.154136, train accuracy = 0.984375\n",
      "[2018-07-17 22:30:36.018735] Iteration 55800, train loss = 0.205265, train accuracy = 0.976562\n",
      "[2018-07-17 22:30:42.519316] Iteration 55900, train loss = 0.139411, train accuracy = 1.000000\n",
      "[2018-07-17 22:30:49.031627] Iteration 56000, train loss = 0.149480, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:30:57.792976] Iteration 56100, train loss = 0.177757, train accuracy = 0.976562\n",
      "[2018-07-17 22:31:04.284850] Iteration 56200, train loss = 0.217083, train accuracy = 0.984375\n",
      "[2018-07-17 22:31:10.776321] Iteration 56300, train loss = 0.144168, train accuracy = 0.992188\n",
      "[2018-07-17 22:31:17.284950] Iteration 56400, train loss = 0.254492, train accuracy = 0.960938\n",
      "[2018-07-17 22:31:23.771746] Iteration 56500, train loss = 0.198431, train accuracy = 0.984375\n",
      "[2018-07-17 22:31:30.278968] Iteration 56600, train loss = 0.161083, train accuracy = 0.984375\n",
      "[2018-07-17 22:31:36.816520] Iteration 56700, train loss = 0.224423, train accuracy = 0.960938\n",
      "[2018-07-17 22:31:43.318230] Iteration 56800, train loss = 0.154229, train accuracy = 0.992188\n",
      "[2018-07-17 22:31:49.822318] Iteration 56900, train loss = 0.289295, train accuracy = 0.953125\n",
      "[2018-07-17 22:31:56.322877] Iteration 57000, train loss = 0.144019, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:32:05.093431] Iteration 57100, train loss = 0.234667, train accuracy = 0.976562\n",
      "[2018-07-17 22:32:11.592505] Iteration 57200, train loss = 0.140551, train accuracy = 1.000000\n",
      "[2018-07-17 22:32:18.106873] Iteration 57300, train loss = 0.170098, train accuracy = 0.992188\n",
      "[2018-07-17 22:32:24.619852] Iteration 57400, train loss = 0.165624, train accuracy = 0.976562\n",
      "[2018-07-17 22:32:31.122518] Iteration 57500, train loss = 0.204814, train accuracy = 0.968750\n",
      "[2018-07-17 22:32:37.629059] Iteration 57600, train loss = 0.139319, train accuracy = 1.000000\n",
      "[2018-07-17 22:32:44.136644] Iteration 57700, train loss = 0.166297, train accuracy = 0.992188\n",
      "[2018-07-17 22:32:50.674224] Iteration 57800, train loss = 0.167105, train accuracy = 0.992188\n",
      "[2018-07-17 22:32:57.186274] Iteration 57900, train loss = 0.148400, train accuracy = 0.984375\n",
      "[2018-07-17 22:33:03.692087] Iteration 58000, train loss = 0.142462, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911800\n",
      "[2018-07-17 22:33:12.452323] Iteration 58100, train loss = 0.144362, train accuracy = 1.000000\n",
      "[2018-07-17 22:33:18.942296] Iteration 58200, train loss = 0.148629, train accuracy = 0.992188\n",
      "[2018-07-17 22:33:25.425850] Iteration 58300, train loss = 0.178144, train accuracy = 0.984375\n",
      "[2018-07-17 22:33:31.923929] Iteration 58400, train loss = 0.190986, train accuracy = 0.976562\n",
      "[2018-07-17 22:33:38.425994] Iteration 58500, train loss = 0.194964, train accuracy = 0.968750\n",
      "[2018-07-17 22:33:44.923181] Iteration 58600, train loss = 0.185482, train accuracy = 0.968750\n",
      "[2018-07-17 22:33:51.423518] Iteration 58700, train loss = 0.180158, train accuracy = 0.984375\n",
      "[2018-07-17 22:33:57.949177] Iteration 58800, train loss = 0.163968, train accuracy = 0.976562\n",
      "[2018-07-17 22:34:04.463661] Iteration 58900, train loss = 0.192964, train accuracy = 0.992188\n",
      "[2018-07-17 22:34:10.955038] Iteration 59000, train loss = 0.152888, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:34:19.707116] Iteration 59100, train loss = 0.181622, train accuracy = 0.976562\n",
      "[2018-07-17 22:34:26.209695] Iteration 59200, train loss = 0.200675, train accuracy = 0.976562\n",
      "[2018-07-17 22:34:32.711074] Iteration 59300, train loss = 0.172183, train accuracy = 0.976562\n",
      "[2018-07-17 22:34:39.203379] Iteration 59400, train loss = 0.153249, train accuracy = 1.000000\n",
      "[2018-07-17 22:34:45.689519] Iteration 59500, train loss = 0.193992, train accuracy = 0.976562\n",
      "[2018-07-17 22:34:52.207855] Iteration 59600, train loss = 0.184832, train accuracy = 0.968750\n",
      "[2018-07-17 22:34:58.710507] Iteration 59700, train loss = 0.188592, train accuracy = 0.984375\n",
      "[2018-07-17 22:35:05.223319] Iteration 59800, train loss = 0.163886, train accuracy = 0.984375\n",
      "[2018-07-17 22:35:11.741499] Iteration 59900, train loss = 0.205736, train accuracy = 0.968750\n",
      "[2018-07-17 22:35:18.249457] Iteration 60000, train loss = 0.168095, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911400\n",
      "[2018-07-17 22:35:27.002527] Iteration 60100, train loss = 0.168938, train accuracy = 0.984375\n",
      "[2018-07-17 22:35:33.499828] Iteration 60200, train loss = 0.176517, train accuracy = 0.976562\n",
      "[2018-07-17 22:35:39.999452] Iteration 60300, train loss = 0.130337, train accuracy = 1.000000\n",
      "[2018-07-17 22:35:46.495324] Iteration 60400, train loss = 0.161836, train accuracy = 0.992188\n",
      "[2018-07-17 22:35:52.992415] Iteration 60500, train loss = 0.160194, train accuracy = 0.992188\n",
      "[2018-07-17 22:35:59.484195] Iteration 60600, train loss = 0.154186, train accuracy = 0.992188\n",
      "[2018-07-17 22:36:05.988928] Iteration 60700, train loss = 0.182390, train accuracy = 0.984375\n",
      "[2018-07-17 22:36:12.491749] Iteration 60800, train loss = 0.178829, train accuracy = 0.976562\n",
      "[2018-07-17 22:36:18.991625] Iteration 60900, train loss = 0.214857, train accuracy = 0.968750\n",
      "[2018-07-17 22:36:25.532813] Iteration 61000, train loss = 0.150835, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.912200\n",
      "[2018-07-17 22:36:34.297305] Iteration 61100, train loss = 0.148529, train accuracy = 1.000000\n",
      "[2018-07-17 22:36:40.790270] Iteration 61200, train loss = 0.185762, train accuracy = 0.984375\n",
      "[2018-07-17 22:36:47.283425] Iteration 61300, train loss = 0.178386, train accuracy = 0.968750\n",
      "[2018-07-17 22:36:53.782751] Iteration 61400, train loss = 0.184757, train accuracy = 0.968750\n",
      "[2018-07-17 22:37:00.275624] Iteration 61500, train loss = 0.165347, train accuracy = 0.984375\n",
      "[2018-07-17 22:37:06.770277] Iteration 61600, train loss = 0.135126, train accuracy = 1.000000\n",
      "[2018-07-17 22:37:13.263008] Iteration 61700, train loss = 0.141794, train accuracy = 0.992188\n",
      "[2018-07-17 22:37:19.766991] Iteration 61800, train loss = 0.196063, train accuracy = 0.960938\n",
      "[2018-07-17 22:37:26.261891] Iteration 61900, train loss = 0.246875, train accuracy = 0.960938\n",
      "[2018-07-17 22:37:32.758094] Iteration 62000, train loss = 0.179969, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.912200\n",
      "[2018-07-17 22:37:41.528175] Iteration 62100, train loss = 0.206522, train accuracy = 0.976562\n",
      "[2018-07-17 22:37:48.038998] Iteration 62200, train loss = 0.186945, train accuracy = 0.976562\n",
      "[2018-07-17 22:37:54.539454] Iteration 62300, train loss = 0.231962, train accuracy = 0.968750\n",
      "[2018-07-17 22:38:01.031750] Iteration 62400, train loss = 0.181553, train accuracy = 0.984375\n",
      "[2018-07-17 22:38:07.526015] Iteration 62500, train loss = 0.196475, train accuracy = 0.984375\n",
      "[2018-07-17 22:38:14.030894] Iteration 62600, train loss = 0.209865, train accuracy = 0.968750\n",
      "[2018-07-17 22:38:20.561924] Iteration 62700, train loss = 0.171094, train accuracy = 0.984375\n",
      "[2018-07-17 22:38:27.067599] Iteration 62800, train loss = 0.240267, train accuracy = 0.960938\n",
      "[2018-07-17 22:38:33.564095] Iteration 62900, train loss = 0.160927, train accuracy = 0.992188\n",
      "[2018-07-17 22:38:40.064274] Iteration 63000, train loss = 0.220638, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-17 22:38:48.825876] Iteration 63100, train loss = 0.181714, train accuracy = 0.976562\n",
      "[2018-07-17 22:38:55.339173] Iteration 63200, train loss = 0.188509, train accuracy = 0.984375\n",
      "[2018-07-17 22:39:01.841301] Iteration 63300, train loss = 0.191224, train accuracy = 0.976562\n",
      "[2018-07-17 22:39:08.344407] Iteration 63400, train loss = 0.148181, train accuracy = 1.000000\n",
      "[2018-07-17 22:39:14.856627] Iteration 63500, train loss = 0.136439, train accuracy = 1.000000\n",
      "[2018-07-17 22:39:21.351486] Iteration 63600, train loss = 0.167519, train accuracy = 0.992188\n",
      "[2018-07-17 22:39:27.853673] Iteration 63700, train loss = 0.188827, train accuracy = 0.976562\n",
      "[2018-07-17 22:39:34.354860] Iteration 63800, train loss = 0.184318, train accuracy = 0.984375\n",
      "[2018-07-17 22:39:40.846755] Iteration 63900, train loss = 0.169000, train accuracy = 0.984375\n",
      "[2018-07-17 22:39:47.349003] Iteration 64000, train loss = 0.160482, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911200\n",
      "[2018-07-17 22:39:56.118412] Iteration 64100, train loss = 0.161507, train accuracy = 0.976562\n",
      "[2018-07-17 22:40:02.634908] Iteration 64200, train loss = 0.179283, train accuracy = 0.976562\n",
      "[2018-07-17 22:40:09.140210] Iteration 64300, train loss = 0.142883, train accuracy = 0.992188\n",
      "[2018-07-17 22:40:15.639715] Iteration 64400, train loss = 0.151342, train accuracy = 0.984375\n",
      "[2018-07-17 22:40:22.155026] Iteration 64500, train loss = 0.174417, train accuracy = 0.976562\n",
      "[2018-07-17 22:40:28.660945] Iteration 64600, train loss = 0.178911, train accuracy = 0.984375\n",
      "[2018-07-17 22:40:35.158515] Iteration 64700, train loss = 0.173336, train accuracy = 0.984375\n",
      "[2018-07-17 22:40:41.644421] Iteration 64800, train loss = 0.140878, train accuracy = 1.000000\n",
      "[2018-07-17 22:40:48.136663] Iteration 64900, train loss = 0.154513, train accuracy = 0.984375\n",
      "[2018-07-17 22:40:54.630830] Iteration 65000, train loss = 0.186704, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 22:41:03.402709] Iteration 65100, train loss = 0.170264, train accuracy = 0.976562\n",
      "[2018-07-17 22:41:09.919532] Iteration 65200, train loss = 0.164338, train accuracy = 0.992188\n",
      "[2018-07-17 22:41:16.435889] Iteration 65300, train loss = 0.182314, train accuracy = 0.984375\n",
      "[2018-07-17 22:41:22.947717] Iteration 65400, train loss = 0.166918, train accuracy = 0.984375\n",
      "[2018-07-17 22:41:29.453595] Iteration 65500, train loss = 0.197394, train accuracy = 0.984375\n",
      "[2018-07-17 22:41:35.950320] Iteration 65600, train loss = 0.178109, train accuracy = 0.976562\n",
      "[2018-07-17 22:41:42.455665] Iteration 65700, train loss = 0.228311, train accuracy = 0.960938\n",
      "[2018-07-17 22:41:48.946111] Iteration 65800, train loss = 0.137174, train accuracy = 1.000000\n",
      "[2018-07-17 22:41:55.453225] Iteration 65900, train loss = 0.141312, train accuracy = 1.000000\n",
      "[2018-07-17 22:42:01.957595] Iteration 66000, train loss = 0.258978, train accuracy = 0.945312\n",
      "Evaluating...\n",
      "Test accuracy = 0.911900\n",
      "[2018-07-17 22:42:10.715315] Iteration 66100, train loss = 0.161325, train accuracy = 0.992188\n",
      "[2018-07-17 22:42:17.212163] Iteration 66200, train loss = 0.159681, train accuracy = 0.984375\n",
      "[2018-07-17 22:42:23.713389] Iteration 66300, train loss = 0.151891, train accuracy = 1.000000\n",
      "[2018-07-17 22:42:30.230109] Iteration 66400, train loss = 0.140110, train accuracy = 1.000000\n",
      "[2018-07-17 22:42:36.765922] Iteration 66500, train loss = 0.211379, train accuracy = 0.960938\n",
      "[2018-07-17 22:42:43.266138] Iteration 66600, train loss = 0.197879, train accuracy = 0.984375\n",
      "[2018-07-17 22:42:49.749826] Iteration 66700, train loss = 0.265697, train accuracy = 0.953125\n",
      "[2018-07-17 22:42:56.240572] Iteration 66800, train loss = 0.152571, train accuracy = 0.984375\n",
      "[2018-07-17 22:43:02.742918] Iteration 66900, train loss = 0.162344, train accuracy = 0.984375\n",
      "[2018-07-17 22:43:09.246541] Iteration 67000, train loss = 0.183340, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:43:17.979685] Iteration 67100, train loss = 0.178929, train accuracy = 0.984375\n",
      "[2018-07-17 22:43:24.485553] Iteration 67200, train loss = 0.208106, train accuracy = 0.976562\n",
      "[2018-07-17 22:43:30.986323] Iteration 67300, train loss = 0.142594, train accuracy = 0.992188\n",
      "[2018-07-17 22:43:37.478396] Iteration 67400, train loss = 0.216663, train accuracy = 0.976562\n",
      "[2018-07-17 22:43:43.994827] Iteration 67500, train loss = 0.142952, train accuracy = 1.000000\n",
      "[2018-07-17 22:43:50.503747] Iteration 67600, train loss = 0.204555, train accuracy = 0.984375\n",
      "[2018-07-17 22:43:57.005606] Iteration 67700, train loss = 0.186478, train accuracy = 0.968750\n",
      "[2018-07-17 22:44:03.507690] Iteration 67800, train loss = 0.155845, train accuracy = 0.992188\n",
      "[2018-07-17 22:44:10.003845] Iteration 67900, train loss = 0.153647, train accuracy = 0.984375\n",
      "[2018-07-17 22:44:16.505288] Iteration 68000, train loss = 0.161058, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911400\n",
      "[2018-07-17 22:44:25.259635] Iteration 68100, train loss = 0.187632, train accuracy = 0.953125\n",
      "[2018-07-17 22:44:31.764628] Iteration 68200, train loss = 0.161014, train accuracy = 0.992188\n",
      "[2018-07-17 22:44:38.255501] Iteration 68300, train loss = 0.152895, train accuracy = 0.992188\n",
      "[2018-07-17 22:44:44.756125] Iteration 68400, train loss = 0.171926, train accuracy = 0.976562\n",
      "[2018-07-17 22:44:51.254502] Iteration 68500, train loss = 0.159169, train accuracy = 0.992188\n",
      "[2018-07-17 22:44:57.785232] Iteration 68600, train loss = 0.174941, train accuracy = 0.976562\n",
      "[2018-07-17 22:45:04.306022] Iteration 68700, train loss = 0.223224, train accuracy = 0.968750\n",
      "[2018-07-17 22:45:10.811035] Iteration 68800, train loss = 0.204986, train accuracy = 0.984375\n",
      "[2018-07-17 22:45:17.316374] Iteration 68900, train loss = 0.166467, train accuracy = 0.984375\n",
      "[2018-07-17 22:45:23.821248] Iteration 69000, train loss = 0.180879, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:45:32.556202] Iteration 69100, train loss = 0.184130, train accuracy = 0.984375\n",
      "[2018-07-17 22:45:39.040567] Iteration 69200, train loss = 0.209903, train accuracy = 0.960938\n",
      "[2018-07-17 22:45:45.530508] Iteration 69300, train loss = 0.152006, train accuracy = 0.992188\n",
      "[2018-07-17 22:45:52.017771] Iteration 69400, train loss = 0.167873, train accuracy = 0.984375\n",
      "[2018-07-17 22:45:58.511230] Iteration 69500, train loss = 0.179981, train accuracy = 0.992188\n",
      "[2018-07-17 22:46:05.022262] Iteration 69600, train loss = 0.171674, train accuracy = 0.984375\n",
      "[2018-07-17 22:46:11.521573] Iteration 69700, train loss = 0.156848, train accuracy = 0.992188\n",
      "[2018-07-17 22:46:18.034765] Iteration 69800, train loss = 0.156503, train accuracy = 0.984375\n",
      "[2018-07-17 22:46:24.531001] Iteration 69900, train loss = 0.172654, train accuracy = 0.984375\n",
      "[2018-07-17 22:46:31.027798] Iteration 70000, train loss = 0.245731, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.911800\n",
      "[2018-07-17 22:46:39.790136] Iteration 70100, train loss = 0.213747, train accuracy = 0.968750\n",
      "[2018-07-17 22:46:46.298364] Iteration 70200, train loss = 0.186721, train accuracy = 0.984375\n",
      "[2018-07-17 22:46:52.801364] Iteration 70300, train loss = 0.187710, train accuracy = 0.976562\n",
      "[2018-07-17 22:46:59.309460] Iteration 70400, train loss = 0.187138, train accuracy = 0.984375\n",
      "[2018-07-17 22:47:05.802645] Iteration 70500, train loss = 0.196287, train accuracy = 0.984375\n",
      "[2018-07-17 22:47:12.320688] Iteration 70600, train loss = 0.208280, train accuracy = 0.976562\n",
      "[2018-07-17 22:47:18.825825] Iteration 70700, train loss = 0.140858, train accuracy = 1.000000\n",
      "[2018-07-17 22:47:25.313552] Iteration 70800, train loss = 0.170313, train accuracy = 0.976562\n",
      "[2018-07-17 22:47:31.816259] Iteration 70900, train loss = 0.155025, train accuracy = 0.992188\n",
      "[2018-07-17 22:47:38.323777] Iteration 71000, train loss = 0.151984, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:47:47.072668] Iteration 71100, train loss = 0.183512, train accuracy = 0.968750\n",
      "[2018-07-17 22:47:53.564768] Iteration 71200, train loss = 0.186007, train accuracy = 0.968750\n",
      "[2018-07-17 22:48:00.053176] Iteration 71300, train loss = 0.158860, train accuracy = 0.992188\n",
      "[2018-07-17 22:48:06.568348] Iteration 71400, train loss = 0.167698, train accuracy = 0.992188\n",
      "[2018-07-17 22:48:13.048910] Iteration 71500, train loss = 0.152168, train accuracy = 0.992188\n",
      "[2018-07-17 22:48:19.546681] Iteration 71600, train loss = 0.168403, train accuracy = 0.984375\n",
      "[2018-07-17 22:48:26.053235] Iteration 71700, train loss = 0.182408, train accuracy = 0.984375\n",
      "[2018-07-17 22:48:32.559361] Iteration 71800, train loss = 0.146537, train accuracy = 0.992188\n",
      "[2018-07-17 22:48:39.097749] Iteration 71900, train loss = 0.199936, train accuracy = 0.968750\n",
      "[2018-07-17 22:48:45.596407] Iteration 72000, train loss = 0.156972, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911500\n",
      "[2018-07-17 22:48:54.380455] Iteration 72100, train loss = 0.194800, train accuracy = 0.984375\n",
      "[2018-07-17 22:49:00.879880] Iteration 72200, train loss = 0.211756, train accuracy = 0.976562\n",
      "[2018-07-17 22:49:07.379375] Iteration 72300, train loss = 0.154249, train accuracy = 0.992188\n",
      "[2018-07-17 22:49:13.879906] Iteration 72400, train loss = 0.180169, train accuracy = 0.984375\n",
      "[2018-07-17 22:49:20.392421] Iteration 72500, train loss = 0.174492, train accuracy = 0.984375\n",
      "[2018-07-17 22:49:26.889568] Iteration 72600, train loss = 0.185217, train accuracy = 0.992188\n",
      "[2018-07-17 22:49:33.392535] Iteration 72700, train loss = 0.156676, train accuracy = 0.984375\n",
      "[2018-07-17 22:49:39.894181] Iteration 72800, train loss = 0.155047, train accuracy = 0.992188\n",
      "[2018-07-17 22:49:46.389157] Iteration 72900, train loss = 0.188685, train accuracy = 0.976562\n",
      "[2018-07-17 22:49:52.896286] Iteration 73000, train loss = 0.140114, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911600\n",
      "[2018-07-17 22:50:01.665087] Iteration 73100, train loss = 0.163872, train accuracy = 0.992188\n",
      "[2018-07-17 22:50:08.165258] Iteration 73200, train loss = 0.145555, train accuracy = 0.992188\n",
      "[2018-07-17 22:50:14.663631] Iteration 73300, train loss = 0.151227, train accuracy = 0.992188\n",
      "[2018-07-17 22:50:21.160023] Iteration 73400, train loss = 0.172112, train accuracy = 0.976562\n",
      "[2018-07-17 22:50:27.664695] Iteration 73500, train loss = 0.182645, train accuracy = 0.976562\n",
      "[2018-07-17 22:50:34.162055] Iteration 73600, train loss = 0.215131, train accuracy = 0.984375\n",
      "[2018-07-17 22:50:40.662551] Iteration 73700, train loss = 0.220208, train accuracy = 0.960938\n",
      "[2018-07-17 22:50:47.165511] Iteration 73800, train loss = 0.147969, train accuracy = 0.992188\n",
      "[2018-07-17 22:50:53.684605] Iteration 73900, train loss = 0.173717, train accuracy = 0.984375\n",
      "[2018-07-17 22:51:00.214693] Iteration 74000, train loss = 0.167364, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911400\n",
      "[2018-07-17 22:51:08.975167] Iteration 74100, train loss = 0.147275, train accuracy = 0.992188\n",
      "[2018-07-17 22:51:15.465741] Iteration 74200, train loss = 0.159234, train accuracy = 0.984375\n",
      "[2018-07-17 22:51:21.964236] Iteration 74300, train loss = 0.167670, train accuracy = 0.984375\n",
      "[2018-07-17 22:51:28.478173] Iteration 74400, train loss = 0.153011, train accuracy = 0.992188\n",
      "[2018-07-17 22:51:34.983189] Iteration 74500, train loss = 0.151098, train accuracy = 0.992188\n",
      "[2018-07-17 22:51:41.485903] Iteration 74600, train loss = 0.151595, train accuracy = 0.992188\n",
      "[2018-07-17 22:51:47.991640] Iteration 74700, train loss = 0.172112, train accuracy = 0.976562\n",
      "[2018-07-17 22:51:54.481837] Iteration 74800, train loss = 0.158635, train accuracy = 0.984375\n",
      "[2018-07-17 22:52:00.987071] Iteration 74900, train loss = 0.132826, train accuracy = 1.000000\n",
      "[2018-07-17 22:52:07.488626] Iteration 75000, train loss = 0.146693, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911300\n",
      "[2018-07-17 22:52:16.250522] Iteration 75100, train loss = 0.187409, train accuracy = 0.984375\n",
      "[2018-07-17 22:52:22.752446] Iteration 75200, train loss = 0.190038, train accuracy = 0.984375\n",
      "[2018-07-17 22:52:29.247943] Iteration 75300, train loss = 0.204338, train accuracy = 0.968750\n",
      "[2018-07-17 22:52:35.767496] Iteration 75400, train loss = 0.174250, train accuracy = 0.984375\n",
      "[2018-07-17 22:52:42.270907] Iteration 75500, train loss = 0.149713, train accuracy = 0.992188\n",
      "[2018-07-17 22:52:48.768382] Iteration 75600, train loss = 0.159526, train accuracy = 0.992188\n",
      "[2018-07-17 22:52:55.265095] Iteration 75700, train loss = 0.180948, train accuracy = 0.976562\n",
      "[2018-07-17 22:53:01.767725] Iteration 75800, train loss = 0.158332, train accuracy = 0.992188\n",
      "[2018-07-17 22:53:08.261484] Iteration 75900, train loss = 0.173184, train accuracy = 0.984375\n",
      "[2018-07-17 22:53:14.744145] Iteration 76000, train loss = 0.170543, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911300\n",
      "[2018-07-17 22:53:23.498798] Iteration 76100, train loss = 0.172675, train accuracy = 0.984375\n",
      "[2018-07-17 22:53:29.992589] Iteration 76200, train loss = 0.195825, train accuracy = 0.976562\n",
      "[2018-07-17 22:53:36.483917] Iteration 76300, train loss = 0.188239, train accuracy = 0.953125\n",
      "[2018-07-17 22:53:42.982664] Iteration 76400, train loss = 0.220187, train accuracy = 0.976562\n",
      "[2018-07-17 22:53:49.484343] Iteration 76500, train loss = 0.248771, train accuracy = 0.960938\n",
      "[2018-07-17 22:53:55.979225] Iteration 76600, train loss = 0.175885, train accuracy = 0.976562\n",
      "[2018-07-17 22:54:02.469864] Iteration 76700, train loss = 0.163147, train accuracy = 0.984375\n",
      "[2018-07-17 22:54:08.962808] Iteration 76800, train loss = 0.202193, train accuracy = 0.968750\n",
      "[2018-07-17 22:54:15.453895] Iteration 76900, train loss = 0.251940, train accuracy = 0.960938\n",
      "[2018-07-17 22:54:21.949019] Iteration 77000, train loss = 0.146407, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.911700\n",
      "[2018-07-17 22:54:30.702925] Iteration 77100, train loss = 0.158025, train accuracy = 0.992188\n",
      "[2018-07-17 22:54:37.218971] Iteration 77200, train loss = 0.164199, train accuracy = 0.984375\n",
      "[2018-07-17 22:54:43.725071] Iteration 77300, train loss = 0.182586, train accuracy = 0.976562\n",
      "[2018-07-17 22:54:50.227775] Iteration 77400, train loss = 0.174279, train accuracy = 0.984375\n",
      "[2018-07-17 22:54:56.712853] Iteration 77500, train loss = 0.155895, train accuracy = 0.984375\n",
      "[2018-07-17 22:55:03.189543] Iteration 77600, train loss = 0.165221, train accuracy = 0.992188\n",
      "[2018-07-17 22:55:09.680813] Iteration 77700, train loss = 0.179673, train accuracy = 0.984375\n",
      "[2018-07-17 22:55:16.177633] Iteration 77800, train loss = 0.197408, train accuracy = 0.984375\n",
      "[2018-07-17 22:55:22.671879] Iteration 77900, train loss = 0.195274, train accuracy = 0.976562\n",
      "[2018-07-17 22:55:29.163970] Iteration 78000, train loss = 0.240641, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.912100\n",
      "[2018-07-17 22:55:37.907396] Iteration 78100, train loss = 0.254254, train accuracy = 0.953125\n",
      "[2018-07-17 22:55:44.419474] Iteration 78200, train loss = 0.140367, train accuracy = 0.992188\n",
      "[2018-07-17 22:55:50.943591] Iteration 78300, train loss = 0.192454, train accuracy = 0.976562\n",
      "[2018-07-17 22:55:57.444602] Iteration 78400, train loss = 0.167157, train accuracy = 0.976562\n",
      "[2018-07-17 22:56:03.941075] Iteration 78500, train loss = 0.184340, train accuracy = 0.968750\n",
      "[2018-07-17 22:56:10.451303] Iteration 78600, train loss = 0.218022, train accuracy = 0.984375\n",
      "[2018-07-17 22:56:16.950132] Iteration 78700, train loss = 0.162306, train accuracy = 0.984375\n",
      "[2018-07-17 22:56:23.458487] Iteration 78800, train loss = 0.220448, train accuracy = 0.960938\n",
      "[2018-07-17 22:56:29.967127] Iteration 78900, train loss = 0.185482, train accuracy = 0.984375\n",
      "[2018-07-17 22:56:36.463854] Iteration 79000, train loss = 0.181211, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911400\n",
      "[2018-07-17 22:56:45.216770] Iteration 79100, train loss = 0.176988, train accuracy = 0.984375\n",
      "[2018-07-17 22:56:51.702612] Iteration 79200, train loss = 0.152894, train accuracy = 0.992188\n",
      "[2018-07-17 22:56:58.216969] Iteration 79300, train loss = 0.137338, train accuracy = 0.992188\n",
      "[2018-07-17 22:57:04.753913] Iteration 79400, train loss = 0.163019, train accuracy = 0.984375\n",
      "[2018-07-17 22:57:11.245739] Iteration 79500, train loss = 0.142023, train accuracy = 1.000000\n",
      "[2018-07-17 22:57:17.733590] Iteration 79600, train loss = 0.236574, train accuracy = 0.968750\n",
      "[2018-07-17 22:57:24.260262] Iteration 79700, train loss = 0.217435, train accuracy = 0.953125\n",
      "[2018-07-17 22:57:30.767286] Iteration 79800, train loss = 0.149667, train accuracy = 0.992188\n",
      "[2018-07-17 22:57:37.268555] Iteration 79900, train loss = 0.229298, train accuracy = 0.968750\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune后的准确率\n",
      "Test accuracy = 0.911500\n"
     ]
    }
   ],
   "source": [
    "print('prune后的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625  -0.0625   0.03125  0.125   -0.0625  -0.0625   0.       0.03125\n",
      "  0.0625  -0.0625 ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
