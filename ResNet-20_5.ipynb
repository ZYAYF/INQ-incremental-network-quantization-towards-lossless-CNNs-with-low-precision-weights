{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "# import ipdb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('residual_net_n', 3, '')\n",
    "tf.app.flags.DEFINE_string('train_tf_path', 'E:/dynamicquantization/data/train.tf', '')\n",
    "tf.app.flags.DEFINE_string('val_tf_path', 'E:/dynamicquantization/data/test.tf', '')\n",
    "tf.app.flags.DEFINE_integer('train_batch_size', 128, '')\n",
    "tf.app.flags.DEFINE_integer('val_batch_size', 100, '')\n",
    "tf.app.flags.DEFINE_float('weight_decay', 0.0005, 'Weight decay')\n",
    "tf.app.flags.DEFINE_integer('summary_interval', 100, 'Interval for summary.')\n",
    "tf.app.flags.DEFINE_integer('val_interval', 1000, 'Interval for evaluation.')\n",
    "tf.app.flags.DEFINE_integer('max_steps', 80000, 'Maximum number of iterations.')\n",
    "tf.app.flags.DEFINE_integer('save_interval', 5000, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_embedding(label, n_classes):\n",
    "  \"\"\"\n",
    "  One-hot embedding\n",
    "  Args:\n",
    "    label: int32 tensor [B]\n",
    "    n_classes: int32, number of classes\n",
    "  Return:\n",
    "    embedding: tensor [B x n_classes]\n",
    "  \"\"\"\n",
    "  embedding_params = np.eye(n_classes, dtype=np.float32)\n",
    "  with tf.device('/cpu:0'):\n",
    "    params = tf.constant(embedding_params)\n",
    "    embedding = tf.gather(params, label)\n",
    "  return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, n_in, n_out, k, s, p='SAME', bias=False, scope='conv'):\n",
    "  with tf.variable_scope(scope):\n",
    "    kernel = tf.Variable(\n",
    "      tf.truncated_normal([k, k, n_in, n_out],\n",
    "        stddev=math.sqrt(2/(k*k*n_in))),\n",
    "      name='weight')\n",
    "    tf.add_to_collection('weights', kernel)\n",
    "    conv = tf.nn.conv2d(x, kernel, [1,s,s,1], padding=p)\n",
    "    if bias:\n",
    "      bias = tf.get_variable('bias', [n_out], initializer=tf.constant_initializer(0.0))\n",
    "      tf.add_to_collection('biases', bias)\n",
    "      conv = tf.nn.bias_add(conv, bias)\n",
    "  return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, scope='bn', affine=True):\n",
    "  \"\"\"\n",
    "  Batch normalization on convolutional maps.\n",
    "  Args:\n",
    "    x: Tensor, 4D BHWD input maps\n",
    "    n_out: integer, depth of input maps\n",
    "    phase_train: boolean tf.Variable, true indicates training phase\n",
    "    scope: string, variable scope\n",
    "    affine: whether to affine-transform outputs\n",
    "  Return:\n",
    "    normed: batch-normalized maps\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope):\n",
    "    beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "      name='beta', trainable=True)\n",
    "    gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "      name='gamma', trainable=affine)\n",
    "    tf.add_to_collection('biases', beta)\n",
    "    tf.add_to_collection('weights', gamma)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "\n",
    "    def mean_var_with_update():\n",
    "      ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "      with tf.control_dependencies([ema_apply_op]):\n",
    "        return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "      mean_var_with_update,\n",
    "      lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var, \n",
    "      beta, gamma, 1e-3, affine)\n",
    "  return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, n_in, n_out, subsample, phase_train, scope='res_block'):\n",
    "  with tf.variable_scope(scope):\n",
    "    if subsample:\n",
    "      y = conv2d(x, n_in, n_out, 3, 2, 'SAME', False, scope='conv_1')\n",
    "      shortcut = conv2d(x, n_in, n_out, 3, 2, 'SAME',\n",
    "                False, scope='shortcut')\n",
    "    else:\n",
    "      y = conv2d(x, n_in, n_out, 3, 1, 'SAME', False, scope='conv_1')\n",
    "      shortcut = tf.identity(x, name='shortcut')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_1')\n",
    "    y = tf.nn.relu(y, name='relu_1')\n",
    "    y = conv2d(y, n_out, n_out, 3, 1, 'SAME', True, scope='conv_2')\n",
    "    y = batch_norm(y, n_out, phase_train, scope='bn_2')\n",
    "    y = y + shortcut\n",
    "    y = tf.nn.relu(y, name='relu_2')\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_group(x, n_in, n_out, n, first_subsample, phase_train, scope='res_group'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = residual_block(x, n_in, n_out, first_subsample, phase_train, scope='block_1')\n",
    "    for i in range(n - 1):\n",
    "      y = residual_block(y, n_out, n_out, False, phase_train, scope='block_%d' % (i + 2))\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_net(x, n, n_classes, phase_train, scope='res_net'):\n",
    "  with tf.variable_scope(scope):\n",
    "    y = conv2d(x, 3, 16, 3, 1, 'SAME', False, scope='conv_init')\n",
    "    y = batch_norm(y, 16, phase_train, scope='bn_init')\n",
    "    y = tf.nn.relu(y, name='relu_init')\n",
    "    y = residual_group(y, 16, 16, n, False, phase_train, scope='group_1')\n",
    "    y = residual_group(y, 16, 32, n, True, phase_train, scope='group_2')\n",
    "    y = residual_group(y, 32, 64, n, True, phase_train, scope='group_3')\n",
    "#     y = conv2d(y, 64, n_classes, 1, 1, 'SAME', True, scope='conv_last')\n",
    "    y = tf.nn.avg_pool(y, [1, 8, 8, 1], [1, 1, 1, 1], 'VALID', name='avg_pool')\n",
    "    y = tf.reshape(y, [-1, 64])\n",
    "    w = tf.get_variable(name='weight_fc', shape=[64, n_classes], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    tf.add_to_collection('weights', w)\n",
    "    b = tf.get_variable(name='weight_biase', shape=[n_classes], initializer=tf.constant_initializer(0))\n",
    "    tf.add_to_collection('last_biases', b)\n",
    "    y = tf.matmul(y, w) + b\n",
    "#     y = tf.squeeze(y, squeeze_dims=[1, 2])\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _loss(logits, labels, scope='loss'):\n",
    "  with tf.variable_scope(scope):\n",
    "    # entropy loss\n",
    "    targets = one_hot_embedding(labels, 10)\n",
    "    entropy_loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),\n",
    "      name='entropy_loss')\n",
    "    tf.add_to_collection('losses', entropy_loss)\n",
    "    # weight l2 decay loss\n",
    "    weight_l2_losses = [tf.nn.l2_loss(o) for o in tf.get_collection('weights')]\n",
    "    weight_decay_loss = FLAGS.weight_decay*tf.add_n(weight_l2_losses)\n",
    "    tf.add_to_collection('losses', weight_decay_loss)\n",
    "  # for var in tf.get_collection('losses'):\n",
    "    # tf.scalar_summary('losses/' + var.op.name, var)\n",
    "  # total loss\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _accuracy(logits, gt_label, scope='accuracy'):\n",
    "  with tf.variable_scope(scope):\n",
    "    pred_label = tf.argmax(logits, 1)\n",
    "    acc = 1.0 - tf.nn.zero_fraction(\n",
    "      tf.cast(tf.equal(pred_label, gt_label), tf.int32))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_op(loss, global_step, learning_rate):\n",
    "  params = tf.trainable_variables()\n",
    "  gradients = tf.gradients(loss, params, name='gradients')\n",
    "  optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "  update = optim.apply_gradients(zip(gradients, params))\n",
    "  with tf.control_dependencies([update]):\n",
    "    train_op = tf.no_op(name='train_op')\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar10_input_stream(records_path):\n",
    "  reader = tf.TFRecordReader()\n",
    "  filename_queue = tf.train.string_input_producer([records_path], None)\n",
    "  _, record_value = reader.read(filename_queue)\n",
    "  features = tf.parse_single_example(record_value,\n",
    "    {\n",
    "      'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "  image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "  image = tf.reshape(image, [32,32,3])\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  label = tf.cast(features['label'], tf.int64)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "  # meanstd = joblib.load(FLAGS.mean_std_path)\n",
    "  # mean, std = meanstd['mean'], meanstd['std']\n",
    "  mean = [ 125.30690002,122.95014954,113.86599731]\n",
    "  std = [ 62.9932518,62.08860397,66.70500946]\n",
    "  normed_image = (image - mean) / std\n",
    "  return normed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_distort_image(image):\n",
    "  distorted_image = image\n",
    "  distorted_image = tf.image.pad_to_bounding_box(\n",
    "    image, 4, 4, 40, 40)  # pad 4 pixels to each side\n",
    "  distorted_image = tf.random_crop(distorted_image, [32, 32, 3])\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "  return distorted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_batch(train_records_path, batch_size):\n",
    "  with tf.variable_scope('train_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      train_image, train_label = cifar10_input_stream(train_records_path)\n",
    "      train_image = normalize_image(train_image)\n",
    "      train_image = random_distort_image(train_image)\n",
    "      train_image_batch, train_label_batch = tf.train.shuffle_batch(\n",
    "        [train_image, train_label], batch_size=batch_size, num_threads=4,\n",
    "        capacity=50000,\n",
    "        min_after_dequeue=1000)\n",
    "  return train_image_batch, train_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_validation_batch(test_records_path, batch_size):\n",
    "  with tf.variable_scope('evaluate_batch'):\n",
    "    with tf.device('/cpu:0'):\n",
    "      test_image, test_label = cifar10_input_stream(test_records_path)\n",
    "      test_image = normalize_image(test_image)\n",
    "      test_image_batch, test_label_batch = tf.train.batch(\n",
    "        [test_image, test_label], batch_size=batch_size, num_threads=1,\n",
    "        capacity=10000)\n",
    "  return test_image_batch, test_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "train_image_batch, train_label_batch = make_train_batch(FLAGS.train_tf_path, FLAGS.train_batch_size)\n",
    "val_image_batch, val_label_batch = make_validation_batch(FLAGS.val_tf_path, FLAGS.val_batch_size)\n",
    "\n",
    "image_batch, label_batch = control_flow_ops.cond(phase_train,lambda: (train_image_batch, train_label_batch),lambda: (val_image_batch, val_label_batch))\n",
    "\n",
    "\n",
    "logits = residual_net(image_batch, FLAGS.residual_net_n, 10, phase_train)\n",
    "\n",
    "\n",
    "loss = _loss(logits, label_batch)\n",
    "accuracy = _accuracy(logits, label_batch)\n",
    "\n",
    "# train one step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "INFO:tensorflow:Restoring parameters from E:/dynamicquantization/full_precision/res20/model/res.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-6, started daemon 1112)>,\n",
       " <Thread(Thread-7, started daemon 1444)>,\n",
       " <Thread(Thread-8, started daemon 2600)>,\n",
       " <Thread(Thread-9, started daemon 7804)>,\n",
       " <Thread(Thread-10, started daemon 6572)>,\n",
       " <Thread(Thread-11, started daemon 3108)>,\n",
       " <Thread(Thread-12, started daemon 7184)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "print('Initializing...')\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'E:/dynamicquantization/full_precision/res20/model/res.ckpt')\n",
    "\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Test accuracy = 0.921200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# validation\n",
    "\n",
    "print('Evaluating...')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "  fetches = [logits, label_batch, loss]\n",
    "  session_outputs = sess.run(\n",
    "    fetches, {phase_train.name: False})\n",
    "  val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "  val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "  val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(\n",
    "  pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_prune_on_grads(grads_and_vars, dict_nzidx):\n",
    "    for key, nzidx in dict_nzidx.items():\n",
    "        count = 0\n",
    "        for grad, var in grads_and_vars:\n",
    "            if var.name == key:\n",
    "                nzidx_obj = tf.cast(tf.constant(sess.run(dict_nzidx[key])), tf.float32)\n",
    "                grads_and_vars[count] = (tf.multiply(nzidx_obj, grad), var)\n",
    "            count += 1\n",
    "    return grads_and_vars\n",
    "\n",
    "def apply_inq(weights, inq_dict, var_name, prune_rate):  \n",
    "    for target in var_name:\n",
    "        wl = target\n",
    "        bit = 32\n",
    "\n",
    "        weight_obj = weights[wl]\n",
    "        weight_arr = sess.run(weight_obj)\n",
    "\n",
    "        weight_rest = np.reshape(weight_arr, [-1])\n",
    "        dic_tem = np.reshape(sess.run(inq_dict[wl]), [-1])\n",
    "        idx_rest = np.flip(np.argsort(abs(np.reshape(weight_rest, [-1]))), 0)\n",
    "        num_prune = int(len(weight_rest) * prune_rate)\n",
    "        weight_toINQ = weight_rest[idx_rest[:num_prune]]\n",
    "\n",
    "        n1 = (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        n2 = n1 + 1 - bit / 4\n",
    "        upper_bound = 2 ** (np.floor(np.log2(max(abs(np.reshape(weight_arr, [-1]))) * 4 / 3)))\n",
    "        lower_bound = 2 ** (n1 + 1 - bit / 4)\n",
    "\n",
    "        weight_toINQ[abs(weight_toINQ) < lower_bound] = 0\n",
    "        weight_toINQ[weight_toINQ != 0] = 2 ** (np.floor(np.log2(abs(weight_toINQ[weight_toINQ != 0] * 4 / 3)))) * np.sign(weight_toINQ[weight_toINQ != 0])\n",
    "\n",
    "        weight_rest[idx_rest[:num_prune]] = weight_toINQ\n",
    "        weight_arr = np.reshape(weight_rest, np.shape(weight_arr))\n",
    "        dic_tem[idx_rest[:num_prune]] = np.zeros_like(dic_tem[idx_rest[:num_prune]])\n",
    "        inq_dict[wl] = tf.cast(np.reshape(dic_tem, np.shape(sess.run(inq_dict[wl]))), tf.float32)\n",
    "        sess.run(weights[wl].assign(weight_arr))\n",
    "    return inq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一轮  量化\n",
    "prune_rate =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.921200\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.06590594 -0.06288774  0.03332484  0.15145954  0.02605803 -0.04664146\n",
      "  0.02131429 -0.0513982  -0.00593484 -0.13121311]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate = 0时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.5)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-05-31 19:19:43.757179] Iteration 100, train loss = 0.183546, train accuracy = 1.000000\n",
      "[2018-05-31 19:19:52.943179] Iteration 200, train loss = 0.202617, train accuracy = 0.984375\n",
      "[2018-05-31 19:20:02.116179] Iteration 300, train loss = 0.204654, train accuracy = 0.984375\n",
      "[2018-05-31 19:20:11.258179] Iteration 400, train loss = 0.205777, train accuracy = 0.968750\n",
      "[2018-05-31 19:20:20.364179] Iteration 500, train loss = 0.198397, train accuracy = 0.984375\n",
      "[2018-05-31 19:20:29.460179] Iteration 600, train loss = 0.190904, train accuracy = 0.992188\n",
      "[2018-05-31 19:20:38.689179] Iteration 700, train loss = 0.197196, train accuracy = 0.984375\n",
      "[2018-05-31 19:20:47.862179] Iteration 800, train loss = 0.226841, train accuracy = 0.960938\n",
      "[2018-05-31 19:20:57.003179] Iteration 900, train loss = 0.182351, train accuracy = 0.992188\n",
      "[2018-05-31 19:21:06.074179] Iteration 1000, train loss = 0.199881, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916400\n",
      "[2018-05-31 19:21:17.194179] Iteration 1100, train loss = 0.269557, train accuracy = 0.945312\n",
      "[2018-05-31 19:21:26.311179] Iteration 1200, train loss = 0.217877, train accuracy = 0.976562\n",
      "[2018-05-31 19:21:35.442179] Iteration 1300, train loss = 0.225644, train accuracy = 0.960938\n",
      "[2018-05-31 19:21:44.580179] Iteration 1400, train loss = 0.197177, train accuracy = 0.984375\n",
      "[2018-05-31 19:21:53.696179] Iteration 1500, train loss = 0.202447, train accuracy = 0.976562\n",
      "[2018-05-31 19:22:02.853179] Iteration 1600, train loss = 0.194231, train accuracy = 0.984375\n",
      "[2018-05-31 19:22:12.109179] Iteration 1700, train loss = 0.224772, train accuracy = 0.968750\n",
      "[2018-05-31 19:22:21.231179] Iteration 1800, train loss = 0.196713, train accuracy = 0.992188\n",
      "[2018-05-31 19:22:30.431179] Iteration 1900, train loss = 0.197837, train accuracy = 0.976562\n",
      "[2018-05-31 19:22:39.620179] Iteration 2000, train loss = 0.224752, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.916900\n",
      "[2018-05-31 19:22:50.664179] Iteration 2100, train loss = 0.184192, train accuracy = 0.992188\n",
      "[2018-05-31 19:22:59.869179] Iteration 2200, train loss = 0.173306, train accuracy = 1.000000\n",
      "[2018-05-31 19:23:09.028179] Iteration 2300, train loss = 0.209729, train accuracy = 0.984375\n",
      "[2018-05-31 19:23:18.189179] Iteration 2400, train loss = 0.182044, train accuracy = 0.984375\n",
      "[2018-05-31 19:23:27.348179] Iteration 2500, train loss = 0.181631, train accuracy = 0.992188\n",
      "[2018-05-31 19:23:36.456179] Iteration 2600, train loss = 0.175166, train accuracy = 1.000000\n",
      "[2018-05-31 19:23:45.571179] Iteration 2700, train loss = 0.181371, train accuracy = 0.992188\n",
      "[2018-05-31 19:23:54.730179] Iteration 2800, train loss = 0.184917, train accuracy = 0.984375\n",
      "[2018-05-31 19:24:03.975179] Iteration 2900, train loss = 0.183529, train accuracy = 0.984375\n",
      "[2018-05-31 19:24:13.146179] Iteration 3000, train loss = 0.216765, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 19:24:24.304179] Iteration 3100, train loss = 0.174496, train accuracy = 1.000000\n",
      "[2018-05-31 19:24:33.487179] Iteration 3200, train loss = 0.210886, train accuracy = 0.968750\n",
      "[2018-05-31 19:24:42.645179] Iteration 3300, train loss = 0.195002, train accuracy = 0.984375\n",
      "[2018-05-31 19:24:51.865179] Iteration 3400, train loss = 0.197121, train accuracy = 0.976562\n",
      "[2018-05-31 19:25:01.007179] Iteration 3500, train loss = 0.183214, train accuracy = 0.976562\n",
      "[2018-05-31 19:25:10.211179] Iteration 3600, train loss = 0.191379, train accuracy = 0.984375\n",
      "[2018-05-31 19:25:19.352179] Iteration 3700, train loss = 0.205062, train accuracy = 0.976562\n",
      "[2018-05-31 19:25:28.510179] Iteration 3800, train loss = 0.164112, train accuracy = 0.992188\n",
      "[2018-05-31 19:25:37.722179] Iteration 3900, train loss = 0.176197, train accuracy = 0.992188\n",
      "[2018-05-31 19:25:46.824179] Iteration 4000, train loss = 0.173824, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 19:25:57.930179] Iteration 4100, train loss = 0.179381, train accuracy = 0.984375\n",
      "[2018-05-31 19:26:07.122179] Iteration 4200, train loss = 0.179982, train accuracy = 0.984375\n",
      "[2018-05-31 19:26:16.233179] Iteration 4300, train loss = 0.180043, train accuracy = 0.984375\n",
      "[2018-05-31 19:26:25.357179] Iteration 4400, train loss = 0.165894, train accuracy = 0.992188\n",
      "[2018-05-31 19:26:34.552179] Iteration 4500, train loss = 0.187674, train accuracy = 0.984375\n",
      "[2018-05-31 19:26:43.676179] Iteration 4600, train loss = 0.198776, train accuracy = 0.984375\n",
      "[2018-05-31 19:26:52.943179] Iteration 4700, train loss = 0.188406, train accuracy = 0.992188\n",
      "[2018-05-31 19:27:02.143179] Iteration 4800, train loss = 0.215107, train accuracy = 0.976562\n",
      "[2018-05-31 19:27:11.288179] Iteration 4900, train loss = 0.187770, train accuracy = 0.992188\n",
      "[2018-05-31 19:27:20.385179] Iteration 5000, train loss = 0.182980, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916200\n",
      "[2018-05-31 19:27:31.523179] Iteration 5100, train loss = 0.172006, train accuracy = 1.000000\n",
      "[2018-05-31 19:27:40.642179] Iteration 5200, train loss = 0.202764, train accuracy = 0.984375\n",
      "[2018-05-31 19:27:49.781179] Iteration 5300, train loss = 0.181708, train accuracy = 0.992188\n",
      "[2018-05-31 19:27:59.006179] Iteration 5400, train loss = 0.161809, train accuracy = 1.000000\n",
      "[2018-05-31 19:28:08.144179] Iteration 5500, train loss = 0.213210, train accuracy = 0.976562\n",
      "[2018-05-31 19:28:17.281179] Iteration 5600, train loss = 0.220083, train accuracy = 0.953125\n",
      "[2018-05-31 19:28:26.460179] Iteration 5700, train loss = 0.178039, train accuracy = 0.992188\n",
      "[2018-05-31 19:28:35.635179] Iteration 5800, train loss = 0.191169, train accuracy = 0.968750\n",
      "[2018-05-31 19:28:44.783179] Iteration 5900, train loss = 0.164708, train accuracy = 1.000000\n",
      "[2018-05-31 19:28:53.913179] Iteration 6000, train loss = 0.197061, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-05-31 19:29:05.079179] Iteration 6100, train loss = 0.192029, train accuracy = 0.984375\n",
      "[2018-05-31 19:29:14.216179] Iteration 6200, train loss = 0.182783, train accuracy = 0.992188\n",
      "[2018-05-31 19:29:23.387179] Iteration 6300, train loss = 0.165855, train accuracy = 0.992188\n",
      "[2018-05-31 19:29:32.618179] Iteration 6400, train loss = 0.175377, train accuracy = 0.992188\n",
      "[2018-05-31 19:29:41.718179] Iteration 6500, train loss = 0.178426, train accuracy = 0.992188\n",
      "[2018-05-31 19:29:50.907179] Iteration 6600, train loss = 0.170214, train accuracy = 0.992188\n",
      "[2018-05-31 19:30:00.100179] Iteration 6700, train loss = 0.175722, train accuracy = 0.984375\n",
      "[2018-05-31 19:30:09.225179] Iteration 6800, train loss = 0.157438, train accuracy = 1.000000\n",
      "[2018-05-31 19:30:18.405179] Iteration 6900, train loss = 0.201959, train accuracy = 0.984375\n",
      "[2018-05-31 19:30:27.578179] Iteration 7000, train loss = 0.187664, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915600\n",
      "[2018-05-31 19:30:38.672179] Iteration 7100, train loss = 0.186802, train accuracy = 0.976562\n",
      "[2018-05-31 19:30:47.771179] Iteration 7200, train loss = 0.173792, train accuracy = 0.992188\n",
      "[2018-05-31 19:30:56.887179] Iteration 7300, train loss = 0.213287, train accuracy = 0.968750\n",
      "[2018-05-31 19:31:06.023179] Iteration 7400, train loss = 0.173961, train accuracy = 1.000000\n",
      "[2018-05-31 19:31:15.183179] Iteration 7500, train loss = 0.163634, train accuracy = 1.000000\n",
      "[2018-05-31 19:31:24.290179] Iteration 7600, train loss = 0.185096, train accuracy = 0.984375\n",
      "[2018-05-31 19:31:33.515179] Iteration 7700, train loss = 0.168357, train accuracy = 1.000000\n",
      "[2018-05-31 19:31:42.663179] Iteration 7800, train loss = 0.171931, train accuracy = 1.000000\n",
      "[2018-05-31 19:31:51.852179] Iteration 7900, train loss = 0.177207, train accuracy = 0.992188\n",
      "[2018-05-31 19:32:01.048179] Iteration 8000, train loss = 0.164713, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 19:32:12.202179] Iteration 8100, train loss = 0.173913, train accuracy = 0.992188\n",
      "[2018-05-31 19:32:21.339179] Iteration 8200, train loss = 0.189705, train accuracy = 0.976562\n",
      "[2018-05-31 19:32:30.585179] Iteration 8300, train loss = 0.210011, train accuracy = 0.960938\n",
      "[2018-05-31 19:32:39.678179] Iteration 8400, train loss = 0.184039, train accuracy = 0.984375\n",
      "[2018-05-31 19:32:48.792179] Iteration 8500, train loss = 0.172825, train accuracy = 0.992188\n",
      "[2018-05-31 19:32:57.916179] Iteration 8600, train loss = 0.187011, train accuracy = 0.976562\n",
      "[2018-05-31 19:33:07.057179] Iteration 8700, train loss = 0.183943, train accuracy = 0.984375\n",
      "[2018-05-31 19:33:16.216179] Iteration 8800, train loss = 0.174727, train accuracy = 0.992188\n",
      "[2018-05-31 19:33:25.385179] Iteration 8900, train loss = 0.177552, train accuracy = 0.992188\n",
      "[2018-05-31 19:33:34.518179] Iteration 9000, train loss = 0.214805, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.916300\n",
      "[2018-05-31 19:33:45.623179] Iteration 9100, train loss = 0.194715, train accuracy = 0.984375\n",
      "[2018-05-31 19:33:54.777179] Iteration 9200, train loss = 0.162462, train accuracy = 0.992188\n",
      "[2018-05-31 19:34:03.955179] Iteration 9300, train loss = 0.178199, train accuracy = 1.000000\n",
      "[2018-05-31 19:34:13.094179] Iteration 9400, train loss = 0.179628, train accuracy = 0.976562\n",
      "[2018-05-31 19:34:22.219179] Iteration 9500, train loss = 0.167672, train accuracy = 0.992188\n",
      "[2018-05-31 19:34:31.441179] Iteration 9600, train loss = 0.161015, train accuracy = 0.992188\n",
      "[2018-05-31 19:34:40.609179] Iteration 9700, train loss = 0.171851, train accuracy = 0.992188\n",
      "[2018-05-31 19:34:49.797179] Iteration 9800, train loss = 0.174543, train accuracy = 0.992188\n",
      "[2018-05-31 19:34:58.914179] Iteration 9900, train loss = 0.183366, train accuracy = 0.984375\n",
      "[2018-05-31 19:35:08.055179] Iteration 10000, train loss = 0.179834, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915900\n",
      "[2018-05-31 19:35:19.190179] Iteration 10100, train loss = 0.182475, train accuracy = 0.976562\n",
      "[2018-05-31 19:35:28.385179] Iteration 10200, train loss = 0.190176, train accuracy = 0.984375\n",
      "[2018-05-31 19:35:37.536179] Iteration 10300, train loss = 0.186569, train accuracy = 0.984375\n",
      "[2018-05-31 19:35:46.704179] Iteration 10400, train loss = 0.178391, train accuracy = 0.992188\n",
      "[2018-05-31 19:35:55.848179] Iteration 10500, train loss = 0.178616, train accuracy = 0.984375\n",
      "[2018-05-31 19:36:05.022179] Iteration 10600, train loss = 0.211718, train accuracy = 0.968750\n",
      "[2018-05-31 19:36:14.140179] Iteration 10700, train loss = 0.157639, train accuracy = 1.000000\n",
      "[2018-05-31 19:36:23.309179] Iteration 10800, train loss = 0.184008, train accuracy = 0.984375\n",
      "[2018-05-31 19:36:32.544179] Iteration 10900, train loss = 0.157603, train accuracy = 1.000000\n",
      "[2018-05-31 19:36:41.693179] Iteration 11000, train loss = 0.186790, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.916600\n",
      "[2018-05-31 19:36:52.853179] Iteration 11100, train loss = 0.164226, train accuracy = 1.000000\n",
      "[2018-05-31 19:37:01.952179] Iteration 11200, train loss = 0.170039, train accuracy = 1.000000\n",
      "[2018-05-31 19:37:11.068179] Iteration 11300, train loss = 0.175358, train accuracy = 0.992188\n",
      "[2018-05-31 19:37:20.170179] Iteration 11400, train loss = 0.162246, train accuracy = 1.000000\n",
      "[2018-05-31 19:37:29.244179] Iteration 11500, train loss = 0.175664, train accuracy = 1.000000\n",
      "[2018-05-31 19:37:38.346179] Iteration 11600, train loss = 0.184478, train accuracy = 0.992188\n",
      "[2018-05-31 19:37:47.515179] Iteration 11700, train loss = 0.159226, train accuracy = 1.000000\n",
      "[2018-05-31 19:37:56.674179] Iteration 11800, train loss = 0.174535, train accuracy = 0.984375\n",
      "[2018-05-31 19:38:05.868179] Iteration 11900, train loss = 0.174332, train accuracy = 0.984375\n",
      "[2018-05-31 19:38:15.080179] Iteration 12000, train loss = 0.193414, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 19:38:26.172179] Iteration 12100, train loss = 0.170360, train accuracy = 0.992188\n",
      "[2018-05-31 19:38:35.290179] Iteration 12200, train loss = 0.192888, train accuracy = 0.968750\n",
      "[2018-05-31 19:38:44.437179] Iteration 12300, train loss = 0.207363, train accuracy = 0.968750\n",
      "[2018-05-31 19:38:53.676179] Iteration 12400, train loss = 0.176028, train accuracy = 0.984375\n",
      "[2018-05-31 19:39:02.847179] Iteration 12500, train loss = 0.165673, train accuracy = 1.000000\n",
      "[2018-05-31 19:39:11.994179] Iteration 12600, train loss = 0.160453, train accuracy = 1.000000\n",
      "[2018-05-31 19:39:21.120179] Iteration 12700, train loss = 0.158404, train accuracy = 1.000000\n",
      "[2018-05-31 19:39:30.276179] Iteration 12800, train loss = 0.152239, train accuracy = 1.000000\n",
      "[2018-05-31 19:39:39.380179] Iteration 12900, train loss = 0.179351, train accuracy = 0.984375\n",
      "[2018-05-31 19:39:48.578179] Iteration 13000, train loss = 0.154375, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915800\n",
      "[2018-05-31 19:39:59.679179] Iteration 13100, train loss = 0.174942, train accuracy = 0.992188\n",
      "[2018-05-31 19:40:08.804179] Iteration 13200, train loss = 0.206998, train accuracy = 0.976562\n",
      "[2018-05-31 19:40:17.980179] Iteration 13300, train loss = 0.187048, train accuracy = 0.992188\n",
      "[2018-05-31 19:40:27.157179] Iteration 13400, train loss = 0.173765, train accuracy = 0.984375\n",
      "[2018-05-31 19:40:36.354179] Iteration 13500, train loss = 0.167147, train accuracy = 1.000000\n",
      "[2018-05-31 19:40:45.482179] Iteration 13600, train loss = 0.178569, train accuracy = 0.992188\n",
      "[2018-05-31 19:40:54.632179] Iteration 13700, train loss = 0.176341, train accuracy = 0.992188\n",
      "[2018-05-31 19:41:03.741179] Iteration 13800, train loss = 0.169053, train accuracy = 0.992188\n",
      "[2018-05-31 19:41:12.874179] Iteration 13900, train loss = 0.194894, train accuracy = 0.992188\n",
      "[2018-05-31 19:41:22.009179] Iteration 14000, train loss = 0.182589, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.916400\n",
      "[2018-05-31 19:41:33.155179] Iteration 14100, train loss = 0.164793, train accuracy = 0.992188\n",
      "[2018-05-31 19:41:42.378179] Iteration 14200, train loss = 0.201842, train accuracy = 0.984375\n",
      "[2018-05-31 19:41:51.578179] Iteration 14300, train loss = 0.193717, train accuracy = 0.976562\n",
      "[2018-05-31 19:42:00.711179] Iteration 14400, train loss = 0.175774, train accuracy = 0.976562\n",
      "[2018-05-31 19:42:09.884179] Iteration 14500, train loss = 0.167208, train accuracy = 1.000000\n",
      "[2018-05-31 19:42:19.027179] Iteration 14600, train loss = 0.230698, train accuracy = 0.976562\n",
      "[2018-05-31 19:42:28.166179] Iteration 14700, train loss = 0.172410, train accuracy = 0.992188\n",
      "[2018-05-31 19:42:37.291179] Iteration 14800, train loss = 0.167612, train accuracy = 0.992188\n",
      "[2018-05-31 19:42:46.403179] Iteration 14900, train loss = 0.178473, train accuracy = 0.992188\n",
      "[2018-05-31 19:42:55.635179] Iteration 15000, train loss = 0.168757, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916000\n",
      "[2018-05-31 19:43:06.806179] Iteration 15100, train loss = 0.156269, train accuracy = 1.000000\n",
      "[2018-05-31 19:43:15.931179] Iteration 15200, train loss = 0.175483, train accuracy = 0.992188\n",
      "[2018-05-31 19:43:25.089179] Iteration 15300, train loss = 0.178906, train accuracy = 0.992188\n",
      "[2018-05-31 19:43:34.273179] Iteration 15400, train loss = 0.193140, train accuracy = 0.976562\n",
      "[2018-05-31 19:43:43.378179] Iteration 15500, train loss = 0.161587, train accuracy = 0.992188\n",
      "[2018-05-31 19:43:52.548179] Iteration 15600, train loss = 0.190070, train accuracy = 0.984375\n",
      "[2018-05-31 19:44:01.738179] Iteration 15700, train loss = 0.180457, train accuracy = 0.992188\n",
      "[2018-05-31 19:44:10.864179] Iteration 15800, train loss = 0.191436, train accuracy = 0.984375\n",
      "[2018-05-31 19:44:20.037179] Iteration 15900, train loss = 0.161483, train accuracy = 1.000000\n",
      "[2018-05-31 19:44:29.204179] Iteration 16000, train loss = 0.180110, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916800\n",
      "[2018-05-31 19:44:40.343179] Iteration 16100, train loss = 0.183984, train accuracy = 0.992188\n",
      "[2018-05-31 19:44:49.550179] Iteration 16200, train loss = 0.201262, train accuracy = 0.976562\n",
      "[2018-05-31 19:44:58.639179] Iteration 16300, train loss = 0.173501, train accuracy = 0.992188\n",
      "[2018-05-31 19:45:07.841179] Iteration 16400, train loss = 0.159403, train accuracy = 1.000000\n",
      "[2018-05-31 19:45:16.983179] Iteration 16500, train loss = 0.168269, train accuracy = 0.992188\n",
      "[2018-05-31 19:45:26.163179] Iteration 16600, train loss = 0.173921, train accuracy = 0.984375\n",
      "[2018-05-31 19:45:35.367179] Iteration 16700, train loss = 0.200832, train accuracy = 0.968750\n",
      "[2018-05-31 19:45:44.547179] Iteration 16800, train loss = 0.162975, train accuracy = 0.992188\n",
      "[2018-05-31 19:45:53.711179] Iteration 16900, train loss = 0.170902, train accuracy = 0.992188\n",
      "[2018-05-31 19:46:02.846179] Iteration 17000, train loss = 0.215571, train accuracy = 0.960938\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-05-31 19:46:13.974179] Iteration 17100, train loss = 0.196185, train accuracy = 0.976562\n",
      "[2018-05-31 19:46:23.124179] Iteration 17200, train loss = 0.151452, train accuracy = 1.000000\n",
      "[2018-05-31 19:46:32.305179] Iteration 17300, train loss = 0.178546, train accuracy = 0.992188\n",
      "[2018-05-31 19:46:41.412179] Iteration 17400, train loss = 0.178061, train accuracy = 0.992188\n",
      "[2018-05-31 19:46:50.597179] Iteration 17500, train loss = 0.151417, train accuracy = 1.000000\n",
      "[2018-05-31 19:46:59.838179] Iteration 17600, train loss = 0.173244, train accuracy = 0.992188\n",
      "[2018-05-31 19:47:08.940179] Iteration 17700, train loss = 0.169662, train accuracy = 1.000000\n",
      "[2018-05-31 19:47:18.086179] Iteration 17800, train loss = 0.157303, train accuracy = 1.000000\n",
      "[2018-05-31 19:47:27.199179] Iteration 17900, train loss = 0.165639, train accuracy = 1.000000\n",
      "[2018-05-31 19:47:36.366179] Iteration 18000, train loss = 0.173466, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 19:47:47.455179] Iteration 18100, train loss = 0.177674, train accuracy = 0.976562\n",
      "[2018-05-31 19:47:56.564179] Iteration 18200, train loss = 0.185848, train accuracy = 0.976562\n",
      "[2018-05-31 19:48:05.748179] Iteration 18300, train loss = 0.195698, train accuracy = 0.984375\n",
      "[2018-05-31 19:48:14.871179] Iteration 18400, train loss = 0.173369, train accuracy = 0.992188\n",
      "[2018-05-31 19:48:24.036179] Iteration 18500, train loss = 0.155056, train accuracy = 0.992188\n",
      "[2018-05-31 19:48:33.204179] Iteration 18600, train loss = 0.176569, train accuracy = 0.992188\n",
      "[2018-05-31 19:48:42.333179] Iteration 18700, train loss = 0.149195, train accuracy = 1.000000\n",
      "[2018-05-31 19:48:51.524179] Iteration 18800, train loss = 0.162438, train accuracy = 0.992188\n",
      "[2018-05-31 19:49:00.688179] Iteration 18900, train loss = 0.174524, train accuracy = 0.984375\n",
      "[2018-05-31 19:49:09.804179] Iteration 19000, train loss = 0.165693, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 19:49:20.978179] Iteration 19100, train loss = 0.168473, train accuracy = 0.992188\n",
      "[2018-05-31 19:49:30.116179] Iteration 19200, train loss = 0.168671, train accuracy = 0.992188\n",
      "[2018-05-31 19:49:39.360179] Iteration 19300, train loss = 0.185941, train accuracy = 0.992188\n",
      "[2018-05-31 19:49:48.488179] Iteration 19400, train loss = 0.172078, train accuracy = 0.992188\n",
      "[2018-05-31 19:49:57.622179] Iteration 19500, train loss = 0.177011, train accuracy = 0.984375\n",
      "[2018-05-31 19:50:06.764179] Iteration 19600, train loss = 0.166996, train accuracy = 1.000000\n",
      "[2018-05-31 19:50:15.964179] Iteration 19700, train loss = 0.174946, train accuracy = 0.992188\n",
      "[2018-05-31 19:50:25.102179] Iteration 19800, train loss = 0.175895, train accuracy = 0.984375\n",
      "[2018-05-31 19:50:34.291179] Iteration 19900, train loss = 0.153644, train accuracy = 1.000000\n",
      "[2018-05-31 19:50:43.432179] Iteration 20000, train loss = 0.170648, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916300\n",
      "[2018-05-31 19:50:54.612179] Iteration 20100, train loss = 0.162740, train accuracy = 0.992188\n",
      "[2018-05-31 19:51:03.797179] Iteration 20200, train loss = 0.181629, train accuracy = 0.984375\n",
      "[2018-05-31 19:51:12.975179] Iteration 20300, train loss = 0.175379, train accuracy = 0.992188\n",
      "[2018-05-31 19:51:22.148179] Iteration 20400, train loss = 0.166539, train accuracy = 1.000000\n",
      "[2018-05-31 19:51:31.314179] Iteration 20500, train loss = 0.164090, train accuracy = 1.000000\n",
      "[2018-05-31 19:51:40.561179] Iteration 20600, train loss = 0.161188, train accuracy = 1.000000\n",
      "[2018-05-31 19:51:49.744179] Iteration 20700, train loss = 0.167536, train accuracy = 0.992188\n",
      "[2018-05-31 19:51:58.872179] Iteration 20800, train loss = 0.167163, train accuracy = 0.992188\n",
      "[2018-05-31 19:52:08.036179] Iteration 20900, train loss = 0.177472, train accuracy = 0.992188\n",
      "[2018-05-31 19:52:17.200179] Iteration 21000, train loss = 0.162283, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915900\n",
      "[2018-05-31 19:52:28.339179] Iteration 21100, train loss = 0.163267, train accuracy = 0.992188\n",
      "[2018-05-31 19:52:37.460179] Iteration 21200, train loss = 0.151978, train accuracy = 1.000000\n",
      "[2018-05-31 19:52:46.635179] Iteration 21300, train loss = 0.178064, train accuracy = 0.984375\n",
      "[2018-05-31 19:52:55.801179] Iteration 21400, train loss = 0.185543, train accuracy = 0.992188\n",
      "[2018-05-31 19:53:04.964179] Iteration 21500, train loss = 0.151243, train accuracy = 1.000000\n",
      "[2018-05-31 19:53:14.186179] Iteration 21600, train loss = 0.175797, train accuracy = 0.984375\n",
      "[2018-05-31 19:53:23.293179] Iteration 21700, train loss = 0.149870, train accuracy = 1.000000\n",
      "[2018-05-31 19:53:32.464179] Iteration 21800, train loss = 0.157196, train accuracy = 1.000000\n",
      "[2018-05-31 19:53:41.641179] Iteration 21900, train loss = 0.148109, train accuracy = 1.000000\n",
      "[2018-05-31 19:53:50.843179] Iteration 22000, train loss = 0.161964, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 19:54:02.080179] Iteration 22100, train loss = 0.176530, train accuracy = 0.992188\n",
      "[2018-05-31 19:54:11.205179] Iteration 22200, train loss = 0.168547, train accuracy = 0.992188\n",
      "[2018-05-31 19:54:20.350179] Iteration 22300, train loss = 0.161569, train accuracy = 0.992188\n",
      "[2018-05-31 19:54:29.514179] Iteration 22400, train loss = 0.153734, train accuracy = 1.000000\n",
      "[2018-05-31 19:54:38.726179] Iteration 22500, train loss = 0.170486, train accuracy = 0.992188\n",
      "[2018-05-31 19:54:47.993179] Iteration 22600, train loss = 0.165215, train accuracy = 0.992188\n",
      "[2018-05-31 19:54:57.163179] Iteration 22700, train loss = 0.170505, train accuracy = 0.992188\n",
      "[2018-05-31 19:55:06.286179] Iteration 22800, train loss = 0.156215, train accuracy = 1.000000\n",
      "[2018-05-31 19:55:15.468179] Iteration 22900, train loss = 0.186545, train accuracy = 0.984375\n",
      "[2018-05-31 19:55:24.642179] Iteration 23000, train loss = 0.170087, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915500\n",
      "[2018-05-31 19:55:35.745179] Iteration 23100, train loss = 0.189554, train accuracy = 0.976562\n",
      "[2018-05-31 19:55:44.961179] Iteration 23200, train loss = 0.175022, train accuracy = 0.992188\n",
      "[2018-05-31 19:55:54.104179] Iteration 23300, train loss = 0.159441, train accuracy = 1.000000\n",
      "[2018-05-31 19:56:03.230179] Iteration 23400, train loss = 0.163336, train accuracy = 0.992188\n",
      "[2018-05-31 19:56:12.401179] Iteration 23500, train loss = 0.154898, train accuracy = 1.000000\n",
      "[2018-05-31 19:56:21.518179] Iteration 23600, train loss = 0.151717, train accuracy = 1.000000\n",
      "[2018-05-31 19:56:30.731179] Iteration 23700, train loss = 0.164532, train accuracy = 0.992188\n",
      "[2018-05-31 19:56:39.873179] Iteration 23800, train loss = 0.163769, train accuracy = 0.984375\n",
      "[2018-05-31 19:56:49.047179] Iteration 23900, train loss = 0.152736, train accuracy = 1.000000\n",
      "[2018-05-31 19:56:58.280179] Iteration 24000, train loss = 0.151573, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915500\n",
      "[2018-05-31 19:57:09.423179] Iteration 24100, train loss = 0.155911, train accuracy = 1.000000\n",
      "[2018-05-31 19:57:18.621179] Iteration 24200, train loss = 0.178417, train accuracy = 0.984375\n",
      "[2018-05-31 19:57:27.814179] Iteration 24300, train loss = 0.167867, train accuracy = 1.000000\n",
      "[2018-05-31 19:57:36.982179] Iteration 24400, train loss = 0.166222, train accuracy = 1.000000\n",
      "[2018-05-31 19:57:46.121179] Iteration 24500, train loss = 0.162458, train accuracy = 0.992188\n",
      "[2018-05-31 19:57:55.309179] Iteration 24600, train loss = 0.170565, train accuracy = 1.000000\n",
      "[2018-05-31 19:58:04.471179] Iteration 24700, train loss = 0.179350, train accuracy = 0.992188\n",
      "[2018-05-31 19:58:13.583179] Iteration 24800, train loss = 0.159498, train accuracy = 1.000000\n",
      "[2018-05-31 19:58:22.714179] Iteration 24900, train loss = 0.171306, train accuracy = 1.000000\n",
      "[2018-05-31 19:58:31.836179] Iteration 25000, train loss = 0.179565, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-05-31 19:58:42.919179] Iteration 25100, train loss = 0.147623, train accuracy = 1.000000\n",
      "[2018-05-31 19:58:52.063179] Iteration 25200, train loss = 0.159394, train accuracy = 0.992188\n",
      "[2018-05-31 19:59:01.221179] Iteration 25300, train loss = 0.168379, train accuracy = 0.992188\n",
      "[2018-05-31 19:59:10.405179] Iteration 25400, train loss = 0.191029, train accuracy = 0.976562\n",
      "[2018-05-31 19:59:19.543179] Iteration 25500, train loss = 0.156762, train accuracy = 1.000000\n",
      "[2018-05-31 19:59:28.636179] Iteration 25600, train loss = 0.218736, train accuracy = 0.984375\n",
      "[2018-05-31 19:59:37.732179] Iteration 25700, train loss = 0.154392, train accuracy = 0.992188\n",
      "[2018-05-31 19:59:46.847179] Iteration 25800, train loss = 0.190216, train accuracy = 0.976562\n",
      "[2018-05-31 19:59:56.057179] Iteration 25900, train loss = 0.175828, train accuracy = 0.992188\n",
      "[2018-05-31 20:00:05.216179] Iteration 26000, train loss = 0.148217, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 20:00:16.345179] Iteration 26100, train loss = 0.167958, train accuracy = 0.992188\n",
      "[2018-05-31 20:00:25.455179] Iteration 26200, train loss = 0.159073, train accuracy = 0.992188\n",
      "[2018-05-31 20:00:34.546179] Iteration 26300, train loss = 0.163277, train accuracy = 1.000000\n",
      "[2018-05-31 20:00:43.740179] Iteration 26400, train loss = 0.184386, train accuracy = 0.992188\n",
      "[2018-05-31 20:00:52.925179] Iteration 26500, train loss = 0.181535, train accuracy = 0.992188\n",
      "[2018-05-31 20:01:02.099179] Iteration 26600, train loss = 0.152485, train accuracy = 1.000000\n",
      "[2018-05-31 20:01:11.247179] Iteration 26700, train loss = 0.174118, train accuracy = 0.992188\n",
      "[2018-05-31 20:01:20.347179] Iteration 26800, train loss = 0.165809, train accuracy = 0.984375\n",
      "[2018-05-31 20:01:29.473179] Iteration 26900, train loss = 0.160123, train accuracy = 0.992188\n",
      "[2018-05-31 20:01:38.603179] Iteration 27000, train loss = 0.177599, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 20:01:49.752179] Iteration 27100, train loss = 0.159113, train accuracy = 0.992188\n",
      "[2018-05-31 20:01:58.871179] Iteration 27200, train loss = 0.169781, train accuracy = 0.992188\n",
      "[2018-05-31 20:02:08.045179] Iteration 27300, train loss = 0.177168, train accuracy = 0.992188\n",
      "[2018-05-31 20:02:17.144179] Iteration 27400, train loss = 0.166026, train accuracy = 0.992188\n",
      "[2018-05-31 20:02:26.360179] Iteration 27500, train loss = 0.185718, train accuracy = 0.984375\n",
      "[2018-05-31 20:02:35.445179] Iteration 27600, train loss = 0.171267, train accuracy = 0.992188\n",
      "[2018-05-31 20:02:44.666179] Iteration 27700, train loss = 0.188416, train accuracy = 0.984375\n",
      "[2018-05-31 20:02:53.807179] Iteration 27800, train loss = 0.172821, train accuracy = 0.992188\n",
      "[2018-05-31 20:03:02.991179] Iteration 27900, train loss = 0.153783, train accuracy = 1.000000\n",
      "[2018-05-31 20:03:12.108179] Iteration 28000, train loss = 0.170005, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915500\n",
      "[2018-05-31 20:03:23.253179] Iteration 28100, train loss = 0.181058, train accuracy = 0.984375\n",
      "[2018-05-31 20:03:32.499179] Iteration 28200, train loss = 0.161356, train accuracy = 1.000000\n",
      "[2018-05-31 20:03:41.744179] Iteration 28300, train loss = 0.167899, train accuracy = 0.984375\n",
      "[2018-05-31 20:03:50.905179] Iteration 28400, train loss = 0.157144, train accuracy = 0.992188\n",
      "[2018-05-31 20:04:00.056179] Iteration 28500, train loss = 0.160030, train accuracy = 0.992188\n",
      "[2018-05-31 20:04:09.161179] Iteration 28600, train loss = 0.152394, train accuracy = 1.000000\n",
      "[2018-05-31 20:04:18.249179] Iteration 28700, train loss = 0.148006, train accuracy = 1.000000\n",
      "[2018-05-31 20:04:27.454179] Iteration 28800, train loss = 0.172539, train accuracy = 0.992188\n",
      "[2018-05-31 20:04:36.571179] Iteration 28900, train loss = 0.168016, train accuracy = 0.992188\n",
      "[2018-05-31 20:04:45.837179] Iteration 29000, train loss = 0.177842, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.915600\n",
      "[2018-05-31 20:04:56.967179] Iteration 29100, train loss = 0.147812, train accuracy = 1.000000\n",
      "[2018-05-31 20:05:06.190179] Iteration 29200, train loss = 0.196720, train accuracy = 0.984375\n",
      "[2018-05-31 20:05:15.250179] Iteration 29300, train loss = 0.219704, train accuracy = 0.984375\n",
      "[2018-05-31 20:05:24.391179] Iteration 29400, train loss = 0.170319, train accuracy = 0.992188\n",
      "[2018-05-31 20:05:33.546179] Iteration 29500, train loss = 0.158045, train accuracy = 1.000000\n",
      "[2018-05-31 20:05:42.708179] Iteration 29600, train loss = 0.158507, train accuracy = 0.992188\n",
      "[2018-05-31 20:05:51.846179] Iteration 29700, train loss = 0.189359, train accuracy = 0.976562\n",
      "[2018-05-31 20:06:00.931179] Iteration 29800, train loss = 0.156099, train accuracy = 1.000000\n",
      "[2018-05-31 20:06:10.061179] Iteration 29900, train loss = 0.180070, train accuracy = 0.992188\n",
      "[2018-05-31 20:06:19.203179] Iteration 30000, train loss = 0.149980, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-05-31 20:06:30.315179] Iteration 30100, train loss = 0.159680, train accuracy = 1.000000\n",
      "[2018-05-31 20:06:39.477179] Iteration 30200, train loss = 0.179891, train accuracy = 0.984375\n",
      "[2018-05-31 20:06:48.656179] Iteration 30300, train loss = 0.198831, train accuracy = 0.984375\n",
      "[2018-05-31 20:06:57.846179] Iteration 30400, train loss = 0.180389, train accuracy = 0.984375\n",
      "[2018-05-31 20:07:07.002179] Iteration 30500, train loss = 0.159825, train accuracy = 0.992188\n",
      "[2018-05-31 20:07:16.164179] Iteration 30600, train loss = 0.166070, train accuracy = 0.992188\n",
      "[2018-05-31 20:07:25.320179] Iteration 30700, train loss = 0.155909, train accuracy = 1.000000\n",
      "[2018-05-31 20:07:34.482179] Iteration 30800, train loss = 0.159359, train accuracy = 1.000000\n",
      "[2018-05-31 20:07:43.626179] Iteration 30900, train loss = 0.178419, train accuracy = 0.976562\n",
      "[2018-05-31 20:07:52.794179] Iteration 31000, train loss = 0.194769, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.916200\n",
      "[2018-05-31 20:08:03.903179] Iteration 31100, train loss = 0.160656, train accuracy = 1.000000\n",
      "[2018-05-31 20:08:13.054179] Iteration 31200, train loss = 0.179097, train accuracy = 0.976562\n",
      "[2018-05-31 20:08:22.267179] Iteration 31300, train loss = 0.174084, train accuracy = 0.992188\n",
      "[2018-05-31 20:08:31.411179] Iteration 31400, train loss = 0.179134, train accuracy = 0.992188\n",
      "[2018-05-31 20:08:40.520179] Iteration 31500, train loss = 0.156218, train accuracy = 1.000000\n",
      "[2018-05-31 20:08:49.639179] Iteration 31600, train loss = 0.201492, train accuracy = 0.976562\n",
      "[2018-05-31 20:08:58.768179] Iteration 31700, train loss = 0.157820, train accuracy = 0.992188\n",
      "[2018-05-31 20:09:07.918179] Iteration 31800, train loss = 0.169567, train accuracy = 0.992188\n",
      "[2018-05-31 20:09:17.139179] Iteration 31900, train loss = 0.194423, train accuracy = 0.976562\n",
      "[2018-05-31 20:09:26.331179] Iteration 32000, train loss = 0.170244, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916200\n",
      "[2018-05-31 20:09:37.441179] Iteration 32100, train loss = 0.161214, train accuracy = 0.992188\n",
      "[2018-05-31 20:09:46.580179] Iteration 32200, train loss = 0.202253, train accuracy = 0.984375\n",
      "[2018-05-31 20:09:55.750179] Iteration 32300, train loss = 0.173865, train accuracy = 0.984375\n",
      "[2018-05-31 20:10:04.851179] Iteration 32400, train loss = 0.154230, train accuracy = 1.000000\n",
      "[2018-05-31 20:10:14.031179] Iteration 32500, train loss = 0.157226, train accuracy = 1.000000\n",
      "[2018-05-31 20:10:23.144179] Iteration 32600, train loss = 0.161436, train accuracy = 1.000000\n",
      "[2018-05-31 20:10:32.219179] Iteration 32700, train loss = 0.154566, train accuracy = 1.000000\n",
      "[2018-05-31 20:10:41.374179] Iteration 32800, train loss = 0.154708, train accuracy = 1.000000\n",
      "[2018-05-31 20:10:50.525179] Iteration 32900, train loss = 0.170866, train accuracy = 0.984375\n",
      "[2018-05-31 20:10:59.616179] Iteration 33000, train loss = 0.161783, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.917000\n",
      "[2018-05-31 20:11:10.788179] Iteration 33100, train loss = 0.208027, train accuracy = 0.976562\n",
      "[2018-05-31 20:11:19.962179] Iteration 33200, train loss = 0.166723, train accuracy = 0.992188\n",
      "[2018-05-31 20:11:29.119179] Iteration 33300, train loss = 0.183834, train accuracy = 0.992188\n",
      "[2018-05-31 20:11:38.304179] Iteration 33400, train loss = 0.151972, train accuracy = 1.000000\n",
      "[2018-05-31 20:11:47.394179] Iteration 33500, train loss = 0.207080, train accuracy = 0.968750\n",
      "[2018-05-31 20:11:56.555179] Iteration 33600, train loss = 0.169348, train accuracy = 0.984375\n",
      "[2018-05-31 20:12:05.743179] Iteration 33700, train loss = 0.156392, train accuracy = 1.000000\n",
      "[2018-05-31 20:12:14.881179] Iteration 33800, train loss = 0.178791, train accuracy = 0.984375\n",
      "[2018-05-31 20:12:23.997179] Iteration 33900, train loss = 0.154985, train accuracy = 1.000000\n",
      "[2018-05-31 20:12:33.144179] Iteration 34000, train loss = 0.156271, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916500\n",
      "[2018-05-31 20:12:44.248179] Iteration 34100, train loss = 0.164159, train accuracy = 0.984375\n",
      "[2018-05-31 20:12:53.485179] Iteration 34200, train loss = 0.160858, train accuracy = 0.992188\n",
      "[2018-05-31 20:13:02.652179] Iteration 34300, train loss = 0.180565, train accuracy = 0.976562\n",
      "[2018-05-31 20:13:11.758179] Iteration 34400, train loss = 0.164601, train accuracy = 0.992188\n",
      "[2018-05-31 20:13:20.987179] Iteration 34500, train loss = 0.153626, train accuracy = 0.992188\n",
      "[2018-05-31 20:13:30.172179] Iteration 34600, train loss = 0.162548, train accuracy = 1.000000\n",
      "[2018-05-31 20:13:39.326179] Iteration 34700, train loss = 0.151483, train accuracy = 1.000000\n",
      "[2018-05-31 20:13:48.450179] Iteration 34800, train loss = 0.157227, train accuracy = 1.000000\n",
      "[2018-05-31 20:13:57.608179] Iteration 34900, train loss = 0.188331, train accuracy = 0.992188\n",
      "[2018-05-31 20:14:06.788179] Iteration 35000, train loss = 0.158544, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 20:14:17.968179] Iteration 35100, train loss = 0.157734, train accuracy = 1.000000\n",
      "[2018-05-31 20:14:27.157179] Iteration 35200, train loss = 0.172694, train accuracy = 0.984375\n",
      "[2018-05-31 20:14:36.352179] Iteration 35300, train loss = 0.160723, train accuracy = 0.992188\n",
      "[2018-05-31 20:14:45.444179] Iteration 35400, train loss = 0.152625, train accuracy = 1.000000\n",
      "[2018-05-31 20:14:54.601179] Iteration 35500, train loss = 0.161189, train accuracy = 1.000000\n",
      "[2018-05-31 20:15:03.808179] Iteration 35600, train loss = 0.144447, train accuracy = 1.000000\n",
      "[2018-05-31 20:15:12.991179] Iteration 35700, train loss = 0.167617, train accuracy = 0.992188\n",
      "[2018-05-31 20:15:22.365179] Iteration 35800, train loss = 0.151961, train accuracy = 1.000000\n",
      "[2018-05-31 20:15:31.561179] Iteration 35900, train loss = 0.161995, train accuracy = 1.000000\n",
      "[2018-05-31 20:15:40.716179] Iteration 36000, train loss = 0.187326, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.913400\n",
      "[2018-05-31 20:15:51.874179] Iteration 36100, train loss = 0.177487, train accuracy = 0.984375\n",
      "[2018-05-31 20:16:01.018179] Iteration 36200, train loss = 0.170861, train accuracy = 0.992188\n",
      "[2018-05-31 20:16:10.157179] Iteration 36300, train loss = 0.166232, train accuracy = 0.992188\n",
      "[2018-05-31 20:16:19.363179] Iteration 36400, train loss = 0.180891, train accuracy = 0.976562\n",
      "[2018-05-31 20:16:28.590179] Iteration 36500, train loss = 0.158053, train accuracy = 1.000000\n",
      "[2018-05-31 20:16:37.706179] Iteration 36600, train loss = 0.145684, train accuracy = 1.000000\n",
      "[2018-05-31 20:16:46.897179] Iteration 36700, train loss = 0.152545, train accuracy = 1.000000\n",
      "[2018-05-31 20:16:56.037179] Iteration 36800, train loss = 0.164649, train accuracy = 0.992188\n",
      "[2018-05-31 20:17:05.186179] Iteration 36900, train loss = 0.164326, train accuracy = 1.000000\n",
      "[2018-05-31 20:17:14.336179] Iteration 37000, train loss = 0.155370, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916700\n",
      "[2018-05-31 20:17:25.457179] Iteration 37100, train loss = 0.184187, train accuracy = 0.968750\n",
      "[2018-05-31 20:17:34.622179] Iteration 37200, train loss = 0.192340, train accuracy = 0.992188\n",
      "[2018-05-31 20:17:43.801179] Iteration 37300, train loss = 0.149778, train accuracy = 1.000000\n",
      "[2018-05-31 20:17:52.936179] Iteration 37400, train loss = 0.163396, train accuracy = 1.000000\n",
      "[2018-05-31 20:18:02.093179] Iteration 37500, train loss = 0.165132, train accuracy = 0.992188\n",
      "[2018-05-31 20:18:11.278179] Iteration 37600, train loss = 0.174421, train accuracy = 0.992188\n",
      "[2018-05-31 20:18:20.487179] Iteration 37700, train loss = 0.151379, train accuracy = 1.000000\n",
      "[2018-05-31 20:18:29.555179] Iteration 37800, train loss = 0.179612, train accuracy = 0.984375\n",
      "[2018-05-31 20:18:38.751179] Iteration 37900, train loss = 0.175407, train accuracy = 0.992188\n",
      "[2018-05-31 20:18:47.888179] Iteration 38000, train loss = 0.171527, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916900\n",
      "[2018-05-31 20:18:59.040179] Iteration 38100, train loss = 0.168032, train accuracy = 1.000000\n",
      "[2018-05-31 20:19:08.293179] Iteration 38200, train loss = 0.148312, train accuracy = 1.000000\n",
      "[2018-05-31 20:19:17.468179] Iteration 38300, train loss = 0.178887, train accuracy = 0.992188\n",
      "[2018-05-31 20:19:26.605179] Iteration 38400, train loss = 0.155122, train accuracy = 1.000000\n",
      "[2018-05-31 20:19:35.862179] Iteration 38500, train loss = 0.172972, train accuracy = 0.984375\n",
      "[2018-05-31 20:19:44.976179] Iteration 38600, train loss = 0.151963, train accuracy = 1.000000\n",
      "[2018-05-31 20:19:54.140179] Iteration 38700, train loss = 0.156287, train accuracy = 1.000000\n",
      "[2018-05-31 20:20:03.291179] Iteration 38800, train loss = 0.173096, train accuracy = 0.984375\n",
      "[2018-05-31 20:20:12.437179] Iteration 38900, train loss = 0.152068, train accuracy = 1.000000\n",
      "[2018-05-31 20:20:21.567179] Iteration 39000, train loss = 0.213683, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 20:20:32.713179] Iteration 39100, train loss = 0.154343, train accuracy = 1.000000\n",
      "[2018-05-31 20:20:41.797179] Iteration 39200, train loss = 0.192220, train accuracy = 0.992188\n",
      "[2018-05-31 20:20:50.963179] Iteration 39300, train loss = 0.187918, train accuracy = 0.976562\n",
      "[2018-05-31 20:21:00.129179] Iteration 39400, train loss = 0.169994, train accuracy = 0.984375\n",
      "[2018-05-31 20:21:09.352179] Iteration 39500, train loss = 0.162442, train accuracy = 0.992188\n",
      "[2018-05-31 20:21:18.448179] Iteration 39600, train loss = 0.157852, train accuracy = 0.992188\n",
      "[2018-05-31 20:21:27.596179] Iteration 39700, train loss = 0.178676, train accuracy = 0.984375\n",
      "[2018-05-31 20:21:36.764179] Iteration 39800, train loss = 0.154156, train accuracy = 1.000000\n",
      "[2018-05-31 20:21:45.906179] Iteration 39900, train loss = 0.160666, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "curr_lr = 0\n",
    "for step in range(40000):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二轮 量化\n",
    "prune_rate = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.914600\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.04053506  0.125       0.07373984 -0.02338518\n",
      "  0.02415705 -0.0625      0.02205998 -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.5时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.75)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-31 20:22:56.240179] Iteration 100, train loss = 0.168795, train accuracy = 1.000000\n",
      "[2018-05-31 20:23:05.334179] Iteration 200, train loss = 0.191281, train accuracy = 0.984375\n",
      "[2018-05-31 20:23:14.409179] Iteration 300, train loss = 0.180166, train accuracy = 0.984375\n",
      "[2018-05-31 20:23:23.536179] Iteration 400, train loss = 0.163208, train accuracy = 1.000000\n",
      "[2018-05-31 20:23:32.721179] Iteration 500, train loss = 0.165209, train accuracy = 1.000000\n",
      "[2018-05-31 20:23:41.878179] Iteration 600, train loss = 0.167137, train accuracy = 0.992188\n",
      "[2018-05-31 20:23:51.005179] Iteration 700, train loss = 0.167458, train accuracy = 0.992188\n",
      "[2018-05-31 20:24:00.185179] Iteration 800, train loss = 0.208009, train accuracy = 0.968750\n",
      "[2018-05-31 20:24:09.356179] Iteration 900, train loss = 0.173252, train accuracy = 0.992188\n",
      "[2018-05-31 20:24:18.562179] Iteration 1000, train loss = 0.176292, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916100\n",
      "[2018-05-31 20:24:29.668179] Iteration 1100, train loss = 0.155556, train accuracy = 1.000000\n",
      "[2018-05-31 20:24:38.900179] Iteration 1200, train loss = 0.184100, train accuracy = 0.984375\n",
      "[2018-05-31 20:24:48.048179] Iteration 1300, train loss = 0.166105, train accuracy = 0.992188\n",
      "[2018-05-31 20:24:57.211179] Iteration 1400, train loss = 0.160131, train accuracy = 0.992188\n",
      "[2018-05-31 20:25:06.443179] Iteration 1500, train loss = 0.159353, train accuracy = 1.000000\n",
      "[2018-05-31 20:25:15.611179] Iteration 1600, train loss = 0.163833, train accuracy = 1.000000\n",
      "[2018-05-31 20:25:24.815179] Iteration 1700, train loss = 0.148236, train accuracy = 1.000000\n",
      "[2018-05-31 20:25:33.976179] Iteration 1800, train loss = 0.173604, train accuracy = 0.992188\n",
      "[2018-05-31 20:25:43.154179] Iteration 1900, train loss = 0.161422, train accuracy = 0.992188\n",
      "[2018-05-31 20:25:52.394179] Iteration 2000, train loss = 0.171771, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 20:26:03.631179] Iteration 2100, train loss = 0.163686, train accuracy = 0.984375\n",
      "[2018-05-31 20:26:12.726179] Iteration 2200, train loss = 0.176444, train accuracy = 0.984375\n",
      "[2018-05-31 20:26:21.796179] Iteration 2300, train loss = 0.182312, train accuracy = 0.992188\n",
      "[2018-05-31 20:26:30.905179] Iteration 2400, train loss = 0.184280, train accuracy = 0.992188\n",
      "[2018-05-31 20:26:40.060179] Iteration 2500, train loss = 0.181654, train accuracy = 0.984375\n",
      "[2018-05-31 20:26:49.183179] Iteration 2600, train loss = 0.163067, train accuracy = 1.000000\n",
      "[2018-05-31 20:26:58.370179] Iteration 2700, train loss = 0.151414, train accuracy = 1.000000\n",
      "[2018-05-31 20:27:07.567179] Iteration 2800, train loss = 0.163143, train accuracy = 0.992188\n",
      "[2018-05-31 20:27:16.661179] Iteration 2900, train loss = 0.168655, train accuracy = 0.992188\n",
      "[2018-05-31 20:27:25.845179] Iteration 3000, train loss = 0.167989, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-05-31 20:27:36.982179] Iteration 3100, train loss = 0.176272, train accuracy = 0.992188\n",
      "[2018-05-31 20:27:46.109179] Iteration 3200, train loss = 0.152539, train accuracy = 1.000000\n",
      "[2018-05-31 20:27:55.302179] Iteration 3300, train loss = 0.162298, train accuracy = 1.000000\n",
      "[2018-05-31 20:28:04.512179] Iteration 3400, train loss = 0.163438, train accuracy = 0.992188\n",
      "[2018-05-31 20:28:13.667179] Iteration 3500, train loss = 0.152374, train accuracy = 1.000000\n",
      "[2018-05-31 20:28:22.832179] Iteration 3600, train loss = 0.147447, train accuracy = 1.000000\n",
      "[2018-05-31 20:28:31.999179] Iteration 3700, train loss = 0.163787, train accuracy = 1.000000\n",
      "[2018-05-31 20:28:41.135179] Iteration 3800, train loss = 0.169228, train accuracy = 1.000000\n",
      "[2018-05-31 20:28:50.359179] Iteration 3900, train loss = 0.153194, train accuracy = 1.000000\n",
      "[2018-05-31 20:28:59.472179] Iteration 4000, train loss = 0.157728, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-05-31 20:29:10.613179] Iteration 4100, train loss = 0.162831, train accuracy = 1.000000\n",
      "[2018-05-31 20:29:19.856179] Iteration 4200, train loss = 0.203440, train accuracy = 0.976562\n",
      "[2018-05-31 20:29:28.959179] Iteration 4300, train loss = 0.161851, train accuracy = 0.992188\n",
      "[2018-05-31 20:29:38.088179] Iteration 4400, train loss = 0.159848, train accuracy = 0.992188\n",
      "[2018-05-31 20:29:47.292179] Iteration 4500, train loss = 0.175778, train accuracy = 0.992188\n",
      "[2018-05-31 20:29:56.440179] Iteration 4600, train loss = 0.182997, train accuracy = 0.984375\n",
      "[2018-05-31 20:30:05.593179] Iteration 4700, train loss = 0.163722, train accuracy = 1.000000\n",
      "[2018-05-31 20:30:14.791179] Iteration 4800, train loss = 0.163433, train accuracy = 1.000000\n",
      "[2018-05-31 20:30:24.019179] Iteration 4900, train loss = 0.155213, train accuracy = 1.000000\n",
      "[2018-05-31 20:30:33.187179] Iteration 5000, train loss = 0.182015, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-05-31 20:30:44.325179] Iteration 5100, train loss = 0.152920, train accuracy = 1.000000\n",
      "[2018-05-31 20:30:53.434179] Iteration 5200, train loss = 0.167421, train accuracy = 1.000000\n",
      "[2018-05-31 20:31:02.527179] Iteration 5300, train loss = 0.160641, train accuracy = 1.000000\n",
      "[2018-05-31 20:31:11.641179] Iteration 5400, train loss = 0.181480, train accuracy = 0.992188\n",
      "[2018-05-31 20:31:20.780179] Iteration 5500, train loss = 0.157820, train accuracy = 1.000000\n",
      "[2018-05-31 20:31:29.913179] Iteration 5600, train loss = 0.159140, train accuracy = 1.000000\n",
      "[2018-05-31 20:31:39.131179] Iteration 5700, train loss = 0.177532, train accuracy = 1.000000\n",
      "[2018-05-31 20:31:48.248179] Iteration 5800, train loss = 0.176085, train accuracy = 0.992188\n",
      "[2018-05-31 20:31:57.432179] Iteration 5900, train loss = 0.157720, train accuracy = 1.000000\n",
      "[2018-05-31 20:32:06.726179] Iteration 6000, train loss = 0.155864, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-05-31 20:32:17.902179] Iteration 6100, train loss = 0.185087, train accuracy = 0.976562\n",
      "[2018-05-31 20:32:27.131179] Iteration 6200, train loss = 0.155157, train accuracy = 1.000000\n",
      "[2018-05-31 20:32:36.274179] Iteration 6300, train loss = 0.158549, train accuracy = 0.992188\n",
      "[2018-05-31 20:32:45.472179] Iteration 6400, train loss = 0.144956, train accuracy = 1.000000\n",
      "[2018-05-31 20:32:54.656179] Iteration 6500, train loss = 0.172890, train accuracy = 1.000000\n",
      "[2018-05-31 20:33:03.755179] Iteration 6600, train loss = 0.169491, train accuracy = 1.000000\n",
      "[2018-05-31 20:33:12.966179] Iteration 6700, train loss = 0.164720, train accuracy = 1.000000\n",
      "[2018-05-31 20:33:22.119179] Iteration 6800, train loss = 0.148452, train accuracy = 1.000000\n",
      "[2018-05-31 20:33:31.264179] Iteration 6900, train loss = 0.158659, train accuracy = 1.000000\n",
      "[2018-05-31 20:33:40.399179] Iteration 7000, train loss = 0.156249, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-05-31 20:33:51.605179] Iteration 7100, train loss = 0.154559, train accuracy = 1.000000\n",
      "[2018-05-31 20:34:00.674179] Iteration 7200, train loss = 0.154485, train accuracy = 1.000000\n",
      "[2018-05-31 20:34:09.857179] Iteration 7300, train loss = 0.154027, train accuracy = 0.992188\n",
      "[2018-05-31 20:34:19.028179] Iteration 7400, train loss = 0.154507, train accuracy = 1.000000\n",
      "[2018-05-31 20:34:28.132179] Iteration 7500, train loss = 0.154424, train accuracy = 1.000000\n",
      "[2018-05-31 20:34:37.305179] Iteration 7600, train loss = 0.210243, train accuracy = 0.960938\n",
      "[2018-05-31 20:34:46.434179] Iteration 7700, train loss = 0.171276, train accuracy = 0.992188\n",
      "[2018-05-31 20:34:55.529179] Iteration 7800, train loss = 0.155297, train accuracy = 1.000000\n",
      "[2018-05-31 20:35:04.666179] Iteration 7900, train loss = 0.166412, train accuracy = 0.992188\n",
      "[2018-05-31 20:35:13.893179] Iteration 8000, train loss = 0.154661, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 20:35:25.034179] Iteration 8100, train loss = 0.153066, train accuracy = 1.000000\n",
      "[2018-05-31 20:35:34.271179] Iteration 8200, train loss = 0.167835, train accuracy = 0.992188\n",
      "[2018-05-31 20:35:43.425179] Iteration 8300, train loss = 0.164984, train accuracy = 1.000000\n",
      "[2018-05-31 20:35:52.580179] Iteration 8400, train loss = 0.180325, train accuracy = 0.984375\n",
      "[2018-05-31 20:36:01.748179] Iteration 8500, train loss = 0.159596, train accuracy = 1.000000\n",
      "[2018-05-31 20:36:10.934179] Iteration 8600, train loss = 0.151216, train accuracy = 1.000000\n",
      "[2018-05-31 20:36:20.185179] Iteration 8700, train loss = 0.166977, train accuracy = 1.000000\n",
      "[2018-05-31 20:36:29.333179] Iteration 8800, train loss = 0.163728, train accuracy = 0.992188\n",
      "[2018-05-31 20:36:38.534179] Iteration 8900, train loss = 0.147698, train accuracy = 1.000000\n",
      "[2018-05-31 20:36:47.654179] Iteration 9000, train loss = 0.172744, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.916400\n",
      "[2018-05-31 20:36:58.798179] Iteration 9100, train loss = 0.186294, train accuracy = 0.976562\n",
      "[2018-05-31 20:37:07.884179] Iteration 9200, train loss = 0.152014, train accuracy = 1.000000\n",
      "[2018-05-31 20:37:17.037179] Iteration 9300, train loss = 0.197883, train accuracy = 0.984375\n",
      "[2018-05-31 20:37:26.162179] Iteration 9400, train loss = 0.159971, train accuracy = 1.000000\n",
      "[2018-05-31 20:37:35.326179] Iteration 9500, train loss = 0.149544, train accuracy = 1.000000\n",
      "[2018-05-31 20:37:44.511179] Iteration 9600, train loss = 0.169355, train accuracy = 0.992188\n",
      "[2018-05-31 20:37:53.762179] Iteration 9700, train loss = 0.154577, train accuracy = 1.000000\n",
      "[2018-05-31 20:38:02.917179] Iteration 9800, train loss = 0.169247, train accuracy = 0.992188\n",
      "[2018-05-31 20:38:12.103179] Iteration 9900, train loss = 0.191153, train accuracy = 0.984375\n",
      "[2018-05-31 20:38:21.265179] Iteration 10000, train loss = 0.160691, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916100\n",
      "[2018-05-31 20:38:32.482179] Iteration 10100, train loss = 0.152912, train accuracy = 1.000000\n",
      "[2018-05-31 20:38:41.630179] Iteration 10200, train loss = 0.176868, train accuracy = 0.992188\n",
      "[2018-05-31 20:38:50.754179] Iteration 10300, train loss = 0.176335, train accuracy = 0.984375\n",
      "[2018-05-31 20:38:59.883179] Iteration 10400, train loss = 0.183509, train accuracy = 0.984375\n",
      "[2018-05-31 20:39:09.044179] Iteration 10500, train loss = 0.185274, train accuracy = 0.984375\n",
      "[2018-05-31 20:39:18.175179] Iteration 10600, train loss = 0.184805, train accuracy = 0.992188\n",
      "[2018-05-31 20:39:27.335179] Iteration 10700, train loss = 0.163161, train accuracy = 1.000000\n",
      "[2018-05-31 20:39:36.417179] Iteration 10800, train loss = 0.147481, train accuracy = 1.000000\n",
      "[2018-05-31 20:39:45.557179] Iteration 10900, train loss = 0.160983, train accuracy = 1.000000\n",
      "[2018-05-31 20:39:54.697179] Iteration 11000, train loss = 0.172125, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 20:40:05.863179] Iteration 11100, train loss = 0.190829, train accuracy = 0.984375\n",
      "[2018-05-31 20:40:14.981179] Iteration 11200, train loss = 0.155250, train accuracy = 1.000000\n",
      "[2018-05-31 20:40:24.203179] Iteration 11300, train loss = 0.193082, train accuracy = 0.976562\n",
      "[2018-05-31 20:40:33.369179] Iteration 11400, train loss = 0.154885, train accuracy = 1.000000\n",
      "[2018-05-31 20:40:42.540179] Iteration 11500, train loss = 0.157647, train accuracy = 0.992188\n",
      "[2018-05-31 20:40:51.732179] Iteration 11600, train loss = 0.158965, train accuracy = 0.992188\n",
      "[2018-05-31 20:41:00.877179] Iteration 11700, train loss = 0.176445, train accuracy = 0.976562\n",
      "[2018-05-31 20:41:10.004179] Iteration 11800, train loss = 0.174645, train accuracy = 0.992188\n",
      "[2018-05-31 20:41:19.098179] Iteration 11900, train loss = 0.155425, train accuracy = 1.000000\n",
      "[2018-05-31 20:41:28.260179] Iteration 12000, train loss = 0.197425, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-05-31 20:41:39.372179] Iteration 12100, train loss = 0.154008, train accuracy = 1.000000\n",
      "[2018-05-31 20:41:48.531179] Iteration 12200, train loss = 0.177051, train accuracy = 0.992188\n",
      "[2018-05-31 20:41:57.717179] Iteration 12300, train loss = 0.166626, train accuracy = 0.992188\n",
      "[2018-05-31 20:42:06.855179] Iteration 12400, train loss = 0.161783, train accuracy = 0.992188\n",
      "[2018-05-31 20:42:15.967179] Iteration 12500, train loss = 0.165877, train accuracy = 0.992188\n",
      "[2018-05-31 20:42:25.140179] Iteration 12600, train loss = 0.162004, train accuracy = 0.992188\n",
      "[2018-05-31 20:42:34.288179] Iteration 12700, train loss = 0.159177, train accuracy = 1.000000\n",
      "[2018-05-31 20:42:43.426179] Iteration 12800, train loss = 0.172266, train accuracy = 0.992188\n",
      "[2018-05-31 20:42:52.502179] Iteration 12900, train loss = 0.150898, train accuracy = 1.000000\n",
      "[2018-05-31 20:43:01.660179] Iteration 13000, train loss = 0.159953, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 20:43:12.766179] Iteration 13100, train loss = 0.165933, train accuracy = 0.992188\n",
      "[2018-05-31 20:43:21.884179] Iteration 13200, train loss = 0.160688, train accuracy = 0.992188\n",
      "[2018-05-31 20:43:31.028179] Iteration 13300, train loss = 0.166012, train accuracy = 1.000000\n",
      "[2018-05-31 20:43:40.133179] Iteration 13400, train loss = 0.168461, train accuracy = 0.992188\n",
      "[2018-05-31 20:43:49.337179] Iteration 13500, train loss = 0.173677, train accuracy = 0.992188\n",
      "[2018-05-31 20:43:58.524179] Iteration 13600, train loss = 0.168302, train accuracy = 0.992188\n",
      "[2018-05-31 20:44:07.667179] Iteration 13700, train loss = 0.157123, train accuracy = 1.000000\n",
      "[2018-05-31 20:44:16.823179] Iteration 13800, train loss = 0.156118, train accuracy = 1.000000\n",
      "[2018-05-31 20:44:25.955179] Iteration 13900, train loss = 0.177602, train accuracy = 0.984375\n",
      "[2018-05-31 20:44:35.123179] Iteration 14000, train loss = 0.158435, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916200\n",
      "[2018-05-31 20:44:46.296179] Iteration 14100, train loss = 0.173006, train accuracy = 0.992188\n",
      "[2018-05-31 20:44:55.438179] Iteration 14200, train loss = 0.190266, train accuracy = 0.984375\n",
      "[2018-05-31 20:45:04.632179] Iteration 14300, train loss = 0.148154, train accuracy = 1.000000\n",
      "[2018-05-31 20:45:13.711179] Iteration 14400, train loss = 0.176588, train accuracy = 0.984375\n",
      "[2018-05-31 20:45:22.916179] Iteration 14500, train loss = 0.159219, train accuracy = 1.000000\n",
      "[2018-05-31 20:45:32.102179] Iteration 14600, train loss = 0.159253, train accuracy = 1.000000\n",
      "[2018-05-31 20:45:41.250179] Iteration 14700, train loss = 0.159886, train accuracy = 1.000000\n",
      "[2018-05-31 20:45:50.342179] Iteration 14800, train loss = 0.166752, train accuracy = 1.000000\n",
      "[2018-05-31 20:45:59.455179] Iteration 14900, train loss = 0.169171, train accuracy = 0.992188\n",
      "[2018-05-31 20:46:08.573179] Iteration 15000, train loss = 0.182453, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.915500\n",
      "[2018-05-31 20:46:19.657179] Iteration 15100, train loss = 0.177479, train accuracy = 0.984375\n",
      "[2018-05-31 20:46:28.743179] Iteration 15200, train loss = 0.163625, train accuracy = 1.000000\n",
      "[2018-05-31 20:46:37.866179] Iteration 15300, train loss = 0.175989, train accuracy = 0.984375\n",
      "[2018-05-31 20:46:46.991179] Iteration 15400, train loss = 0.171794, train accuracy = 0.984375\n",
      "[2018-05-31 20:46:56.125179] Iteration 15500, train loss = 0.164577, train accuracy = 1.000000\n",
      "[2018-05-31 20:47:05.219179] Iteration 15600, train loss = 0.177600, train accuracy = 0.984375\n",
      "[2018-05-31 20:47:14.411179] Iteration 15700, train loss = 0.163212, train accuracy = 0.992188\n",
      "[2018-05-31 20:47:23.563179] Iteration 15800, train loss = 0.154586, train accuracy = 1.000000\n",
      "[2018-05-31 20:47:32.712179] Iteration 15900, train loss = 0.176714, train accuracy = 0.992188\n",
      "[2018-05-31 20:47:41.854179] Iteration 16000, train loss = 0.151936, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916200\n",
      "[2018-05-31 20:47:52.929179] Iteration 16100, train loss = 0.177222, train accuracy = 0.984375\n",
      "[2018-05-31 20:48:02.127179] Iteration 16200, train loss = 0.149225, train accuracy = 1.000000\n",
      "[2018-05-31 20:48:11.298179] Iteration 16300, train loss = 0.168545, train accuracy = 0.984375\n",
      "[2018-05-31 20:48:20.408179] Iteration 16400, train loss = 0.151179, train accuracy = 1.000000\n",
      "[2018-05-31 20:48:29.607179] Iteration 16500, train loss = 0.163462, train accuracy = 1.000000\n",
      "[2018-05-31 20:48:38.765179] Iteration 16600, train loss = 0.154222, train accuracy = 1.000000\n",
      "[2018-05-31 20:48:47.890179] Iteration 16700, train loss = 0.171264, train accuracy = 0.992188\n",
      "[2018-05-31 20:48:56.987179] Iteration 16800, train loss = 0.164974, train accuracy = 1.000000\n",
      "[2018-05-31 20:49:06.131179] Iteration 16900, train loss = 0.180153, train accuracy = 0.984375\n",
      "[2018-05-31 20:49:15.244179] Iteration 17000, train loss = 0.164187, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-05-31 20:49:26.388179] Iteration 17100, train loss = 0.166347, train accuracy = 0.992188\n",
      "[2018-05-31 20:49:35.482179] Iteration 17200, train loss = 0.152676, train accuracy = 1.000000\n",
      "[2018-05-31 20:49:44.652179] Iteration 17300, train loss = 0.176482, train accuracy = 0.976562\n",
      "[2018-05-31 20:49:53.775179] Iteration 17400, train loss = 0.185852, train accuracy = 0.984375\n",
      "[2018-05-31 20:50:02.958179] Iteration 17500, train loss = 0.193846, train accuracy = 0.976562\n",
      "[2018-05-31 20:50:12.107179] Iteration 17600, train loss = 0.177099, train accuracy = 0.992188\n",
      "[2018-05-31 20:50:21.237179] Iteration 17700, train loss = 0.177903, train accuracy = 0.984375\n",
      "[2018-05-31 20:50:30.556179] Iteration 17800, train loss = 0.177651, train accuracy = 0.992188\n",
      "[2018-05-31 20:50:39.702179] Iteration 17900, train loss = 0.154918, train accuracy = 1.000000\n",
      "[2018-05-31 20:50:48.901179] Iteration 18000, train loss = 0.154143, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915600\n",
      "[2018-05-31 20:51:00.081179] Iteration 18100, train loss = 0.165268, train accuracy = 0.992188\n",
      "[2018-05-31 20:51:09.279179] Iteration 18200, train loss = 0.173703, train accuracy = 0.984375\n",
      "[2018-05-31 20:51:18.449179] Iteration 18300, train loss = 0.183122, train accuracy = 0.976562\n",
      "[2018-05-31 20:51:27.505179] Iteration 18400, train loss = 0.161646, train accuracy = 0.992188\n",
      "[2018-05-31 20:51:36.741179] Iteration 18500, train loss = 0.147386, train accuracy = 1.000000\n",
      "[2018-05-31 20:51:45.855179] Iteration 18600, train loss = 0.153283, train accuracy = 1.000000\n",
      "[2018-05-31 20:51:55.004179] Iteration 18700, train loss = 0.146597, train accuracy = 1.000000\n",
      "[2018-05-31 20:52:04.146179] Iteration 18800, train loss = 0.157398, train accuracy = 1.000000\n",
      "[2018-05-31 20:52:13.333179] Iteration 18900, train loss = 0.167492, train accuracy = 0.992188\n",
      "[2018-05-31 20:52:22.478179] Iteration 19000, train loss = 0.160683, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916500\n",
      "[2018-05-31 20:52:33.652179] Iteration 19100, train loss = 0.173548, train accuracy = 0.984375\n",
      "[2018-05-31 20:52:42.847179] Iteration 19200, train loss = 0.157522, train accuracy = 1.000000\n",
      "[2018-05-31 20:52:52.015179] Iteration 19300, train loss = 0.169813, train accuracy = 0.984375\n",
      "[2018-05-31 20:53:01.165179] Iteration 19400, train loss = 0.180619, train accuracy = 0.992188\n",
      "[2018-05-31 20:53:10.314179] Iteration 19500, train loss = 0.156332, train accuracy = 1.000000\n",
      "[2018-05-31 20:53:19.543179] Iteration 19600, train loss = 0.157170, train accuracy = 0.992188\n",
      "[2018-05-31 20:53:28.661179] Iteration 19700, train loss = 0.188993, train accuracy = 0.984375\n",
      "[2018-05-31 20:53:37.808179] Iteration 19800, train loss = 0.170304, train accuracy = 0.992188\n",
      "[2018-05-31 20:53:46.975179] Iteration 19900, train loss = 0.150937, train accuracy = 1.000000\n",
      "[2018-05-31 20:53:56.181179] Iteration 20000, train loss = 0.159671, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916300\n",
      "[2018-05-31 20:54:07.312179] Iteration 20100, train loss = 0.159420, train accuracy = 0.992188\n",
      "[2018-05-31 20:54:16.457179] Iteration 20200, train loss = 0.185868, train accuracy = 0.976562\n",
      "[2018-05-31 20:54:25.601179] Iteration 20300, train loss = 0.152471, train accuracy = 1.000000\n",
      "[2018-05-31 20:54:34.694179] Iteration 20400, train loss = 0.156963, train accuracy = 1.000000\n",
      "[2018-05-31 20:54:43.873179] Iteration 20500, train loss = 0.150899, train accuracy = 1.000000\n",
      "[2018-05-31 20:54:53.026179] Iteration 20600, train loss = 0.158518, train accuracy = 1.000000\n",
      "[2018-05-31 20:55:02.202179] Iteration 20700, train loss = 0.158673, train accuracy = 0.992188\n",
      "[2018-05-31 20:55:11.395179] Iteration 20800, train loss = 0.153053, train accuracy = 1.000000\n",
      "[2018-05-31 20:55:20.573179] Iteration 20900, train loss = 0.165800, train accuracy = 0.992188\n",
      "[2018-05-31 20:55:29.765179] Iteration 21000, train loss = 0.160770, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-05-31 20:55:40.884179] Iteration 21100, train loss = 0.172707, train accuracy = 0.992188\n",
      "[2018-05-31 20:55:50.012179] Iteration 21200, train loss = 0.159753, train accuracy = 0.992188\n",
      "[2018-05-31 20:55:59.095179] Iteration 21300, train loss = 0.148065, train accuracy = 1.000000\n",
      "[2018-05-31 20:56:08.241179] Iteration 21400, train loss = 0.170347, train accuracy = 0.992188\n",
      "[2018-05-31 20:56:17.361179] Iteration 21500, train loss = 0.147121, train accuracy = 1.000000\n",
      "[2018-05-31 20:56:26.588179] Iteration 21600, train loss = 0.174499, train accuracy = 0.984375\n",
      "[2018-05-31 20:56:35.763179] Iteration 21700, train loss = 0.161907, train accuracy = 0.992188\n",
      "[2018-05-31 20:56:44.959179] Iteration 21800, train loss = 0.167787, train accuracy = 0.992188\n",
      "[2018-05-31 20:56:54.121179] Iteration 21900, train loss = 0.157723, train accuracy = 1.000000\n",
      "[2018-05-31 20:57:03.255179] Iteration 22000, train loss = 0.164119, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.917400\n",
      "[2018-05-31 20:57:14.381179] Iteration 22100, train loss = 0.160457, train accuracy = 1.000000\n",
      "[2018-05-31 20:57:23.450179] Iteration 22200, train loss = 0.174513, train accuracy = 0.992188\n",
      "[2018-05-31 20:57:32.576179] Iteration 22300, train loss = 0.169810, train accuracy = 0.984375\n",
      "[2018-05-31 20:57:41.722179] Iteration 22400, train loss = 0.166706, train accuracy = 1.000000\n",
      "[2018-05-31 20:57:50.904179] Iteration 22500, train loss = 0.170723, train accuracy = 0.992188\n",
      "[2018-05-31 20:58:00.039179] Iteration 22600, train loss = 0.166992, train accuracy = 1.000000\n",
      "[2018-05-31 20:58:09.208179] Iteration 22700, train loss = 0.174573, train accuracy = 0.984375\n",
      "[2018-05-31 20:58:18.389179] Iteration 22800, train loss = 0.160884, train accuracy = 0.992188\n",
      "[2018-05-31 20:58:27.552179] Iteration 22900, train loss = 0.168091, train accuracy = 0.992188\n",
      "[2018-05-31 20:58:36.699179] Iteration 23000, train loss = 0.147939, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 20:58:47.832179] Iteration 23100, train loss = 0.147452, train accuracy = 1.000000\n",
      "[2018-05-31 20:58:56.992179] Iteration 23200, train loss = 0.151864, train accuracy = 1.000000\n",
      "[2018-05-31 20:59:06.146179] Iteration 23300, train loss = 0.152147, train accuracy = 1.000000\n",
      "[2018-05-31 20:59:15.335179] Iteration 23400, train loss = 0.180347, train accuracy = 0.984375\n",
      "[2018-05-31 20:59:24.431179] Iteration 23500, train loss = 0.152968, train accuracy = 1.000000\n",
      "[2018-05-31 20:59:33.647179] Iteration 23600, train loss = 0.159852, train accuracy = 0.992188\n",
      "[2018-05-31 20:59:42.802179] Iteration 23700, train loss = 0.149502, train accuracy = 1.000000\n",
      "[2018-05-31 20:59:52.009179] Iteration 23800, train loss = 0.157968, train accuracy = 0.992188\n",
      "[2018-05-31 21:00:01.141179] Iteration 23900, train loss = 0.170215, train accuracy = 0.992188\n",
      "[2018-05-31 21:00:10.350179] Iteration 24000, train loss = 0.166182, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913400\n",
      "[2018-05-31 21:00:21.458179] Iteration 24100, train loss = 0.168636, train accuracy = 0.992188\n",
      "[2018-05-31 21:00:30.666179] Iteration 24200, train loss = 0.161609, train accuracy = 0.992188\n",
      "[2018-05-31 21:00:39.771179] Iteration 24300, train loss = 0.165682, train accuracy = 0.992188\n",
      "[2018-05-31 21:00:48.955179] Iteration 24400, train loss = 0.155577, train accuracy = 1.000000\n",
      "[2018-05-31 21:00:58.038179] Iteration 24500, train loss = 0.157387, train accuracy = 1.000000\n",
      "[2018-05-31 21:01:07.190179] Iteration 24600, train loss = 0.176824, train accuracy = 0.992188\n",
      "[2018-05-31 21:01:16.339179] Iteration 24700, train loss = 0.153897, train accuracy = 1.000000\n",
      "[2018-05-31 21:01:25.499179] Iteration 24800, train loss = 0.172047, train accuracy = 0.992188\n",
      "[2018-05-31 21:01:34.625179] Iteration 24900, train loss = 0.167095, train accuracy = 0.992188\n",
      "[2018-05-31 21:01:43.837179] Iteration 25000, train loss = 0.161101, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915300\n",
      "[2018-05-31 21:01:54.983179] Iteration 25100, train loss = 0.174112, train accuracy = 0.984375\n",
      "[2018-05-31 21:02:04.196179] Iteration 25200, train loss = 0.159221, train accuracy = 1.000000\n",
      "[2018-05-31 21:02:13.301179] Iteration 25300, train loss = 0.173664, train accuracy = 0.992188\n",
      "[2018-05-31 21:02:22.508179] Iteration 25400, train loss = 0.151304, train accuracy = 1.000000\n",
      "[2018-05-31 21:02:31.629179] Iteration 25500, train loss = 0.167093, train accuracy = 1.000000\n",
      "[2018-05-31 21:02:40.784179] Iteration 25600, train loss = 0.149847, train accuracy = 1.000000\n",
      "[2018-05-31 21:02:49.849179] Iteration 25700, train loss = 0.148659, train accuracy = 1.000000\n",
      "[2018-05-31 21:02:58.993179] Iteration 25800, train loss = 0.171310, train accuracy = 0.992188\n",
      "[2018-05-31 21:03:08.142179] Iteration 25900, train loss = 0.165217, train accuracy = 0.984375\n",
      "[2018-05-31 21:03:17.341179] Iteration 26000, train loss = 0.171703, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-05-31 21:03:28.440179] Iteration 26100, train loss = 0.149010, train accuracy = 1.000000\n",
      "[2018-05-31 21:03:37.529179] Iteration 26200, train loss = 0.157633, train accuracy = 0.992188\n",
      "[2018-05-31 21:03:46.663179] Iteration 26300, train loss = 0.165155, train accuracy = 1.000000\n",
      "[2018-05-31 21:03:55.785179] Iteration 26400, train loss = 0.175537, train accuracy = 0.984375\n",
      "[2018-05-31 21:04:04.996179] Iteration 26500, train loss = 0.165969, train accuracy = 0.992188\n",
      "[2018-05-31 21:04:14.156179] Iteration 26600, train loss = 0.168063, train accuracy = 0.992188\n",
      "[2018-05-31 21:04:23.295179] Iteration 26700, train loss = 0.171379, train accuracy = 0.992188\n",
      "[2018-05-31 21:04:32.455179] Iteration 26800, train loss = 0.152504, train accuracy = 1.000000\n",
      "[2018-05-31 21:04:41.643179] Iteration 26900, train loss = 0.158445, train accuracy = 1.000000\n",
      "[2018-05-31 21:04:50.810179] Iteration 27000, train loss = 0.170970, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 21:05:01.937179] Iteration 27100, train loss = 0.157997, train accuracy = 1.000000\n",
      "[2018-05-31 21:05:11.099179] Iteration 27200, train loss = 0.170426, train accuracy = 0.992188\n",
      "[2018-05-31 21:05:20.269179] Iteration 27300, train loss = 0.152471, train accuracy = 1.000000\n",
      "[2018-05-31 21:05:29.361179] Iteration 27400, train loss = 0.176979, train accuracy = 0.984375\n",
      "[2018-05-31 21:05:38.490179] Iteration 27500, train loss = 0.173065, train accuracy = 0.984375\n",
      "[2018-05-31 21:05:47.656179] Iteration 27600, train loss = 0.152799, train accuracy = 1.000000\n",
      "[2018-05-31 21:05:56.872179] Iteration 27700, train loss = 0.171121, train accuracy = 0.992188\n",
      "[2018-05-31 21:06:06.035179] Iteration 27800, train loss = 0.172122, train accuracy = 0.992188\n",
      "[2018-05-31 21:06:15.203179] Iteration 27900, train loss = 0.156173, train accuracy = 1.000000\n",
      "[2018-05-31 21:06:24.337179] Iteration 28000, train loss = 0.153602, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 21:06:35.522179] Iteration 28100, train loss = 0.153417, train accuracy = 1.000000\n",
      "[2018-05-31 21:06:44.632179] Iteration 28200, train loss = 0.160011, train accuracy = 0.992188\n",
      "[2018-05-31 21:06:53.811179] Iteration 28300, train loss = 0.147859, train accuracy = 1.000000\n",
      "[2018-05-31 21:07:02.979179] Iteration 28400, train loss = 0.184473, train accuracy = 0.992188\n",
      "[2018-05-31 21:07:12.093179] Iteration 28500, train loss = 0.148292, train accuracy = 1.000000\n",
      "[2018-05-31 21:07:21.260179] Iteration 28600, train loss = 0.179690, train accuracy = 0.984375\n",
      "[2018-05-31 21:07:30.446179] Iteration 28700, train loss = 0.155511, train accuracy = 1.000000\n",
      "[2018-05-31 21:07:39.603179] Iteration 28800, train loss = 0.150046, train accuracy = 1.000000\n",
      "[2018-05-31 21:07:48.896179] Iteration 28900, train loss = 0.155646, train accuracy = 1.000000\n",
      "[2018-05-31 21:07:58.069179] Iteration 29000, train loss = 0.150720, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 21:08:09.183179] Iteration 29100, train loss = 0.179000, train accuracy = 0.992188\n",
      "[2018-05-31 21:08:18.394179] Iteration 29200, train loss = 0.163019, train accuracy = 0.992188\n",
      "[2018-05-31 21:08:27.483179] Iteration 29300, train loss = 0.161750, train accuracy = 1.000000\n",
      "[2018-05-31 21:08:36.661179] Iteration 29400, train loss = 0.171336, train accuracy = 0.992188\n",
      "[2018-05-31 21:08:45.730179] Iteration 29500, train loss = 0.155165, train accuracy = 1.000000\n",
      "[2018-05-31 21:08:54.845179] Iteration 29600, train loss = 0.146899, train accuracy = 1.000000\n",
      "[2018-05-31 21:09:04.113179] Iteration 29700, train loss = 0.166277, train accuracy = 1.000000\n",
      "[2018-05-31 21:09:13.215179] Iteration 29800, train loss = 0.157859, train accuracy = 0.992188\n",
      "[2018-05-31 21:09:22.305179] Iteration 29900, train loss = 0.151433, train accuracy = 1.000000\n",
      "[2018-05-31 21:09:31.511179] Iteration 30000, train loss = 0.179772, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 21:09:42.645179] Iteration 30100, train loss = 0.168174, train accuracy = 0.992188\n",
      "[2018-05-31 21:09:51.813179] Iteration 30200, train loss = 0.151176, train accuracy = 1.000000\n",
      "[2018-05-31 21:10:00.984179] Iteration 30300, train loss = 0.156867, train accuracy = 1.000000\n",
      "[2018-05-31 21:10:10.139179] Iteration 30400, train loss = 0.157600, train accuracy = 1.000000\n",
      "[2018-05-31 21:10:19.303179] Iteration 30500, train loss = 0.161143, train accuracy = 0.992188\n",
      "[2018-05-31 21:10:28.407179] Iteration 30600, train loss = 0.181368, train accuracy = 0.984375\n",
      "[2018-05-31 21:10:37.512179] Iteration 30700, train loss = 0.165621, train accuracy = 0.992188\n",
      "[2018-05-31 21:10:46.735179] Iteration 30800, train loss = 0.163984, train accuracy = 0.992188\n",
      "[2018-05-31 21:10:55.960179] Iteration 30900, train loss = 0.148416, train accuracy = 1.000000\n",
      "[2018-05-31 21:11:05.077179] Iteration 31000, train loss = 0.181823, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-05-31 21:11:16.183179] Iteration 31100, train loss = 0.159106, train accuracy = 0.992188\n",
      "[2018-05-31 21:11:25.350179] Iteration 31200, train loss = 0.156717, train accuracy = 0.992188\n",
      "[2018-05-31 21:11:34.429179] Iteration 31300, train loss = 0.161732, train accuracy = 0.992188\n",
      "[2018-05-31 21:11:43.584179] Iteration 31400, train loss = 0.165459, train accuracy = 0.992188\n",
      "[2018-05-31 21:11:52.748179] Iteration 31500, train loss = 0.167743, train accuracy = 0.992188\n",
      "[2018-05-31 21:12:01.977179] Iteration 31600, train loss = 0.154701, train accuracy = 1.000000\n",
      "[2018-05-31 21:12:11.174179] Iteration 31700, train loss = 0.153329, train accuracy = 1.000000\n",
      "[2018-05-31 21:12:20.341179] Iteration 31800, train loss = 0.164097, train accuracy = 0.992188\n",
      "[2018-05-31 21:12:29.476179] Iteration 31900, train loss = 0.152024, train accuracy = 1.000000\n",
      "[2018-05-31 21:12:38.620179] Iteration 32000, train loss = 0.148674, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-05-31 21:12:49.741179] Iteration 32100, train loss = 0.156152, train accuracy = 0.992188\n",
      "[2018-05-31 21:12:58.891179] Iteration 32200, train loss = 0.154975, train accuracy = 1.000000\n",
      "[2018-05-31 21:13:08.035179] Iteration 32300, train loss = 0.163700, train accuracy = 0.992188\n",
      "[2018-05-31 21:13:17.119179] Iteration 32400, train loss = 0.160764, train accuracy = 1.000000\n",
      "[2018-05-31 21:13:26.221179] Iteration 32500, train loss = 0.174009, train accuracy = 0.984375\n",
      "[2018-05-31 21:13:35.362179] Iteration 32600, train loss = 0.167014, train accuracy = 0.984375\n",
      "[2018-05-31 21:13:44.504179] Iteration 32700, train loss = 0.149333, train accuracy = 1.000000\n",
      "[2018-05-31 21:13:53.598179] Iteration 32800, train loss = 0.167001, train accuracy = 0.992188\n",
      "[2018-05-31 21:14:02.730179] Iteration 32900, train loss = 0.163992, train accuracy = 0.992188\n",
      "[2018-05-31 21:14:11.847179] Iteration 33000, train loss = 0.158562, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 21:14:22.950179] Iteration 33100, train loss = 0.158797, train accuracy = 1.000000\n",
      "[2018-05-31 21:14:32.080179] Iteration 33200, train loss = 0.161159, train accuracy = 1.000000\n",
      "[2018-05-31 21:14:41.226179] Iteration 33300, train loss = 0.182914, train accuracy = 0.984375\n",
      "[2018-05-31 21:14:50.419179] Iteration 33400, train loss = 0.157015, train accuracy = 1.000000\n",
      "[2018-05-31 21:14:59.708179] Iteration 33500, train loss = 0.156194, train accuracy = 1.000000\n",
      "[2018-05-31 21:15:08.962179] Iteration 33600, train loss = 0.149554, train accuracy = 1.000000\n",
      "[2018-05-31 21:15:18.204179] Iteration 33700, train loss = 0.154431, train accuracy = 1.000000\n",
      "[2018-05-31 21:15:27.382179] Iteration 33800, train loss = 0.154463, train accuracy = 1.000000\n",
      "[2018-05-31 21:15:36.526179] Iteration 33900, train loss = 0.170201, train accuracy = 0.992188\n",
      "[2018-05-31 21:15:45.644179] Iteration 34000, train loss = 0.163301, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.916300\n",
      "[2018-05-31 21:15:56.771179] Iteration 34100, train loss = 0.161633, train accuracy = 0.992188\n",
      "[2018-05-31 21:16:05.904179] Iteration 34200, train loss = 0.160018, train accuracy = 0.992188\n",
      "[2018-05-31 21:16:15.022179] Iteration 34300, train loss = 0.174675, train accuracy = 0.984375\n",
      "[2018-05-31 21:16:24.130179] Iteration 34400, train loss = 0.180786, train accuracy = 0.992188\n",
      "[2018-05-31 21:16:33.282179] Iteration 34500, train loss = 0.162141, train accuracy = 0.992188\n",
      "[2018-05-31 21:16:42.386179] Iteration 34600, train loss = 0.154353, train accuracy = 1.000000\n",
      "[2018-05-31 21:16:51.564179] Iteration 34700, train loss = 0.170473, train accuracy = 0.984375\n",
      "[2018-05-31 21:17:00.701179] Iteration 34800, train loss = 0.205407, train accuracy = 0.976562\n",
      "[2018-05-31 21:17:09.773179] Iteration 34900, train loss = 0.177478, train accuracy = 0.984375\n",
      "[2018-05-31 21:17:18.946179] Iteration 35000, train loss = 0.157335, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 21:17:30.021179] Iteration 35100, train loss = 0.155242, train accuracy = 1.000000\n",
      "[2018-05-31 21:17:39.185179] Iteration 35200, train loss = 0.149576, train accuracy = 1.000000\n",
      "[2018-05-31 21:17:48.320179] Iteration 35300, train loss = 0.155599, train accuracy = 1.000000\n",
      "[2018-05-31 21:17:57.435179] Iteration 35400, train loss = 0.178365, train accuracy = 0.984375\n",
      "[2018-05-31 21:18:06.591179] Iteration 35500, train loss = 0.151455, train accuracy = 1.000000\n",
      "[2018-05-31 21:18:15.759179] Iteration 35600, train loss = 0.161777, train accuracy = 1.000000\n",
      "[2018-05-31 21:18:24.881179] Iteration 35700, train loss = 0.153921, train accuracy = 1.000000\n",
      "[2018-05-31 21:18:34.040179] Iteration 35800, train loss = 0.159876, train accuracy = 1.000000\n",
      "[2018-05-31 21:18:43.196179] Iteration 35900, train loss = 0.149024, train accuracy = 1.000000\n",
      "[2018-05-31 21:18:52.269179] Iteration 36000, train loss = 0.170621, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 21:19:03.355179] Iteration 36100, train loss = 0.165112, train accuracy = 0.992188\n",
      "[2018-05-31 21:19:12.563179] Iteration 36200, train loss = 0.168598, train accuracy = 0.992188\n",
      "[2018-05-31 21:19:21.716179] Iteration 36300, train loss = 0.154202, train accuracy = 1.000000\n",
      "[2018-05-31 21:19:30.823179] Iteration 36400, train loss = 0.149396, train accuracy = 1.000000\n",
      "[2018-05-31 21:19:39.994179] Iteration 36500, train loss = 0.153796, train accuracy = 1.000000\n",
      "[2018-05-31 21:19:49.108179] Iteration 36600, train loss = 0.173707, train accuracy = 0.992188\n",
      "[2018-05-31 21:19:58.309179] Iteration 36700, train loss = 0.157159, train accuracy = 0.992188\n",
      "[2018-05-31 21:20:07.428179] Iteration 36800, train loss = 0.153919, train accuracy = 1.000000\n",
      "[2018-05-31 21:20:16.615179] Iteration 36900, train loss = 0.161990, train accuracy = 0.992188\n",
      "[2018-05-31 21:20:25.739179] Iteration 37000, train loss = 0.154673, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 21:20:36.900179] Iteration 37100, train loss = 0.163954, train accuracy = 0.992188\n",
      "[2018-05-31 21:20:46.035179] Iteration 37200, train loss = 0.170476, train accuracy = 0.992188\n",
      "[2018-05-31 21:20:55.175179] Iteration 37300, train loss = 0.155891, train accuracy = 0.992188\n",
      "[2018-05-31 21:21:04.335179] Iteration 37400, train loss = 0.165256, train accuracy = 0.992188\n",
      "[2018-05-31 21:21:13.497179] Iteration 37500, train loss = 0.149620, train accuracy = 1.000000\n",
      "[2018-05-31 21:21:22.635179] Iteration 37600, train loss = 0.153927, train accuracy = 1.000000\n",
      "[2018-05-31 21:21:31.791179] Iteration 37700, train loss = 0.149395, train accuracy = 1.000000\n",
      "[2018-05-31 21:21:40.940179] Iteration 37800, train loss = 0.152033, train accuracy = 1.000000\n",
      "[2018-05-31 21:21:50.087179] Iteration 37900, train loss = 0.151046, train accuracy = 1.000000\n",
      "[2018-05-31 21:21:59.182179] Iteration 38000, train loss = 0.167292, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 21:22:10.292179] Iteration 38100, train loss = 0.153916, train accuracy = 1.000000\n",
      "[2018-05-31 21:22:19.425179] Iteration 38200, train loss = 0.150352, train accuracy = 1.000000\n",
      "[2018-05-31 21:22:28.574179] Iteration 38300, train loss = 0.149491, train accuracy = 1.000000\n",
      "[2018-05-31 21:22:37.764179] Iteration 38400, train loss = 0.150560, train accuracy = 1.000000\n",
      "[2018-05-31 21:22:46.986179] Iteration 38500, train loss = 0.151588, train accuracy = 1.000000\n",
      "[2018-05-31 21:22:56.138179] Iteration 38600, train loss = 0.162708, train accuracy = 1.000000\n",
      "[2018-05-31 21:23:05.339179] Iteration 38700, train loss = 0.162421, train accuracy = 0.992188\n",
      "[2018-05-31 21:23:14.512179] Iteration 38800, train loss = 0.147539, train accuracy = 1.000000\n",
      "[2018-05-31 21:23:23.629179] Iteration 38900, train loss = 0.162856, train accuracy = 1.000000\n",
      "[2018-05-31 21:23:32.797179] Iteration 39000, train loss = 0.172323, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-05-31 21:23:43.898179] Iteration 39100, train loss = 0.159570, train accuracy = 1.000000\n",
      "[2018-05-31 21:23:52.990179] Iteration 39200, train loss = 0.148786, train accuracy = 1.000000\n",
      "[2018-05-31 21:24:02.200179] Iteration 39300, train loss = 0.158680, train accuracy = 1.000000\n",
      "[2018-05-31 21:24:11.434179] Iteration 39400, train loss = 0.165344, train accuracy = 1.000000\n",
      "[2018-05-31 21:24:20.566179] Iteration 39500, train loss = 0.149514, train accuracy = 1.000000\n",
      "[2018-05-31 21:24:29.774179] Iteration 39600, train loss = 0.149045, train accuracy = 1.000000\n",
      "[2018-05-31 21:24:38.891179] Iteration 39700, train loss = 0.152163, train accuracy = 1.000000\n",
      "[2018-05-31 21:24:48.004179] Iteration 39800, train loss = 0.174310, train accuracy = 0.992188\n",
      "[2018-05-31 21:24:57.205179] Iteration 39900, train loss = 0.153258, train accuracy = 1.000000\n",
      "[2018-05-31 21:25:06.456179] Iteration 40000, train loss = 0.172046, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 21:25:17.497179] Iteration 40100, train loss = 0.169304, train accuracy = 0.984375\n",
      "[2018-05-31 21:25:26.594179] Iteration 40200, train loss = 0.163799, train accuracy = 1.000000\n",
      "[2018-05-31 21:25:35.779179] Iteration 40300, train loss = 0.157386, train accuracy = 0.992188\n",
      "[2018-05-31 21:25:44.980179] Iteration 40400, train loss = 0.176790, train accuracy = 0.976562\n",
      "[2018-05-31 21:25:54.140179] Iteration 40500, train loss = 0.161675, train accuracy = 0.992188\n",
      "[2018-05-31 21:26:03.323179] Iteration 40600, train loss = 0.170376, train accuracy = 0.992188\n",
      "[2018-05-31 21:26:12.453179] Iteration 40700, train loss = 0.152966, train accuracy = 0.992188\n",
      "[2018-05-31 21:26:21.649179] Iteration 40800, train loss = 0.164956, train accuracy = 0.984375\n",
      "[2018-05-31 21:26:30.720179] Iteration 40900, train loss = 0.156414, train accuracy = 1.000000\n",
      "[2018-05-31 21:26:39.850179] Iteration 41000, train loss = 0.153339, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916600\n",
      "[2018-05-31 21:26:50.957179] Iteration 41100, train loss = 0.170884, train accuracy = 0.984375\n",
      "[2018-05-31 21:27:00.052179] Iteration 41200, train loss = 0.156243, train accuracy = 1.000000\n",
      "[2018-05-31 21:27:09.164179] Iteration 41300, train loss = 0.153140, train accuracy = 1.000000\n",
      "[2018-05-31 21:27:18.284179] Iteration 41400, train loss = 0.191988, train accuracy = 0.976562\n",
      "[2018-05-31 21:27:27.409179] Iteration 41500, train loss = 0.162291, train accuracy = 0.992188\n",
      "[2018-05-31 21:27:36.595179] Iteration 41600, train loss = 0.178409, train accuracy = 0.984375\n",
      "[2018-05-31 21:27:45.679179] Iteration 41700, train loss = 0.151269, train accuracy = 1.000000\n",
      "[2018-05-31 21:27:54.860179] Iteration 41800, train loss = 0.154217, train accuracy = 1.000000\n",
      "[2018-05-31 21:28:04.006179] Iteration 41900, train loss = 0.154127, train accuracy = 1.000000\n",
      "[2018-05-31 21:28:13.194179] Iteration 42000, train loss = 0.161291, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915300\n",
      "[2018-05-31 21:28:24.355179] Iteration 42100, train loss = 0.149420, train accuracy = 1.000000\n",
      "[2018-05-31 21:28:33.506179] Iteration 42200, train loss = 0.166525, train accuracy = 1.000000\n",
      "[2018-05-31 21:28:42.671179] Iteration 42300, train loss = 0.155147, train accuracy = 1.000000\n",
      "[2018-05-31 21:28:51.799179] Iteration 42400, train loss = 0.149725, train accuracy = 1.000000\n",
      "[2018-05-31 21:29:00.980179] Iteration 42500, train loss = 0.150853, train accuracy = 1.000000\n",
      "[2018-05-31 21:29:10.129179] Iteration 42600, train loss = 0.150185, train accuracy = 1.000000\n",
      "[2018-05-31 21:29:19.316179] Iteration 42700, train loss = 0.152718, train accuracy = 1.000000\n",
      "[2018-05-31 21:29:28.466179] Iteration 42800, train loss = 0.151453, train accuracy = 1.000000\n",
      "[2018-05-31 21:29:37.676179] Iteration 42900, train loss = 0.162152, train accuracy = 1.000000\n",
      "[2018-05-31 21:29:46.784179] Iteration 43000, train loss = 0.153241, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-05-31 21:29:57.910179] Iteration 43100, train loss = 0.156150, train accuracy = 1.000000\n",
      "[2018-05-31 21:30:07.140179] Iteration 43200, train loss = 0.153921, train accuracy = 1.000000\n",
      "[2018-05-31 21:30:16.300179] Iteration 43300, train loss = 0.150141, train accuracy = 1.000000\n",
      "[2018-05-31 21:30:25.449179] Iteration 43400, train loss = 0.196174, train accuracy = 0.960938\n",
      "[2018-05-31 21:30:34.639179] Iteration 43500, train loss = 0.167290, train accuracy = 0.984375\n",
      "[2018-05-31 21:30:43.835179] Iteration 43600, train loss = 0.154608, train accuracy = 1.000000\n",
      "[2018-05-31 21:30:52.961179] Iteration 43700, train loss = 0.143402, train accuracy = 1.000000\n",
      "[2018-05-31 21:31:02.045179] Iteration 43800, train loss = 0.164150, train accuracy = 1.000000\n",
      "[2018-05-31 21:31:11.295179] Iteration 43900, train loss = 0.169168, train accuracy = 0.992188\n",
      "[2018-05-31 21:31:20.471179] Iteration 44000, train loss = 0.159820, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-05-31 21:31:31.623179] Iteration 44100, train loss = 0.156539, train accuracy = 1.000000\n",
      "[2018-05-31 21:31:40.852179] Iteration 44200, train loss = 0.148171, train accuracy = 1.000000\n",
      "[2018-05-31 21:31:50.033179] Iteration 44300, train loss = 0.159117, train accuracy = 1.000000\n",
      "[2018-05-31 21:31:59.123179] Iteration 44400, train loss = 0.160615, train accuracy = 0.992188\n",
      "[2018-05-31 21:32:08.288179] Iteration 44500, train loss = 0.169102, train accuracy = 0.984375\n",
      "[2018-05-31 21:32:17.453179] Iteration 44600, train loss = 0.162966, train accuracy = 0.992188\n",
      "[2018-05-31 21:32:26.659179] Iteration 44700, train loss = 0.164874, train accuracy = 0.992188\n",
      "[2018-05-31 21:32:35.843179] Iteration 44800, train loss = 0.152076, train accuracy = 1.000000\n",
      "[2018-05-31 21:32:45.049179] Iteration 44900, train loss = 0.186483, train accuracy = 0.968750\n",
      "[2018-05-31 21:32:54.163179] Iteration 45000, train loss = 0.149272, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-05-31 21:33:05.331179] Iteration 45100, train loss = 0.162079, train accuracy = 0.992188\n",
      "[2018-05-31 21:33:14.456179] Iteration 45200, train loss = 0.162399, train accuracy = 1.000000\n",
      "[2018-05-31 21:33:23.678179] Iteration 45300, train loss = 0.156666, train accuracy = 1.000000\n",
      "[2018-05-31 21:33:32.838179] Iteration 45400, train loss = 0.166348, train accuracy = 0.992188\n",
      "[2018-05-31 21:33:42.005179] Iteration 45500, train loss = 0.158213, train accuracy = 0.992188\n",
      "[2018-05-31 21:33:51.119179] Iteration 45600, train loss = 0.156717, train accuracy = 0.992188\n",
      "[2018-05-31 21:34:00.275179] Iteration 45700, train loss = 0.146379, train accuracy = 1.000000\n",
      "[2018-05-31 21:34:09.500179] Iteration 45800, train loss = 0.153318, train accuracy = 0.992188\n",
      "[2018-05-31 21:34:18.598179] Iteration 45900, train loss = 0.150617, train accuracy = 1.000000\n",
      "[2018-05-31 21:34:27.746179] Iteration 46000, train loss = 0.162558, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-05-31 21:34:38.848179] Iteration 46100, train loss = 0.172514, train accuracy = 0.992188\n",
      "[2018-05-31 21:34:48.000179] Iteration 46200, train loss = 0.151507, train accuracy = 1.000000\n",
      "[2018-05-31 21:34:57.176179] Iteration 46300, train loss = 0.159168, train accuracy = 1.000000\n",
      "[2018-05-31 21:35:06.405179] Iteration 46400, train loss = 0.161848, train accuracy = 1.000000\n",
      "[2018-05-31 21:35:15.562179] Iteration 46500, train loss = 0.162995, train accuracy = 1.000000\n",
      "[2018-05-31 21:35:24.745179] Iteration 46600, train loss = 0.163734, train accuracy = 0.992188\n",
      "[2018-05-31 21:35:33.894179] Iteration 46700, train loss = 0.177044, train accuracy = 0.992188\n",
      "[2018-05-31 21:35:43.044179] Iteration 46800, train loss = 0.172991, train accuracy = 0.984375\n",
      "[2018-05-31 21:35:52.183179] Iteration 46900, train loss = 0.151462, train accuracy = 1.000000\n",
      "[2018-05-31 21:36:01.421179] Iteration 47000, train loss = 0.164734, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913300\n",
      "[2018-05-31 21:36:12.588179] Iteration 47100, train loss = 0.152594, train accuracy = 1.000000\n",
      "[2018-05-31 21:36:21.811179] Iteration 47200, train loss = 0.162731, train accuracy = 0.992188\n",
      "[2018-05-31 21:36:30.969179] Iteration 47300, train loss = 0.156353, train accuracy = 0.992188\n",
      "[2018-05-31 21:36:40.168179] Iteration 47400, train loss = 0.163929, train accuracy = 0.992188\n",
      "[2018-05-31 21:36:49.353179] Iteration 47500, train loss = 0.152674, train accuracy = 1.000000\n",
      "[2018-05-31 21:36:58.496179] Iteration 47600, train loss = 0.166498, train accuracy = 0.992188\n",
      "[2018-05-31 21:37:07.678179] Iteration 47700, train loss = 0.149050, train accuracy = 1.000000\n",
      "[2018-05-31 21:37:16.859179] Iteration 47800, train loss = 0.180746, train accuracy = 0.992188\n",
      "[2018-05-31 21:37:25.955179] Iteration 47900, train loss = 0.187054, train accuracy = 0.992188\n",
      "[2018-05-31 21:37:35.124179] Iteration 48000, train loss = 0.176120, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913500\n",
      "Learning rate set to 0.001000\n",
      "[2018-05-31 21:37:46.366179] Iteration 48100, train loss = 0.175836, train accuracy = 0.984375\n",
      "[2018-05-31 21:37:55.587179] Iteration 48200, train loss = 0.152801, train accuracy = 1.000000\n",
      "[2018-05-31 21:38:04.680179] Iteration 48300, train loss = 0.152227, train accuracy = 1.000000\n",
      "[2018-05-31 21:38:13.819179] Iteration 48400, train loss = 0.156073, train accuracy = 1.000000\n",
      "[2018-05-31 21:38:23.022179] Iteration 48500, train loss = 0.150700, train accuracy = 1.000000\n",
      "[2018-05-31 21:38:32.152179] Iteration 48600, train loss = 0.159339, train accuracy = 1.000000\n",
      "[2018-05-31 21:38:41.289179] Iteration 48700, train loss = 0.167077, train accuracy = 0.992188\n",
      "[2018-05-31 21:38:50.525179] Iteration 48800, train loss = 0.180900, train accuracy = 0.984375\n",
      "[2018-05-31 21:38:59.688179] Iteration 48900, train loss = 0.161991, train accuracy = 1.000000\n",
      "[2018-05-31 21:39:08.899179] Iteration 49000, train loss = 0.149536, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 21:39:20.000179] Iteration 49100, train loss = 0.153458, train accuracy = 1.000000\n",
      "[2018-05-31 21:39:29.197179] Iteration 49200, train loss = 0.160578, train accuracy = 0.992188\n",
      "[2018-05-31 21:39:38.298179] Iteration 49300, train loss = 0.157285, train accuracy = 1.000000\n",
      "[2018-05-31 21:39:47.379179] Iteration 49400, train loss = 0.157839, train accuracy = 1.000000\n",
      "[2018-05-31 21:39:56.583179] Iteration 49500, train loss = 0.148488, train accuracy = 1.000000\n",
      "[2018-05-31 21:40:05.667179] Iteration 49600, train loss = 0.148509, train accuracy = 1.000000\n",
      "[2018-05-31 21:40:14.849179] Iteration 49700, train loss = 0.149288, train accuracy = 1.000000\n",
      "[2018-05-31 21:40:23.992179] Iteration 49800, train loss = 0.181899, train accuracy = 0.984375\n",
      "[2018-05-31 21:40:33.201179] Iteration 49900, train loss = 0.150926, train accuracy = 1.000000\n",
      "[2018-05-31 21:40:42.395179] Iteration 50000, train loss = 0.153039, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 21:40:53.676179] Iteration 50100, train loss = 0.158949, train accuracy = 1.000000\n",
      "[2018-05-31 21:41:02.851179] Iteration 50200, train loss = 0.155989, train accuracy = 1.000000\n",
      "[2018-05-31 21:41:12.037179] Iteration 50300, train loss = 0.153204, train accuracy = 1.000000\n",
      "[2018-05-31 21:41:21.181179] Iteration 50400, train loss = 0.158811, train accuracy = 0.992188\n",
      "[2018-05-31 21:41:30.256179] Iteration 50500, train loss = 0.161394, train accuracy = 1.000000\n",
      "[2018-05-31 21:41:39.400179] Iteration 50600, train loss = 0.154144, train accuracy = 0.992188\n",
      "[2018-05-31 21:41:48.557179] Iteration 50700, train loss = 0.164510, train accuracy = 0.984375\n",
      "[2018-05-31 21:41:57.756179] Iteration 50800, train loss = 0.155202, train accuracy = 1.000000\n",
      "[2018-05-31 21:42:06.930179] Iteration 50900, train loss = 0.161784, train accuracy = 0.992188\n",
      "[2018-05-31 21:42:16.073179] Iteration 51000, train loss = 0.160235, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 21:42:27.262179] Iteration 51100, train loss = 0.151246, train accuracy = 1.000000\n",
      "[2018-05-31 21:42:36.466179] Iteration 51200, train loss = 0.150922, train accuracy = 1.000000\n",
      "[2018-05-31 21:42:45.611179] Iteration 51300, train loss = 0.153096, train accuracy = 0.992188\n",
      "[2018-05-31 21:42:54.769179] Iteration 51400, train loss = 0.152881, train accuracy = 1.000000\n",
      "[2018-05-31 21:43:03.958179] Iteration 51500, train loss = 0.188822, train accuracy = 0.984375\n",
      "[2018-05-31 21:43:13.076179] Iteration 51600, train loss = 0.150382, train accuracy = 1.000000\n",
      "[2018-05-31 21:43:22.209179] Iteration 51700, train loss = 0.152960, train accuracy = 1.000000\n",
      "[2018-05-31 21:43:31.396179] Iteration 51800, train loss = 0.171808, train accuracy = 0.984375\n",
      "[2018-05-31 21:43:40.504179] Iteration 51900, train loss = 0.178516, train accuracy = 0.992188\n",
      "[2018-05-31 21:43:49.668179] Iteration 52000, train loss = 0.159100, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-05-31 21:44:00.821179] Iteration 52100, train loss = 0.153216, train accuracy = 1.000000\n",
      "[2018-05-31 21:44:10.006179] Iteration 52200, train loss = 0.160100, train accuracy = 1.000000\n",
      "[2018-05-31 21:44:19.190179] Iteration 52300, train loss = 0.153450, train accuracy = 1.000000\n",
      "[2018-05-31 21:44:28.392179] Iteration 52400, train loss = 0.153588, train accuracy = 1.000000\n",
      "[2018-05-31 21:44:37.628179] Iteration 52500, train loss = 0.150733, train accuracy = 1.000000\n",
      "[2018-05-31 21:44:46.763179] Iteration 52600, train loss = 0.167887, train accuracy = 0.992188\n",
      "[2018-05-31 21:44:55.939179] Iteration 52700, train loss = 0.166560, train accuracy = 0.992188\n",
      "[2018-05-31 21:45:05.163179] Iteration 52800, train loss = 0.151695, train accuracy = 1.000000\n",
      "[2018-05-31 21:45:14.333179] Iteration 52900, train loss = 0.153262, train accuracy = 1.000000\n",
      "[2018-05-31 21:45:23.452179] Iteration 53000, train loss = 0.153005, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 21:45:34.645179] Iteration 53100, train loss = 0.172817, train accuracy = 0.984375\n",
      "[2018-05-31 21:45:43.846179] Iteration 53200, train loss = 0.152231, train accuracy = 1.000000\n",
      "[2018-05-31 21:45:52.951179] Iteration 53300, train loss = 0.170199, train accuracy = 0.992188\n",
      "[2018-05-31 21:46:02.074179] Iteration 53400, train loss = 0.154545, train accuracy = 1.000000\n",
      "[2018-05-31 21:46:11.184179] Iteration 53500, train loss = 0.158250, train accuracy = 0.992188\n",
      "[2018-05-31 21:46:20.335179] Iteration 53600, train loss = 0.157563, train accuracy = 1.000000\n",
      "[2018-05-31 21:46:29.535179] Iteration 53700, train loss = 0.164072, train accuracy = 1.000000\n",
      "[2018-05-31 21:46:38.644179] Iteration 53800, train loss = 0.152231, train accuracy = 0.992188\n",
      "[2018-05-31 21:46:47.856179] Iteration 53900, train loss = 0.162086, train accuracy = 0.992188\n",
      "[2018-05-31 21:46:56.990179] Iteration 54000, train loss = 0.166712, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-05-31 21:47:08.135179] Iteration 54100, train loss = 0.162210, train accuracy = 1.000000\n",
      "[2018-05-31 21:47:17.327179] Iteration 54200, train loss = 0.157525, train accuracy = 1.000000\n",
      "[2018-05-31 21:47:26.553179] Iteration 54300, train loss = 0.159331, train accuracy = 1.000000\n",
      "[2018-05-31 21:47:35.696179] Iteration 54400, train loss = 0.172522, train accuracy = 0.984375\n",
      "[2018-05-31 21:47:44.900179] Iteration 54500, train loss = 0.159476, train accuracy = 0.992188\n",
      "[2018-05-31 21:47:54.145179] Iteration 54600, train loss = 0.145927, train accuracy = 1.000000\n",
      "[2018-05-31 21:48:03.303179] Iteration 54700, train loss = 0.162640, train accuracy = 1.000000\n",
      "[2018-05-31 21:48:12.363179] Iteration 54800, train loss = 0.160297, train accuracy = 1.000000\n",
      "[2018-05-31 21:48:21.595179] Iteration 54900, train loss = 0.186854, train accuracy = 0.992188\n",
      "[2018-05-31 21:48:30.789179] Iteration 55000, train loss = 0.147273, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-05-31 21:48:41.959179] Iteration 55100, train loss = 0.151820, train accuracy = 1.000000\n",
      "[2018-05-31 21:48:51.104179] Iteration 55200, train loss = 0.162402, train accuracy = 1.000000\n",
      "[2018-05-31 21:49:00.294179] Iteration 55300, train loss = 0.170115, train accuracy = 0.984375\n",
      "[2018-05-31 21:49:09.449179] Iteration 55400, train loss = 0.155316, train accuracy = 1.000000\n",
      "[2018-05-31 21:49:18.614179] Iteration 55500, train loss = 0.183379, train accuracy = 0.976562\n",
      "[2018-05-31 21:49:27.745179] Iteration 55600, train loss = 0.160254, train accuracy = 1.000000\n",
      "[2018-05-31 21:49:36.840179] Iteration 55700, train loss = 0.151627, train accuracy = 1.000000\n",
      "[2018-05-31 21:49:45.984179] Iteration 55800, train loss = 0.152464, train accuracy = 1.000000\n",
      "[2018-05-31 21:49:55.137179] Iteration 55900, train loss = 0.159888, train accuracy = 1.000000\n",
      "[2018-05-31 21:50:04.313179] Iteration 56000, train loss = 0.159093, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 21:50:15.404179] Iteration 56100, train loss = 0.184242, train accuracy = 0.984375\n",
      "[2018-05-31 21:50:24.540179] Iteration 56200, train loss = 0.153110, train accuracy = 1.000000\n",
      "[2018-05-31 21:50:33.800179] Iteration 56300, train loss = 0.159106, train accuracy = 0.992188\n",
      "[2018-05-31 21:50:42.981179] Iteration 56400, train loss = 0.162972, train accuracy = 0.992188\n",
      "[2018-05-31 21:50:52.089179] Iteration 56500, train loss = 0.163333, train accuracy = 1.000000\n",
      "[2018-05-31 21:51:01.242179] Iteration 56600, train loss = 0.161879, train accuracy = 0.992188\n",
      "[2018-05-31 21:51:10.302179] Iteration 56700, train loss = 0.159331, train accuracy = 1.000000\n",
      "[2018-05-31 21:51:19.428179] Iteration 56800, train loss = 0.185567, train accuracy = 0.992188\n",
      "[2018-05-31 21:51:28.613179] Iteration 56900, train loss = 0.149989, train accuracy = 1.000000\n",
      "[2018-05-31 21:51:37.739179] Iteration 57000, train loss = 0.163941, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 21:51:48.864179] Iteration 57100, train loss = 0.160133, train accuracy = 0.992188\n",
      "[2018-05-31 21:51:58.096179] Iteration 57200, train loss = 0.151966, train accuracy = 1.000000\n",
      "[2018-05-31 21:52:07.312179] Iteration 57300, train loss = 0.160143, train accuracy = 1.000000\n",
      "[2018-05-31 21:52:16.409179] Iteration 57400, train loss = 0.170120, train accuracy = 0.992188\n",
      "[2018-05-31 21:52:25.559179] Iteration 57500, train loss = 0.170659, train accuracy = 0.992188\n",
      "[2018-05-31 21:52:34.765179] Iteration 57600, train loss = 0.155158, train accuracy = 1.000000\n",
      "[2018-05-31 21:52:43.882179] Iteration 57700, train loss = 0.147891, train accuracy = 1.000000\n",
      "[2018-05-31 21:52:53.123179] Iteration 57800, train loss = 0.154812, train accuracy = 1.000000\n",
      "[2018-05-31 21:53:02.247179] Iteration 57900, train loss = 0.168350, train accuracy = 0.992188\n",
      "[2018-05-31 21:53:11.362179] Iteration 58000, train loss = 0.165855, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 21:53:22.489179] Iteration 58100, train loss = 0.182068, train accuracy = 0.984375\n",
      "[2018-05-31 21:53:31.680179] Iteration 58200, train loss = 0.152404, train accuracy = 1.000000\n",
      "[2018-05-31 21:53:40.853179] Iteration 58300, train loss = 0.153995, train accuracy = 1.000000\n",
      "[2018-05-31 21:53:49.983179] Iteration 58400, train loss = 0.154832, train accuracy = 1.000000\n",
      "[2018-05-31 21:53:59.167179] Iteration 58500, train loss = 0.158861, train accuracy = 1.000000\n",
      "[2018-05-31 21:54:08.314179] Iteration 58600, train loss = 0.158886, train accuracy = 0.992188\n",
      "[2018-05-31 21:54:17.489179] Iteration 58700, train loss = 0.154966, train accuracy = 1.000000\n",
      "[2018-05-31 21:54:26.674179] Iteration 58800, train loss = 0.159993, train accuracy = 1.000000\n",
      "[2018-05-31 21:54:35.863179] Iteration 58900, train loss = 0.154025, train accuracy = 1.000000\n",
      "[2018-05-31 21:54:44.997179] Iteration 59000, train loss = 0.173431, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-05-31 21:54:56.208179] Iteration 59100, train loss = 0.164312, train accuracy = 0.992188\n",
      "[2018-05-31 21:55:05.375179] Iteration 59200, train loss = 0.149251, train accuracy = 1.000000\n",
      "[2018-05-31 21:55:14.498179] Iteration 59300, train loss = 0.158492, train accuracy = 0.992188\n",
      "[2018-05-31 21:55:23.688179] Iteration 59400, train loss = 0.151460, train accuracy = 1.000000\n",
      "[2018-05-31 21:55:32.805179] Iteration 59500, train loss = 0.154444, train accuracy = 1.000000\n",
      "[2018-05-31 21:55:41.953179] Iteration 59600, train loss = 0.160072, train accuracy = 0.992188\n",
      "[2018-05-31 21:55:51.097179] Iteration 59700, train loss = 0.155253, train accuracy = 1.000000\n",
      "[2018-05-31 21:56:00.255179] Iteration 59800, train loss = 0.148837, train accuracy = 1.000000\n",
      "[2018-05-31 21:56:09.434179] Iteration 59900, train loss = 0.154891, train accuracy = 1.000000\n",
      "[2018-05-31 21:56:18.561179] Iteration 60000, train loss = 0.170719, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 21:56:29.646179] Iteration 60100, train loss = 0.154072, train accuracy = 1.000000\n",
      "[2018-05-31 21:56:38.801179] Iteration 60200, train loss = 0.153369, train accuracy = 1.000000\n",
      "[2018-05-31 21:56:47.859179] Iteration 60300, train loss = 0.156049, train accuracy = 1.000000\n",
      "[2018-05-31 21:56:56.975179] Iteration 60400, train loss = 0.162213, train accuracy = 1.000000\n",
      "[2018-05-31 21:57:06.084179] Iteration 60500, train loss = 0.157456, train accuracy = 1.000000\n",
      "[2018-05-31 21:57:15.255179] Iteration 60600, train loss = 0.160249, train accuracy = 1.000000\n",
      "[2018-05-31 21:57:24.376179] Iteration 60700, train loss = 0.156658, train accuracy = 0.992188\n",
      "[2018-05-31 21:57:33.481179] Iteration 60800, train loss = 0.146589, train accuracy = 1.000000\n",
      "[2018-05-31 21:57:42.674179] Iteration 60900, train loss = 0.169028, train accuracy = 0.992188\n",
      "[2018-05-31 21:57:51.816179] Iteration 61000, train loss = 0.149038, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-05-31 21:58:03.034179] Iteration 61100, train loss = 0.161729, train accuracy = 1.000000\n",
      "[2018-05-31 21:58:12.171179] Iteration 61200, train loss = 0.148114, train accuracy = 1.000000\n",
      "[2018-05-31 21:58:21.402179] Iteration 61300, train loss = 0.158069, train accuracy = 1.000000\n",
      "[2018-05-31 21:58:30.572179] Iteration 61400, train loss = 0.152656, train accuracy = 1.000000\n",
      "[2018-05-31 21:58:39.654179] Iteration 61500, train loss = 0.153198, train accuracy = 1.000000\n",
      "[2018-05-31 21:58:48.780179] Iteration 61600, train loss = 0.152816, train accuracy = 1.000000\n",
      "[2018-05-31 21:58:58.022179] Iteration 61700, train loss = 0.168918, train accuracy = 0.992188\n",
      "[2018-05-31 21:59:07.281179] Iteration 61800, train loss = 0.158690, train accuracy = 0.992188\n",
      "[2018-05-31 21:59:16.435179] Iteration 61900, train loss = 0.161866, train accuracy = 1.000000\n",
      "[2018-05-31 21:59:25.562179] Iteration 62000, train loss = 0.148875, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 21:59:36.726179] Iteration 62100, train loss = 0.156514, train accuracy = 1.000000\n",
      "[2018-05-31 21:59:45.898179] Iteration 62200, train loss = 0.160211, train accuracy = 0.992188\n",
      "[2018-05-31 21:59:55.012179] Iteration 62300, train loss = 0.154332, train accuracy = 1.000000\n",
      "[2018-05-31 22:00:04.171179] Iteration 62400, train loss = 0.153795, train accuracy = 1.000000\n",
      "[2018-05-31 22:00:13.267179] Iteration 62500, train loss = 0.156987, train accuracy = 0.992188\n",
      "[2018-05-31 22:00:22.458179] Iteration 62600, train loss = 0.152861, train accuracy = 1.000000\n",
      "[2018-05-31 22:00:31.661179] Iteration 62700, train loss = 0.149562, train accuracy = 1.000000\n",
      "[2018-05-31 22:00:40.853179] Iteration 62800, train loss = 0.169312, train accuracy = 0.992188\n",
      "[2018-05-31 22:00:50.023179] Iteration 62900, train loss = 0.162850, train accuracy = 1.000000\n",
      "[2018-05-31 22:00:59.257179] Iteration 63000, train loss = 0.163995, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-05-31 22:01:10.438179] Iteration 63100, train loss = 0.155683, train accuracy = 1.000000\n",
      "[2018-05-31 22:01:19.566179] Iteration 63200, train loss = 0.150965, train accuracy = 1.000000\n",
      "[2018-05-31 22:01:28.804179] Iteration 63300, train loss = 0.148867, train accuracy = 1.000000\n",
      "[2018-05-31 22:01:38.037179] Iteration 63400, train loss = 0.152637, train accuracy = 1.000000\n",
      "[2018-05-31 22:01:47.195179] Iteration 63500, train loss = 0.153062, train accuracy = 1.000000\n",
      "[2018-05-31 22:01:56.377179] Iteration 63600, train loss = 0.153200, train accuracy = 0.992188\n",
      "[2018-05-31 22:02:05.638179] Iteration 63700, train loss = 0.151752, train accuracy = 1.000000\n",
      "[2018-05-31 22:02:14.767179] Iteration 63800, train loss = 0.156112, train accuracy = 1.000000\n",
      "[2018-05-31 22:02:23.915179] Iteration 63900, train loss = 0.165252, train accuracy = 0.984375\n",
      "[2018-05-31 22:02:33.170179] Iteration 64000, train loss = 0.150023, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-05-31 22:02:44.378179] Iteration 64100, train loss = 0.158199, train accuracy = 1.000000\n",
      "[2018-05-31 22:02:53.506179] Iteration 64200, train loss = 0.146777, train accuracy = 1.000000\n",
      "[2018-05-31 22:03:02.635179] Iteration 64300, train loss = 0.153268, train accuracy = 1.000000\n",
      "[2018-05-31 22:03:11.765179] Iteration 64400, train loss = 0.153379, train accuracy = 1.000000\n",
      "[2018-05-31 22:03:20.897179] Iteration 64500, train loss = 0.157895, train accuracy = 0.992188\n",
      "[2018-05-31 22:03:30.054179] Iteration 64600, train loss = 0.157543, train accuracy = 0.992188\n",
      "[2018-05-31 22:03:39.200179] Iteration 64700, train loss = 0.160398, train accuracy = 0.992188\n",
      "[2018-05-31 22:03:48.412179] Iteration 64800, train loss = 0.159727, train accuracy = 0.992188\n",
      "[2018-05-31 22:03:57.629179] Iteration 64900, train loss = 0.168510, train accuracy = 0.992188\n",
      "[2018-05-31 22:04:06.838179] Iteration 65000, train loss = 0.164173, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 22:04:17.965179] Iteration 65100, train loss = 0.186013, train accuracy = 0.976562\n",
      "[2018-05-31 22:04:27.070179] Iteration 65200, train loss = 0.146310, train accuracy = 1.000000\n",
      "[2018-05-31 22:04:36.174179] Iteration 65300, train loss = 0.150417, train accuracy = 1.000000\n",
      "[2018-05-31 22:04:45.339179] Iteration 65400, train loss = 0.159127, train accuracy = 1.000000\n",
      "[2018-05-31 22:04:54.596179] Iteration 65500, train loss = 0.154034, train accuracy = 1.000000\n",
      "[2018-05-31 22:05:03.738179] Iteration 65600, train loss = 0.158089, train accuracy = 1.000000\n",
      "[2018-05-31 22:05:12.934179] Iteration 65700, train loss = 0.152065, train accuracy = 0.992188\n",
      "[2018-05-31 22:05:22.078179] Iteration 65800, train loss = 0.156189, train accuracy = 1.000000\n",
      "[2018-05-31 22:05:31.230179] Iteration 65900, train loss = 0.157089, train accuracy = 1.000000\n",
      "[2018-05-31 22:05:40.396179] Iteration 66000, train loss = 0.153884, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 22:05:51.561179] Iteration 66100, train loss = 0.152327, train accuracy = 1.000000\n",
      "[2018-05-31 22:06:00.740179] Iteration 66200, train loss = 0.163988, train accuracy = 1.000000\n",
      "[2018-05-31 22:06:09.892179] Iteration 66300, train loss = 0.154540, train accuracy = 1.000000\n",
      "[2018-05-31 22:06:19.006179] Iteration 66400, train loss = 0.167043, train accuracy = 0.992188\n",
      "[2018-05-31 22:06:28.172179] Iteration 66500, train loss = 0.150351, train accuracy = 1.000000\n",
      "[2018-05-31 22:06:37.292179] Iteration 66600, train loss = 0.151558, train accuracy = 0.992188\n",
      "[2018-05-31 22:06:46.501179] Iteration 66700, train loss = 0.158849, train accuracy = 1.000000\n",
      "[2018-05-31 22:06:55.647179] Iteration 66800, train loss = 0.170657, train accuracy = 1.000000\n",
      "[2018-05-31 22:07:04.785179] Iteration 66900, train loss = 0.153599, train accuracy = 1.000000\n",
      "[2018-05-31 22:07:13.978179] Iteration 67000, train loss = 0.145651, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 22:07:25.210179] Iteration 67100, train loss = 0.165761, train accuracy = 0.992188\n",
      "[2018-05-31 22:07:34.388179] Iteration 67200, train loss = 0.169358, train accuracy = 0.984375\n",
      "[2018-05-31 22:07:43.568179] Iteration 67300, train loss = 0.171270, train accuracy = 0.984375\n",
      "[2018-05-31 22:07:52.789179] Iteration 67400, train loss = 0.170828, train accuracy = 0.984375\n",
      "[2018-05-31 22:08:01.958179] Iteration 67500, train loss = 0.170310, train accuracy = 0.984375\n",
      "[2018-05-31 22:08:11.164179] Iteration 67600, train loss = 0.148864, train accuracy = 1.000000\n",
      "[2018-05-31 22:08:20.398179] Iteration 67700, train loss = 0.170263, train accuracy = 1.000000\n",
      "[2018-05-31 22:08:29.539179] Iteration 67800, train loss = 0.158898, train accuracy = 1.000000\n",
      "[2018-05-31 22:08:38.669179] Iteration 67900, train loss = 0.150498, train accuracy = 1.000000\n",
      "[2018-05-31 22:08:47.835179] Iteration 68000, train loss = 0.149510, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-05-31 22:08:58.952179] Iteration 68100, train loss = 0.151113, train accuracy = 1.000000\n",
      "[2018-05-31 22:09:08.149179] Iteration 68200, train loss = 0.176526, train accuracy = 0.984375\n",
      "[2018-05-31 22:09:17.325179] Iteration 68300, train loss = 0.146400, train accuracy = 1.000000\n",
      "[2018-05-31 22:09:26.448179] Iteration 68400, train loss = 0.159394, train accuracy = 1.000000\n",
      "[2018-05-31 22:09:35.584179] Iteration 68500, train loss = 0.162734, train accuracy = 0.992188\n",
      "[2018-05-31 22:09:44.738179] Iteration 68600, train loss = 0.152487, train accuracy = 1.000000\n",
      "[2018-05-31 22:09:53.964179] Iteration 68700, train loss = 0.155419, train accuracy = 1.000000\n",
      "[2018-05-31 22:10:03.076179] Iteration 68800, train loss = 0.155445, train accuracy = 1.000000\n",
      "[2018-05-31 22:10:12.277179] Iteration 68900, train loss = 0.162263, train accuracy = 1.000000\n",
      "[2018-05-31 22:10:21.468179] Iteration 69000, train loss = 0.149027, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 22:10:32.673179] Iteration 69100, train loss = 0.158045, train accuracy = 1.000000\n",
      "[2018-05-31 22:10:41.809179] Iteration 69200, train loss = 0.157803, train accuracy = 1.000000\n",
      "[2018-05-31 22:10:50.934179] Iteration 69300, train loss = 0.146112, train accuracy = 1.000000\n",
      "[2018-05-31 22:11:00.084179] Iteration 69400, train loss = 0.151156, train accuracy = 1.000000\n",
      "[2018-05-31 22:11:09.307179] Iteration 69500, train loss = 0.150237, train accuracy = 1.000000\n",
      "[2018-05-31 22:11:18.481179] Iteration 69600, train loss = 0.162359, train accuracy = 0.992188\n",
      "[2018-05-31 22:11:27.682179] Iteration 69700, train loss = 0.170466, train accuracy = 0.984375\n",
      "[2018-05-31 22:11:36.899179] Iteration 69800, train loss = 0.173669, train accuracy = 0.992188\n",
      "[2018-05-31 22:11:46.087179] Iteration 69900, train loss = 0.172340, train accuracy = 0.984375\n",
      "[2018-05-31 22:11:55.236179] Iteration 70000, train loss = 0.156723, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-05-31 22:12:06.408179] Iteration 70100, train loss = 0.167172, train accuracy = 0.984375\n",
      "[2018-05-31 22:12:15.642179] Iteration 70200, train loss = 0.178013, train accuracy = 0.992188\n",
      "[2018-05-31 22:12:24.844179] Iteration 70300, train loss = 0.173575, train accuracy = 0.992188\n",
      "[2018-05-31 22:12:34.041179] Iteration 70400, train loss = 0.156853, train accuracy = 1.000000\n",
      "[2018-05-31 22:12:43.137179] Iteration 70500, train loss = 0.151602, train accuracy = 1.000000\n",
      "[2018-05-31 22:12:52.349179] Iteration 70600, train loss = 0.157386, train accuracy = 1.000000\n",
      "[2018-05-31 22:13:01.519179] Iteration 70700, train loss = 0.147602, train accuracy = 1.000000\n",
      "[2018-05-31 22:13:10.658179] Iteration 70800, train loss = 0.153335, train accuracy = 1.000000\n",
      "[2018-05-31 22:13:19.773179] Iteration 70900, train loss = 0.155386, train accuracy = 1.000000\n",
      "[2018-05-31 22:13:28.923179] Iteration 71000, train loss = 0.151000, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 22:13:40.083179] Iteration 71100, train loss = 0.159577, train accuracy = 1.000000\n",
      "[2018-05-31 22:13:49.211179] Iteration 71200, train loss = 0.165430, train accuracy = 1.000000\n",
      "[2018-05-31 22:13:58.411179] Iteration 71300, train loss = 0.158311, train accuracy = 1.000000\n",
      "[2018-05-31 22:14:07.586179] Iteration 71400, train loss = 0.147409, train accuracy = 1.000000\n",
      "[2018-05-31 22:14:16.685179] Iteration 71500, train loss = 0.178640, train accuracy = 0.984375\n",
      "[2018-05-31 22:14:25.862179] Iteration 71600, train loss = 0.156705, train accuracy = 1.000000\n",
      "[2018-05-31 22:14:35.011179] Iteration 71700, train loss = 0.158239, train accuracy = 0.992188\n",
      "[2018-05-31 22:14:44.136179] Iteration 71800, train loss = 0.169914, train accuracy = 0.984375\n",
      "[2018-05-31 22:14:53.310179] Iteration 71900, train loss = 0.148482, train accuracy = 1.000000\n",
      "[2018-05-31 22:15:02.405179] Iteration 72000, train loss = 0.161139, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 22:15:13.548179] Iteration 72100, train loss = 0.162895, train accuracy = 0.992188\n",
      "[2018-05-31 22:15:22.698179] Iteration 72200, train loss = 0.165633, train accuracy = 0.992188\n",
      "[2018-05-31 22:15:31.856179] Iteration 72300, train loss = 0.151289, train accuracy = 1.000000\n",
      "[2018-05-31 22:15:41.095179] Iteration 72400, train loss = 0.167732, train accuracy = 0.992188\n",
      "[2018-05-31 22:15:50.365179] Iteration 72500, train loss = 0.157619, train accuracy = 1.000000\n",
      "[2018-05-31 22:15:59.479179] Iteration 72600, train loss = 0.144567, train accuracy = 1.000000\n",
      "[2018-05-31 22:16:08.714179] Iteration 72700, train loss = 0.154253, train accuracy = 1.000000\n",
      "[2018-05-31 22:16:17.997179] Iteration 72800, train loss = 0.178954, train accuracy = 0.984375\n",
      "[2018-05-31 22:16:27.299179] Iteration 72900, train loss = 0.157802, train accuracy = 1.000000\n",
      "[2018-05-31 22:16:36.545179] Iteration 73000, train loss = 0.166338, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-05-31 22:16:47.732179] Iteration 73100, train loss = 0.153606, train accuracy = 1.000000\n",
      "[2018-05-31 22:16:56.888179] Iteration 73200, train loss = 0.151117, train accuracy = 1.000000\n",
      "[2018-05-31 22:17:06.009179] Iteration 73300, train loss = 0.156687, train accuracy = 1.000000\n",
      "[2018-05-31 22:17:15.147179] Iteration 73400, train loss = 0.160261, train accuracy = 0.992188\n",
      "[2018-05-31 22:17:24.355179] Iteration 73500, train loss = 0.154286, train accuracy = 1.000000\n",
      "[2018-05-31 22:17:33.537179] Iteration 73600, train loss = 0.157936, train accuracy = 1.000000\n",
      "[2018-05-31 22:17:42.685179] Iteration 73700, train loss = 0.151379, train accuracy = 1.000000\n",
      "[2018-05-31 22:17:51.857179] Iteration 73800, train loss = 0.151021, train accuracy = 1.000000\n",
      "[2018-05-31 22:18:01.083179] Iteration 73900, train loss = 0.155369, train accuracy = 1.000000\n",
      "[2018-05-31 22:18:10.174179] Iteration 74000, train loss = 0.168835, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 22:18:21.293179] Iteration 74100, train loss = 0.163867, train accuracy = 1.000000\n",
      "[2018-05-31 22:18:30.512179] Iteration 74200, train loss = 0.157907, train accuracy = 1.000000\n",
      "[2018-05-31 22:18:39.686179] Iteration 74300, train loss = 0.162110, train accuracy = 0.992188\n",
      "[2018-05-31 22:18:48.830179] Iteration 74400, train loss = 0.163104, train accuracy = 1.000000\n",
      "[2018-05-31 22:18:58.010179] Iteration 74500, train loss = 0.149693, train accuracy = 1.000000\n",
      "[2018-05-31 22:19:07.152179] Iteration 74600, train loss = 0.147188, train accuracy = 1.000000\n",
      "[2018-05-31 22:19:16.332179] Iteration 74700, train loss = 0.165400, train accuracy = 0.992188\n",
      "[2018-05-31 22:19:25.478179] Iteration 74800, train loss = 0.159878, train accuracy = 0.992188\n",
      "[2018-05-31 22:19:34.594179] Iteration 74900, train loss = 0.147424, train accuracy = 1.000000\n",
      "[2018-05-31 22:19:43.793179] Iteration 75000, train loss = 0.148233, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-05-31 22:19:54.940179] Iteration 75100, train loss = 0.166251, train accuracy = 0.992188\n",
      "[2018-05-31 22:20:04.070179] Iteration 75200, train loss = 0.150554, train accuracy = 1.000000\n",
      "[2018-05-31 22:20:13.252179] Iteration 75300, train loss = 0.163179, train accuracy = 0.992188\n",
      "[2018-05-31 22:20:22.418179] Iteration 75400, train loss = 0.149684, train accuracy = 1.000000\n",
      "[2018-05-31 22:20:31.579179] Iteration 75500, train loss = 0.152459, train accuracy = 1.000000\n",
      "[2018-05-31 22:20:40.855179] Iteration 75600, train loss = 0.155431, train accuracy = 1.000000\n",
      "[2018-05-31 22:20:49.998179] Iteration 75700, train loss = 0.160294, train accuracy = 1.000000\n",
      "[2018-05-31 22:20:59.210179] Iteration 75800, train loss = 0.157175, train accuracy = 0.992188\n",
      "[2018-05-31 22:21:08.393179] Iteration 75900, train loss = 0.150695, train accuracy = 1.000000\n",
      "[2018-05-31 22:21:17.545179] Iteration 76000, train loss = 0.170142, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 22:21:28.761179] Iteration 76100, train loss = 0.153954, train accuracy = 1.000000\n",
      "[2018-05-31 22:21:37.871179] Iteration 76200, train loss = 0.154611, train accuracy = 1.000000\n",
      "[2018-05-31 22:21:47.016179] Iteration 76300, train loss = 0.159514, train accuracy = 1.000000\n",
      "[2018-05-31 22:21:56.203179] Iteration 76400, train loss = 0.152732, train accuracy = 1.000000\n",
      "[2018-05-31 22:22:05.448179] Iteration 76500, train loss = 0.157139, train accuracy = 1.000000\n",
      "[2018-05-31 22:22:14.629179] Iteration 76600, train loss = 0.151238, train accuracy = 1.000000\n",
      "[2018-05-31 22:22:23.791179] Iteration 76700, train loss = 0.155242, train accuracy = 1.000000\n",
      "[2018-05-31 22:22:33.029179] Iteration 76800, train loss = 0.148161, train accuracy = 1.000000\n",
      "[2018-05-31 22:22:42.141179] Iteration 76900, train loss = 0.157223, train accuracy = 1.000000\n",
      "[2018-05-31 22:22:51.328179] Iteration 77000, train loss = 0.159622, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 22:23:02.460179] Iteration 77100, train loss = 0.149431, train accuracy = 1.000000\n",
      "[2018-05-31 22:23:11.635179] Iteration 77200, train loss = 0.157501, train accuracy = 1.000000\n",
      "[2018-05-31 22:23:20.844179] Iteration 77300, train loss = 0.148030, train accuracy = 1.000000\n",
      "[2018-05-31 22:23:30.000179] Iteration 77400, train loss = 0.154272, train accuracy = 1.000000\n",
      "[2018-05-31 22:23:39.176179] Iteration 77500, train loss = 0.157714, train accuracy = 1.000000\n",
      "[2018-05-31 22:23:48.413179] Iteration 77600, train loss = 0.155729, train accuracy = 1.000000\n",
      "[2018-05-31 22:23:57.518179] Iteration 77700, train loss = 0.160827, train accuracy = 0.992188\n",
      "[2018-05-31 22:24:06.688179] Iteration 77800, train loss = 0.161209, train accuracy = 1.000000\n",
      "[2018-05-31 22:24:15.827179] Iteration 77900, train loss = 0.164265, train accuracy = 0.992188\n",
      "[2018-05-31 22:24:24.946179] Iteration 78000, train loss = 0.166177, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-05-31 22:24:36.101179] Iteration 78100, train loss = 0.152199, train accuracy = 1.000000\n",
      "[2018-05-31 22:24:45.288179] Iteration 78200, train loss = 0.150759, train accuracy = 1.000000\n",
      "[2018-05-31 22:24:54.454179] Iteration 78300, train loss = 0.160397, train accuracy = 0.992188\n",
      "[2018-05-31 22:25:03.605179] Iteration 78400, train loss = 0.185705, train accuracy = 0.992188\n",
      "[2018-05-31 22:25:12.773179] Iteration 78500, train loss = 0.159758, train accuracy = 1.000000\n",
      "[2018-05-31 22:25:21.891179] Iteration 78600, train loss = 0.157362, train accuracy = 0.992188\n",
      "[2018-05-31 22:25:31.096179] Iteration 78700, train loss = 0.165120, train accuracy = 0.984375\n",
      "[2018-05-31 22:25:40.311179] Iteration 78800, train loss = 0.152343, train accuracy = 1.000000\n",
      "[2018-05-31 22:25:49.516179] Iteration 78900, train loss = 0.181722, train accuracy = 0.976562\n",
      "[2018-05-31 22:25:58.756179] Iteration 79000, train loss = 0.152389, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 22:26:09.899179] Iteration 79100, train loss = 0.167615, train accuracy = 1.000000\n",
      "[2018-05-31 22:26:19.045179] Iteration 79200, train loss = 0.195367, train accuracy = 0.984375\n",
      "[2018-05-31 22:26:28.177179] Iteration 79300, train loss = 0.156391, train accuracy = 1.000000\n",
      "[2018-05-31 22:26:37.364179] Iteration 79400, train loss = 0.178746, train accuracy = 0.984375\n",
      "[2018-05-31 22:26:46.494179] Iteration 79500, train loss = 0.187076, train accuracy = 0.984375\n",
      "[2018-05-31 22:26:55.650179] Iteration 79600, train loss = 0.153446, train accuracy = 1.000000\n",
      "[2018-05-31 22:27:04.788179] Iteration 79700, train loss = 0.154000, train accuracy = 1.000000\n",
      "[2018-05-31 22:27:13.914179] Iteration 79800, train loss = 0.152854, train accuracy = 1.000000\n",
      "[2018-05-31 22:27:23.062179] Iteration 79900, train loss = 0.152834, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三轮  量化\n",
    "prune_rate = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.914800\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.03125     0.125       0.0625     -0.03569455\n",
      "  0.01388224 -0.0625      0.04664616 -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.75时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,0.85)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-05-31 22:28:55.211179] Iteration 100, train loss = 0.156757, train accuracy = 1.000000\n",
      "[2018-05-31 22:29:04.412179] Iteration 200, train loss = 0.152015, train accuracy = 1.000000\n",
      "[2018-05-31 22:29:13.544179] Iteration 300, train loss = 0.185140, train accuracy = 0.976562\n",
      "[2018-05-31 22:29:22.874179] Iteration 400, train loss = 0.166822, train accuracy = 0.984375\n",
      "[2018-05-31 22:29:32.108179] Iteration 500, train loss = 0.157782, train accuracy = 1.000000\n",
      "[2018-05-31 22:29:41.258179] Iteration 600, train loss = 0.170761, train accuracy = 1.000000\n",
      "[2018-05-31 22:29:50.380179] Iteration 700, train loss = 0.166418, train accuracy = 0.992188\n",
      "[2018-05-31 22:29:59.504179] Iteration 800, train loss = 0.166498, train accuracy = 1.000000\n",
      "[2018-05-31 22:30:08.667179] Iteration 900, train loss = 0.173670, train accuracy = 0.992188\n",
      "[2018-05-31 22:30:17.854179] Iteration 1000, train loss = 0.159718, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 22:30:28.988179] Iteration 1100, train loss = 0.154124, train accuracy = 1.000000\n",
      "[2018-05-31 22:30:38.114179] Iteration 1200, train loss = 0.157162, train accuracy = 1.000000\n",
      "[2018-05-31 22:30:47.294179] Iteration 1300, train loss = 0.173860, train accuracy = 0.992188\n",
      "[2018-05-31 22:30:56.389179] Iteration 1400, train loss = 0.148503, train accuracy = 1.000000\n",
      "[2018-05-31 22:31:05.513179] Iteration 1500, train loss = 0.165441, train accuracy = 0.984375\n",
      "[2018-05-31 22:31:14.655179] Iteration 1600, train loss = 0.156091, train accuracy = 1.000000\n",
      "[2018-05-31 22:31:23.806179] Iteration 1700, train loss = 0.185456, train accuracy = 0.984375\n",
      "[2018-05-31 22:31:32.911179] Iteration 1800, train loss = 0.152060, train accuracy = 1.000000\n",
      "[2018-05-31 22:31:42.033179] Iteration 1900, train loss = 0.151617, train accuracy = 1.000000\n",
      "[2018-05-31 22:31:51.210179] Iteration 2000, train loss = 0.161670, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 22:32:02.323179] Iteration 2100, train loss = 0.158802, train accuracy = 1.000000\n",
      "[2018-05-31 22:32:11.462179] Iteration 2200, train loss = 0.165184, train accuracy = 0.992188\n",
      "[2018-05-31 22:32:20.593179] Iteration 2300, train loss = 0.164305, train accuracy = 0.992188\n",
      "[2018-05-31 22:32:29.710179] Iteration 2400, train loss = 0.154681, train accuracy = 1.000000\n",
      "[2018-05-31 22:32:38.854179] Iteration 2500, train loss = 0.165934, train accuracy = 0.992188\n",
      "[2018-05-31 22:32:48.064179] Iteration 2600, train loss = 0.155777, train accuracy = 1.000000\n",
      "[2018-05-31 22:32:57.256179] Iteration 2700, train loss = 0.159666, train accuracy = 1.000000\n",
      "[2018-05-31 22:33:06.349179] Iteration 2800, train loss = 0.166405, train accuracy = 0.984375\n",
      "[2018-05-31 22:33:15.581179] Iteration 2900, train loss = 0.171595, train accuracy = 0.992188\n",
      "[2018-05-31 22:33:24.724179] Iteration 3000, train loss = 0.151898, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913600\n",
      "[2018-05-31 22:33:35.980179] Iteration 3100, train loss = 0.158784, train accuracy = 1.000000\n",
      "[2018-05-31 22:33:45.119179] Iteration 3200, train loss = 0.162010, train accuracy = 1.000000\n",
      "[2018-05-31 22:33:54.227179] Iteration 3300, train loss = 0.164015, train accuracy = 1.000000\n",
      "[2018-05-31 22:34:03.366179] Iteration 3400, train loss = 0.158124, train accuracy = 1.000000\n",
      "[2018-05-31 22:34:12.499179] Iteration 3500, train loss = 0.154889, train accuracy = 1.000000\n",
      "[2018-05-31 22:34:21.670179] Iteration 3600, train loss = 0.156579, train accuracy = 0.992188\n",
      "[2018-05-31 22:34:30.838179] Iteration 3700, train loss = 0.162923, train accuracy = 0.984375\n",
      "[2018-05-31 22:34:40.060179] Iteration 3800, train loss = 0.155203, train accuracy = 1.000000\n",
      "[2018-05-31 22:34:49.249179] Iteration 3900, train loss = 0.152288, train accuracy = 1.000000\n",
      "[2018-05-31 22:34:58.390179] Iteration 4000, train loss = 0.161590, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-05-31 22:35:09.508179] Iteration 4100, train loss = 0.156447, train accuracy = 1.000000\n",
      "[2018-05-31 22:35:18.688179] Iteration 4200, train loss = 0.148523, train accuracy = 1.000000\n",
      "[2018-05-31 22:35:27.844179] Iteration 4300, train loss = 0.163978, train accuracy = 1.000000\n",
      "[2018-05-31 22:35:36.995179] Iteration 4400, train loss = 0.147254, train accuracy = 1.000000\n",
      "[2018-05-31 22:35:46.262179] Iteration 4500, train loss = 0.154620, train accuracy = 1.000000\n",
      "[2018-05-31 22:35:55.385179] Iteration 4600, train loss = 0.172674, train accuracy = 0.984375\n",
      "[2018-05-31 22:36:04.545179] Iteration 4700, train loss = 0.162418, train accuracy = 0.992188\n",
      "[2018-05-31 22:36:13.686179] Iteration 4800, train loss = 0.150709, train accuracy = 1.000000\n",
      "[2018-05-31 22:36:22.834179] Iteration 4900, train loss = 0.176882, train accuracy = 0.976562\n",
      "[2018-05-31 22:36:31.991179] Iteration 5000, train loss = 0.158081, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 22:36:43.211179] Iteration 5100, train loss = 0.156115, train accuracy = 1.000000\n",
      "[2018-05-31 22:36:52.426179] Iteration 5200, train loss = 0.158225, train accuracy = 0.992188\n",
      "[2018-05-31 22:37:01.577179] Iteration 5300, train loss = 0.163406, train accuracy = 0.992188\n",
      "[2018-05-31 22:37:10.680179] Iteration 5400, train loss = 0.189355, train accuracy = 0.984375\n",
      "[2018-05-31 22:37:19.842179] Iteration 5500, train loss = 0.159843, train accuracy = 0.992188\n",
      "[2018-05-31 22:37:29.019179] Iteration 5600, train loss = 0.189696, train accuracy = 0.984375\n",
      "[2018-05-31 22:37:38.201179] Iteration 5700, train loss = 0.152238, train accuracy = 1.000000\n",
      "[2018-05-31 22:37:47.342179] Iteration 5800, train loss = 0.172633, train accuracy = 1.000000\n",
      "[2018-05-31 22:37:56.494179] Iteration 5900, train loss = 0.168344, train accuracy = 0.984375\n",
      "[2018-05-31 22:38:05.655179] Iteration 6000, train loss = 0.160395, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 22:38:16.795179] Iteration 6100, train loss = 0.163707, train accuracy = 0.992188\n",
      "[2018-05-31 22:38:26.006179] Iteration 6200, train loss = 0.150040, train accuracy = 1.000000\n",
      "[2018-05-31 22:38:35.191179] Iteration 6300, train loss = 0.160594, train accuracy = 0.992188\n",
      "[2018-05-31 22:38:44.370179] Iteration 6400, train loss = 0.156418, train accuracy = 1.000000\n",
      "[2018-05-31 22:38:53.572179] Iteration 6500, train loss = 0.182212, train accuracy = 0.984375\n",
      "[2018-05-31 22:39:02.801179] Iteration 6600, train loss = 0.155877, train accuracy = 1.000000\n",
      "[2018-05-31 22:39:11.884179] Iteration 6700, train loss = 0.157518, train accuracy = 0.992188\n",
      "[2018-05-31 22:39:21.024179] Iteration 6800, train loss = 0.153041, train accuracy = 1.000000\n",
      "[2018-05-31 22:39:30.257179] Iteration 6900, train loss = 0.163873, train accuracy = 0.992188\n",
      "[2018-05-31 22:39:39.423179] Iteration 7000, train loss = 0.162583, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-05-31 22:39:50.506179] Iteration 7100, train loss = 0.171127, train accuracy = 1.000000\n",
      "[2018-05-31 22:39:59.707179] Iteration 7200, train loss = 0.162740, train accuracy = 0.992188\n",
      "[2018-05-31 22:40:08.913179] Iteration 7300, train loss = 0.158043, train accuracy = 1.000000\n",
      "[2018-05-31 22:40:18.030179] Iteration 7400, train loss = 0.160830, train accuracy = 0.992188\n",
      "[2018-05-31 22:40:27.243179] Iteration 7500, train loss = 0.175059, train accuracy = 0.984375\n",
      "[2018-05-31 22:40:36.354179] Iteration 7600, train loss = 0.156700, train accuracy = 1.000000\n",
      "[2018-05-31 22:40:45.528179] Iteration 7700, train loss = 0.154656, train accuracy = 1.000000\n",
      "[2018-05-31 22:40:54.733179] Iteration 7800, train loss = 0.160860, train accuracy = 0.992188\n",
      "[2018-05-31 22:41:03.955179] Iteration 7900, train loss = 0.152894, train accuracy = 1.000000\n",
      "[2018-05-31 22:41:13.106179] Iteration 8000, train loss = 0.159106, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-05-31 22:41:24.254179] Iteration 8100, train loss = 0.156375, train accuracy = 1.000000\n",
      "[2018-05-31 22:41:33.389179] Iteration 8200, train loss = 0.157493, train accuracy = 1.000000\n",
      "[2018-05-31 22:41:42.609179] Iteration 8300, train loss = 0.155559, train accuracy = 1.000000\n",
      "[2018-05-31 22:41:51.727179] Iteration 8400, train loss = 0.152543, train accuracy = 1.000000\n",
      "[2018-05-31 22:42:00.912179] Iteration 8500, train loss = 0.156190, train accuracy = 0.992188\n",
      "[2018-05-31 22:42:09.988179] Iteration 8600, train loss = 0.169274, train accuracy = 0.992188\n",
      "[2018-05-31 22:42:19.133179] Iteration 8700, train loss = 0.150192, train accuracy = 1.000000\n",
      "[2018-05-31 22:42:28.304179] Iteration 8800, train loss = 0.147614, train accuracy = 1.000000\n",
      "[2018-05-31 22:42:37.502179] Iteration 8900, train loss = 0.159095, train accuracy = 1.000000\n",
      "[2018-05-31 22:42:46.628179] Iteration 9000, train loss = 0.182706, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 22:42:57.748179] Iteration 9100, train loss = 0.160996, train accuracy = 1.000000\n",
      "[2018-05-31 22:43:06.914179] Iteration 9200, train loss = 0.158261, train accuracy = 0.992188\n",
      "[2018-05-31 22:43:16.056179] Iteration 9300, train loss = 0.169044, train accuracy = 0.992188\n",
      "[2018-05-31 22:43:25.201179] Iteration 9400, train loss = 0.173241, train accuracy = 0.992188\n",
      "[2018-05-31 22:43:34.334179] Iteration 9500, train loss = 0.166861, train accuracy = 1.000000\n",
      "[2018-05-31 22:43:43.483179] Iteration 9600, train loss = 0.171553, train accuracy = 0.992188\n",
      "[2018-05-31 22:43:52.622179] Iteration 9700, train loss = 0.158241, train accuracy = 0.992188\n",
      "[2018-05-31 22:44:01.833179] Iteration 9800, train loss = 0.179211, train accuracy = 0.984375\n",
      "[2018-05-31 22:44:10.977179] Iteration 9900, train loss = 0.173461, train accuracy = 0.992188\n",
      "[2018-05-31 22:44:20.131179] Iteration 10000, train loss = 0.182234, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 22:44:31.316179] Iteration 10100, train loss = 0.159855, train accuracy = 1.000000\n",
      "[2018-05-31 22:44:40.464179] Iteration 10200, train loss = 0.150733, train accuracy = 1.000000\n",
      "[2018-05-31 22:44:49.634179] Iteration 10300, train loss = 0.159630, train accuracy = 1.000000\n",
      "[2018-05-31 22:44:58.826179] Iteration 10400, train loss = 0.169451, train accuracy = 0.992188\n",
      "[2018-05-31 22:45:07.899179] Iteration 10500, train loss = 0.149164, train accuracy = 1.000000\n",
      "[2018-05-31 22:45:17.038179] Iteration 10600, train loss = 0.177531, train accuracy = 0.984375\n",
      "[2018-05-31 22:45:26.233179] Iteration 10700, train loss = 0.157647, train accuracy = 1.000000\n",
      "[2018-05-31 22:45:35.322179] Iteration 10800, train loss = 0.145940, train accuracy = 1.000000\n",
      "[2018-05-31 22:45:44.456179] Iteration 10900, train loss = 0.163818, train accuracy = 0.984375\n",
      "[2018-05-31 22:45:53.641179] Iteration 11000, train loss = 0.154287, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914000\n",
      "[2018-05-31 22:46:04.826179] Iteration 11100, train loss = 0.165738, train accuracy = 0.992188\n",
      "[2018-05-31 22:46:13.964179] Iteration 11200, train loss = 0.182488, train accuracy = 0.984375\n",
      "[2018-05-31 22:46:23.038179] Iteration 11300, train loss = 0.164463, train accuracy = 0.992188\n",
      "[2018-05-31 22:46:32.216179] Iteration 11400, train loss = 0.158277, train accuracy = 0.992188\n",
      "[2018-05-31 22:46:41.372179] Iteration 11500, train loss = 0.173490, train accuracy = 0.984375\n",
      "[2018-05-31 22:46:50.523179] Iteration 11600, train loss = 0.160655, train accuracy = 1.000000\n",
      "[2018-05-31 22:46:59.660179] Iteration 11700, train loss = 0.168601, train accuracy = 0.984375\n",
      "[2018-05-31 22:47:08.827179] Iteration 11800, train loss = 0.170764, train accuracy = 0.984375\n",
      "[2018-05-31 22:47:18.003179] Iteration 11900, train loss = 0.149714, train accuracy = 1.000000\n",
      "[2018-05-31 22:47:27.180179] Iteration 12000, train loss = 0.158370, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-05-31 22:47:38.252179] Iteration 12100, train loss = 0.150005, train accuracy = 1.000000\n",
      "[2018-05-31 22:47:47.366179] Iteration 12200, train loss = 0.164969, train accuracy = 1.000000\n",
      "[2018-05-31 22:47:56.571179] Iteration 12300, train loss = 0.161418, train accuracy = 1.000000\n",
      "[2018-05-31 22:48:05.720179] Iteration 12400, train loss = 0.164110, train accuracy = 1.000000\n",
      "[2018-05-31 22:48:14.854179] Iteration 12500, train loss = 0.151280, train accuracy = 1.000000\n",
      "[2018-05-31 22:48:23.960179] Iteration 12600, train loss = 0.154547, train accuracy = 1.000000\n",
      "[2018-05-31 22:48:33.104179] Iteration 12700, train loss = 0.162803, train accuracy = 1.000000\n",
      "[2018-05-31 22:48:42.264179] Iteration 12800, train loss = 0.153560, train accuracy = 1.000000\n",
      "[2018-05-31 22:48:51.353179] Iteration 12900, train loss = 0.151618, train accuracy = 1.000000\n",
      "[2018-05-31 22:49:00.474179] Iteration 13000, train loss = 0.167694, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914100\n",
      "[2018-05-31 22:49:11.562179] Iteration 13100, train loss = 0.184619, train accuracy = 0.984375\n",
      "[2018-05-31 22:49:20.716179] Iteration 13200, train loss = 0.161235, train accuracy = 0.992188\n",
      "[2018-05-31 22:49:29.862179] Iteration 13300, train loss = 0.157488, train accuracy = 0.992188\n",
      "[2018-05-31 22:49:38.991179] Iteration 13400, train loss = 0.172524, train accuracy = 0.992188\n",
      "[2018-05-31 22:49:48.265179] Iteration 13500, train loss = 0.148082, train accuracy = 1.000000\n",
      "[2018-05-31 22:49:57.377179] Iteration 13600, train loss = 0.165363, train accuracy = 1.000000\n",
      "[2018-05-31 22:50:06.548179] Iteration 13700, train loss = 0.152779, train accuracy = 1.000000\n",
      "[2018-05-31 22:50:15.678179] Iteration 13800, train loss = 0.151388, train accuracy = 1.000000\n",
      "[2018-05-31 22:50:24.833179] Iteration 13900, train loss = 0.177840, train accuracy = 0.992188\n",
      "[2018-05-31 22:50:34.030179] Iteration 14000, train loss = 0.163922, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 22:50:45.169179] Iteration 14100, train loss = 0.168108, train accuracy = 0.992188\n",
      "[2018-05-31 22:50:54.285179] Iteration 14200, train loss = 0.158277, train accuracy = 0.992188\n",
      "[2018-05-31 22:51:03.379179] Iteration 14300, train loss = 0.154458, train accuracy = 1.000000\n",
      "[2018-05-31 22:51:12.539179] Iteration 14400, train loss = 0.156913, train accuracy = 1.000000\n",
      "[2018-05-31 22:51:21.699179] Iteration 14500, train loss = 0.154955, train accuracy = 1.000000\n",
      "[2018-05-31 22:51:30.824179] Iteration 14600, train loss = 0.164748, train accuracy = 1.000000\n",
      "[2018-05-31 22:51:39.909179] Iteration 14700, train loss = 0.174515, train accuracy = 0.984375\n",
      "[2018-05-31 22:51:49.088179] Iteration 14800, train loss = 0.161769, train accuracy = 1.000000\n",
      "[2018-05-31 22:51:58.249179] Iteration 14900, train loss = 0.149254, train accuracy = 1.000000\n",
      "[2018-05-31 22:52:07.387179] Iteration 15000, train loss = 0.168789, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 22:52:18.581179] Iteration 15100, train loss = 0.159935, train accuracy = 0.992188\n",
      "[2018-05-31 22:52:27.774179] Iteration 15200, train loss = 0.181643, train accuracy = 0.984375\n",
      "[2018-05-31 22:52:36.913179] Iteration 15300, train loss = 0.177765, train accuracy = 0.984375\n",
      "[2018-05-31 22:52:45.996179] Iteration 15400, train loss = 0.160560, train accuracy = 1.000000\n",
      "[2018-05-31 22:52:55.116179] Iteration 15500, train loss = 0.164775, train accuracy = 1.000000\n",
      "[2018-05-31 22:53:04.276179] Iteration 15600, train loss = 0.158620, train accuracy = 0.992188\n",
      "[2018-05-31 22:53:13.420179] Iteration 15700, train loss = 0.155989, train accuracy = 1.000000\n",
      "[2018-05-31 22:53:22.602179] Iteration 15800, train loss = 0.151765, train accuracy = 1.000000\n",
      "[2018-05-31 22:53:31.747179] Iteration 15900, train loss = 0.152651, train accuracy = 1.000000\n",
      "[2018-05-31 22:53:40.910179] Iteration 16000, train loss = 0.150095, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 22:53:52.067179] Iteration 16100, train loss = 0.158910, train accuracy = 1.000000\n",
      "[2018-05-31 22:54:01.203179] Iteration 16200, train loss = 0.149614, train accuracy = 1.000000\n",
      "[2018-05-31 22:54:10.376179] Iteration 16300, train loss = 0.165126, train accuracy = 0.992188\n",
      "[2018-05-31 22:54:19.571179] Iteration 16400, train loss = 0.168551, train accuracy = 0.992188\n",
      "[2018-05-31 22:54:28.642179] Iteration 16500, train loss = 0.166690, train accuracy = 0.992188\n",
      "[2018-05-31 22:54:37.756179] Iteration 16600, train loss = 0.153129, train accuracy = 1.000000\n",
      "[2018-05-31 22:54:46.979179] Iteration 16700, train loss = 0.151854, train accuracy = 1.000000\n",
      "[2018-05-31 22:54:56.133179] Iteration 16800, train loss = 0.156776, train accuracy = 1.000000\n",
      "[2018-05-31 22:55:05.317179] Iteration 16900, train loss = 0.185883, train accuracy = 0.984375\n",
      "[2018-05-31 22:55:14.483179] Iteration 17000, train loss = 0.158275, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-05-31 22:55:25.665179] Iteration 17100, train loss = 0.146699, train accuracy = 1.000000\n",
      "[2018-05-31 22:55:34.819179] Iteration 17200, train loss = 0.153684, train accuracy = 1.000000\n",
      "[2018-05-31 22:55:44.061179] Iteration 17300, train loss = 0.159788, train accuracy = 1.000000\n",
      "[2018-05-31 22:55:53.236179] Iteration 17400, train loss = 0.164545, train accuracy = 1.000000\n",
      "[2018-05-31 22:56:02.424179] Iteration 17500, train loss = 0.201233, train accuracy = 0.984375\n",
      "[2018-05-31 22:56:11.590179] Iteration 17600, train loss = 0.154365, train accuracy = 1.000000\n",
      "[2018-05-31 22:56:20.752179] Iteration 17700, train loss = 0.165393, train accuracy = 0.992188\n",
      "[2018-05-31 22:56:29.985179] Iteration 17800, train loss = 0.177708, train accuracy = 0.984375\n",
      "[2018-05-31 22:56:39.053179] Iteration 17900, train loss = 0.165606, train accuracy = 0.992188\n",
      "[2018-05-31 22:56:48.237179] Iteration 18000, train loss = 0.150944, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-05-31 22:56:59.462179] Iteration 18100, train loss = 0.168217, train accuracy = 1.000000\n",
      "[2018-05-31 22:57:08.553179] Iteration 18200, train loss = 0.158384, train accuracy = 1.000000\n",
      "[2018-05-31 22:57:17.688179] Iteration 18300, train loss = 0.184459, train accuracy = 0.984375\n",
      "[2018-05-31 22:57:26.918179] Iteration 18400, train loss = 0.155012, train accuracy = 1.000000\n",
      "[2018-05-31 22:57:36.090179] Iteration 18500, train loss = 0.158923, train accuracy = 0.992188\n",
      "[2018-05-31 22:57:45.228179] Iteration 18600, train loss = 0.153450, train accuracy = 1.000000\n",
      "[2018-05-31 22:57:54.334179] Iteration 18700, train loss = 0.148071, train accuracy = 1.000000\n",
      "[2018-05-31 22:58:03.400179] Iteration 18800, train loss = 0.169090, train accuracy = 0.992188\n",
      "[2018-05-31 22:58:12.533179] Iteration 18900, train loss = 0.164948, train accuracy = 0.992188\n",
      "[2018-05-31 22:58:21.615179] Iteration 19000, train loss = 0.159391, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 22:58:32.723179] Iteration 19100, train loss = 0.158095, train accuracy = 1.000000\n",
      "[2018-05-31 22:58:41.921179] Iteration 19200, train loss = 0.156305, train accuracy = 1.000000\n",
      "[2018-05-31 22:58:51.065179] Iteration 19300, train loss = 0.189190, train accuracy = 0.976562\n",
      "[2018-05-31 22:59:00.221179] Iteration 19400, train loss = 0.160508, train accuracy = 1.000000\n",
      "[2018-05-31 22:59:09.331179] Iteration 19500, train loss = 0.164784, train accuracy = 0.992188\n",
      "[2018-05-31 22:59:18.539179] Iteration 19600, train loss = 0.167427, train accuracy = 1.000000\n",
      "[2018-05-31 22:59:27.636179] Iteration 19700, train loss = 0.159739, train accuracy = 1.000000\n",
      "[2018-05-31 22:59:36.795179] Iteration 19800, train loss = 0.166279, train accuracy = 0.992188\n",
      "[2018-05-31 22:59:45.959179] Iteration 19900, train loss = 0.155191, train accuracy = 1.000000\n",
      "[2018-05-31 22:59:55.108179] Iteration 20000, train loss = 0.154194, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-05-31 23:00:06.264179] Iteration 20100, train loss = 0.163542, train accuracy = 1.000000\n",
      "[2018-05-31 23:00:15.414179] Iteration 20200, train loss = 0.165068, train accuracy = 1.000000\n",
      "[2018-05-31 23:00:24.531179] Iteration 20300, train loss = 0.166408, train accuracy = 0.992188\n",
      "[2018-05-31 23:00:33.672179] Iteration 20400, train loss = 0.152820, train accuracy = 1.000000\n",
      "[2018-05-31 23:00:42.831179] Iteration 20500, train loss = 0.155503, train accuracy = 1.000000\n",
      "[2018-05-31 23:00:52.060179] Iteration 20600, train loss = 0.149081, train accuracy = 1.000000\n",
      "[2018-05-31 23:01:01.246179] Iteration 20700, train loss = 0.157912, train accuracy = 1.000000\n",
      "[2018-05-31 23:01:10.390179] Iteration 20800, train loss = 0.147250, train accuracy = 1.000000\n",
      "[2018-05-31 23:01:19.591179] Iteration 20900, train loss = 0.165679, train accuracy = 0.992188\n",
      "[2018-05-31 23:01:28.671179] Iteration 21000, train loss = 0.176207, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 23:01:39.812179] Iteration 21100, train loss = 0.160733, train accuracy = 1.000000\n",
      "[2018-05-31 23:01:49.035179] Iteration 21200, train loss = 0.163288, train accuracy = 0.984375\n",
      "[2018-05-31 23:01:58.138179] Iteration 21300, train loss = 0.181002, train accuracy = 0.992188\n",
      "[2018-05-31 23:02:07.258179] Iteration 21400, train loss = 0.173157, train accuracy = 0.992188\n",
      "[2018-05-31 23:02:16.479179] Iteration 21500, train loss = 0.148739, train accuracy = 1.000000\n",
      "[2018-05-31 23:02:25.555179] Iteration 21600, train loss = 0.159308, train accuracy = 0.992188\n",
      "[2018-05-31 23:02:34.755179] Iteration 21700, train loss = 0.170014, train accuracy = 1.000000\n",
      "[2018-05-31 23:02:43.869179] Iteration 21800, train loss = 0.161316, train accuracy = 1.000000\n",
      "[2018-05-31 23:02:53.092179] Iteration 21900, train loss = 0.152109, train accuracy = 1.000000\n",
      "[2018-05-31 23:03:02.248179] Iteration 22000, train loss = 0.152554, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 23:03:13.387179] Iteration 22100, train loss = 0.170858, train accuracy = 0.992188\n",
      "[2018-05-31 23:03:22.507179] Iteration 22200, train loss = 0.154065, train accuracy = 0.992188\n",
      "[2018-05-31 23:03:31.695179] Iteration 22300, train loss = 0.173838, train accuracy = 0.992188\n",
      "[2018-05-31 23:03:40.940179] Iteration 22400, train loss = 0.159242, train accuracy = 1.000000\n",
      "[2018-05-31 23:03:50.119179] Iteration 22500, train loss = 0.171136, train accuracy = 0.992188\n",
      "[2018-05-31 23:03:59.353179] Iteration 22600, train loss = 0.167506, train accuracy = 0.992188\n",
      "[2018-05-31 23:04:08.470179] Iteration 22700, train loss = 0.159334, train accuracy = 1.000000\n",
      "[2018-05-31 23:04:17.676179] Iteration 22800, train loss = 0.175020, train accuracy = 0.992188\n",
      "[2018-05-31 23:04:26.883179] Iteration 22900, train loss = 0.150348, train accuracy = 1.000000\n",
      "[2018-05-31 23:04:36.060179] Iteration 23000, train loss = 0.161062, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-05-31 23:04:47.180179] Iteration 23100, train loss = 0.163460, train accuracy = 0.992188\n",
      "[2018-05-31 23:04:56.330179] Iteration 23200, train loss = 0.155991, train accuracy = 1.000000\n",
      "[2018-05-31 23:05:05.556179] Iteration 23300, train loss = 0.149262, train accuracy = 1.000000\n",
      "[2018-05-31 23:05:14.738179] Iteration 23400, train loss = 0.150466, train accuracy = 1.000000\n",
      "[2018-05-31 23:05:23.864179] Iteration 23500, train loss = 0.178331, train accuracy = 0.976562\n",
      "[2018-05-31 23:05:33.058179] Iteration 23600, train loss = 0.177731, train accuracy = 0.984375\n",
      "[2018-05-31 23:05:42.195179] Iteration 23700, train loss = 0.150302, train accuracy = 1.000000\n",
      "[2018-05-31 23:05:51.335179] Iteration 23800, train loss = 0.162562, train accuracy = 0.992188\n",
      "[2018-05-31 23:06:00.460179] Iteration 23900, train loss = 0.160144, train accuracy = 1.000000\n",
      "[2018-05-31 23:06:09.545179] Iteration 24000, train loss = 0.157054, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913500\n",
      "[2018-05-31 23:06:20.577179] Iteration 24100, train loss = 0.166954, train accuracy = 0.992188\n",
      "[2018-05-31 23:06:29.756179] Iteration 24200, train loss = 0.155748, train accuracy = 0.992188\n",
      "[2018-05-31 23:06:38.915179] Iteration 24300, train loss = 0.156083, train accuracy = 1.000000\n",
      "[2018-05-31 23:06:48.059179] Iteration 24400, train loss = 0.152810, train accuracy = 1.000000\n",
      "[2018-05-31 23:06:57.179179] Iteration 24500, train loss = 0.155862, train accuracy = 1.000000\n",
      "[2018-05-31 23:07:06.297179] Iteration 24600, train loss = 0.179745, train accuracy = 0.992188\n",
      "[2018-05-31 23:07:15.452179] Iteration 24700, train loss = 0.155136, train accuracy = 1.000000\n",
      "[2018-05-31 23:07:24.576179] Iteration 24800, train loss = 0.152488, train accuracy = 1.000000\n",
      "[2018-05-31 23:07:33.741179] Iteration 24900, train loss = 0.168854, train accuracy = 1.000000\n",
      "[2018-05-31 23:07:42.859179] Iteration 25000, train loss = 0.154120, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-05-31 23:07:53.953179] Iteration 25100, train loss = 0.155489, train accuracy = 1.000000\n",
      "[2018-05-31 23:08:03.091179] Iteration 25200, train loss = 0.168396, train accuracy = 0.992188\n",
      "[2018-05-31 23:08:12.215179] Iteration 25300, train loss = 0.157254, train accuracy = 0.992188\n",
      "[2018-05-31 23:08:21.332179] Iteration 25400, train loss = 0.151388, train accuracy = 1.000000\n",
      "[2018-05-31 23:08:30.517179] Iteration 25500, train loss = 0.178383, train accuracy = 0.992188\n",
      "[2018-05-31 23:08:39.734179] Iteration 25600, train loss = 0.147808, train accuracy = 1.000000\n",
      "[2018-05-31 23:08:48.859179] Iteration 25700, train loss = 0.157437, train accuracy = 1.000000\n",
      "[2018-05-31 23:08:58.047179] Iteration 25800, train loss = 0.162089, train accuracy = 0.992188\n",
      "[2018-05-31 23:09:07.310179] Iteration 25900, train loss = 0.174996, train accuracy = 0.992188\n",
      "[2018-05-31 23:09:16.421179] Iteration 26000, train loss = 0.149500, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 23:09:27.549179] Iteration 26100, train loss = 0.157641, train accuracy = 1.000000\n",
      "[2018-05-31 23:09:36.721179] Iteration 26200, train loss = 0.158074, train accuracy = 1.000000\n",
      "[2018-05-31 23:09:45.866179] Iteration 26300, train loss = 0.153782, train accuracy = 1.000000\n",
      "[2018-05-31 23:09:55.124179] Iteration 26400, train loss = 0.206907, train accuracy = 0.976562\n",
      "[2018-05-31 23:10:04.311179] Iteration 26500, train loss = 0.155986, train accuracy = 0.992188\n",
      "[2018-05-31 23:10:13.513179] Iteration 26600, train loss = 0.153861, train accuracy = 1.000000\n",
      "[2018-05-31 23:10:22.640179] Iteration 26700, train loss = 0.160690, train accuracy = 0.992188\n",
      "[2018-05-31 23:10:31.819179] Iteration 26800, train loss = 0.158115, train accuracy = 1.000000\n",
      "[2018-05-31 23:10:40.972179] Iteration 26900, train loss = 0.150330, train accuracy = 1.000000\n",
      "[2018-05-31 23:10:50.091179] Iteration 27000, train loss = 0.150147, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-05-31 23:11:01.189179] Iteration 27100, train loss = 0.177406, train accuracy = 0.992188\n",
      "[2018-05-31 23:11:10.374179] Iteration 27200, train loss = 0.180196, train accuracy = 0.992188\n",
      "[2018-05-31 23:11:19.578179] Iteration 27300, train loss = 0.147759, train accuracy = 1.000000\n",
      "[2018-05-31 23:11:28.731179] Iteration 27400, train loss = 0.154305, train accuracy = 1.000000\n",
      "[2018-05-31 23:11:37.870179] Iteration 27500, train loss = 0.164553, train accuracy = 1.000000\n",
      "[2018-05-31 23:11:46.965179] Iteration 27600, train loss = 0.153202, train accuracy = 1.000000\n",
      "[2018-05-31 23:11:56.131179] Iteration 27700, train loss = 0.155041, train accuracy = 1.000000\n",
      "[2018-05-31 23:12:05.301179] Iteration 27800, train loss = 0.193619, train accuracy = 0.984375\n",
      "[2018-05-31 23:12:14.439179] Iteration 27900, train loss = 0.150427, train accuracy = 1.000000\n",
      "[2018-05-31 23:12:23.629179] Iteration 28000, train loss = 0.147712, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 23:12:34.717179] Iteration 28100, train loss = 0.163237, train accuracy = 0.992188\n",
      "[2018-05-31 23:12:43.943179] Iteration 28200, train loss = 0.191281, train accuracy = 0.992188\n",
      "[2018-05-31 23:12:53.098179] Iteration 28300, train loss = 0.163508, train accuracy = 0.992188\n",
      "[2018-05-31 23:13:02.327179] Iteration 28400, train loss = 0.159224, train accuracy = 1.000000\n",
      "[2018-05-31 23:13:11.509179] Iteration 28500, train loss = 0.156871, train accuracy = 1.000000\n",
      "[2018-05-31 23:13:20.698179] Iteration 28600, train loss = 0.149494, train accuracy = 1.000000\n",
      "[2018-05-31 23:13:29.880179] Iteration 28700, train loss = 0.154651, train accuracy = 1.000000\n",
      "[2018-05-31 23:13:39.015179] Iteration 28800, train loss = 0.168400, train accuracy = 0.992188\n",
      "[2018-05-31 23:13:48.224179] Iteration 28900, train loss = 0.152087, train accuracy = 1.000000\n",
      "[2018-05-31 23:13:57.377179] Iteration 29000, train loss = 0.201055, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.913000\n",
      "[2018-05-31 23:14:08.579179] Iteration 29100, train loss = 0.155207, train accuracy = 1.000000\n",
      "[2018-05-31 23:14:17.751179] Iteration 29200, train loss = 0.155696, train accuracy = 1.000000\n",
      "[2018-05-31 23:14:26.912179] Iteration 29300, train loss = 0.152681, train accuracy = 1.000000\n",
      "[2018-05-31 23:14:36.175179] Iteration 29400, train loss = 0.160149, train accuracy = 1.000000\n",
      "[2018-05-31 23:14:45.304179] Iteration 29500, train loss = 0.155397, train accuracy = 0.992188\n",
      "[2018-05-31 23:14:54.435179] Iteration 29600, train loss = 0.152799, train accuracy = 1.000000\n",
      "[2018-05-31 23:15:03.551179] Iteration 29700, train loss = 0.154102, train accuracy = 1.000000\n",
      "[2018-05-31 23:15:12.692179] Iteration 29800, train loss = 0.157853, train accuracy = 1.000000\n",
      "[2018-05-31 23:15:21.792179] Iteration 29900, train loss = 0.147834, train accuracy = 1.000000\n",
      "[2018-05-31 23:15:31.036179] Iteration 30000, train loss = 0.163561, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913200\n",
      "[2018-05-31 23:15:42.222179] Iteration 30100, train loss = 0.168401, train accuracy = 0.992188\n",
      "[2018-05-31 23:15:51.369179] Iteration 30200, train loss = 0.166958, train accuracy = 0.992188\n",
      "[2018-05-31 23:16:00.457179] Iteration 30300, train loss = 0.158482, train accuracy = 0.992188\n",
      "[2018-05-31 23:16:09.568179] Iteration 30400, train loss = 0.151480, train accuracy = 1.000000\n",
      "[2018-05-31 23:16:18.713179] Iteration 30500, train loss = 0.153897, train accuracy = 1.000000\n",
      "[2018-05-31 23:16:27.871179] Iteration 30600, train loss = 0.179593, train accuracy = 0.984375\n",
      "[2018-05-31 23:16:36.996179] Iteration 30700, train loss = 0.153169, train accuracy = 0.992188\n",
      "[2018-05-31 23:16:46.125179] Iteration 30800, train loss = 0.161794, train accuracy = 1.000000\n",
      "[2018-05-31 23:16:55.354179] Iteration 30900, train loss = 0.161394, train accuracy = 0.992188\n",
      "[2018-05-31 23:17:04.496179] Iteration 31000, train loss = 0.170186, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 23:17:15.593179] Iteration 31100, train loss = 0.151385, train accuracy = 1.000000\n",
      "[2018-05-31 23:17:24.711179] Iteration 31200, train loss = 0.161964, train accuracy = 0.992188\n",
      "[2018-05-31 23:17:33.897179] Iteration 31300, train loss = 0.151158, train accuracy = 1.000000\n",
      "[2018-05-31 23:17:42.999179] Iteration 31400, train loss = 0.156611, train accuracy = 1.000000\n",
      "[2018-05-31 23:17:52.145179] Iteration 31500, train loss = 0.151418, train accuracy = 1.000000\n",
      "[2018-05-31 23:18:01.313179] Iteration 31600, train loss = 0.148523, train accuracy = 1.000000\n",
      "[2018-05-31 23:18:10.450179] Iteration 31700, train loss = 0.160061, train accuracy = 0.992188\n",
      "[2018-05-31 23:18:19.584179] Iteration 31800, train loss = 0.164166, train accuracy = 0.992188\n",
      "[2018-05-31 23:18:28.810179] Iteration 31900, train loss = 0.194407, train accuracy = 0.984375\n",
      "[2018-05-31 23:18:37.997179] Iteration 32000, train loss = 0.169211, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.913500\n",
      "[2018-05-31 23:18:49.178179] Iteration 32100, train loss = 0.145751, train accuracy = 1.000000\n",
      "[2018-05-31 23:18:58.330179] Iteration 32200, train loss = 0.155556, train accuracy = 1.000000\n",
      "[2018-05-31 23:19:07.444179] Iteration 32300, train loss = 0.158094, train accuracy = 1.000000\n",
      "[2018-05-31 23:19:16.599179] Iteration 32400, train loss = 0.167066, train accuracy = 0.984375\n",
      "[2018-05-31 23:19:25.778179] Iteration 32500, train loss = 0.174736, train accuracy = 0.984375\n",
      "[2018-05-31 23:19:34.892179] Iteration 32600, train loss = 0.148034, train accuracy = 1.000000\n",
      "[2018-05-31 23:19:44.029179] Iteration 32700, train loss = 0.149303, train accuracy = 1.000000\n",
      "[2018-05-31 23:19:53.170179] Iteration 32800, train loss = 0.153415, train accuracy = 1.000000\n",
      "[2018-05-31 23:20:02.374179] Iteration 32900, train loss = 0.163930, train accuracy = 1.000000\n",
      "[2018-05-31 23:20:11.572179] Iteration 33000, train loss = 0.149485, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-05-31 23:20:22.650179] Iteration 33100, train loss = 0.150900, train accuracy = 1.000000\n",
      "[2018-05-31 23:20:31.771179] Iteration 33200, train loss = 0.176427, train accuracy = 0.992188\n",
      "[2018-05-31 23:20:40.952179] Iteration 33300, train loss = 0.151506, train accuracy = 1.000000\n",
      "[2018-05-31 23:20:50.104179] Iteration 33400, train loss = 0.149452, train accuracy = 1.000000\n",
      "[2018-05-31 23:20:59.304179] Iteration 33500, train loss = 0.151233, train accuracy = 1.000000\n",
      "[2018-05-31 23:21:08.480179] Iteration 33600, train loss = 0.149017, train accuracy = 1.000000\n",
      "[2018-05-31 23:21:17.644179] Iteration 33700, train loss = 0.149585, train accuracy = 1.000000\n",
      "[2018-05-31 23:21:26.755179] Iteration 33800, train loss = 0.153537, train accuracy = 1.000000\n",
      "[2018-05-31 23:21:35.968179] Iteration 33900, train loss = 0.172704, train accuracy = 0.984375\n",
      "[2018-05-31 23:21:45.115179] Iteration 34000, train loss = 0.155948, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913700\n",
      "[2018-05-31 23:21:56.268179] Iteration 34100, train loss = 0.153868, train accuracy = 0.992188\n",
      "[2018-05-31 23:22:05.428179] Iteration 34200, train loss = 0.167744, train accuracy = 0.992188\n",
      "[2018-05-31 23:22:14.591179] Iteration 34300, train loss = 0.156965, train accuracy = 1.000000\n",
      "[2018-05-31 23:22:23.795179] Iteration 34400, train loss = 0.150492, train accuracy = 1.000000\n",
      "[2018-05-31 23:22:32.926179] Iteration 34500, train loss = 0.173421, train accuracy = 0.992188\n",
      "[2018-05-31 23:22:42.042179] Iteration 34600, train loss = 0.159238, train accuracy = 0.992188\n",
      "[2018-05-31 23:22:51.111179] Iteration 34700, train loss = 0.157880, train accuracy = 1.000000\n",
      "[2018-05-31 23:23:00.204179] Iteration 34800, train loss = 0.148933, train accuracy = 1.000000\n",
      "[2018-05-31 23:23:09.364179] Iteration 34900, train loss = 0.156755, train accuracy = 1.000000\n",
      "[2018-05-31 23:23:18.608179] Iteration 35000, train loss = 0.151253, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 23:23:29.753179] Iteration 35100, train loss = 0.162379, train accuracy = 0.992188\n",
      "[2018-05-31 23:23:38.881179] Iteration 35200, train loss = 0.150242, train accuracy = 1.000000\n",
      "[2018-05-31 23:23:48.019179] Iteration 35300, train loss = 0.157902, train accuracy = 1.000000\n",
      "[2018-05-31 23:23:57.187179] Iteration 35400, train loss = 0.151058, train accuracy = 1.000000\n",
      "[2018-05-31 23:24:06.357179] Iteration 35500, train loss = 0.147356, train accuracy = 1.000000\n",
      "[2018-05-31 23:24:15.502179] Iteration 35600, train loss = 0.152061, train accuracy = 1.000000\n",
      "[2018-05-31 23:24:24.697179] Iteration 35700, train loss = 0.148400, train accuracy = 1.000000\n",
      "[2018-05-31 23:24:33.797179] Iteration 35800, train loss = 0.188732, train accuracy = 0.968750\n",
      "[2018-05-31 23:24:42.936179] Iteration 35900, train loss = 0.167999, train accuracy = 0.992188\n",
      "[2018-05-31 23:24:52.150179] Iteration 36000, train loss = 0.155336, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 23:25:03.365179] Iteration 36100, train loss = 0.176170, train accuracy = 0.984375\n",
      "[2018-05-31 23:25:12.477179] Iteration 36200, train loss = 0.157072, train accuracy = 1.000000\n",
      "[2018-05-31 23:25:21.633179] Iteration 36300, train loss = 0.153206, train accuracy = 1.000000\n",
      "[2018-05-31 23:25:30.817179] Iteration 36400, train loss = 0.150247, train accuracy = 1.000000\n",
      "[2018-05-31 23:25:40.032179] Iteration 36500, train loss = 0.166238, train accuracy = 0.992188\n",
      "[2018-05-31 23:25:49.193179] Iteration 36600, train loss = 0.151739, train accuracy = 1.000000\n",
      "[2018-05-31 23:25:58.319179] Iteration 36700, train loss = 0.155629, train accuracy = 1.000000\n",
      "[2018-05-31 23:26:07.440179] Iteration 36800, train loss = 0.158556, train accuracy = 1.000000\n",
      "[2018-05-31 23:26:16.548179] Iteration 36900, train loss = 0.151922, train accuracy = 1.000000\n",
      "[2018-05-31 23:26:25.674179] Iteration 37000, train loss = 0.157337, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 23:26:36.799179] Iteration 37100, train loss = 0.161545, train accuracy = 1.000000\n",
      "[2018-05-31 23:26:45.988179] Iteration 37200, train loss = 0.161020, train accuracy = 1.000000\n",
      "[2018-05-31 23:26:55.118179] Iteration 37300, train loss = 0.146479, train accuracy = 1.000000\n",
      "[2018-05-31 23:27:04.296179] Iteration 37400, train loss = 0.152237, train accuracy = 1.000000\n",
      "[2018-05-31 23:27:13.425179] Iteration 37500, train loss = 0.171422, train accuracy = 0.992188\n",
      "[2018-05-31 23:27:22.586179] Iteration 37600, train loss = 0.153141, train accuracy = 1.000000\n",
      "[2018-05-31 23:27:31.746179] Iteration 37700, train loss = 0.157395, train accuracy = 0.992188\n",
      "[2018-05-31 23:27:40.861179] Iteration 37800, train loss = 0.170361, train accuracy = 0.992188\n",
      "[2018-05-31 23:27:49.961179] Iteration 37900, train loss = 0.168658, train accuracy = 0.992188\n",
      "[2018-05-31 23:27:59.149179] Iteration 38000, train loss = 0.165645, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 23:28:10.334179] Iteration 38100, train loss = 0.156130, train accuracy = 1.000000\n",
      "[2018-05-31 23:28:19.430179] Iteration 38200, train loss = 0.156122, train accuracy = 1.000000\n",
      "[2018-05-31 23:28:28.564179] Iteration 38300, train loss = 0.148629, train accuracy = 1.000000\n",
      "[2018-05-31 23:28:37.722179] Iteration 38400, train loss = 0.189965, train accuracy = 0.992188\n",
      "[2018-05-31 23:28:46.914179] Iteration 38500, train loss = 0.165428, train accuracy = 0.992188\n",
      "[2018-05-31 23:28:56.029179] Iteration 38600, train loss = 0.151581, train accuracy = 1.000000\n",
      "[2018-05-31 23:29:05.195179] Iteration 38700, train loss = 0.152493, train accuracy = 1.000000\n",
      "[2018-05-31 23:29:14.467179] Iteration 38800, train loss = 0.160116, train accuracy = 1.000000\n",
      "[2018-05-31 23:29:23.618179] Iteration 38900, train loss = 0.173372, train accuracy = 0.984375\n",
      "[2018-05-31 23:29:32.813179] Iteration 39000, train loss = 0.167834, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 23:29:43.952179] Iteration 39100, train loss = 0.161228, train accuracy = 0.992188\n",
      "[2018-05-31 23:29:53.062179] Iteration 39200, train loss = 0.176248, train accuracy = 0.992188\n",
      "[2018-05-31 23:30:02.287179] Iteration 39300, train loss = 0.155297, train accuracy = 1.000000\n",
      "[2018-05-31 23:30:11.410179] Iteration 39400, train loss = 0.165945, train accuracy = 0.992188\n",
      "[2018-05-31 23:30:20.628179] Iteration 39500, train loss = 0.157959, train accuracy = 0.992188\n",
      "[2018-05-31 23:30:29.756179] Iteration 39600, train loss = 0.164998, train accuracy = 1.000000\n",
      "[2018-05-31 23:30:38.898179] Iteration 39700, train loss = 0.187193, train accuracy = 0.984375\n",
      "[2018-05-31 23:30:48.011179] Iteration 39800, train loss = 0.155554, train accuracy = 1.000000\n",
      "[2018-05-31 23:30:57.192179] Iteration 39900, train loss = 0.157403, train accuracy = 1.000000\n",
      "[2018-05-31 23:31:06.449179] Iteration 40000, train loss = 0.161522, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914300\n",
      "[2018-05-31 23:31:17.551179] Iteration 40100, train loss = 0.162738, train accuracy = 0.992188\n",
      "[2018-05-31 23:31:26.623179] Iteration 40200, train loss = 0.152582, train accuracy = 0.992188\n",
      "[2018-05-31 23:31:35.754179] Iteration 40300, train loss = 0.179792, train accuracy = 0.984375\n",
      "[2018-05-31 23:31:44.942179] Iteration 40400, train loss = 0.151210, train accuracy = 1.000000\n",
      "[2018-05-31 23:31:54.104179] Iteration 40500, train loss = 0.173466, train accuracy = 0.992188\n",
      "[2018-05-31 23:32:03.226179] Iteration 40600, train loss = 0.163752, train accuracy = 0.992188\n",
      "[2018-05-31 23:32:12.342179] Iteration 40700, train loss = 0.159150, train accuracy = 1.000000\n",
      "[2018-05-31 23:32:21.516179] Iteration 40800, train loss = 0.164088, train accuracy = 0.992188\n",
      "[2018-05-31 23:32:30.632179] Iteration 40900, train loss = 0.151315, train accuracy = 1.000000\n",
      "[2018-05-31 23:32:39.831179] Iteration 41000, train loss = 0.152037, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 23:32:50.989179] Iteration 41100, train loss = 0.161353, train accuracy = 1.000000\n",
      "[2018-05-31 23:33:00.168179] Iteration 41200, train loss = 0.156955, train accuracy = 1.000000\n",
      "[2018-05-31 23:33:09.332179] Iteration 41300, train loss = 0.151617, train accuracy = 1.000000\n",
      "[2018-05-31 23:33:18.501179] Iteration 41400, train loss = 0.160509, train accuracy = 0.992188\n",
      "[2018-05-31 23:33:27.619179] Iteration 41500, train loss = 0.169741, train accuracy = 0.992188\n",
      "[2018-05-31 23:33:36.820179] Iteration 41600, train loss = 0.158187, train accuracy = 1.000000\n",
      "[2018-05-31 23:33:45.946179] Iteration 41700, train loss = 0.165706, train accuracy = 0.992188\n",
      "[2018-05-31 23:33:55.084179] Iteration 41800, train loss = 0.175969, train accuracy = 0.984375\n",
      "[2018-05-31 23:34:04.373179] Iteration 41900, train loss = 0.159808, train accuracy = 1.000000\n",
      "[2018-05-31 23:34:13.434179] Iteration 42000, train loss = 0.154053, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 23:34:24.593179] Iteration 42100, train loss = 0.160609, train accuracy = 0.992188\n",
      "[2018-05-31 23:34:33.725179] Iteration 42200, train loss = 0.159291, train accuracy = 1.000000\n",
      "[2018-05-31 23:34:42.910179] Iteration 42300, train loss = 0.151413, train accuracy = 1.000000\n",
      "[2018-05-31 23:34:52.069179] Iteration 42400, train loss = 0.154007, train accuracy = 1.000000\n",
      "[2018-05-31 23:35:01.266179] Iteration 42500, train loss = 0.162053, train accuracy = 0.984375\n",
      "[2018-05-31 23:35:10.428179] Iteration 42600, train loss = 0.154914, train accuracy = 1.000000\n",
      "[2018-05-31 23:35:19.561179] Iteration 42700, train loss = 0.177242, train accuracy = 0.992188\n",
      "[2018-05-31 23:35:28.705179] Iteration 42800, train loss = 0.167862, train accuracy = 0.992188\n",
      "[2018-05-31 23:35:37.916179] Iteration 42900, train loss = 0.164719, train accuracy = 1.000000\n",
      "[2018-05-31 23:35:47.052179] Iteration 43000, train loss = 0.192885, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-05-31 23:35:58.273179] Iteration 43100, train loss = 0.148966, train accuracy = 1.000000\n",
      "[2018-05-31 23:36:07.427179] Iteration 43200, train loss = 0.170838, train accuracy = 0.992188\n",
      "[2018-05-31 23:36:16.552179] Iteration 43300, train loss = 0.175826, train accuracy = 0.992188\n",
      "[2018-05-31 23:36:25.721179] Iteration 43400, train loss = 0.158151, train accuracy = 1.000000\n",
      "[2018-05-31 23:36:34.899179] Iteration 43500, train loss = 0.163053, train accuracy = 0.992188\n",
      "[2018-05-31 23:36:44.080179] Iteration 43600, train loss = 0.152730, train accuracy = 1.000000\n",
      "[2018-05-31 23:36:53.268179] Iteration 43700, train loss = 0.149655, train accuracy = 1.000000\n",
      "[2018-05-31 23:37:02.467179] Iteration 43800, train loss = 0.152834, train accuracy = 1.000000\n",
      "[2018-05-31 23:37:11.617179] Iteration 43900, train loss = 0.163498, train accuracy = 1.000000\n",
      "[2018-05-31 23:37:20.830179] Iteration 44000, train loss = 0.157639, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 23:37:31.903179] Iteration 44100, train loss = 0.147270, train accuracy = 1.000000\n",
      "[2018-05-31 23:37:41.021179] Iteration 44200, train loss = 0.149208, train accuracy = 1.000000\n",
      "[2018-05-31 23:37:50.152179] Iteration 44300, train loss = 0.148257, train accuracy = 1.000000\n",
      "[2018-05-31 23:37:59.322179] Iteration 44400, train loss = 0.167685, train accuracy = 1.000000\n",
      "[2018-05-31 23:38:08.527179] Iteration 44500, train loss = 0.167525, train accuracy = 0.992188\n",
      "[2018-05-31 23:38:17.728179] Iteration 44600, train loss = 0.152583, train accuracy = 1.000000\n",
      "[2018-05-31 23:38:26.931179] Iteration 44700, train loss = 0.151866, train accuracy = 1.000000\n",
      "[2018-05-31 23:38:36.108179] Iteration 44800, train loss = 0.151332, train accuracy = 1.000000\n",
      "[2018-05-31 23:38:45.201179] Iteration 44900, train loss = 0.152319, train accuracy = 1.000000\n",
      "[2018-05-31 23:38:54.446179] Iteration 45000, train loss = 0.145832, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.913900\n",
      "[2018-05-31 23:39:05.505179] Iteration 45100, train loss = 0.172588, train accuracy = 0.992188\n",
      "[2018-05-31 23:39:14.648179] Iteration 45200, train loss = 0.174841, train accuracy = 0.984375\n",
      "[2018-05-31 23:39:23.807179] Iteration 45300, train loss = 0.155460, train accuracy = 1.000000\n",
      "[2018-05-31 23:39:32.942179] Iteration 45400, train loss = 0.161714, train accuracy = 0.992188\n",
      "[2018-05-31 23:39:42.142179] Iteration 45500, train loss = 0.175691, train accuracy = 0.984375\n",
      "[2018-05-31 23:39:51.265179] Iteration 45600, train loss = 0.162908, train accuracy = 1.000000\n",
      "[2018-05-31 23:40:00.422179] Iteration 45700, train loss = 0.161623, train accuracy = 0.992188\n",
      "[2018-05-31 23:40:09.613179] Iteration 45800, train loss = 0.149983, train accuracy = 1.000000\n",
      "[2018-05-31 23:40:18.742179] Iteration 45900, train loss = 0.158607, train accuracy = 0.984375\n",
      "[2018-05-31 23:40:27.918179] Iteration 46000, train loss = 0.172517, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.913800\n",
      "[2018-05-31 23:40:39.008179] Iteration 46100, train loss = 0.149793, train accuracy = 1.000000\n",
      "[2018-05-31 23:40:48.188179] Iteration 46200, train loss = 0.157509, train accuracy = 1.000000\n",
      "[2018-05-31 23:40:57.393179] Iteration 46300, train loss = 0.156951, train accuracy = 0.992188\n",
      "[2018-05-31 23:41:06.566179] Iteration 46400, train loss = 0.168663, train accuracy = 0.992188\n",
      "[2018-05-31 23:41:15.717179] Iteration 46500, train loss = 0.191173, train accuracy = 0.992188\n",
      "[2018-05-31 23:41:24.942179] Iteration 46600, train loss = 0.156235, train accuracy = 0.992188\n",
      "[2018-05-31 23:41:34.125179] Iteration 46700, train loss = 0.163101, train accuracy = 1.000000\n",
      "[2018-05-31 23:41:43.270179] Iteration 46800, train loss = 0.155418, train accuracy = 1.000000\n",
      "[2018-05-31 23:41:52.398179] Iteration 46900, train loss = 0.168447, train accuracy = 0.984375\n",
      "[2018-05-31 23:42:01.592179] Iteration 47000, train loss = 0.159436, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-05-31 23:42:12.774179] Iteration 47100, train loss = 0.177090, train accuracy = 0.984375\n",
      "[2018-05-31 23:42:21.940179] Iteration 47200, train loss = 0.159768, train accuracy = 1.000000\n",
      "[2018-05-31 23:42:31.096179] Iteration 47300, train loss = 0.155808, train accuracy = 1.000000\n",
      "[2018-05-31 23:42:40.384179] Iteration 47400, train loss = 0.157315, train accuracy = 1.000000\n",
      "[2018-05-31 23:42:49.610179] Iteration 47500, train loss = 0.151221, train accuracy = 1.000000\n",
      "[2018-05-31 23:42:58.744179] Iteration 47600, train loss = 0.158052, train accuracy = 1.000000\n",
      "[2018-05-31 23:43:07.878179] Iteration 47700, train loss = 0.147706, train accuracy = 1.000000\n",
      "[2018-05-31 23:43:17.031179] Iteration 47800, train loss = 0.166672, train accuracy = 1.000000\n",
      "[2018-05-31 23:43:26.272179] Iteration 47900, train loss = 0.156263, train accuracy = 1.000000\n",
      "[2018-05-31 23:43:35.460179] Iteration 48000, train loss = 0.152162, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "Learning rate set to 0.001000\n",
      "[2018-05-31 23:43:46.603179] Iteration 48100, train loss = 0.147630, train accuracy = 1.000000\n",
      "[2018-05-31 23:43:55.732179] Iteration 48200, train loss = 0.155778, train accuracy = 0.992188\n",
      "[2018-05-31 23:44:04.830179] Iteration 48300, train loss = 0.153415, train accuracy = 0.992188\n",
      "[2018-05-31 23:44:13.993179] Iteration 48400, train loss = 0.147652, train accuracy = 1.000000\n",
      "[2018-05-31 23:44:23.117179] Iteration 48500, train loss = 0.160502, train accuracy = 0.992188\n",
      "[2018-05-31 23:44:32.302179] Iteration 48600, train loss = 0.149170, train accuracy = 1.000000\n",
      "[2018-05-31 23:44:41.433179] Iteration 48700, train loss = 0.158986, train accuracy = 1.000000\n",
      "[2018-05-31 23:44:50.660179] Iteration 48800, train loss = 0.160481, train accuracy = 1.000000\n",
      "[2018-05-31 23:44:59.754179] Iteration 48900, train loss = 0.160347, train accuracy = 1.000000\n",
      "[2018-05-31 23:45:08.934179] Iteration 49000, train loss = 0.152269, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 23:45:20.108179] Iteration 49100, train loss = 0.157162, train accuracy = 1.000000\n",
      "[2018-05-31 23:45:29.324179] Iteration 49200, train loss = 0.149049, train accuracy = 1.000000\n",
      "[2018-05-31 23:45:38.491179] Iteration 49300, train loss = 0.162919, train accuracy = 0.992188\n",
      "[2018-05-31 23:45:47.697179] Iteration 49400, train loss = 0.150499, train accuracy = 1.000000\n",
      "[2018-05-31 23:45:56.860179] Iteration 49500, train loss = 0.153710, train accuracy = 1.000000\n",
      "[2018-05-31 23:46:06.058179] Iteration 49600, train loss = 0.147623, train accuracy = 1.000000\n",
      "[2018-05-31 23:46:15.172179] Iteration 49700, train loss = 0.149518, train accuracy = 1.000000\n",
      "[2018-05-31 23:46:24.364179] Iteration 49800, train loss = 0.170123, train accuracy = 0.984375\n",
      "[2018-05-31 23:46:33.605179] Iteration 49900, train loss = 0.167620, train accuracy = 0.984375\n",
      "[2018-05-31 23:46:42.773179] Iteration 50000, train loss = 0.206594, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-05-31 23:46:53.965179] Iteration 50100, train loss = 0.150005, train accuracy = 1.000000\n",
      "[2018-05-31 23:47:03.147179] Iteration 50200, train loss = 0.150587, train accuracy = 1.000000\n",
      "[2018-05-31 23:47:12.341179] Iteration 50300, train loss = 0.160393, train accuracy = 0.992188\n",
      "[2018-05-31 23:47:21.536179] Iteration 50400, train loss = 0.167688, train accuracy = 1.000000\n",
      "[2018-05-31 23:47:30.753179] Iteration 50500, train loss = 0.147858, train accuracy = 1.000000\n",
      "[2018-05-31 23:47:39.913179] Iteration 50600, train loss = 0.152843, train accuracy = 1.000000\n",
      "[2018-05-31 23:47:49.006179] Iteration 50700, train loss = 0.164116, train accuracy = 1.000000\n",
      "[2018-05-31 23:47:58.139179] Iteration 50800, train loss = 0.180269, train accuracy = 0.976562\n",
      "[2018-05-31 23:48:07.262179] Iteration 50900, train loss = 0.152839, train accuracy = 1.000000\n",
      "[2018-05-31 23:48:16.443179] Iteration 51000, train loss = 0.175069, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-05-31 23:48:27.674179] Iteration 51100, train loss = 0.153616, train accuracy = 1.000000\n",
      "[2018-05-31 23:48:36.841179] Iteration 51200, train loss = 0.153174, train accuracy = 1.000000\n",
      "[2018-05-31 23:48:45.947179] Iteration 51300, train loss = 0.161209, train accuracy = 0.992188\n",
      "[2018-05-31 23:48:55.111179] Iteration 51400, train loss = 0.153859, train accuracy = 1.000000\n",
      "[2018-05-31 23:49:04.289179] Iteration 51500, train loss = 0.155973, train accuracy = 0.992188\n",
      "[2018-05-31 23:49:13.467179] Iteration 51600, train loss = 0.152269, train accuracy = 1.000000\n",
      "[2018-05-31 23:49:22.647179] Iteration 51700, train loss = 0.156922, train accuracy = 1.000000\n",
      "[2018-05-31 23:49:31.818179] Iteration 51800, train loss = 0.156440, train accuracy = 1.000000\n",
      "[2018-05-31 23:49:40.943179] Iteration 51900, train loss = 0.153591, train accuracy = 1.000000\n",
      "[2018-05-31 23:49:50.093179] Iteration 52000, train loss = 0.166616, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-05-31 23:50:01.174179] Iteration 52100, train loss = 0.165348, train accuracy = 0.992188\n",
      "[2018-05-31 23:50:10.303179] Iteration 52200, train loss = 0.158254, train accuracy = 0.992188\n",
      "[2018-05-31 23:50:19.535179] Iteration 52300, train loss = 0.153635, train accuracy = 1.000000\n",
      "[2018-05-31 23:50:28.668179] Iteration 52400, train loss = 0.175972, train accuracy = 0.992188\n",
      "[2018-05-31 23:50:37.871179] Iteration 52500, train loss = 0.150711, train accuracy = 1.000000\n",
      "[2018-05-31 23:50:47.061179] Iteration 52600, train loss = 0.169686, train accuracy = 0.984375\n",
      "[2018-05-31 23:50:56.194179] Iteration 52700, train loss = 0.166357, train accuracy = 0.992188\n",
      "[2018-05-31 23:51:05.312179] Iteration 52800, train loss = 0.159602, train accuracy = 0.992188\n",
      "[2018-05-31 23:51:14.459179] Iteration 52900, train loss = 0.170013, train accuracy = 0.984375\n",
      "[2018-05-31 23:51:23.608179] Iteration 53000, train loss = 0.167014, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-05-31 23:51:34.714179] Iteration 53100, train loss = 0.155673, train accuracy = 0.992188\n",
      "[2018-05-31 23:51:43.876179] Iteration 53200, train loss = 0.155572, train accuracy = 1.000000\n",
      "[2018-05-31 23:51:53.029179] Iteration 53300, train loss = 0.158340, train accuracy = 1.000000\n",
      "[2018-05-31 23:52:02.157179] Iteration 53400, train loss = 0.158401, train accuracy = 0.992188\n",
      "[2018-05-31 23:52:11.427179] Iteration 53500, train loss = 0.214668, train accuracy = 0.976562\n",
      "[2018-05-31 23:52:20.565179] Iteration 53600, train loss = 0.159376, train accuracy = 0.992188\n",
      "[2018-05-31 23:52:29.681179] Iteration 53700, train loss = 0.156348, train accuracy = 1.000000\n",
      "[2018-05-31 23:52:38.874179] Iteration 53800, train loss = 0.160006, train accuracy = 1.000000\n",
      "[2018-05-31 23:52:48.086179] Iteration 53900, train loss = 0.156398, train accuracy = 1.000000\n",
      "[2018-05-31 23:52:57.263179] Iteration 54000, train loss = 0.170265, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-05-31 23:53:08.424179] Iteration 54100, train loss = 0.168159, train accuracy = 0.992188\n",
      "[2018-05-31 23:53:17.606179] Iteration 54200, train loss = 0.150380, train accuracy = 1.000000\n",
      "[2018-05-31 23:53:26.734179] Iteration 54300, train loss = 0.150602, train accuracy = 1.000000\n",
      "[2018-05-31 23:53:35.934179] Iteration 54400, train loss = 0.163113, train accuracy = 0.992188\n",
      "[2018-05-31 23:53:45.186179] Iteration 54500, train loss = 0.149278, train accuracy = 1.000000\n",
      "[2018-05-31 23:53:54.398179] Iteration 54600, train loss = 0.154762, train accuracy = 0.992188\n",
      "[2018-05-31 23:54:03.575179] Iteration 54700, train loss = 0.164478, train accuracy = 0.992188\n",
      "[2018-05-31 23:54:12.770179] Iteration 54800, train loss = 0.155491, train accuracy = 0.992188\n",
      "[2018-05-31 23:54:21.878179] Iteration 54900, train loss = 0.170256, train accuracy = 0.984375\n",
      "[2018-05-31 23:54:30.991179] Iteration 55000, train loss = 0.161845, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914500\n",
      "[2018-05-31 23:54:42.131179] Iteration 55100, train loss = 0.151732, train accuracy = 1.000000\n",
      "[2018-05-31 23:54:51.355179] Iteration 55200, train loss = 0.177051, train accuracy = 0.992188\n",
      "[2018-05-31 23:55:00.561179] Iteration 55300, train loss = 0.183341, train accuracy = 0.976562\n",
      "[2018-05-31 23:55:09.769179] Iteration 55400, train loss = 0.154116, train accuracy = 1.000000\n",
      "[2018-05-31 23:55:18.945179] Iteration 55500, train loss = 0.180127, train accuracy = 0.984375\n",
      "[2018-05-31 23:55:28.167179] Iteration 55600, train loss = 0.153991, train accuracy = 1.000000\n",
      "[2018-05-31 23:55:37.274179] Iteration 55700, train loss = 0.161198, train accuracy = 0.992188\n",
      "[2018-05-31 23:55:46.349179] Iteration 55800, train loss = 0.165686, train accuracy = 1.000000\n",
      "[2018-05-31 23:55:55.504179] Iteration 55900, train loss = 0.152758, train accuracy = 1.000000\n",
      "[2018-05-31 23:56:04.638179] Iteration 56000, train loss = 0.152224, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 23:56:15.809179] Iteration 56100, train loss = 0.188387, train accuracy = 0.992188\n",
      "[2018-05-31 23:56:24.915179] Iteration 56200, train loss = 0.163722, train accuracy = 1.000000\n",
      "[2018-05-31 23:56:34.045179] Iteration 56300, train loss = 0.153148, train accuracy = 1.000000\n",
      "[2018-05-31 23:56:43.191179] Iteration 56400, train loss = 0.149267, train accuracy = 1.000000\n",
      "[2018-05-31 23:56:52.365179] Iteration 56500, train loss = 0.150932, train accuracy = 1.000000\n",
      "[2018-05-31 23:57:01.513179] Iteration 56600, train loss = 0.156695, train accuracy = 1.000000\n",
      "[2018-05-31 23:57:10.730179] Iteration 56700, train loss = 0.156682, train accuracy = 1.000000\n",
      "[2018-05-31 23:57:19.841179] Iteration 56800, train loss = 0.154793, train accuracy = 1.000000\n",
      "[2018-05-31 23:57:29.054179] Iteration 56900, train loss = 0.171997, train accuracy = 0.992188\n",
      "[2018-05-31 23:57:38.214179] Iteration 57000, train loss = 0.147922, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-05-31 23:57:49.360179] Iteration 57100, train loss = 0.152814, train accuracy = 1.000000\n",
      "[2018-05-31 23:57:58.510179] Iteration 57200, train loss = 0.160279, train accuracy = 1.000000\n",
      "[2018-05-31 23:58:07.624179] Iteration 57300, train loss = 0.187510, train accuracy = 0.984375\n",
      "[2018-05-31 23:58:16.731179] Iteration 57400, train loss = 0.149558, train accuracy = 1.000000\n",
      "[2018-05-31 23:58:25.912179] Iteration 57500, train loss = 0.163047, train accuracy = 1.000000\n",
      "[2018-05-31 23:58:35.061179] Iteration 57600, train loss = 0.152169, train accuracy = 1.000000\n",
      "[2018-05-31 23:58:44.200179] Iteration 57700, train loss = 0.163552, train accuracy = 1.000000\n",
      "[2018-05-31 23:58:53.373179] Iteration 57800, train loss = 0.152174, train accuracy = 1.000000\n",
      "[2018-05-31 23:59:02.554179] Iteration 57900, train loss = 0.161884, train accuracy = 1.000000\n",
      "[2018-05-31 23:59:11.745179] Iteration 58000, train loss = 0.161373, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-05-31 23:59:22.906179] Iteration 58100, train loss = 0.167733, train accuracy = 0.992188\n",
      "[2018-05-31 23:59:32.048179] Iteration 58200, train loss = 0.182056, train accuracy = 0.984375\n",
      "[2018-05-31 23:59:41.192179] Iteration 58300, train loss = 0.158610, train accuracy = 1.000000\n",
      "[2018-05-31 23:59:50.380179] Iteration 58400, train loss = 0.163797, train accuracy = 0.992188\n",
      "[2018-05-31 23:59:59.545179] Iteration 58500, train loss = 0.167340, train accuracy = 1.000000\n",
      "[2018-06-01 00:00:08.698179] Iteration 58600, train loss = 0.153311, train accuracy = 1.000000\n",
      "[2018-06-01 00:00:17.856179] Iteration 58700, train loss = 0.153904, train accuracy = 1.000000\n",
      "[2018-06-01 00:00:27.042179] Iteration 58800, train loss = 0.162766, train accuracy = 0.992188\n",
      "[2018-06-01 00:00:36.211179] Iteration 58900, train loss = 0.152066, train accuracy = 1.000000\n",
      "[2018-06-01 00:00:45.368179] Iteration 59000, train loss = 0.163523, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-06-01 00:00:56.555179] Iteration 59100, train loss = 0.175056, train accuracy = 0.992188\n",
      "[2018-06-01 00:01:05.702179] Iteration 59200, train loss = 0.166129, train accuracy = 1.000000\n",
      "[2018-06-01 00:01:14.769179] Iteration 59300, train loss = 0.153396, train accuracy = 0.992188\n",
      "[2018-06-01 00:01:23.971179] Iteration 59400, train loss = 0.163109, train accuracy = 0.992188\n",
      "[2018-06-01 00:01:33.095179] Iteration 59500, train loss = 0.157842, train accuracy = 0.992188\n",
      "[2018-06-01 00:01:42.243179] Iteration 59600, train loss = 0.160841, train accuracy = 0.992188\n",
      "[2018-06-01 00:01:51.358179] Iteration 59700, train loss = 0.158200, train accuracy = 1.000000\n",
      "[2018-06-01 00:02:00.548179] Iteration 59800, train loss = 0.151574, train accuracy = 1.000000\n",
      "[2018-06-01 00:02:09.737179] Iteration 59900, train loss = 0.159403, train accuracy = 1.000000\n",
      "[2018-06-01 00:02:18.895179] Iteration 60000, train loss = 0.171298, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-06-01 00:02:30.047179] Iteration 60100, train loss = 0.163422, train accuracy = 0.992188\n",
      "[2018-06-01 00:02:39.208179] Iteration 60200, train loss = 0.146100, train accuracy = 1.000000\n",
      "[2018-06-01 00:02:48.326179] Iteration 60300, train loss = 0.150153, train accuracy = 1.000000\n",
      "[2018-06-01 00:02:57.476179] Iteration 60400, train loss = 0.156181, train accuracy = 1.000000\n",
      "[2018-06-01 00:03:06.599179] Iteration 60500, train loss = 0.153148, train accuracy = 1.000000\n",
      "[2018-06-01 00:03:15.714179] Iteration 60600, train loss = 0.162484, train accuracy = 0.992188\n",
      "[2018-06-01 00:03:24.852179] Iteration 60700, train loss = 0.162707, train accuracy = 1.000000\n",
      "[2018-06-01 00:03:33.951179] Iteration 60800, train loss = 0.165154, train accuracy = 0.992188\n",
      "[2018-06-01 00:03:43.113179] Iteration 60900, train loss = 0.195389, train accuracy = 0.968750\n",
      "[2018-06-01 00:03:52.270179] Iteration 61000, train loss = 0.162721, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-06-01 00:04:03.395179] Iteration 61100, train loss = 0.167428, train accuracy = 0.992188\n",
      "[2018-06-01 00:04:12.477179] Iteration 61200, train loss = 0.153305, train accuracy = 1.000000\n",
      "[2018-06-01 00:04:21.593179] Iteration 61300, train loss = 0.147323, train accuracy = 1.000000\n",
      "[2018-06-01 00:04:30.717179] Iteration 61400, train loss = 0.161092, train accuracy = 1.000000\n",
      "[2018-06-01 00:04:39.818179] Iteration 61500, train loss = 0.158329, train accuracy = 1.000000\n",
      "[2018-06-01 00:04:49.044179] Iteration 61600, train loss = 0.152350, train accuracy = 1.000000\n",
      "[2018-06-01 00:04:58.206179] Iteration 61700, train loss = 0.149149, train accuracy = 1.000000\n",
      "[2018-06-01 00:05:07.328179] Iteration 61800, train loss = 0.154522, train accuracy = 1.000000\n",
      "[2018-06-01 00:05:16.537179] Iteration 61900, train loss = 0.160230, train accuracy = 1.000000\n",
      "[2018-06-01 00:05:25.725179] Iteration 62000, train loss = 0.152188, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915000\n",
      "[2018-06-01 00:05:36.897179] Iteration 62100, train loss = 0.150127, train accuracy = 1.000000\n",
      "[2018-06-01 00:05:46.037179] Iteration 62200, train loss = 0.158433, train accuracy = 1.000000\n",
      "[2018-06-01 00:05:55.184179] Iteration 62300, train loss = 0.146909, train accuracy = 1.000000\n",
      "[2018-06-01 00:06:04.348179] Iteration 62400, train loss = 0.168426, train accuracy = 0.992188\n",
      "[2018-06-01 00:06:13.601179] Iteration 62500, train loss = 0.163002, train accuracy = 1.000000\n",
      "[2018-06-01 00:06:22.860179] Iteration 62600, train loss = 0.154103, train accuracy = 1.000000\n",
      "[2018-06-01 00:06:31.982179] Iteration 62700, train loss = 0.157664, train accuracy = 1.000000\n",
      "[2018-06-01 00:06:41.223179] Iteration 62800, train loss = 0.153014, train accuracy = 1.000000\n",
      "[2018-06-01 00:06:50.363179] Iteration 62900, train loss = 0.150493, train accuracy = 1.000000\n",
      "[2018-06-01 00:06:59.541179] Iteration 63000, train loss = 0.170431, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914400\n",
      "[2018-06-01 00:07:10.824179] Iteration 63100, train loss = 0.151686, train accuracy = 1.000000\n",
      "[2018-06-01 00:07:19.901179] Iteration 63200, train loss = 0.182547, train accuracy = 0.984375\n",
      "[2018-06-01 00:07:29.046179] Iteration 63300, train loss = 0.160203, train accuracy = 1.000000\n",
      "[2018-06-01 00:07:38.172179] Iteration 63400, train loss = 0.157189, train accuracy = 1.000000\n",
      "[2018-06-01 00:07:47.327179] Iteration 63500, train loss = 0.171847, train accuracy = 1.000000\n",
      "[2018-06-01 00:07:56.499179] Iteration 63600, train loss = 0.175943, train accuracy = 0.992188\n",
      "[2018-06-01 00:08:05.557179] Iteration 63700, train loss = 0.146721, train accuracy = 1.000000\n",
      "[2018-06-01 00:08:14.627179] Iteration 63800, train loss = 0.157524, train accuracy = 1.000000\n",
      "[2018-06-01 00:08:23.782179] Iteration 63900, train loss = 0.150661, train accuracy = 1.000000\n",
      "[2018-06-01 00:08:32.963179] Iteration 64000, train loss = 0.157986, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914600\n",
      "[2018-06-01 00:08:44.124179] Iteration 64100, train loss = 0.149641, train accuracy = 1.000000\n",
      "[2018-06-01 00:08:53.295179] Iteration 64200, train loss = 0.184416, train accuracy = 0.984375\n",
      "[2018-06-01 00:09:02.437179] Iteration 64300, train loss = 0.168558, train accuracy = 1.000000\n",
      "[2018-06-01 00:09:11.598179] Iteration 64400, train loss = 0.161638, train accuracy = 1.000000\n",
      "[2018-06-01 00:09:20.740179] Iteration 64500, train loss = 0.171745, train accuracy = 0.992188\n",
      "[2018-06-01 00:09:29.848179] Iteration 64600, train loss = 0.154006, train accuracy = 1.000000\n",
      "[2018-06-01 00:09:39.026179] Iteration 64700, train loss = 0.151791, train accuracy = 1.000000\n",
      "[2018-06-01 00:09:48.171179] Iteration 64800, train loss = 0.156539, train accuracy = 1.000000\n",
      "[2018-06-01 00:09:57.348179] Iteration 64900, train loss = 0.152979, train accuracy = 1.000000\n",
      "[2018-06-01 00:10:06.664179] Iteration 65000, train loss = 0.168692, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-06-01 00:10:17.779179] Iteration 65100, train loss = 0.147346, train accuracy = 1.000000\n",
      "[2018-06-01 00:10:26.957179] Iteration 65200, train loss = 0.147055, train accuracy = 1.000000\n",
      "[2018-06-01 00:10:36.121179] Iteration 65300, train loss = 0.166382, train accuracy = 0.984375\n",
      "[2018-06-01 00:10:45.244179] Iteration 65400, train loss = 0.164329, train accuracy = 1.000000\n",
      "[2018-06-01 00:10:54.381179] Iteration 65500, train loss = 0.171887, train accuracy = 0.992188\n",
      "[2018-06-01 00:11:03.510179] Iteration 65600, train loss = 0.147567, train accuracy = 1.000000\n",
      "[2018-06-01 00:11:12.714179] Iteration 65700, train loss = 0.158881, train accuracy = 1.000000\n",
      "[2018-06-01 00:11:21.880179] Iteration 65800, train loss = 0.167561, train accuracy = 0.992188\n",
      "[2018-06-01 00:11:31.007179] Iteration 65900, train loss = 0.179763, train accuracy = 0.992188\n",
      "[2018-06-01 00:11:40.170179] Iteration 66000, train loss = 0.155805, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914200\n",
      "[2018-06-01 00:11:51.243179] Iteration 66100, train loss = 0.169595, train accuracy = 0.992188\n",
      "[2018-06-01 00:12:00.416179] Iteration 66200, train loss = 0.152286, train accuracy = 1.000000\n",
      "[2018-06-01 00:12:09.620179] Iteration 66300, train loss = 0.147161, train accuracy = 1.000000\n",
      "[2018-06-01 00:12:18.772179] Iteration 66400, train loss = 0.148817, train accuracy = 1.000000\n",
      "[2018-06-01 00:12:27.907179] Iteration 66500, train loss = 0.161160, train accuracy = 1.000000\n",
      "[2018-06-01 00:12:37.054179] Iteration 66600, train loss = 0.156344, train accuracy = 1.000000\n",
      "[2018-06-01 00:12:46.177179] Iteration 66700, train loss = 0.155310, train accuracy = 0.992188\n",
      "[2018-06-01 00:12:55.250179] Iteration 66800, train loss = 0.176441, train accuracy = 0.992188\n",
      "[2018-06-01 00:13:04.405179] Iteration 66900, train loss = 0.164185, train accuracy = 0.992188\n",
      "[2018-06-01 00:13:13.519179] Iteration 67000, train loss = 0.148398, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-06-01 00:13:24.633179] Iteration 67100, train loss = 0.171647, train accuracy = 0.992188\n",
      "[2018-06-01 00:13:33.812179] Iteration 67200, train loss = 0.165164, train accuracy = 0.992188\n",
      "[2018-06-01 00:13:42.974179] Iteration 67300, train loss = 0.161600, train accuracy = 1.000000\n",
      "[2018-06-01 00:13:52.220179] Iteration 67400, train loss = 0.152414, train accuracy = 1.000000\n",
      "[2018-06-01 00:14:01.376179] Iteration 67500, train loss = 0.148855, train accuracy = 1.000000\n",
      "[2018-06-01 00:14:10.485179] Iteration 67600, train loss = 0.157277, train accuracy = 1.000000\n",
      "[2018-06-01 00:14:19.641179] Iteration 67700, train loss = 0.157034, train accuracy = 1.000000\n",
      "[2018-06-01 00:14:28.703179] Iteration 67800, train loss = 0.160767, train accuracy = 1.000000\n",
      "[2018-06-01 00:14:37.908179] Iteration 67900, train loss = 0.153087, train accuracy = 1.000000\n",
      "[2018-06-01 00:14:47.040179] Iteration 68000, train loss = 0.161116, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.914800\n",
      "[2018-06-01 00:14:58.178179] Iteration 68100, train loss = 0.148359, train accuracy = 1.000000\n",
      "[2018-06-01 00:15:07.351179] Iteration 68200, train loss = 0.161190, train accuracy = 1.000000\n",
      "[2018-06-01 00:15:16.521179] Iteration 68300, train loss = 0.167040, train accuracy = 0.992188\n",
      "[2018-06-01 00:15:25.717179] Iteration 68400, train loss = 0.161277, train accuracy = 0.992188\n",
      "[2018-06-01 00:15:34.951179] Iteration 68500, train loss = 0.149683, train accuracy = 1.000000\n",
      "[2018-06-01 00:15:44.131179] Iteration 68600, train loss = 0.161533, train accuracy = 1.000000\n",
      "[2018-06-01 00:15:53.322179] Iteration 68700, train loss = 0.156830, train accuracy = 1.000000\n",
      "[2018-06-01 00:16:02.451179] Iteration 68800, train loss = 0.157782, train accuracy = 1.000000\n",
      "[2018-06-01 00:16:11.595179] Iteration 68900, train loss = 0.169612, train accuracy = 0.992188\n",
      "[2018-06-01 00:16:20.785179] Iteration 69000, train loss = 0.152227, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-06-01 00:16:31.852179] Iteration 69100, train loss = 0.165188, train accuracy = 0.992188\n",
      "[2018-06-01 00:16:41.043179] Iteration 69200, train loss = 0.172090, train accuracy = 0.992188\n",
      "[2018-06-01 00:16:50.195179] Iteration 69300, train loss = 0.160702, train accuracy = 1.000000\n",
      "[2018-06-01 00:16:59.347179] Iteration 69400, train loss = 0.166588, train accuracy = 0.992188\n",
      "[2018-06-01 00:17:08.536179] Iteration 69500, train loss = 0.165207, train accuracy = 0.984375\n",
      "[2018-06-01 00:17:17.635179] Iteration 69600, train loss = 0.162446, train accuracy = 1.000000\n",
      "[2018-06-01 00:17:26.762179] Iteration 69700, train loss = 0.178893, train accuracy = 0.992188\n",
      "[2018-06-01 00:17:35.887179] Iteration 69800, train loss = 0.164227, train accuracy = 0.992188\n",
      "[2018-06-01 00:17:45.069179] Iteration 69900, train loss = 0.154467, train accuracy = 1.000000\n",
      "[2018-06-01 00:17:54.272179] Iteration 70000, train loss = 0.151746, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914700\n",
      "[2018-06-01 00:18:05.385179] Iteration 70100, train loss = 0.158805, train accuracy = 0.992188\n",
      "[2018-06-01 00:18:14.542179] Iteration 70200, train loss = 0.149248, train accuracy = 1.000000\n",
      "[2018-06-01 00:18:23.693179] Iteration 70300, train loss = 0.152281, train accuracy = 1.000000\n",
      "[2018-06-01 00:18:32.863179] Iteration 70400, train loss = 0.158728, train accuracy = 0.992188\n",
      "[2018-06-01 00:18:42.101179] Iteration 70500, train loss = 0.152083, train accuracy = 1.000000\n",
      "[2018-06-01 00:18:51.262179] Iteration 70600, train loss = 0.147102, train accuracy = 1.000000\n",
      "[2018-06-01 00:19:00.387179] Iteration 70700, train loss = 0.159664, train accuracy = 1.000000\n",
      "[2018-06-01 00:19:09.582179] Iteration 70800, train loss = 0.147128, train accuracy = 1.000000\n",
      "[2018-06-01 00:19:18.777179] Iteration 70900, train loss = 0.158265, train accuracy = 1.000000\n",
      "[2018-06-01 00:19:27.855179] Iteration 71000, train loss = 0.149261, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-06-01 00:19:39.008179] Iteration 71100, train loss = 0.161422, train accuracy = 0.992188\n",
      "[2018-06-01 00:19:48.191179] Iteration 71200, train loss = 0.167633, train accuracy = 0.984375\n",
      "[2018-06-01 00:19:57.358179] Iteration 71300, train loss = 0.151863, train accuracy = 1.000000\n",
      "[2018-06-01 00:20:06.471179] Iteration 71400, train loss = 0.150955, train accuracy = 1.000000\n",
      "[2018-06-01 00:20:15.605179] Iteration 71500, train loss = 0.177622, train accuracy = 0.984375\n",
      "[2018-06-01 00:20:24.768179] Iteration 71600, train loss = 0.163969, train accuracy = 0.992188\n",
      "[2018-06-01 00:20:33.930179] Iteration 71700, train loss = 0.153506, train accuracy = 1.000000\n",
      "[2018-06-01 00:20:43.035179] Iteration 71800, train loss = 0.151673, train accuracy = 1.000000\n",
      "[2018-06-01 00:20:52.125179] Iteration 71900, train loss = 0.166452, train accuracy = 0.992188\n",
      "[2018-06-01 00:21:01.260179] Iteration 72000, train loss = 0.149508, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915500\n",
      "[2018-06-01 00:21:12.351179] Iteration 72100, train loss = 0.154434, train accuracy = 0.992188\n",
      "[2018-06-01 00:21:21.484179] Iteration 72200, train loss = 0.158783, train accuracy = 0.992188\n",
      "[2018-06-01 00:21:30.653179] Iteration 72300, train loss = 0.154443, train accuracy = 1.000000\n",
      "[2018-06-01 00:21:39.796179] Iteration 72400, train loss = 0.179218, train accuracy = 0.992188\n",
      "[2018-06-01 00:21:48.958179] Iteration 72500, train loss = 0.171372, train accuracy = 0.992188\n",
      "[2018-06-01 00:21:58.130179] Iteration 72600, train loss = 0.158536, train accuracy = 1.000000\n",
      "[2018-06-01 00:22:07.358179] Iteration 72700, train loss = 0.154431, train accuracy = 1.000000\n",
      "[2018-06-01 00:22:16.612179] Iteration 72800, train loss = 0.156710, train accuracy = 1.000000\n",
      "[2018-06-01 00:22:25.736179] Iteration 72900, train loss = 0.152091, train accuracy = 1.000000\n",
      "[2018-06-01 00:22:35.012179] Iteration 73000, train loss = 0.155979, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915200\n",
      "[2018-06-01 00:22:46.132179] Iteration 73100, train loss = 0.161037, train accuracy = 1.000000\n",
      "[2018-06-01 00:22:55.278179] Iteration 73200, train loss = 0.166163, train accuracy = 1.000000\n",
      "[2018-06-01 00:23:04.383179] Iteration 73300, train loss = 0.160048, train accuracy = 1.000000\n",
      "[2018-06-01 00:23:13.580179] Iteration 73400, train loss = 0.154007, train accuracy = 1.000000\n",
      "[2018-06-01 00:23:22.784179] Iteration 73500, train loss = 0.176187, train accuracy = 0.984375\n",
      "[2018-06-01 00:23:31.964179] Iteration 73600, train loss = 0.183434, train accuracy = 0.984375\n",
      "[2018-06-01 00:23:41.140179] Iteration 73700, train loss = 0.151704, train accuracy = 1.000000\n",
      "[2018-06-01 00:23:50.296179] Iteration 73800, train loss = 0.156623, train accuracy = 1.000000\n",
      "[2018-06-01 00:23:59.393179] Iteration 73900, train loss = 0.152253, train accuracy = 1.000000\n",
      "[2018-06-01 00:24:08.538179] Iteration 74000, train loss = 0.164962, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.914900\n",
      "[2018-06-01 00:24:19.649179] Iteration 74100, train loss = 0.154059, train accuracy = 1.000000\n",
      "[2018-06-01 00:24:28.755179] Iteration 74200, train loss = 0.148590, train accuracy = 1.000000\n",
      "[2018-06-01 00:24:37.966179] Iteration 74300, train loss = 0.158215, train accuracy = 1.000000\n",
      "[2018-06-01 00:24:47.045179] Iteration 74400, train loss = 0.150802, train accuracy = 1.000000\n",
      "[2018-06-01 00:24:56.229179] Iteration 74500, train loss = 0.168779, train accuracy = 0.992188\n",
      "[2018-06-01 00:25:05.359179] Iteration 74600, train loss = 0.148509, train accuracy = 1.000000\n",
      "[2018-06-01 00:25:14.575179] Iteration 74700, train loss = 0.157979, train accuracy = 0.992188\n",
      "[2018-06-01 00:25:23.712179] Iteration 74800, train loss = 0.156010, train accuracy = 1.000000\n",
      "[2018-06-01 00:25:32.886179] Iteration 74900, train loss = 0.153774, train accuracy = 1.000000\n",
      "[2018-06-01 00:25:42.095179] Iteration 75000, train loss = 0.167044, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915700\n",
      "[2018-06-01 00:25:53.246179] Iteration 75100, train loss = 0.159687, train accuracy = 1.000000\n",
      "[2018-06-01 00:26:02.408179] Iteration 75200, train loss = 0.169050, train accuracy = 0.984375\n",
      "[2018-06-01 00:26:11.604179] Iteration 75300, train loss = 0.157248, train accuracy = 0.992188\n",
      "[2018-06-01 00:26:20.786179] Iteration 75400, train loss = 0.159179, train accuracy = 1.000000\n",
      "[2018-06-01 00:26:29.995179] Iteration 75500, train loss = 0.152197, train accuracy = 1.000000\n",
      "[2018-06-01 00:26:39.178179] Iteration 75600, train loss = 0.165611, train accuracy = 0.992188\n",
      "[2018-06-01 00:26:48.279179] Iteration 75700, train loss = 0.159953, train accuracy = 1.000000\n",
      "[2018-06-01 00:26:57.349179] Iteration 75800, train loss = 0.150988, train accuracy = 1.000000\n",
      "[2018-06-01 00:27:06.458179] Iteration 75900, train loss = 0.148397, train accuracy = 1.000000\n",
      "[2018-06-01 00:27:15.612179] Iteration 76000, train loss = 0.156133, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.916000\n",
      "[2018-06-01 00:27:26.702179] Iteration 76100, train loss = 0.164205, train accuracy = 0.992188\n",
      "[2018-06-01 00:27:35.880179] Iteration 76200, train loss = 0.156306, train accuracy = 1.000000\n",
      "[2018-06-01 00:27:45.109179] Iteration 76300, train loss = 0.162878, train accuracy = 0.992188\n",
      "[2018-06-01 00:27:54.273179] Iteration 76400, train loss = 0.175374, train accuracy = 0.992188\n",
      "[2018-06-01 00:28:03.391179] Iteration 76500, train loss = 0.158677, train accuracy = 1.000000\n",
      "[2018-06-01 00:28:12.615179] Iteration 76600, train loss = 0.146385, train accuracy = 1.000000\n",
      "[2018-06-01 00:28:21.862179] Iteration 76700, train loss = 0.162567, train accuracy = 1.000000\n",
      "[2018-06-01 00:28:30.965179] Iteration 76800, train loss = 0.153968, train accuracy = 1.000000\n",
      "[2018-06-01 00:28:40.123179] Iteration 76900, train loss = 0.181078, train accuracy = 0.984375\n",
      "[2018-06-01 00:28:49.304179] Iteration 77000, train loss = 0.170587, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-06-01 00:29:00.447179] Iteration 77100, train loss = 0.152480, train accuracy = 1.000000\n",
      "[2018-06-01 00:29:09.595179] Iteration 77200, train loss = 0.159030, train accuracy = 0.992188\n",
      "[2018-06-01 00:29:18.696179] Iteration 77300, train loss = 0.150673, train accuracy = 1.000000\n",
      "[2018-06-01 00:29:27.884179] Iteration 77400, train loss = 0.150194, train accuracy = 1.000000\n",
      "[2018-06-01 00:29:37.055179] Iteration 77500, train loss = 0.164653, train accuracy = 0.992188\n",
      "[2018-06-01 00:29:46.231179] Iteration 77600, train loss = 0.156756, train accuracy = 1.000000\n",
      "[2018-06-01 00:29:55.393179] Iteration 77700, train loss = 0.150644, train accuracy = 1.000000\n",
      "[2018-06-01 00:30:04.628179] Iteration 77800, train loss = 0.156346, train accuracy = 1.000000\n",
      "[2018-06-01 00:30:13.812179] Iteration 77900, train loss = 0.159061, train accuracy = 1.000000\n",
      "[2018-06-01 00:30:22.921179] Iteration 78000, train loss = 0.154317, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.915400\n",
      "[2018-06-01 00:30:34.052179] Iteration 78100, train loss = 0.155588, train accuracy = 1.000000\n",
      "[2018-06-01 00:30:43.261179] Iteration 78200, train loss = 0.148587, train accuracy = 1.000000\n",
      "[2018-06-01 00:30:52.410179] Iteration 78300, train loss = 0.146932, train accuracy = 1.000000\n",
      "[2018-06-01 00:31:01.578179] Iteration 78400, train loss = 0.158423, train accuracy = 0.992188\n",
      "[2018-06-01 00:31:10.688179] Iteration 78500, train loss = 0.156368, train accuracy = 1.000000\n",
      "[2018-06-01 00:31:19.858179] Iteration 78600, train loss = 0.172324, train accuracy = 0.992188\n",
      "[2018-06-01 00:31:29.001179] Iteration 78700, train loss = 0.159920, train accuracy = 1.000000\n",
      "[2018-06-01 00:31:38.154179] Iteration 78800, train loss = 0.176610, train accuracy = 0.984375\n",
      "[2018-06-01 00:31:47.282179] Iteration 78900, train loss = 0.153022, train accuracy = 1.000000\n",
      "[2018-06-01 00:31:56.424179] Iteration 79000, train loss = 0.165659, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.915100\n",
      "[2018-06-01 00:32:07.642179] Iteration 79100, train loss = 0.149135, train accuracy = 1.000000\n",
      "[2018-06-01 00:32:16.832179] Iteration 79200, train loss = 0.178015, train accuracy = 0.984375\n",
      "[2018-06-01 00:32:25.998179] Iteration 79300, train loss = 0.155872, train accuracy = 1.000000\n",
      "[2018-06-01 00:32:35.106179] Iteration 79400, train loss = 0.164510, train accuracy = 1.000000\n",
      "[2018-06-01 00:32:44.328179] Iteration 79500, train loss = 0.148123, train accuracy = 1.000000\n",
      "[2018-06-01 00:32:53.417179] Iteration 79600, train loss = 0.173776, train accuracy = 0.984375\n",
      "[2018-06-01 00:33:02.555179] Iteration 79700, train loss = 0.145459, train accuracy = 1.000000\n",
      "[2018-06-01 00:33:11.641179] Iteration 79800, train loss = 0.161134, train accuracy = 0.992188\n",
      "[2018-06-01 00:33:20.863179] Iteration 79900, train loss = 0.159564, train accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四轮  量化  \n",
    "prune_rate = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune前的准确率\n",
      "Test accuracy = 0.914700\n"
     ]
    }
   ],
   "source": [
    "print('prune前的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625     -0.0625      0.0169739   0.125       0.0625     -0.03125\n",
      " -0.00027391 -0.0625      0.03125    -0.125     ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =0.85时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para_dict = {}\n",
    "one_dict = {}\n",
    "var_name = []\n",
    "for k in tf.trainable_variables():\n",
    "    para_dict[k.name] = k\n",
    "    one_dict[k.name] =tf.ones_like(k)\n",
    "    var_name.append(k.name)\n",
    "prune_dict=apply_inq(para_dict,one_dict,var_name,1)\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = trainer.compute_gradients(loss)\n",
    "grads_and_vars = apply_prune_on_grads(grads_and_vars, prune_dict)\n",
    "train_step = trainer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.010000\n",
      "[2018-06-01 00:35:19.190179] Iteration 100, train loss = 0.193945, train accuracy = 0.992188\n",
      "[2018-06-01 00:35:28.295179] Iteration 200, train loss = 0.162194, train accuracy = 1.000000\n",
      "[2018-06-01 00:35:37.426179] Iteration 300, train loss = 0.159959, train accuracy = 1.000000\n",
      "[2018-06-01 00:35:46.542179] Iteration 400, train loss = 0.175181, train accuracy = 0.984375\n",
      "[2018-06-01 00:35:55.688179] Iteration 500, train loss = 0.203241, train accuracy = 0.976562\n",
      "[2018-06-01 00:36:04.832179] Iteration 600, train loss = 0.201473, train accuracy = 0.976562\n",
      "[2018-06-01 00:36:13.979179] Iteration 700, train loss = 0.165028, train accuracy = 0.992188\n",
      "[2018-06-01 00:36:23.134179] Iteration 800, train loss = 0.179771, train accuracy = 0.984375\n",
      "[2018-06-01 00:36:32.297179] Iteration 900, train loss = 0.177710, train accuracy = 0.992188\n",
      "[2018-06-01 00:36:41.485179] Iteration 1000, train loss = 0.165789, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910300\n",
      "[2018-06-01 00:36:52.735179] Iteration 1100, train loss = 0.160408, train accuracy = 1.000000\n",
      "[2018-06-01 00:37:01.953179] Iteration 1200, train loss = 0.196447, train accuracy = 0.984375\n",
      "[2018-06-01 00:37:11.094179] Iteration 1300, train loss = 0.183626, train accuracy = 0.984375\n",
      "[2018-06-01 00:37:20.222179] Iteration 1400, train loss = 0.167968, train accuracy = 0.992188\n",
      "[2018-06-01 00:37:29.326179] Iteration 1500, train loss = 0.181515, train accuracy = 0.984375\n",
      "[2018-06-01 00:37:38.495179] Iteration 1600, train loss = 0.169496, train accuracy = 1.000000\n",
      "[2018-06-01 00:37:47.732179] Iteration 1700, train loss = 0.174985, train accuracy = 0.992188\n",
      "[2018-06-01 00:37:56.932179] Iteration 1800, train loss = 0.166738, train accuracy = 1.000000\n",
      "[2018-06-01 00:38:06.110179] Iteration 1900, train loss = 0.170790, train accuracy = 0.992188\n",
      "[2018-06-01 00:38:15.279179] Iteration 2000, train loss = 0.162421, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910900\n",
      "[2018-06-01 00:38:26.436179] Iteration 2100, train loss = 0.155040, train accuracy = 1.000000\n",
      "[2018-06-01 00:38:35.587179] Iteration 2200, train loss = 0.181492, train accuracy = 0.992188\n",
      "[2018-06-01 00:38:44.704179] Iteration 2300, train loss = 0.180247, train accuracy = 0.984375\n",
      "[2018-06-01 00:38:53.866179] Iteration 2400, train loss = 0.151551, train accuracy = 1.000000\n",
      "[2018-06-01 00:39:03.071179] Iteration 2500, train loss = 0.152385, train accuracy = 1.000000\n",
      "[2018-06-01 00:39:12.246179] Iteration 2600, train loss = 0.165669, train accuracy = 1.000000\n",
      "[2018-06-01 00:39:21.397179] Iteration 2700, train loss = 0.168395, train accuracy = 1.000000\n",
      "[2018-06-01 00:39:30.511179] Iteration 2800, train loss = 0.154599, train accuracy = 1.000000\n",
      "[2018-06-01 00:39:39.685179] Iteration 2900, train loss = 0.176212, train accuracy = 0.992188\n",
      "[2018-06-01 00:39:48.944179] Iteration 3000, train loss = 0.151472, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 00:40:00.154179] Iteration 3100, train loss = 0.149024, train accuracy = 1.000000\n",
      "[2018-06-01 00:40:09.351179] Iteration 3200, train loss = 0.176391, train accuracy = 0.992188\n",
      "[2018-06-01 00:40:18.481179] Iteration 3300, train loss = 0.154980, train accuracy = 0.992188\n",
      "[2018-06-01 00:40:27.629179] Iteration 3400, train loss = 0.166010, train accuracy = 1.000000\n",
      "[2018-06-01 00:40:36.741179] Iteration 3500, train loss = 0.174453, train accuracy = 0.992188\n",
      "[2018-06-01 00:40:45.863179] Iteration 3600, train loss = 0.155390, train accuracy = 1.000000\n",
      "[2018-06-01 00:40:55.033179] Iteration 3700, train loss = 0.171854, train accuracy = 0.992188\n",
      "[2018-06-01 00:41:04.150179] Iteration 3800, train loss = 0.205311, train accuracy = 0.976562\n",
      "[2018-06-01 00:41:13.333179] Iteration 3900, train loss = 0.183319, train accuracy = 0.976562\n",
      "[2018-06-01 00:41:22.503179] Iteration 4000, train loss = 0.157110, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910300\n",
      "[2018-06-01 00:41:33.637179] Iteration 4100, train loss = 0.175868, train accuracy = 0.984375\n",
      "[2018-06-01 00:41:42.806179] Iteration 4200, train loss = 0.172800, train accuracy = 0.992188\n",
      "[2018-06-01 00:41:52.007179] Iteration 4300, train loss = 0.171622, train accuracy = 1.000000\n",
      "[2018-06-01 00:42:01.096179] Iteration 4400, train loss = 0.156698, train accuracy = 1.000000\n",
      "[2018-06-01 00:42:10.244179] Iteration 4500, train loss = 0.188023, train accuracy = 0.984375\n",
      "[2018-06-01 00:42:19.444179] Iteration 4600, train loss = 0.166245, train accuracy = 1.000000\n",
      "[2018-06-01 00:42:28.625179] Iteration 4700, train loss = 0.163929, train accuracy = 0.992188\n",
      "[2018-06-01 00:42:37.762179] Iteration 4800, train loss = 0.180258, train accuracy = 0.984375\n",
      "[2018-06-01 00:42:46.948179] Iteration 4900, train loss = 0.156909, train accuracy = 1.000000\n",
      "[2018-06-01 00:42:56.147179] Iteration 5000, train loss = 0.166021, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.909900\n",
      "[2018-06-01 00:43:07.265179] Iteration 5100, train loss = 0.154467, train accuracy = 1.000000\n",
      "[2018-06-01 00:43:16.448179] Iteration 5200, train loss = 0.203957, train accuracy = 0.984375\n",
      "[2018-06-01 00:43:25.618179] Iteration 5300, train loss = 0.190274, train accuracy = 0.992188\n",
      "[2018-06-01 00:43:34.728179] Iteration 5400, train loss = 0.234825, train accuracy = 0.976562\n",
      "[2018-06-01 00:43:43.871179] Iteration 5500, train loss = 0.175778, train accuracy = 0.992188\n",
      "[2018-06-01 00:43:53.004179] Iteration 5600, train loss = 0.176226, train accuracy = 1.000000\n",
      "[2018-06-01 00:44:02.189179] Iteration 5700, train loss = 0.173309, train accuracy = 0.992188\n",
      "[2018-06-01 00:44:11.394179] Iteration 5800, train loss = 0.172640, train accuracy = 0.992188\n",
      "[2018-06-01 00:44:20.534179] Iteration 5900, train loss = 0.160911, train accuracy = 0.992188\n",
      "[2018-06-01 00:44:29.739179] Iteration 6000, train loss = 0.163928, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910900\n",
      "[2018-06-01 00:44:40.793179] Iteration 6100, train loss = 0.175402, train accuracy = 0.992188\n",
      "[2018-06-01 00:44:49.980179] Iteration 6200, train loss = 0.189288, train accuracy = 0.984375\n",
      "[2018-06-01 00:44:59.212179] Iteration 6300, train loss = 0.155855, train accuracy = 1.000000\n",
      "[2018-06-01 00:45:08.363179] Iteration 6400, train loss = 0.167683, train accuracy = 0.992188\n",
      "[2018-06-01 00:45:17.528179] Iteration 6500, train loss = 0.180051, train accuracy = 0.984375\n",
      "[2018-06-01 00:45:26.695179] Iteration 6600, train loss = 0.172982, train accuracy = 0.992188\n",
      "[2018-06-01 00:45:35.816179] Iteration 6700, train loss = 0.174694, train accuracy = 1.000000\n",
      "[2018-06-01 00:45:44.916179] Iteration 6800, train loss = 0.184015, train accuracy = 0.984375\n",
      "[2018-06-01 00:45:54.013179] Iteration 6900, train loss = 0.172122, train accuracy = 0.984375\n",
      "[2018-06-01 00:46:03.236179] Iteration 7000, train loss = 0.176909, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 00:46:14.415179] Iteration 7100, train loss = 0.168026, train accuracy = 1.000000\n",
      "[2018-06-01 00:46:23.606179] Iteration 7200, train loss = 0.173273, train accuracy = 0.992188\n",
      "[2018-06-01 00:46:32.730179] Iteration 7300, train loss = 0.165595, train accuracy = 0.992188\n",
      "[2018-06-01 00:46:41.911179] Iteration 7400, train loss = 0.168275, train accuracy = 0.992188\n",
      "[2018-06-01 00:46:51.072179] Iteration 7500, train loss = 0.171848, train accuracy = 0.992188\n",
      "[2018-06-01 00:47:00.222179] Iteration 7600, train loss = 0.154484, train accuracy = 1.000000\n",
      "[2018-06-01 00:47:09.339179] Iteration 7700, train loss = 0.164692, train accuracy = 0.992188\n",
      "[2018-06-01 00:47:18.636179] Iteration 7800, train loss = 0.208942, train accuracy = 0.968750\n",
      "[2018-06-01 00:47:27.798179] Iteration 7900, train loss = 0.159686, train accuracy = 0.992188\n",
      "[2018-06-01 00:47:36.957179] Iteration 8000, train loss = 0.160701, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910100\n",
      "[2018-06-01 00:47:48.115179] Iteration 8100, train loss = 0.197517, train accuracy = 0.968750\n",
      "[2018-06-01 00:47:57.205179] Iteration 8200, train loss = 0.155906, train accuracy = 1.000000\n",
      "[2018-06-01 00:48:06.366179] Iteration 8300, train loss = 0.226019, train accuracy = 0.976562\n",
      "[2018-06-01 00:48:15.506179] Iteration 8400, train loss = 0.209510, train accuracy = 0.968750\n",
      "[2018-06-01 00:48:24.725179] Iteration 8500, train loss = 0.156963, train accuracy = 1.000000\n",
      "[2018-06-01 00:48:33.898179] Iteration 8600, train loss = 0.179014, train accuracy = 0.992188\n",
      "[2018-06-01 00:48:43.112179] Iteration 8700, train loss = 0.166333, train accuracy = 0.992188\n",
      "[2018-06-01 00:48:52.262179] Iteration 8800, train loss = 0.163408, train accuracy = 1.000000\n",
      "[2018-06-01 00:49:01.427179] Iteration 8900, train loss = 0.156983, train accuracy = 1.000000\n",
      "[2018-06-01 00:49:10.605179] Iteration 9000, train loss = 0.188502, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 00:49:21.792179] Iteration 9100, train loss = 0.181119, train accuracy = 0.992188\n",
      "[2018-06-01 00:49:30.953179] Iteration 9200, train loss = 0.167561, train accuracy = 0.992188\n",
      "[2018-06-01 00:49:40.082179] Iteration 9300, train loss = 0.190654, train accuracy = 0.968750\n",
      "[2018-06-01 00:49:49.287179] Iteration 9400, train loss = 0.191646, train accuracy = 0.984375\n",
      "[2018-06-01 00:49:58.491179] Iteration 9500, train loss = 0.170433, train accuracy = 0.992188\n",
      "[2018-06-01 00:50:07.686179] Iteration 9600, train loss = 0.163984, train accuracy = 1.000000\n",
      "[2018-06-01 00:50:16.879179] Iteration 9700, train loss = 0.167859, train accuracy = 1.000000\n",
      "[2018-06-01 00:50:26.099179] Iteration 9800, train loss = 0.158401, train accuracy = 0.992188\n",
      "[2018-06-01 00:50:35.289179] Iteration 9900, train loss = 0.186338, train accuracy = 0.984375\n",
      "[2018-06-01 00:50:44.435179] Iteration 10000, train loss = 0.183831, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.909900\n",
      "[2018-06-01 00:50:55.591179] Iteration 10100, train loss = 0.168583, train accuracy = 0.992188\n",
      "[2018-06-01 00:51:04.755179] Iteration 10200, train loss = 0.175273, train accuracy = 0.992188\n",
      "[2018-06-01 00:51:13.977179] Iteration 10300, train loss = 0.163669, train accuracy = 0.992188\n",
      "[2018-06-01 00:51:23.145179] Iteration 10400, train loss = 0.168259, train accuracy = 0.992188\n",
      "[2018-06-01 00:51:32.255179] Iteration 10500, train loss = 0.182471, train accuracy = 0.968750\n",
      "[2018-06-01 00:51:41.388179] Iteration 10600, train loss = 0.240390, train accuracy = 0.968750\n",
      "[2018-06-01 00:51:50.559179] Iteration 10700, train loss = 0.177650, train accuracy = 0.984375\n",
      "[2018-06-01 00:51:59.691179] Iteration 10800, train loss = 0.156108, train accuracy = 1.000000\n",
      "[2018-06-01 00:52:08.876179] Iteration 10900, train loss = 0.161637, train accuracy = 1.000000\n",
      "[2018-06-01 00:52:18.005179] Iteration 11000, train loss = 0.173185, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.909700\n",
      "[2018-06-01 00:52:29.128179] Iteration 11100, train loss = 0.191618, train accuracy = 0.984375\n",
      "[2018-06-01 00:52:38.300179] Iteration 11200, train loss = 0.198514, train accuracy = 0.976562\n",
      "[2018-06-01 00:52:47.475179] Iteration 11300, train loss = 0.158839, train accuracy = 1.000000\n",
      "[2018-06-01 00:52:56.592179] Iteration 11400, train loss = 0.154283, train accuracy = 1.000000\n",
      "[2018-06-01 00:53:05.706179] Iteration 11500, train loss = 0.172522, train accuracy = 0.992188\n",
      "[2018-06-01 00:53:14.839179] Iteration 11600, train loss = 0.158263, train accuracy = 1.000000\n",
      "[2018-06-01 00:53:23.972179] Iteration 11700, train loss = 0.157986, train accuracy = 1.000000\n",
      "[2018-06-01 00:53:33.127179] Iteration 11800, train loss = 0.170135, train accuracy = 0.984375\n",
      "[2018-06-01 00:53:42.269179] Iteration 11900, train loss = 0.193562, train accuracy = 0.968750\n",
      "[2018-06-01 00:53:51.422179] Iteration 12000, train loss = 0.161846, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 00:54:02.618179] Iteration 12100, train loss = 0.152836, train accuracy = 1.000000\n",
      "[2018-06-01 00:54:11.828179] Iteration 12200, train loss = 0.179974, train accuracy = 0.984375\n",
      "[2018-06-01 00:54:20.926179] Iteration 12300, train loss = 0.188374, train accuracy = 0.984375\n",
      "[2018-06-01 00:54:30.040179] Iteration 12400, train loss = 0.169354, train accuracy = 0.976562\n",
      "[2018-06-01 00:54:39.229179] Iteration 12500, train loss = 0.173696, train accuracy = 0.992188\n",
      "[2018-06-01 00:54:48.356179] Iteration 12600, train loss = 0.160089, train accuracy = 1.000000\n",
      "[2018-06-01 00:54:57.481179] Iteration 12700, train loss = 0.164362, train accuracy = 1.000000\n",
      "[2018-06-01 00:55:06.589179] Iteration 12800, train loss = 0.163097, train accuracy = 0.992188\n",
      "[2018-06-01 00:55:15.731179] Iteration 12900, train loss = 0.169030, train accuracy = 0.992188\n",
      "[2018-06-01 00:55:24.966179] Iteration 13000, train loss = 0.175670, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911000\n",
      "[2018-06-01 00:55:36.067179] Iteration 13100, train loss = 0.177754, train accuracy = 0.984375\n",
      "[2018-06-01 00:55:45.184179] Iteration 13200, train loss = 0.154959, train accuracy = 1.000000\n",
      "[2018-06-01 00:55:54.344179] Iteration 13300, train loss = 0.160766, train accuracy = 1.000000\n",
      "[2018-06-01 00:56:03.546179] Iteration 13400, train loss = 0.179707, train accuracy = 0.992188\n",
      "[2018-06-01 00:56:12.692179] Iteration 13500, train loss = 0.187935, train accuracy = 0.976562\n",
      "[2018-06-01 00:56:21.786179] Iteration 13600, train loss = 0.168195, train accuracy = 0.992188\n",
      "[2018-06-01 00:56:30.947179] Iteration 13700, train loss = 0.176342, train accuracy = 0.992188\n",
      "[2018-06-01 00:56:40.105179] Iteration 13800, train loss = 0.189456, train accuracy = 0.984375\n",
      "[2018-06-01 00:56:49.294179] Iteration 13900, train loss = 0.201936, train accuracy = 0.968750\n",
      "[2018-06-01 00:56:58.390179] Iteration 14000, train loss = 0.156940, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 00:57:09.538179] Iteration 14100, train loss = 0.189257, train accuracy = 0.984375\n",
      "[2018-06-01 00:57:18.778179] Iteration 14200, train loss = 0.152764, train accuracy = 1.000000\n",
      "[2018-06-01 00:57:27.955179] Iteration 14300, train loss = 0.158377, train accuracy = 0.992188\n",
      "[2018-06-01 00:57:37.068179] Iteration 14400, train loss = 0.168036, train accuracy = 1.000000\n",
      "[2018-06-01 00:57:46.247179] Iteration 14500, train loss = 0.202775, train accuracy = 0.976562\n",
      "[2018-06-01 00:57:55.392179] Iteration 14600, train loss = 0.171167, train accuracy = 0.992188\n",
      "[2018-06-01 00:58:04.571179] Iteration 14700, train loss = 0.179892, train accuracy = 0.992188\n",
      "[2018-06-01 00:58:13.785179] Iteration 14800, train loss = 0.161186, train accuracy = 0.992188\n",
      "[2018-06-01 00:58:22.944179] Iteration 14900, train loss = 0.163121, train accuracy = 1.000000\n",
      "[2018-06-01 00:58:32.094179] Iteration 15000, train loss = 0.153452, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 00:58:43.207179] Iteration 15100, train loss = 0.181363, train accuracy = 0.976562\n",
      "[2018-06-01 00:58:52.356179] Iteration 15200, train loss = 0.154938, train accuracy = 1.000000\n",
      "[2018-06-01 00:59:01.625179] Iteration 15300, train loss = 0.178850, train accuracy = 0.992188\n",
      "[2018-06-01 00:59:10.774179] Iteration 15400, train loss = 0.177189, train accuracy = 0.992188\n",
      "[2018-06-01 00:59:19.975179] Iteration 15500, train loss = 0.187630, train accuracy = 0.984375\n",
      "[2018-06-01 00:59:29.146179] Iteration 15600, train loss = 0.181898, train accuracy = 0.984375\n",
      "[2018-06-01 00:59:38.301179] Iteration 15700, train loss = 0.188671, train accuracy = 0.984375\n",
      "[2018-06-01 00:59:47.400179] Iteration 15800, train loss = 0.201637, train accuracy = 0.984375\n",
      "[2018-06-01 00:59:56.537179] Iteration 15900, train loss = 0.203516, train accuracy = 0.976562\n",
      "[2018-06-01 01:00:05.615179] Iteration 16000, train loss = 0.176822, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.910800\n",
      "[2018-06-01 01:00:16.707179] Iteration 16100, train loss = 0.173066, train accuracy = 0.992188\n",
      "[2018-06-01 01:00:25.841179] Iteration 16200, train loss = 0.176194, train accuracy = 0.984375\n",
      "[2018-06-01 01:00:35.017179] Iteration 16300, train loss = 0.164674, train accuracy = 0.992188\n",
      "[2018-06-01 01:00:44.151179] Iteration 16400, train loss = 0.179026, train accuracy = 0.992188\n",
      "[2018-06-01 01:00:53.406179] Iteration 16500, train loss = 0.190676, train accuracy = 0.976562\n",
      "[2018-06-01 01:01:02.568179] Iteration 16600, train loss = 0.208804, train accuracy = 0.984375\n",
      "[2018-06-01 01:01:11.679179] Iteration 16700, train loss = 0.173485, train accuracy = 0.992188\n",
      "[2018-06-01 01:01:20.840179] Iteration 16800, train loss = 0.165711, train accuracy = 0.984375\n",
      "[2018-06-01 01:01:30.007179] Iteration 16900, train loss = 0.185160, train accuracy = 0.984375\n",
      "[2018-06-01 01:01:39.154179] Iteration 17000, train loss = 0.183271, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 01:01:50.261179] Iteration 17100, train loss = 0.193416, train accuracy = 0.992188\n",
      "[2018-06-01 01:01:59.420179] Iteration 17200, train loss = 0.169469, train accuracy = 0.992188\n",
      "[2018-06-01 01:02:08.533179] Iteration 17300, train loss = 0.178202, train accuracy = 0.992188\n",
      "[2018-06-01 01:02:17.734179] Iteration 17400, train loss = 0.173522, train accuracy = 0.992188\n",
      "[2018-06-01 01:02:26.959179] Iteration 17500, train loss = 0.161386, train accuracy = 1.000000\n",
      "[2018-06-01 01:02:36.114179] Iteration 17600, train loss = 0.168381, train accuracy = 0.992188\n",
      "[2018-06-01 01:02:45.214179] Iteration 17700, train loss = 0.203624, train accuracy = 0.976562\n",
      "[2018-06-01 01:02:54.394179] Iteration 17800, train loss = 0.159618, train accuracy = 1.000000\n",
      "[2018-06-01 01:03:03.623179] Iteration 17900, train loss = 0.182462, train accuracy = 0.984375\n",
      "[2018-06-01 01:03:12.858179] Iteration 18000, train loss = 0.207718, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.910500\n",
      "[2018-06-01 01:03:24.058179] Iteration 18100, train loss = 0.155661, train accuracy = 1.000000\n",
      "[2018-06-01 01:03:33.174179] Iteration 18200, train loss = 0.157114, train accuracy = 1.000000\n",
      "[2018-06-01 01:03:42.305179] Iteration 18300, train loss = 0.201715, train accuracy = 0.976562\n",
      "[2018-06-01 01:03:51.441179] Iteration 18400, train loss = 0.170769, train accuracy = 0.984375\n",
      "[2018-06-01 01:04:00.596179] Iteration 18500, train loss = 0.186483, train accuracy = 0.976562\n",
      "[2018-06-01 01:04:09.828179] Iteration 18600, train loss = 0.157660, train accuracy = 0.992188\n",
      "[2018-06-01 01:04:18.936179] Iteration 18700, train loss = 0.151527, train accuracy = 0.992188\n",
      "[2018-06-01 01:04:28.106179] Iteration 18800, train loss = 0.196389, train accuracy = 0.976562\n",
      "[2018-06-01 01:04:37.274179] Iteration 18900, train loss = 0.183076, train accuracy = 0.976562\n",
      "[2018-06-01 01:04:46.418179] Iteration 19000, train loss = 0.170654, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910700\n",
      "[2018-06-01 01:04:57.692179] Iteration 19100, train loss = 0.183859, train accuracy = 0.984375\n",
      "[2018-06-01 01:05:06.785179] Iteration 19200, train loss = 0.169749, train accuracy = 0.984375\n",
      "[2018-06-01 01:05:15.926179] Iteration 19300, train loss = 0.167333, train accuracy = 0.992188\n",
      "[2018-06-01 01:05:25.114179] Iteration 19400, train loss = 0.150933, train accuracy = 1.000000\n",
      "[2018-06-01 01:05:34.249179] Iteration 19500, train loss = 0.151811, train accuracy = 1.000000\n",
      "[2018-06-01 01:05:43.409179] Iteration 19600, train loss = 0.189640, train accuracy = 0.976562\n",
      "[2018-06-01 01:05:52.642179] Iteration 19700, train loss = 0.169233, train accuracy = 1.000000\n",
      "[2018-06-01 01:06:01.955179] Iteration 19800, train loss = 0.182941, train accuracy = 0.984375\n",
      "[2018-06-01 01:06:11.088179] Iteration 19900, train loss = 0.161240, train accuracy = 0.992188\n",
      "[2018-06-01 01:06:20.290179] Iteration 20000, train loss = 0.179168, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 01:06:31.418179] Iteration 20100, train loss = 0.156996, train accuracy = 0.992188\n",
      "[2018-06-01 01:06:40.544179] Iteration 20200, train loss = 0.169331, train accuracy = 0.992188\n",
      "[2018-06-01 01:06:49.763179] Iteration 20300, train loss = 0.156195, train accuracy = 1.000000\n",
      "[2018-06-01 01:06:58.944179] Iteration 20400, train loss = 0.189765, train accuracy = 0.968750\n",
      "[2018-06-01 01:07:08.034179] Iteration 20500, train loss = 0.155023, train accuracy = 0.992188\n",
      "[2018-06-01 01:07:17.202179] Iteration 20600, train loss = 0.183223, train accuracy = 0.976562\n",
      "[2018-06-01 01:07:26.315179] Iteration 20700, train loss = 0.170929, train accuracy = 0.992188\n",
      "[2018-06-01 01:07:35.501179] Iteration 20800, train loss = 0.170297, train accuracy = 0.992188\n",
      "[2018-06-01 01:07:44.664179] Iteration 20900, train loss = 0.180055, train accuracy = 0.992188\n",
      "[2018-06-01 01:07:53.852179] Iteration 21000, train loss = 0.176649, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910500\n",
      "[2018-06-01 01:08:05.029179] Iteration 21100, train loss = 0.176794, train accuracy = 0.992188\n",
      "[2018-06-01 01:08:14.165179] Iteration 21200, train loss = 0.164211, train accuracy = 0.984375\n",
      "[2018-06-01 01:08:23.328179] Iteration 21300, train loss = 0.167184, train accuracy = 0.992188\n",
      "[2018-06-01 01:08:32.489179] Iteration 21400, train loss = 0.181437, train accuracy = 0.976562\n",
      "[2018-06-01 01:08:41.663179] Iteration 21500, train loss = 0.160701, train accuracy = 1.000000\n",
      "[2018-06-01 01:08:50.767179] Iteration 21600, train loss = 0.170927, train accuracy = 0.992188\n",
      "[2018-06-01 01:09:00.037179] Iteration 21700, train loss = 0.159288, train accuracy = 0.992188\n",
      "[2018-06-01 01:09:09.250179] Iteration 21800, train loss = 0.187121, train accuracy = 0.984375\n",
      "[2018-06-01 01:09:18.416179] Iteration 21900, train loss = 0.193113, train accuracy = 0.984375\n",
      "[2018-06-01 01:09:27.541179] Iteration 22000, train loss = 0.156887, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.909800\n",
      "[2018-06-01 01:09:38.690179] Iteration 22100, train loss = 0.207967, train accuracy = 0.968750\n",
      "[2018-06-01 01:09:47.877179] Iteration 22200, train loss = 0.180714, train accuracy = 0.984375\n",
      "[2018-06-01 01:09:57.037179] Iteration 22300, train loss = 0.171606, train accuracy = 1.000000\n",
      "[2018-06-01 01:10:06.246179] Iteration 22400, train loss = 0.158456, train accuracy = 1.000000\n",
      "[2018-06-01 01:10:15.391179] Iteration 22500, train loss = 0.192904, train accuracy = 0.976562\n",
      "[2018-06-01 01:10:24.483179] Iteration 22600, train loss = 0.177787, train accuracy = 0.984375\n",
      "[2018-06-01 01:10:33.615179] Iteration 22700, train loss = 0.183982, train accuracy = 0.976562\n",
      "[2018-06-01 01:10:42.817179] Iteration 22800, train loss = 0.164134, train accuracy = 1.000000\n",
      "[2018-06-01 01:10:52.017179] Iteration 22900, train loss = 0.217799, train accuracy = 0.968750\n",
      "[2018-06-01 01:11:01.132179] Iteration 23000, train loss = 0.185039, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910100\n",
      "[2018-06-01 01:11:12.169179] Iteration 23100, train loss = 0.191883, train accuracy = 0.984375\n",
      "[2018-06-01 01:11:21.376179] Iteration 23200, train loss = 0.179380, train accuracy = 0.992188\n",
      "[2018-06-01 01:11:30.548179] Iteration 23300, train loss = 0.163728, train accuracy = 0.984375\n",
      "[2018-06-01 01:11:39.733179] Iteration 23400, train loss = 0.175004, train accuracy = 0.992188\n",
      "[2018-06-01 01:11:48.906179] Iteration 23500, train loss = 0.175955, train accuracy = 0.992188\n",
      "[2018-06-01 01:11:58.047179] Iteration 23600, train loss = 0.168096, train accuracy = 0.992188\n",
      "[2018-06-01 01:12:07.228179] Iteration 23700, train loss = 0.153846, train accuracy = 1.000000\n",
      "[2018-06-01 01:12:16.489179] Iteration 23800, train loss = 0.163677, train accuracy = 1.000000\n",
      "[2018-06-01 01:12:25.625179] Iteration 23900, train loss = 0.194573, train accuracy = 0.976562\n",
      "[2018-06-01 01:12:34.740179] Iteration 24000, train loss = 0.167891, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910300\n",
      "[2018-06-01 01:12:45.920179] Iteration 24100, train loss = 0.175775, train accuracy = 0.984375\n",
      "[2018-06-01 01:12:55.174179] Iteration 24200, train loss = 0.168403, train accuracy = 1.000000\n",
      "[2018-06-01 01:13:04.327179] Iteration 24300, train loss = 0.165427, train accuracy = 1.000000\n",
      "[2018-06-01 01:13:13.419179] Iteration 24400, train loss = 0.173840, train accuracy = 1.000000\n",
      "[2018-06-01 01:13:22.539179] Iteration 24500, train loss = 0.152670, train accuracy = 1.000000\n",
      "[2018-06-01 01:13:31.686179] Iteration 24600, train loss = 0.163317, train accuracy = 1.000000\n",
      "[2018-06-01 01:13:40.839179] Iteration 24700, train loss = 0.172710, train accuracy = 0.984375\n",
      "[2018-06-01 01:13:49.981179] Iteration 24800, train loss = 0.170688, train accuracy = 0.984375\n",
      "[2018-06-01 01:13:59.178179] Iteration 24900, train loss = 0.158707, train accuracy = 1.000000\n",
      "[2018-06-01 01:14:08.321179] Iteration 25000, train loss = 0.181218, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910300\n",
      "[2018-06-01 01:14:19.438179] Iteration 25100, train loss = 0.179437, train accuracy = 0.984375\n",
      "[2018-06-01 01:14:28.591179] Iteration 25200, train loss = 0.162174, train accuracy = 1.000000\n",
      "[2018-06-01 01:14:37.736179] Iteration 25300, train loss = 0.185705, train accuracy = 0.984375\n",
      "[2018-06-01 01:14:46.867179] Iteration 25400, train loss = 0.170260, train accuracy = 0.992188\n",
      "[2018-06-01 01:14:56.057179] Iteration 25500, train loss = 0.170981, train accuracy = 0.992188\n",
      "[2018-06-01 01:15:05.308179] Iteration 25600, train loss = 0.154289, train accuracy = 1.000000\n",
      "[2018-06-01 01:15:14.445179] Iteration 25700, train loss = 0.168631, train accuracy = 1.000000\n",
      "[2018-06-01 01:15:23.638179] Iteration 25800, train loss = 0.166433, train accuracy = 1.000000\n",
      "[2018-06-01 01:15:32.816179] Iteration 25900, train loss = 0.152979, train accuracy = 1.000000\n",
      "[2018-06-01 01:15:41.965179] Iteration 26000, train loss = 0.157511, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 01:15:53.154179] Iteration 26100, train loss = 0.185787, train accuracy = 0.984375\n",
      "[2018-06-01 01:16:02.317179] Iteration 26200, train loss = 0.161569, train accuracy = 1.000000\n",
      "[2018-06-01 01:16:11.469179] Iteration 26300, train loss = 0.177293, train accuracy = 0.992188\n",
      "[2018-06-01 01:16:20.609179] Iteration 26400, train loss = 0.180919, train accuracy = 0.976562\n",
      "[2018-06-01 01:16:29.836179] Iteration 26500, train loss = 0.162612, train accuracy = 1.000000\n",
      "[2018-06-01 01:16:38.960179] Iteration 26600, train loss = 0.170518, train accuracy = 0.992188\n",
      "[2018-06-01 01:16:48.159179] Iteration 26700, train loss = 0.164155, train accuracy = 1.000000\n",
      "[2018-06-01 01:16:57.407179] Iteration 26800, train loss = 0.174992, train accuracy = 0.984375\n",
      "[2018-06-01 01:17:06.552179] Iteration 26900, train loss = 0.173358, train accuracy = 0.992188\n",
      "[2018-06-01 01:17:15.690179] Iteration 27000, train loss = 0.180108, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910200\n",
      "[2018-06-01 01:17:26.849179] Iteration 27100, train loss = 0.179244, train accuracy = 0.992188\n",
      "[2018-06-01 01:17:35.995179] Iteration 27200, train loss = 0.158897, train accuracy = 0.992188\n",
      "[2018-06-01 01:17:45.160179] Iteration 27300, train loss = 0.175096, train accuracy = 0.984375\n",
      "[2018-06-01 01:17:54.350179] Iteration 27400, train loss = 0.183593, train accuracy = 0.976562\n",
      "[2018-06-01 01:18:03.531179] Iteration 27500, train loss = 0.185163, train accuracy = 0.992188\n",
      "[2018-06-01 01:18:12.650179] Iteration 27600, train loss = 0.177845, train accuracy = 0.984375\n",
      "[2018-06-01 01:18:21.838179] Iteration 27700, train loss = 0.171384, train accuracy = 1.000000\n",
      "[2018-06-01 01:18:30.958179] Iteration 27800, train loss = 0.217981, train accuracy = 0.984375\n",
      "[2018-06-01 01:18:40.151179] Iteration 27900, train loss = 0.191927, train accuracy = 0.968750\n",
      "[2018-06-01 01:18:49.289179] Iteration 28000, train loss = 0.163990, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 01:19:00.448179] Iteration 28100, train loss = 0.181884, train accuracy = 0.992188\n",
      "[2018-06-01 01:19:09.538179] Iteration 28200, train loss = 0.172239, train accuracy = 0.992188\n",
      "[2018-06-01 01:19:18.675179] Iteration 28300, train loss = 0.188037, train accuracy = 0.992188\n",
      "[2018-06-01 01:19:27.835179] Iteration 28400, train loss = 0.153266, train accuracy = 1.000000\n",
      "[2018-06-01 01:19:36.995179] Iteration 28500, train loss = 0.190029, train accuracy = 0.992188\n",
      "[2018-06-01 01:19:46.176179] Iteration 28600, train loss = 0.165788, train accuracy = 0.992188\n",
      "[2018-06-01 01:19:55.322179] Iteration 28700, train loss = 0.178026, train accuracy = 0.992188\n",
      "[2018-06-01 01:20:04.497179] Iteration 28800, train loss = 0.171422, train accuracy = 0.984375\n",
      "[2018-06-01 01:20:13.695179] Iteration 28900, train loss = 0.181828, train accuracy = 0.984375\n",
      "[2018-06-01 01:20:22.929179] Iteration 29000, train loss = 0.177798, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 01:20:34.099179] Iteration 29100, train loss = 0.150966, train accuracy = 1.000000\n",
      "[2018-06-01 01:20:43.334179] Iteration 29200, train loss = 0.186077, train accuracy = 0.984375\n",
      "[2018-06-01 01:20:52.427179] Iteration 29300, train loss = 0.167192, train accuracy = 0.984375\n",
      "[2018-06-01 01:21:01.521179] Iteration 29400, train loss = 0.169849, train accuracy = 0.992188\n",
      "[2018-06-01 01:21:10.626179] Iteration 29500, train loss = 0.176710, train accuracy = 0.992188\n",
      "[2018-06-01 01:21:19.788179] Iteration 29600, train loss = 0.174938, train accuracy = 0.992188\n",
      "[2018-06-01 01:21:28.940179] Iteration 29700, train loss = 0.205064, train accuracy = 0.976562\n",
      "[2018-06-01 01:21:38.117179] Iteration 29800, train loss = 0.205256, train accuracy = 0.960938\n",
      "[2018-06-01 01:21:47.309179] Iteration 29900, train loss = 0.156574, train accuracy = 1.000000\n",
      "[2018-06-01 01:21:56.446179] Iteration 30000, train loss = 0.183115, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911100\n",
      "[2018-06-01 01:22:07.546179] Iteration 30100, train loss = 0.164174, train accuracy = 1.000000\n",
      "[2018-06-01 01:22:16.643179] Iteration 30200, train loss = 0.186357, train accuracy = 0.976562\n",
      "[2018-06-01 01:22:25.858179] Iteration 30300, train loss = 0.198866, train accuracy = 0.976562\n",
      "[2018-06-01 01:22:34.994179] Iteration 30400, train loss = 0.168453, train accuracy = 0.992188\n",
      "[2018-06-01 01:22:44.222179] Iteration 30500, train loss = 0.157424, train accuracy = 1.000000\n",
      "[2018-06-01 01:22:53.349179] Iteration 30600, train loss = 0.202356, train accuracy = 0.968750\n",
      "[2018-06-01 01:23:02.548179] Iteration 30700, train loss = 0.161062, train accuracy = 1.000000\n",
      "[2018-06-01 01:23:11.746179] Iteration 30800, train loss = 0.165295, train accuracy = 0.992188\n",
      "[2018-06-01 01:23:20.912179] Iteration 30900, train loss = 0.198044, train accuracy = 0.984375\n",
      "[2018-06-01 01:23:30.062179] Iteration 31000, train loss = 0.173572, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.909700\n",
      "[2018-06-01 01:23:41.111179] Iteration 31100, train loss = 0.172528, train accuracy = 0.992188\n",
      "[2018-06-01 01:23:50.266179] Iteration 31200, train loss = 0.184241, train accuracy = 0.984375\n",
      "[2018-06-01 01:23:59.370179] Iteration 31300, train loss = 0.151622, train accuracy = 1.000000\n",
      "[2018-06-01 01:24:08.550179] Iteration 31400, train loss = 0.169623, train accuracy = 1.000000\n",
      "[2018-06-01 01:24:17.703179] Iteration 31500, train loss = 0.191958, train accuracy = 0.992188\n",
      "[2018-06-01 01:24:26.903179] Iteration 31600, train loss = 0.193827, train accuracy = 0.976562\n",
      "[2018-06-01 01:24:36.040179] Iteration 31700, train loss = 0.187451, train accuracy = 0.976562\n",
      "[2018-06-01 01:24:45.251179] Iteration 31800, train loss = 0.178874, train accuracy = 0.984375\n",
      "[2018-06-01 01:24:54.383179] Iteration 31900, train loss = 0.190253, train accuracy = 0.992188\n",
      "[2018-06-01 01:25:03.527179] Iteration 32000, train loss = 0.158059, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910900\n",
      "[2018-06-01 01:25:14.633179] Iteration 32100, train loss = 0.180049, train accuracy = 0.984375\n",
      "[2018-06-01 01:25:23.813179] Iteration 32200, train loss = 0.164127, train accuracy = 0.992188\n",
      "[2018-06-01 01:25:33.006179] Iteration 32300, train loss = 0.177219, train accuracy = 0.992188\n",
      "[2018-06-01 01:25:42.172179] Iteration 32400, train loss = 0.184820, train accuracy = 0.992188\n",
      "[2018-06-01 01:25:51.299179] Iteration 32500, train loss = 0.177179, train accuracy = 0.992188\n",
      "[2018-06-01 01:26:00.472179] Iteration 32600, train loss = 0.164564, train accuracy = 0.992188\n",
      "[2018-06-01 01:26:09.599179] Iteration 32700, train loss = 0.169044, train accuracy = 0.992188\n",
      "[2018-06-01 01:26:18.677179] Iteration 32800, train loss = 0.155524, train accuracy = 1.000000\n",
      "[2018-06-01 01:26:27.781179] Iteration 32900, train loss = 0.158312, train accuracy = 1.000000\n",
      "[2018-06-01 01:26:36.988179] Iteration 33000, train loss = 0.171294, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910300\n",
      "[2018-06-01 01:26:48.117179] Iteration 33100, train loss = 0.170195, train accuracy = 0.984375\n",
      "[2018-06-01 01:26:57.300179] Iteration 33200, train loss = 0.169491, train accuracy = 0.992188\n",
      "[2018-06-01 01:27:06.392179] Iteration 33300, train loss = 0.151639, train accuracy = 1.000000\n",
      "[2018-06-01 01:27:15.569179] Iteration 33400, train loss = 0.177659, train accuracy = 0.992188\n",
      "[2018-06-01 01:27:24.677179] Iteration 33500, train loss = 0.155641, train accuracy = 1.000000\n",
      "[2018-06-01 01:27:33.896179] Iteration 33600, train loss = 0.197810, train accuracy = 0.976562\n",
      "[2018-06-01 01:27:43.037179] Iteration 33700, train loss = 0.155642, train accuracy = 1.000000\n",
      "[2018-06-01 01:27:52.226179] Iteration 33800, train loss = 0.174774, train accuracy = 0.992188\n",
      "[2018-06-01 01:28:01.414179] Iteration 33900, train loss = 0.165228, train accuracy = 0.992188\n",
      "[2018-06-01 01:28:10.622179] Iteration 34000, train loss = 0.181391, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910200\n",
      "[2018-06-01 01:28:21.783179] Iteration 34100, train loss = 0.166497, train accuracy = 0.992188\n",
      "[2018-06-01 01:28:30.924179] Iteration 34200, train loss = 0.154868, train accuracy = 1.000000\n",
      "[2018-06-01 01:28:40.093179] Iteration 34300, train loss = 0.165336, train accuracy = 1.000000\n",
      "[2018-06-01 01:28:49.250179] Iteration 34400, train loss = 0.171630, train accuracy = 0.992188\n",
      "[2018-06-01 01:28:58.440179] Iteration 34500, train loss = 0.166866, train accuracy = 0.992188\n",
      "[2018-06-01 01:29:07.642179] Iteration 34600, train loss = 0.159983, train accuracy = 0.992188\n",
      "[2018-06-01 01:29:16.791179] Iteration 34700, train loss = 0.174837, train accuracy = 0.984375\n",
      "[2018-06-01 01:29:25.921179] Iteration 34800, train loss = 0.169516, train accuracy = 0.992188\n",
      "[2018-06-01 01:29:35.108179] Iteration 34900, train loss = 0.163828, train accuracy = 0.992188\n",
      "[2018-06-01 01:29:44.298179] Iteration 35000, train loss = 0.152347, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 01:29:55.409179] Iteration 35100, train loss = 0.185283, train accuracy = 0.984375\n",
      "[2018-06-01 01:30:04.465179] Iteration 35200, train loss = 0.165148, train accuracy = 0.992188\n",
      "[2018-06-01 01:30:13.703179] Iteration 35300, train loss = 0.150616, train accuracy = 1.000000\n",
      "[2018-06-01 01:30:22.859179] Iteration 35400, train loss = 0.157389, train accuracy = 1.000000\n",
      "[2018-06-01 01:30:32.046179] Iteration 35500, train loss = 0.163074, train accuracy = 0.992188\n",
      "[2018-06-01 01:30:41.175179] Iteration 35600, train loss = 0.160965, train accuracy = 1.000000\n",
      "[2018-06-01 01:30:50.380179] Iteration 35700, train loss = 0.156124, train accuracy = 1.000000\n",
      "[2018-06-01 01:30:59.542179] Iteration 35800, train loss = 0.155293, train accuracy = 1.000000\n",
      "[2018-06-01 01:31:08.721179] Iteration 35900, train loss = 0.154950, train accuracy = 1.000000\n",
      "[2018-06-01 01:31:17.884179] Iteration 36000, train loss = 0.192176, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910300\n",
      "[2018-06-01 01:31:29.090179] Iteration 36100, train loss = 0.172231, train accuracy = 0.992188\n",
      "[2018-06-01 01:31:38.265179] Iteration 36200, train loss = 0.152074, train accuracy = 1.000000\n",
      "[2018-06-01 01:31:47.465179] Iteration 36300, train loss = 0.194405, train accuracy = 0.976562\n",
      "[2018-06-01 01:31:56.598179] Iteration 36400, train loss = 0.164948, train accuracy = 0.992188\n",
      "[2018-06-01 01:32:05.858179] Iteration 36500, train loss = 0.169526, train accuracy = 0.992188\n",
      "[2018-06-01 01:32:15.049179] Iteration 36600, train loss = 0.180682, train accuracy = 0.984375\n",
      "[2018-06-01 01:32:24.132179] Iteration 36700, train loss = 0.163077, train accuracy = 0.992188\n",
      "[2018-06-01 01:32:33.306179] Iteration 36800, train loss = 0.163260, train accuracy = 1.000000\n",
      "[2018-06-01 01:32:42.477179] Iteration 36900, train loss = 0.166879, train accuracy = 0.992188\n",
      "[2018-06-01 01:32:51.698179] Iteration 37000, train loss = 0.170115, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910700\n",
      "[2018-06-01 01:33:02.935179] Iteration 37100, train loss = 0.190351, train accuracy = 0.976562\n",
      "[2018-06-01 01:33:12.139179] Iteration 37200, train loss = 0.162585, train accuracy = 0.992188\n",
      "[2018-06-01 01:33:21.243179] Iteration 37300, train loss = 0.185863, train accuracy = 0.976562\n",
      "[2018-06-01 01:33:30.441179] Iteration 37400, train loss = 0.155308, train accuracy = 1.000000\n",
      "[2018-06-01 01:33:39.573179] Iteration 37500, train loss = 0.173078, train accuracy = 0.992188\n",
      "[2018-06-01 01:33:48.729179] Iteration 37600, train loss = 0.184607, train accuracy = 0.984375\n",
      "[2018-06-01 01:33:57.873179] Iteration 37700, train loss = 0.178097, train accuracy = 1.000000\n",
      "[2018-06-01 01:34:06.991179] Iteration 37800, train loss = 0.179312, train accuracy = 0.992188\n",
      "[2018-06-01 01:34:16.124179] Iteration 37900, train loss = 0.154488, train accuracy = 1.000000\n",
      "[2018-06-01 01:34:25.262179] Iteration 38000, train loss = 0.180846, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.909800\n",
      "[2018-06-01 01:34:36.394179] Iteration 38100, train loss = 0.155797, train accuracy = 1.000000\n",
      "[2018-06-01 01:34:45.562179] Iteration 38200, train loss = 0.180177, train accuracy = 0.984375\n",
      "[2018-06-01 01:34:54.751179] Iteration 38300, train loss = 0.191950, train accuracy = 0.968750\n",
      "[2018-06-01 01:35:03.911179] Iteration 38400, train loss = 0.166230, train accuracy = 0.992188\n",
      "[2018-06-01 01:35:13.144179] Iteration 38500, train loss = 0.180522, train accuracy = 0.984375\n",
      "[2018-06-01 01:35:22.310179] Iteration 38600, train loss = 0.165689, train accuracy = 1.000000\n",
      "[2018-06-01 01:35:31.436179] Iteration 38700, train loss = 0.151593, train accuracy = 1.000000\n",
      "[2018-06-01 01:35:40.588179] Iteration 38800, train loss = 0.182995, train accuracy = 1.000000\n",
      "[2018-06-01 01:35:49.726179] Iteration 38900, train loss = 0.159723, train accuracy = 1.000000\n",
      "[2018-06-01 01:35:58.864179] Iteration 39000, train loss = 0.156360, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910200\n",
      "[2018-06-01 01:36:10.113179] Iteration 39100, train loss = 0.164509, train accuracy = 1.000000\n",
      "[2018-06-01 01:36:19.345179] Iteration 39200, train loss = 0.170737, train accuracy = 1.000000\n",
      "[2018-06-01 01:36:28.446179] Iteration 39300, train loss = 0.162604, train accuracy = 1.000000\n",
      "[2018-06-01 01:36:37.590179] Iteration 39400, train loss = 0.161162, train accuracy = 0.992188\n",
      "[2018-06-01 01:36:46.713179] Iteration 39500, train loss = 0.214351, train accuracy = 0.976562\n",
      "[2018-06-01 01:36:55.953179] Iteration 39600, train loss = 0.153695, train accuracy = 1.000000\n",
      "[2018-06-01 01:37:05.164179] Iteration 39700, train loss = 0.167744, train accuracy = 0.992188\n",
      "[2018-06-01 01:37:14.276179] Iteration 39800, train loss = 0.179172, train accuracy = 0.992188\n",
      "[2018-06-01 01:37:23.442179] Iteration 39900, train loss = 0.164197, train accuracy = 0.992188\n",
      "[2018-06-01 01:37:32.616179] Iteration 40000, train loss = 0.155159, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 01:37:43.690179] Iteration 40100, train loss = 0.185914, train accuracy = 0.992188\n",
      "[2018-06-01 01:37:52.859179] Iteration 40200, train loss = 0.175680, train accuracy = 0.992188\n",
      "[2018-06-01 01:38:02.022179] Iteration 40300, train loss = 0.150650, train accuracy = 1.000000\n",
      "[2018-06-01 01:38:11.122179] Iteration 40400, train loss = 0.178427, train accuracy = 0.992188\n",
      "[2018-06-01 01:38:20.255179] Iteration 40500, train loss = 0.156985, train accuracy = 1.000000\n",
      "[2018-06-01 01:38:29.458179] Iteration 40600, train loss = 0.173549, train accuracy = 0.984375\n",
      "[2018-06-01 01:38:38.609179] Iteration 40700, train loss = 0.191076, train accuracy = 0.992188\n",
      "[2018-06-01 01:38:47.799179] Iteration 40800, train loss = 0.165373, train accuracy = 0.984375\n",
      "[2018-06-01 01:38:56.888179] Iteration 40900, train loss = 0.164671, train accuracy = 0.992188\n",
      "[2018-06-01 01:39:06.072179] Iteration 41000, train loss = 0.202971, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911000\n",
      "[2018-06-01 01:39:17.312179] Iteration 41100, train loss = 0.158570, train accuracy = 1.000000\n",
      "[2018-06-01 01:39:26.457179] Iteration 41200, train loss = 0.159072, train accuracy = 0.992188\n",
      "[2018-06-01 01:39:35.601179] Iteration 41300, train loss = 0.151191, train accuracy = 1.000000\n",
      "[2018-06-01 01:39:44.780179] Iteration 41400, train loss = 0.161203, train accuracy = 0.992188\n",
      "[2018-06-01 01:39:53.911179] Iteration 41500, train loss = 0.165703, train accuracy = 0.992188\n",
      "[2018-06-01 01:40:03.050179] Iteration 41600, train loss = 0.180104, train accuracy = 0.984375\n",
      "[2018-06-01 01:40:12.175179] Iteration 41700, train loss = 0.199639, train accuracy = 0.976562\n",
      "[2018-06-01 01:40:21.363179] Iteration 41800, train loss = 0.196317, train accuracy = 0.976562\n",
      "[2018-06-01 01:40:30.531179] Iteration 41900, train loss = 0.170844, train accuracy = 0.992188\n",
      "[2018-06-01 01:40:39.708179] Iteration 42000, train loss = 0.166427, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 01:40:50.876179] Iteration 42100, train loss = 0.161778, train accuracy = 1.000000\n",
      "[2018-06-01 01:40:59.988179] Iteration 42200, train loss = 0.183651, train accuracy = 0.984375\n",
      "[2018-06-01 01:41:09.165179] Iteration 42300, train loss = 0.201667, train accuracy = 0.984375\n",
      "[2018-06-01 01:41:18.343179] Iteration 42400, train loss = 0.178335, train accuracy = 0.992188\n",
      "[2018-06-01 01:41:27.431179] Iteration 42500, train loss = 0.205049, train accuracy = 0.984375\n",
      "[2018-06-01 01:41:36.564179] Iteration 42600, train loss = 0.163699, train accuracy = 0.992188\n",
      "[2018-06-01 01:41:45.695179] Iteration 42700, train loss = 0.167565, train accuracy = 0.992188\n",
      "[2018-06-01 01:41:54.817179] Iteration 42800, train loss = 0.160690, train accuracy = 0.992188\n",
      "[2018-06-01 01:42:04.002179] Iteration 42900, train loss = 0.201200, train accuracy = 0.976562\n",
      "[2018-06-01 01:42:13.140179] Iteration 43000, train loss = 0.164818, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 01:42:24.311179] Iteration 43100, train loss = 0.160947, train accuracy = 0.992188\n",
      "[2018-06-01 01:42:33.517179] Iteration 43200, train loss = 0.177713, train accuracy = 0.984375\n",
      "[2018-06-01 01:42:42.674179] Iteration 43300, train loss = 0.177462, train accuracy = 0.992188\n",
      "[2018-06-01 01:42:51.817179] Iteration 43400, train loss = 0.161863, train accuracy = 0.992188\n",
      "[2018-06-01 01:43:01.066179] Iteration 43500, train loss = 0.156204, train accuracy = 1.000000\n",
      "[2018-06-01 01:43:10.250179] Iteration 43600, train loss = 0.160317, train accuracy = 1.000000\n",
      "[2018-06-01 01:43:19.451179] Iteration 43700, train loss = 0.156746, train accuracy = 1.000000\n",
      "[2018-06-01 01:43:28.649179] Iteration 43800, train loss = 0.186568, train accuracy = 0.984375\n",
      "[2018-06-01 01:43:37.785179] Iteration 43900, train loss = 0.170606, train accuracy = 0.984375\n",
      "[2018-06-01 01:43:46.955179] Iteration 44000, train loss = 0.164578, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.909900\n",
      "[2018-06-01 01:43:58.171179] Iteration 44100, train loss = 0.167590, train accuracy = 0.992188\n",
      "[2018-06-01 01:44:07.397179] Iteration 44200, train loss = 0.167210, train accuracy = 0.992188\n",
      "[2018-06-01 01:44:16.535179] Iteration 44300, train loss = 0.157626, train accuracy = 1.000000\n",
      "[2018-06-01 01:44:25.690179] Iteration 44400, train loss = 0.170855, train accuracy = 0.992188\n",
      "[2018-06-01 01:44:34.794179] Iteration 44500, train loss = 0.165101, train accuracy = 0.992188\n",
      "[2018-06-01 01:44:43.918179] Iteration 44600, train loss = 0.204394, train accuracy = 0.992188\n",
      "[2018-06-01 01:44:53.035179] Iteration 44700, train loss = 0.193688, train accuracy = 0.984375\n",
      "[2018-06-01 01:45:02.305179] Iteration 44800, train loss = 0.157416, train accuracy = 1.000000\n",
      "[2018-06-01 01:45:11.442179] Iteration 44900, train loss = 0.186404, train accuracy = 0.984375\n",
      "[2018-06-01 01:45:20.670179] Iteration 45000, train loss = 0.156613, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.911000\n",
      "[2018-06-01 01:45:31.798179] Iteration 45100, train loss = 0.159753, train accuracy = 1.000000\n",
      "[2018-06-01 01:45:41.047179] Iteration 45200, train loss = 0.172380, train accuracy = 0.992188\n",
      "[2018-06-01 01:45:50.186179] Iteration 45300, train loss = 0.177408, train accuracy = 0.984375\n",
      "[2018-06-01 01:45:59.468179] Iteration 45400, train loss = 0.192713, train accuracy = 0.984375\n",
      "[2018-06-01 01:46:08.618179] Iteration 45500, train loss = 0.155198, train accuracy = 0.992188\n",
      "[2018-06-01 01:46:17.762179] Iteration 45600, train loss = 0.160123, train accuracy = 0.992188\n",
      "[2018-06-01 01:46:26.954179] Iteration 45700, train loss = 0.157016, train accuracy = 1.000000\n",
      "[2018-06-01 01:46:36.075179] Iteration 45800, train loss = 0.174729, train accuracy = 0.984375\n",
      "[2018-06-01 01:46:45.186179] Iteration 45900, train loss = 0.170902, train accuracy = 0.992188\n",
      "[2018-06-01 01:46:54.310179] Iteration 46000, train loss = 0.156430, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910200\n",
      "[2018-06-01 01:47:05.381179] Iteration 46100, train loss = 0.158960, train accuracy = 0.992188\n",
      "[2018-06-01 01:47:14.555179] Iteration 46200, train loss = 0.179373, train accuracy = 1.000000\n",
      "[2018-06-01 01:47:23.688179] Iteration 46300, train loss = 0.181019, train accuracy = 0.992188\n",
      "[2018-06-01 01:47:32.866179] Iteration 46400, train loss = 0.196009, train accuracy = 0.976562\n",
      "[2018-06-01 01:47:42.056179] Iteration 46500, train loss = 0.200074, train accuracy = 0.984375\n",
      "[2018-06-01 01:47:51.287179] Iteration 46600, train loss = 0.180252, train accuracy = 0.984375\n",
      "[2018-06-01 01:48:00.451179] Iteration 46700, train loss = 0.164814, train accuracy = 0.992188\n",
      "[2018-06-01 01:48:09.572179] Iteration 46800, train loss = 0.168504, train accuracy = 0.992188\n",
      "[2018-06-01 01:48:18.713179] Iteration 46900, train loss = 0.180672, train accuracy = 0.984375\n",
      "[2018-06-01 01:48:27.890179] Iteration 47000, train loss = 0.183734, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.911000\n",
      "[2018-06-01 01:48:39.017179] Iteration 47100, train loss = 0.181506, train accuracy = 0.984375\n",
      "[2018-06-01 01:48:48.220179] Iteration 47200, train loss = 0.174415, train accuracy = 0.984375\n",
      "[2018-06-01 01:48:57.396179] Iteration 47300, train loss = 0.173951, train accuracy = 0.992188\n",
      "[2018-06-01 01:49:06.523179] Iteration 47400, train loss = 0.183319, train accuracy = 0.992188\n",
      "[2018-06-01 01:49:15.679179] Iteration 47500, train loss = 0.167044, train accuracy = 0.992188\n",
      "[2018-06-01 01:49:24.830179] Iteration 47600, train loss = 0.164707, train accuracy = 0.992188\n",
      "[2018-06-01 01:49:33.949179] Iteration 47700, train loss = 0.156211, train accuracy = 1.000000\n",
      "[2018-06-01 01:49:43.088179] Iteration 47800, train loss = 0.166204, train accuracy = 0.992188\n",
      "[2018-06-01 01:49:52.220179] Iteration 47900, train loss = 0.161144, train accuracy = 0.992188\n",
      "[2018-06-01 01:50:01.336179] Iteration 48000, train loss = 0.204429, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "Learning rate set to 0.001000\n",
      "[2018-06-01 01:50:12.464179] Iteration 48100, train loss = 0.170063, train accuracy = 0.984375\n",
      "[2018-06-01 01:50:21.609179] Iteration 48200, train loss = 0.187365, train accuracy = 0.984375\n",
      "[2018-06-01 01:50:30.729179] Iteration 48300, train loss = 0.184709, train accuracy = 0.984375\n",
      "[2018-06-01 01:50:39.954179] Iteration 48400, train loss = 0.159249, train accuracy = 1.000000\n",
      "[2018-06-01 01:50:49.089179] Iteration 48500, train loss = 0.167553, train accuracy = 0.992188\n",
      "[2018-06-01 01:50:58.182179] Iteration 48600, train loss = 0.165810, train accuracy = 0.992188\n",
      "[2018-06-01 01:51:07.349179] Iteration 48700, train loss = 0.178313, train accuracy = 1.000000\n",
      "[2018-06-01 01:51:16.545179] Iteration 48800, train loss = 0.192734, train accuracy = 0.968750\n",
      "[2018-06-01 01:51:25.781179] Iteration 48900, train loss = 0.159119, train accuracy = 1.000000\n",
      "[2018-06-01 01:51:34.969179] Iteration 49000, train loss = 0.229691, train accuracy = 0.953125\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 01:51:46.098179] Iteration 49100, train loss = 0.157445, train accuracy = 1.000000\n",
      "[2018-06-01 01:51:55.243179] Iteration 49200, train loss = 0.167019, train accuracy = 0.984375\n",
      "[2018-06-01 01:52:04.401179] Iteration 49300, train loss = 0.180981, train accuracy = 0.992188\n",
      "[2018-06-01 01:52:13.591179] Iteration 49400, train loss = 0.201199, train accuracy = 0.984375\n",
      "[2018-06-01 01:52:22.772179] Iteration 49500, train loss = 0.167928, train accuracy = 0.992188\n",
      "[2018-06-01 01:52:31.942179] Iteration 49600, train loss = 0.172407, train accuracy = 0.984375\n",
      "[2018-06-01 01:52:41.081179] Iteration 49700, train loss = 0.186165, train accuracy = 0.992188\n",
      "[2018-06-01 01:52:50.288179] Iteration 49800, train loss = 0.176379, train accuracy = 0.984375\n",
      "[2018-06-01 01:52:59.385179] Iteration 49900, train loss = 0.190224, train accuracy = 0.984375\n",
      "[2018-06-01 01:53:08.605179] Iteration 50000, train loss = 0.164600, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 01:53:19.785179] Iteration 50100, train loss = 0.171703, train accuracy = 1.000000\n",
      "[2018-06-01 01:53:28.925179] Iteration 50200, train loss = 0.157246, train accuracy = 1.000000\n",
      "[2018-06-01 01:53:38.088179] Iteration 50300, train loss = 0.170850, train accuracy = 0.992188\n",
      "[2018-06-01 01:53:47.221179] Iteration 50400, train loss = 0.157538, train accuracy = 0.992188\n",
      "[2018-06-01 01:53:56.310179] Iteration 50500, train loss = 0.159423, train accuracy = 1.000000\n",
      "[2018-06-01 01:54:05.418179] Iteration 50600, train loss = 0.154855, train accuracy = 1.000000\n",
      "[2018-06-01 01:54:14.494179] Iteration 50700, train loss = 0.150815, train accuracy = 1.000000\n",
      "[2018-06-01 01:54:23.622179] Iteration 50800, train loss = 0.169187, train accuracy = 0.992188\n",
      "[2018-06-01 01:54:32.808179] Iteration 50900, train loss = 0.163117, train accuracy = 0.992188\n",
      "[2018-06-01 01:54:41.950179] Iteration 51000, train loss = 0.164062, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910100\n",
      "[2018-06-01 01:54:53.090179] Iteration 51100, train loss = 0.156813, train accuracy = 1.000000\n",
      "[2018-06-01 01:55:02.297179] Iteration 51200, train loss = 0.167054, train accuracy = 0.992188\n",
      "[2018-06-01 01:55:11.441179] Iteration 51300, train loss = 0.167284, train accuracy = 0.992188\n",
      "[2018-06-01 01:55:20.533179] Iteration 51400, train loss = 0.202953, train accuracy = 0.976562\n",
      "[2018-06-01 01:55:29.644179] Iteration 51500, train loss = 0.184319, train accuracy = 0.992188\n",
      "[2018-06-01 01:55:38.855179] Iteration 51600, train loss = 0.149291, train accuracy = 1.000000\n",
      "[2018-06-01 01:55:47.945179] Iteration 51700, train loss = 0.173768, train accuracy = 0.992188\n",
      "[2018-06-01 01:55:57.068179] Iteration 51800, train loss = 0.206855, train accuracy = 0.960938\n",
      "[2018-06-01 01:56:06.211179] Iteration 51900, train loss = 0.173697, train accuracy = 0.984375\n",
      "[2018-06-01 01:56:15.299179] Iteration 52000, train loss = 0.163326, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 01:56:26.482179] Iteration 52100, train loss = 0.163135, train accuracy = 0.992188\n",
      "[2018-06-01 01:56:35.624179] Iteration 52200, train loss = 0.187653, train accuracy = 0.984375\n",
      "[2018-06-01 01:56:44.811179] Iteration 52300, train loss = 0.178728, train accuracy = 0.984375\n",
      "[2018-06-01 01:56:54.009179] Iteration 52400, train loss = 0.163625, train accuracy = 0.984375\n",
      "[2018-06-01 01:57:03.152179] Iteration 52500, train loss = 0.169538, train accuracy = 0.992188\n",
      "[2018-06-01 01:57:12.260179] Iteration 52600, train loss = 0.157831, train accuracy = 1.000000\n",
      "[2018-06-01 01:57:21.436179] Iteration 52700, train loss = 0.201428, train accuracy = 0.984375\n",
      "[2018-06-01 01:57:30.535179] Iteration 52800, train loss = 0.183664, train accuracy = 0.992188\n",
      "[2018-06-01 01:57:39.733179] Iteration 52900, train loss = 0.178542, train accuracy = 0.984375\n",
      "[2018-06-01 01:57:48.894179] Iteration 53000, train loss = 0.166583, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910500\n",
      "[2018-06-01 01:58:00.072179] Iteration 53100, train loss = 0.212393, train accuracy = 0.976562\n",
      "[2018-06-01 01:58:09.229179] Iteration 53200, train loss = 0.158449, train accuracy = 0.992188\n",
      "[2018-06-01 01:58:18.361179] Iteration 53300, train loss = 0.157292, train accuracy = 1.000000\n",
      "[2018-06-01 01:58:27.488179] Iteration 53400, train loss = 0.151046, train accuracy = 1.000000\n",
      "[2018-06-01 01:58:36.607179] Iteration 53500, train loss = 0.164332, train accuracy = 1.000000\n",
      "[2018-06-01 01:58:45.775179] Iteration 53600, train loss = 0.166706, train accuracy = 0.992188\n",
      "[2018-06-01 01:58:54.910179] Iteration 53700, train loss = 0.209340, train accuracy = 0.968750\n",
      "[2018-06-01 01:59:04.135179] Iteration 53800, train loss = 0.199297, train accuracy = 0.984375\n",
      "[2018-06-01 01:59:13.294179] Iteration 53900, train loss = 0.150829, train accuracy = 1.000000\n",
      "[2018-06-01 01:59:22.520179] Iteration 54000, train loss = 0.174689, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 01:59:33.680179] Iteration 54100, train loss = 0.198719, train accuracy = 0.976562\n",
      "[2018-06-01 01:59:42.827179] Iteration 54200, train loss = 0.157872, train accuracy = 1.000000\n",
      "[2018-06-01 01:59:52.118179] Iteration 54300, train loss = 0.161709, train accuracy = 1.000000\n",
      "[2018-06-01 02:00:01.254179] Iteration 54400, train loss = 0.161314, train accuracy = 1.000000\n",
      "[2018-06-01 02:00:10.386179] Iteration 54500, train loss = 0.164066, train accuracy = 0.992188\n",
      "[2018-06-01 02:00:19.553179] Iteration 54600, train loss = 0.157705, train accuracy = 1.000000\n",
      "[2018-06-01 02:00:28.706179] Iteration 54700, train loss = 0.162120, train accuracy = 0.992188\n",
      "[2018-06-01 02:00:37.925179] Iteration 54800, train loss = 0.176732, train accuracy = 0.984375\n",
      "[2018-06-01 02:00:47.069179] Iteration 54900, train loss = 0.165444, train accuracy = 0.992188\n",
      "[2018-06-01 02:00:56.277179] Iteration 55000, train loss = 0.159589, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 02:01:07.402179] Iteration 55100, train loss = 0.168651, train accuracy = 0.984375\n",
      "[2018-06-01 02:01:16.541179] Iteration 55200, train loss = 0.161097, train accuracy = 0.992188\n",
      "[2018-06-01 02:01:25.713179] Iteration 55300, train loss = 0.162680, train accuracy = 0.992188\n",
      "[2018-06-01 02:01:34.867179] Iteration 55400, train loss = 0.160900, train accuracy = 1.000000\n",
      "[2018-06-01 02:01:44.068179] Iteration 55500, train loss = 0.162278, train accuracy = 0.992188\n",
      "[2018-06-01 02:01:53.229179] Iteration 55600, train loss = 0.165240, train accuracy = 0.992188\n",
      "[2018-06-01 02:02:02.375179] Iteration 55700, train loss = 0.166710, train accuracy = 1.000000\n",
      "[2018-06-01 02:02:11.540179] Iteration 55800, train loss = 0.190853, train accuracy = 0.984375\n",
      "[2018-06-01 02:02:20.593179] Iteration 55900, train loss = 0.205326, train accuracy = 0.976562\n",
      "[2018-06-01 02:02:29.709179] Iteration 56000, train loss = 0.167356, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910100\n",
      "[2018-06-01 02:02:40.881179] Iteration 56100, train loss = 0.202148, train accuracy = 0.976562\n",
      "[2018-06-01 02:02:50.061179] Iteration 56200, train loss = 0.165689, train accuracy = 0.992188\n",
      "[2018-06-01 02:02:59.303179] Iteration 56300, train loss = 0.176069, train accuracy = 0.984375\n",
      "[2018-06-01 02:03:08.426179] Iteration 56400, train loss = 0.171720, train accuracy = 0.992188\n",
      "[2018-06-01 02:03:17.518179] Iteration 56500, train loss = 0.167823, train accuracy = 0.992188\n",
      "[2018-06-01 02:03:26.655179] Iteration 56600, train loss = 0.196442, train accuracy = 0.984375\n",
      "[2018-06-01 02:03:35.898179] Iteration 56700, train loss = 0.159210, train accuracy = 0.992188\n",
      "[2018-06-01 02:03:44.994179] Iteration 56800, train loss = 0.207399, train accuracy = 0.968750\n",
      "[2018-06-01 02:03:54.176179] Iteration 56900, train loss = 0.197998, train accuracy = 0.976562\n",
      "[2018-06-01 02:04:03.300179] Iteration 57000, train loss = 0.189617, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.909800\n",
      "[2018-06-01 02:04:14.485179] Iteration 57100, train loss = 0.183360, train accuracy = 0.984375\n",
      "[2018-06-01 02:04:23.640179] Iteration 57200, train loss = 0.148577, train accuracy = 1.000000\n",
      "[2018-06-01 02:04:32.801179] Iteration 57300, train loss = 0.164829, train accuracy = 0.992188\n",
      "[2018-06-01 02:04:41.930179] Iteration 57400, train loss = 0.166796, train accuracy = 1.000000\n",
      "[2018-06-01 02:04:51.089179] Iteration 57500, train loss = 0.165869, train accuracy = 1.000000\n",
      "[2018-06-01 02:05:00.206179] Iteration 57600, train loss = 0.179980, train accuracy = 0.984375\n",
      "[2018-06-01 02:05:09.366179] Iteration 57700, train loss = 0.185580, train accuracy = 0.984375\n",
      "[2018-06-01 02:05:18.543179] Iteration 57800, train loss = 0.189349, train accuracy = 0.984375\n",
      "[2018-06-01 02:05:27.744179] Iteration 57900, train loss = 0.155111, train accuracy = 1.000000\n",
      "[2018-06-01 02:05:36.912179] Iteration 58000, train loss = 0.178017, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.909600\n",
      "[2018-06-01 02:05:47.997179] Iteration 58100, train loss = 0.167913, train accuracy = 0.992188\n",
      "[2018-06-01 02:05:57.234179] Iteration 58200, train loss = 0.174837, train accuracy = 0.992188\n",
      "[2018-06-01 02:06:06.352179] Iteration 58300, train loss = 0.177035, train accuracy = 0.992188\n",
      "[2018-06-01 02:06:15.506179] Iteration 58400, train loss = 0.169812, train accuracy = 0.984375\n",
      "[2018-06-01 02:06:24.646179] Iteration 58500, train loss = 0.193371, train accuracy = 0.984375\n",
      "[2018-06-01 02:06:33.728179] Iteration 58600, train loss = 0.174231, train accuracy = 0.992188\n",
      "[2018-06-01 02:06:42.924179] Iteration 58700, train loss = 0.187245, train accuracy = 0.984375\n",
      "[2018-06-01 02:06:52.028179] Iteration 58800, train loss = 0.152234, train accuracy = 1.000000\n",
      "[2018-06-01 02:07:01.175179] Iteration 58900, train loss = 0.162685, train accuracy = 1.000000\n",
      "[2018-06-01 02:07:10.386179] Iteration 59000, train loss = 0.173583, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910100\n",
      "[2018-06-01 02:07:21.491179] Iteration 59100, train loss = 0.163277, train accuracy = 0.992188\n",
      "[2018-06-01 02:07:30.642179] Iteration 59200, train loss = 0.166474, train accuracy = 0.992188\n",
      "[2018-06-01 02:07:39.843179] Iteration 59300, train loss = 0.160740, train accuracy = 0.992188\n",
      "[2018-06-01 02:07:49.004179] Iteration 59400, train loss = 0.164841, train accuracy = 0.992188\n",
      "[2018-06-01 02:07:58.235179] Iteration 59500, train loss = 0.150760, train accuracy = 1.000000\n",
      "[2018-06-01 02:08:07.398179] Iteration 59600, train loss = 0.157827, train accuracy = 1.000000\n",
      "[2018-06-01 02:08:16.605179] Iteration 59700, train loss = 0.183590, train accuracy = 0.984375\n",
      "[2018-06-01 02:08:25.743179] Iteration 59800, train loss = 0.150909, train accuracy = 1.000000\n",
      "[2018-06-01 02:08:34.868179] Iteration 59900, train loss = 0.190241, train accuracy = 0.976562\n",
      "[2018-06-01 02:08:43.988179] Iteration 60000, train loss = 0.153889, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 02:08:55.223179] Iteration 60100, train loss = 0.210127, train accuracy = 0.976562\n",
      "[2018-06-01 02:09:04.380179] Iteration 60200, train loss = 0.201116, train accuracy = 0.976562\n",
      "[2018-06-01 02:09:13.551179] Iteration 60300, train loss = 0.174122, train accuracy = 0.992188\n",
      "[2018-06-01 02:09:22.717179] Iteration 60400, train loss = 0.187378, train accuracy = 0.992188\n",
      "[2018-06-01 02:09:31.951179] Iteration 60500, train loss = 0.171287, train accuracy = 0.992188\n",
      "[2018-06-01 02:09:41.065179] Iteration 60600, train loss = 0.196424, train accuracy = 0.976562\n",
      "[2018-06-01 02:09:50.248179] Iteration 60700, train loss = 0.162524, train accuracy = 0.992188\n",
      "[2018-06-01 02:09:59.319179] Iteration 60800, train loss = 0.179491, train accuracy = 0.992188\n",
      "[2018-06-01 02:10:08.432179] Iteration 60900, train loss = 0.205124, train accuracy = 0.976562\n",
      "[2018-06-01 02:10:17.537179] Iteration 61000, train loss = 0.179086, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.909500\n",
      "[2018-06-01 02:10:28.647179] Iteration 61100, train loss = 0.164582, train accuracy = 0.984375\n",
      "[2018-06-01 02:10:37.877179] Iteration 61200, train loss = 0.208523, train accuracy = 0.984375\n",
      "[2018-06-01 02:10:47.091179] Iteration 61300, train loss = 0.169051, train accuracy = 0.992188\n",
      "[2018-06-01 02:10:56.211179] Iteration 61400, train loss = 0.183141, train accuracy = 0.984375\n",
      "[2018-06-01 02:11:05.400179] Iteration 61500, train loss = 0.184623, train accuracy = 0.984375\n",
      "[2018-06-01 02:11:14.499179] Iteration 61600, train loss = 0.175512, train accuracy = 0.984375\n",
      "[2018-06-01 02:11:23.690179] Iteration 61700, train loss = 0.173255, train accuracy = 0.992188\n",
      "[2018-06-01 02:11:32.865179] Iteration 61800, train loss = 0.203376, train accuracy = 0.976562\n",
      "[2018-06-01 02:11:42.057179] Iteration 61900, train loss = 0.162481, train accuracy = 1.000000\n",
      "[2018-06-01 02:11:51.269179] Iteration 62000, train loss = 0.161097, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910500\n",
      "[2018-06-01 02:12:02.372179] Iteration 62100, train loss = 0.178745, train accuracy = 0.984375\n",
      "[2018-06-01 02:12:11.561179] Iteration 62200, train loss = 0.159450, train accuracy = 0.992188\n",
      "[2018-06-01 02:12:20.778179] Iteration 62300, train loss = 0.168402, train accuracy = 0.992188\n",
      "[2018-06-01 02:12:30.004179] Iteration 62400, train loss = 0.173217, train accuracy = 0.992188\n",
      "[2018-06-01 02:12:39.136179] Iteration 62500, train loss = 0.180183, train accuracy = 0.984375\n",
      "[2018-06-01 02:12:48.324179] Iteration 62600, train loss = 0.173617, train accuracy = 0.984375\n",
      "[2018-06-01 02:12:57.495179] Iteration 62700, train loss = 0.191227, train accuracy = 0.984375\n",
      "[2018-06-01 02:13:06.619179] Iteration 62800, train loss = 0.180349, train accuracy = 0.984375\n",
      "[2018-06-01 02:13:15.817179] Iteration 62900, train loss = 0.157266, train accuracy = 1.000000\n",
      "[2018-06-01 02:13:25.022179] Iteration 63000, train loss = 0.162777, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910100\n",
      "[2018-06-01 02:13:36.215179] Iteration 63100, train loss = 0.158961, train accuracy = 1.000000\n",
      "[2018-06-01 02:13:45.345179] Iteration 63200, train loss = 0.181170, train accuracy = 0.984375\n",
      "[2018-06-01 02:13:54.472179] Iteration 63300, train loss = 0.211034, train accuracy = 0.968750\n",
      "[2018-06-01 02:14:03.623179] Iteration 63400, train loss = 0.158077, train accuracy = 1.000000\n",
      "[2018-06-01 02:14:12.758179] Iteration 63500, train loss = 0.175441, train accuracy = 0.984375\n",
      "[2018-06-01 02:14:21.930179] Iteration 63600, train loss = 0.221113, train accuracy = 0.953125\n",
      "[2018-06-01 02:14:31.122179] Iteration 63700, train loss = 0.166811, train accuracy = 0.992188\n",
      "[2018-06-01 02:14:40.208179] Iteration 63800, train loss = 0.177407, train accuracy = 0.992188\n",
      "[2018-06-01 02:14:49.311179] Iteration 63900, train loss = 0.178829, train accuracy = 0.992188\n",
      "[2018-06-01 02:14:58.499179] Iteration 64000, train loss = 0.166231, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.909900\n",
      "[2018-06-01 02:15:09.632179] Iteration 64100, train loss = 0.187163, train accuracy = 0.976562\n",
      "[2018-06-01 02:15:18.789179] Iteration 64200, train loss = 0.179625, train accuracy = 0.984375\n",
      "[2018-06-01 02:15:27.979179] Iteration 64300, train loss = 0.187424, train accuracy = 0.968750\n",
      "[2018-06-01 02:15:37.104179] Iteration 64400, train loss = 0.199577, train accuracy = 0.984375\n",
      "[2018-06-01 02:15:46.297179] Iteration 64500, train loss = 0.189736, train accuracy = 0.976562\n",
      "[2018-06-01 02:15:55.450179] Iteration 64600, train loss = 0.173990, train accuracy = 0.992188\n",
      "[2018-06-01 02:16:04.631179] Iteration 64700, train loss = 0.153576, train accuracy = 1.000000\n",
      "[2018-06-01 02:16:13.810179] Iteration 64800, train loss = 0.147710, train accuracy = 1.000000\n",
      "[2018-06-01 02:16:22.918179] Iteration 64900, train loss = 0.179681, train accuracy = 0.992188\n",
      "[2018-06-01 02:16:32.090179] Iteration 65000, train loss = 0.193791, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 02:16:43.220179] Iteration 65100, train loss = 0.187483, train accuracy = 0.984375\n",
      "[2018-06-01 02:16:52.424179] Iteration 65200, train loss = 0.180363, train accuracy = 0.992188\n",
      "[2018-06-01 02:17:01.557179] Iteration 65300, train loss = 0.181426, train accuracy = 0.992188\n",
      "[2018-06-01 02:17:10.816179] Iteration 65400, train loss = 0.181286, train accuracy = 0.992188\n",
      "[2018-06-01 02:17:19.931179] Iteration 65500, train loss = 0.167884, train accuracy = 0.992188\n",
      "[2018-06-01 02:17:29.098179] Iteration 65600, train loss = 0.170462, train accuracy = 0.992188\n",
      "[2018-06-01 02:17:38.302179] Iteration 65700, train loss = 0.166368, train accuracy = 0.992188\n",
      "[2018-06-01 02:17:47.449179] Iteration 65800, train loss = 0.190859, train accuracy = 0.976562\n",
      "[2018-06-01 02:17:56.567179] Iteration 65900, train loss = 0.168732, train accuracy = 0.992188\n",
      "[2018-06-01 02:18:05.765179] Iteration 66000, train loss = 0.191009, train accuracy = 0.984375\n",
      "Evaluating...\n",
      "Test accuracy = 0.910700\n",
      "[2018-06-01 02:18:16.906179] Iteration 66100, train loss = 0.166636, train accuracy = 0.992188\n",
      "[2018-06-01 02:18:26.015179] Iteration 66200, train loss = 0.166635, train accuracy = 0.984375\n",
      "[2018-06-01 02:18:35.216179] Iteration 66300, train loss = 0.152319, train accuracy = 1.000000\n",
      "[2018-06-01 02:18:44.412179] Iteration 66400, train loss = 0.193743, train accuracy = 0.984375\n",
      "[2018-06-01 02:18:53.539179] Iteration 66500, train loss = 0.168210, train accuracy = 1.000000\n",
      "[2018-06-01 02:19:02.689179] Iteration 66600, train loss = 0.158760, train accuracy = 0.992188\n",
      "[2018-06-01 02:19:11.941179] Iteration 66700, train loss = 0.222035, train accuracy = 0.968750\n",
      "[2018-06-01 02:19:21.129179] Iteration 66800, train loss = 0.163803, train accuracy = 0.992188\n",
      "[2018-06-01 02:19:30.313179] Iteration 66900, train loss = 0.165395, train accuracy = 1.000000\n",
      "[2018-06-01 02:19:39.428179] Iteration 67000, train loss = 0.171071, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.909900\n",
      "[2018-06-01 02:19:50.547179] Iteration 67100, train loss = 0.180176, train accuracy = 0.984375\n",
      "[2018-06-01 02:19:59.654179] Iteration 67200, train loss = 0.186391, train accuracy = 0.992188\n",
      "[2018-06-01 02:20:08.790179] Iteration 67300, train loss = 0.159025, train accuracy = 1.000000\n",
      "[2018-06-01 02:20:17.866179] Iteration 67400, train loss = 0.177850, train accuracy = 0.984375\n",
      "[2018-06-01 02:20:26.992179] Iteration 67500, train loss = 0.168602, train accuracy = 1.000000\n",
      "[2018-06-01 02:20:36.222179] Iteration 67600, train loss = 0.149561, train accuracy = 1.000000\n",
      "[2018-06-01 02:20:45.409179] Iteration 67700, train loss = 0.171746, train accuracy = 0.992188\n",
      "[2018-06-01 02:20:54.620179] Iteration 67800, train loss = 0.157197, train accuracy = 1.000000\n",
      "[2018-06-01 02:21:03.781179] Iteration 67900, train loss = 0.207029, train accuracy = 0.968750\n",
      "[2018-06-01 02:21:12.969179] Iteration 68000, train loss = 0.203524, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 02:21:24.090179] Iteration 68100, train loss = 0.168821, train accuracy = 1.000000\n",
      "[2018-06-01 02:21:33.207179] Iteration 68200, train loss = 0.172930, train accuracy = 0.992188\n",
      "[2018-06-01 02:21:42.350179] Iteration 68300, train loss = 0.167484, train accuracy = 1.000000\n",
      "[2018-06-01 02:21:51.562179] Iteration 68400, train loss = 0.170560, train accuracy = 0.984375\n",
      "[2018-06-01 02:22:00.721179] Iteration 68500, train loss = 0.170348, train accuracy = 0.992188\n",
      "[2018-06-01 02:22:09.916179] Iteration 68600, train loss = 0.194106, train accuracy = 0.968750\n",
      "[2018-06-01 02:22:19.073179] Iteration 68700, train loss = 0.154264, train accuracy = 1.000000\n",
      "[2018-06-01 02:22:28.214179] Iteration 68800, train loss = 0.161526, train accuracy = 0.992188\n",
      "[2018-06-01 02:22:37.411179] Iteration 68900, train loss = 0.164038, train accuracy = 1.000000\n",
      "[2018-06-01 02:22:46.553179] Iteration 69000, train loss = 0.200042, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 02:22:57.745179] Iteration 69100, train loss = 0.150395, train accuracy = 1.000000\n",
      "[2018-06-01 02:23:06.872179] Iteration 69200, train loss = 0.180126, train accuracy = 0.992188\n",
      "[2018-06-01 02:23:16.065179] Iteration 69300, train loss = 0.159156, train accuracy = 0.992188\n",
      "[2018-06-01 02:23:25.237179] Iteration 69400, train loss = 0.191904, train accuracy = 0.984375\n",
      "[2018-06-01 02:23:34.380179] Iteration 69500, train loss = 0.173328, train accuracy = 1.000000\n",
      "[2018-06-01 02:23:43.483179] Iteration 69600, train loss = 0.213647, train accuracy = 0.976562\n",
      "[2018-06-01 02:23:52.664179] Iteration 69700, train loss = 0.156073, train accuracy = 1.000000\n",
      "[2018-06-01 02:24:01.838179] Iteration 69800, train loss = 0.158697, train accuracy = 1.000000\n",
      "[2018-06-01 02:24:11.018179] Iteration 69900, train loss = 0.155354, train accuracy = 1.000000\n",
      "[2018-06-01 02:24:20.150179] Iteration 70000, train loss = 0.153420, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 02:24:31.347179] Iteration 70100, train loss = 0.155515, train accuracy = 0.992188\n",
      "[2018-06-01 02:24:40.499179] Iteration 70200, train loss = 0.162830, train accuracy = 1.000000\n",
      "[2018-06-01 02:24:49.724179] Iteration 70300, train loss = 0.165771, train accuracy = 1.000000\n",
      "[2018-06-01 02:24:58.943179] Iteration 70400, train loss = 0.184845, train accuracy = 0.976562\n",
      "[2018-06-01 02:25:08.104179] Iteration 70500, train loss = 0.187391, train accuracy = 0.984375\n",
      "[2018-06-01 02:25:17.207179] Iteration 70600, train loss = 0.156367, train accuracy = 0.992188\n",
      "[2018-06-01 02:25:26.366179] Iteration 70700, train loss = 0.157169, train accuracy = 1.000000\n",
      "[2018-06-01 02:25:35.560179] Iteration 70800, train loss = 0.158011, train accuracy = 1.000000\n",
      "[2018-06-01 02:25:44.810179] Iteration 70900, train loss = 0.174665, train accuracy = 0.992188\n",
      "[2018-06-01 02:25:54.008179] Iteration 71000, train loss = 0.163722, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910700\n",
      "[2018-06-01 02:26:05.141179] Iteration 71100, train loss = 0.176704, train accuracy = 0.992188\n",
      "[2018-06-01 02:26:14.287179] Iteration 71200, train loss = 0.175846, train accuracy = 0.984375\n",
      "[2018-06-01 02:26:23.429179] Iteration 71300, train loss = 0.181353, train accuracy = 0.992188\n",
      "[2018-06-01 02:26:32.555179] Iteration 71400, train loss = 0.176578, train accuracy = 0.992188\n",
      "[2018-06-01 02:26:41.723179] Iteration 71500, train loss = 0.154788, train accuracy = 1.000000\n",
      "[2018-06-01 02:26:50.927179] Iteration 71600, train loss = 0.167071, train accuracy = 0.984375\n",
      "[2018-06-01 02:27:00.139179] Iteration 71700, train loss = 0.171617, train accuracy = 0.992188\n",
      "[2018-06-01 02:27:09.333179] Iteration 71800, train loss = 0.154592, train accuracy = 0.992188\n",
      "[2018-06-01 02:27:18.466179] Iteration 71900, train loss = 0.163041, train accuracy = 1.000000\n",
      "[2018-06-01 02:27:27.644179] Iteration 72000, train loss = 0.166300, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910300\n",
      "[2018-06-01 02:27:38.809179] Iteration 72100, train loss = 0.168782, train accuracy = 0.992188\n",
      "[2018-06-01 02:27:47.986179] Iteration 72200, train loss = 0.163423, train accuracy = 0.992188\n",
      "[2018-06-01 02:27:57.159179] Iteration 72300, train loss = 0.170102, train accuracy = 0.984375\n",
      "[2018-06-01 02:28:06.356179] Iteration 72400, train loss = 0.177761, train accuracy = 0.992188\n",
      "[2018-06-01 02:28:15.592179] Iteration 72500, train loss = 0.178531, train accuracy = 0.992188\n",
      "[2018-06-01 02:28:24.750179] Iteration 72600, train loss = 0.177889, train accuracy = 0.984375\n",
      "[2018-06-01 02:28:33.909179] Iteration 72700, train loss = 0.178947, train accuracy = 0.992188\n",
      "[2018-06-01 02:28:42.986179] Iteration 72800, train loss = 0.154544, train accuracy = 0.992188\n",
      "[2018-06-01 02:28:52.124179] Iteration 72900, train loss = 0.208326, train accuracy = 0.976562\n",
      "[2018-06-01 02:29:01.253179] Iteration 73000, train loss = 0.167104, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.909700\n",
      "[2018-06-01 02:29:12.347179] Iteration 73100, train loss = 0.159405, train accuracy = 1.000000\n",
      "[2018-06-01 02:29:21.546179] Iteration 73200, train loss = 0.191701, train accuracy = 0.984375\n",
      "[2018-06-01 02:29:30.640179] Iteration 73300, train loss = 0.187858, train accuracy = 0.992188\n",
      "[2018-06-01 02:29:39.857179] Iteration 73400, train loss = 0.206041, train accuracy = 0.984375\n",
      "[2018-06-01 02:29:48.993179] Iteration 73500, train loss = 0.167245, train accuracy = 1.000000\n",
      "[2018-06-01 02:29:58.169179] Iteration 73600, train loss = 0.162453, train accuracy = 0.992188\n",
      "[2018-06-01 02:30:07.338179] Iteration 73700, train loss = 0.191369, train accuracy = 0.984375\n",
      "[2018-06-01 02:30:16.528179] Iteration 73800, train loss = 0.179133, train accuracy = 0.992188\n",
      "[2018-06-01 02:30:25.714179] Iteration 73900, train loss = 0.175028, train accuracy = 0.992188\n",
      "[2018-06-01 02:30:34.861179] Iteration 74000, train loss = 0.176109, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 02:30:46.079179] Iteration 74100, train loss = 0.175789, train accuracy = 0.992188\n",
      "[2018-06-01 02:30:55.277179] Iteration 74200, train loss = 0.207349, train accuracy = 0.976562\n",
      "[2018-06-01 02:31:04.526179] Iteration 74300, train loss = 0.172170, train accuracy = 0.984375\n",
      "[2018-06-01 02:31:13.704179] Iteration 74400, train loss = 0.191329, train accuracy = 0.976562\n",
      "[2018-06-01 02:31:22.848179] Iteration 74500, train loss = 0.193980, train accuracy = 0.992188\n",
      "[2018-06-01 02:31:32.038179] Iteration 74600, train loss = 0.168060, train accuracy = 0.992188\n",
      "[2018-06-01 02:31:41.280179] Iteration 74700, train loss = 0.171687, train accuracy = 0.992188\n",
      "[2018-06-01 02:31:50.387179] Iteration 74800, train loss = 0.189796, train accuracy = 0.984375\n",
      "[2018-06-01 02:31:59.515179] Iteration 74900, train loss = 0.171281, train accuracy = 0.984375\n",
      "[2018-06-01 02:32:08.658179] Iteration 75000, train loss = 0.155753, train accuracy = 1.000000\n",
      "Evaluating...\n",
      "Test accuracy = 0.910400\n",
      "[2018-06-01 02:32:19.776179] Iteration 75100, train loss = 0.155663, train accuracy = 1.000000\n",
      "[2018-06-01 02:32:28.997179] Iteration 75200, train loss = 0.167641, train accuracy = 0.992188\n",
      "[2018-06-01 02:32:38.189179] Iteration 75300, train loss = 0.227088, train accuracy = 0.953125\n",
      "[2018-06-01 02:32:47.367179] Iteration 75400, train loss = 0.153146, train accuracy = 1.000000\n",
      "[2018-06-01 02:32:56.492179] Iteration 75500, train loss = 0.191916, train accuracy = 0.984375\n",
      "[2018-06-01 02:33:05.684179] Iteration 75600, train loss = 0.205378, train accuracy = 0.984375\n",
      "[2018-06-01 02:33:14.788179] Iteration 75700, train loss = 0.156157, train accuracy = 1.000000\n",
      "[2018-06-01 02:33:23.938179] Iteration 75800, train loss = 0.155636, train accuracy = 1.000000\n",
      "[2018-06-01 02:33:33.099179] Iteration 75900, train loss = 0.182600, train accuracy = 0.984375\n",
      "[2018-06-01 02:33:42.232179] Iteration 76000, train loss = 0.191963, train accuracy = 0.976562\n",
      "Evaluating...\n",
      "Test accuracy = 0.911100\n",
      "[2018-06-01 02:33:53.460179] Iteration 76100, train loss = 0.193029, train accuracy = 0.984375\n",
      "[2018-06-01 02:34:02.656179] Iteration 76200, train loss = 0.153114, train accuracy = 1.000000\n",
      "[2018-06-01 02:34:11.743179] Iteration 76300, train loss = 0.161468, train accuracy = 1.000000\n",
      "[2018-06-01 02:34:20.884179] Iteration 76400, train loss = 0.173522, train accuracy = 0.992188\n",
      "[2018-06-01 02:34:30.179179] Iteration 76500, train loss = 0.170607, train accuracy = 0.992188\n",
      "[2018-06-01 02:34:39.268179] Iteration 76600, train loss = 0.171644, train accuracy = 0.984375\n",
      "[2018-06-01 02:34:48.425179] Iteration 76700, train loss = 0.161888, train accuracy = 0.992188\n",
      "[2018-06-01 02:34:57.577179] Iteration 76800, train loss = 0.181011, train accuracy = 0.992188\n",
      "[2018-06-01 02:35:06.742179] Iteration 76900, train loss = 0.152468, train accuracy = 1.000000\n",
      "[2018-06-01 02:35:15.907179] Iteration 77000, train loss = 0.235506, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.910600\n",
      "[2018-06-01 02:35:27.033179] Iteration 77100, train loss = 0.157659, train accuracy = 1.000000\n",
      "[2018-06-01 02:35:36.200179] Iteration 77200, train loss = 0.172767, train accuracy = 0.992188\n",
      "[2018-06-01 02:35:45.362179] Iteration 77300, train loss = 0.212903, train accuracy = 0.976562\n",
      "[2018-06-01 02:35:54.577179] Iteration 77400, train loss = 0.174387, train accuracy = 0.992188\n",
      "[2018-06-01 02:36:03.682179] Iteration 77500, train loss = 0.161513, train accuracy = 1.000000\n",
      "[2018-06-01 02:36:12.821179] Iteration 77600, train loss = 0.213466, train accuracy = 0.976562\n",
      "[2018-06-01 02:36:21.922179] Iteration 77700, train loss = 0.158205, train accuracy = 1.000000\n",
      "[2018-06-01 02:36:31.080179] Iteration 77800, train loss = 0.186437, train accuracy = 0.976562\n",
      "[2018-06-01 02:36:40.242179] Iteration 77900, train loss = 0.165152, train accuracy = 0.992188\n",
      "[2018-06-01 02:36:49.437179] Iteration 78000, train loss = 0.170153, train accuracy = 0.992188\n",
      "Evaluating...\n",
      "Test accuracy = 0.910000\n",
      "[2018-06-01 02:37:00.540179] Iteration 78100, train loss = 0.207673, train accuracy = 0.968750\n",
      "[2018-06-01 02:37:09.699179] Iteration 78200, train loss = 0.167941, train accuracy = 0.992188\n",
      "[2018-06-01 02:37:18.916179] Iteration 78300, train loss = 0.188849, train accuracy = 0.976562\n",
      "[2018-06-01 02:37:28.117179] Iteration 78400, train loss = 0.189096, train accuracy = 0.984375\n",
      "[2018-06-01 02:37:37.294179] Iteration 78500, train loss = 0.168118, train accuracy = 0.992188\n",
      "[2018-06-01 02:37:46.396179] Iteration 78600, train loss = 0.163552, train accuracy = 0.992188\n",
      "[2018-06-01 02:37:55.567179] Iteration 78700, train loss = 0.193389, train accuracy = 0.984375\n",
      "[2018-06-01 02:38:04.724179] Iteration 78800, train loss = 0.169914, train accuracy = 0.992188\n",
      "[2018-06-01 02:38:13.859179] Iteration 78900, train loss = 0.166347, train accuracy = 0.992188\n",
      "[2018-06-01 02:38:22.980179] Iteration 79000, train loss = 0.199950, train accuracy = 0.968750\n",
      "Evaluating...\n",
      "Test accuracy = 0.910200\n",
      "[2018-06-01 02:38:34.116179] Iteration 79100, train loss = 0.184934, train accuracy = 0.992188\n",
      "[2018-06-01 02:38:43.289179] Iteration 79200, train loss = 0.184193, train accuracy = 0.992188\n",
      "[2018-06-01 02:38:52.485179] Iteration 79300, train loss = 0.173480, train accuracy = 1.000000\n",
      "[2018-06-01 02:39:01.678179] Iteration 79400, train loss = 0.157514, train accuracy = 1.000000\n",
      "[2018-06-01 02:39:10.805179] Iteration 79500, train loss = 0.155119, train accuracy = 1.000000\n",
      "[2018-06-01 02:39:19.978179] Iteration 79600, train loss = 0.160759, train accuracy = 0.992188\n",
      "[2018-06-01 02:39:29.016179] Iteration 79700, train loss = 0.148380, train accuracy = 1.000000\n",
      "[2018-06-01 02:39:38.174179] Iteration 79800, train loss = 0.160431, train accuracy = 1.000000\n",
      "[2018-06-01 02:39:47.255179] Iteration 79900, train loss = 0.181921, train accuracy = 0.992188\n"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.max_steps):\n",
    "  if step <= 48000:\n",
    "    _lr = 1e-2\n",
    "  else:\n",
    "    _lr = 1e-3\n",
    "  if curr_lr != _lr:\n",
    "    curr_lr = _lr\n",
    "    print('Learning rate set to %f' % curr_lr)\n",
    "\n",
    "  # train\n",
    "  fetches = [train_step, loss]\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    fetches += [accuracy]\n",
    "  sess_outputs = sess.run(fetches, {phase_train.name: True, learning_rate.name: curr_lr})\n",
    "\n",
    "\n",
    "  if step > 0 and step % FLAGS.summary_interval == 0:\n",
    "    train_loss_value, train_acc_value= sess_outputs[1:]\n",
    "    print('[%s] Iteration %d, train loss = %f, train accuracy = %f' %\n",
    "        (datetime.now(), step, train_loss_value, train_acc_value))\n",
    "\n",
    "  # validation\n",
    "  if step > 0 and step % FLAGS.val_interval == 0:\n",
    "    print('Evaluating...')\n",
    "    n_val_samples = 10000\n",
    "    val_batch_size = FLAGS.val_batch_size\n",
    "    n_val_batch = int(n_val_samples / val_batch_size)\n",
    "    val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "    val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "    val_losses = []\n",
    "    for i in range(n_val_batch):\n",
    "      fetches = [logits, label_batch, loss]\n",
    "      session_outputs = sess.run(\n",
    "        fetches, {phase_train.name: False})\n",
    "      val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "      val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "      val_losses.append(session_outputs[2])\n",
    "    pred_labels = np.argmax(val_logits, axis=1)\n",
    "    val_accuracy = np.count_nonzero(\n",
    "      pred_labels == val_labels) / n_val_samples\n",
    "    val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "    print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune后的准确率\n",
      "Test accuracy = 0.910100\n"
     ]
    }
   ],
   "source": [
    "print('prune后的准确率')\n",
    "n_val_samples = 10000\n",
    "val_batch_size = FLAGS.val_batch_size\n",
    "n_val_batch = int(n_val_samples / val_batch_size)\n",
    "val_logits = np.zeros((n_val_samples, 10), dtype=np.float32)\n",
    "val_labels = np.zeros((n_val_samples), dtype=np.int64)\n",
    "val_losses = []\n",
    "for i in range(n_val_batch):\n",
    "    fetches = [logits, label_batch, loss]\n",
    "    session_outputs = sess.run(fetches, {phase_train.name: False})\n",
    "    val_logits[i*val_batch_size:(i+1)*val_batch_size, :] = session_outputs[0]\n",
    "    val_labels[i*val_batch_size:(i+1)*val_batch_size] = session_outputs[1]\n",
    "val_losses.append(session_outputs[2])\n",
    "pred_labels = np.argmax(val_logits, axis=1)\n",
    "val_accuracy = np.count_nonzero(pred_labels == val_labels) / n_val_samples\n",
    "val_loss = float(np.mean(np.asarray(val_losses)))\n",
    "print('Test accuracy = %f' % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0\n",
      "[ 0.0625   -0.0625    0.015625  0.125     0.0625   -0.03125   0.       -0.0625\n",
      "  0.03125  -0.125   ]\n"
     ]
    }
   ],
   "source": [
    "print('prune_rate =1.00时，可视化部分参数：res_net/conv_last/bias:0')\n",
    "print(sess.run(tf.get_collection('last_biases')[0]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
